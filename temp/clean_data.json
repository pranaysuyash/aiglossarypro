{
  "categories": [
    {
      "id": "cbe8a329-1cea-4241-b3a7-b6a4e1c342b4",
      "name": "Introduction"
    },
    {
      "id": "1f040ace-1de8-4478-99d5-4bba03d281a3",
      "name": "Prerequisites"
    },
    {
      "id": "88d10e8f-59a4-4024-b73f-af9ac7363677",
      "name": "Theoretical Concepts"
    },
    {
      "id": "7a86cc45-2dee-4cf8-baa7-94675e0d15f6",
      "name": "How It Works"
    },
    {
      "id": "7ff442a6-56bb-4251-8779-19b0bf00f40a",
      "name": "Variants or Extensions"
    },
    {
      "id": "00a669b6-faca-49f8-a044-afe287e1b8ae",
      "name": "Applications"
    },
    {
      "id": "f49af14c-52d4-429e-a87e-fab8a864fced",
      "name": "Implementation"
    },
    {
      "id": "e7b68c41-b380-4564-8bdd-364915d55508",
      "name": "Evaluation and Metrics"
    },
    {
      "id": "6b41e672-f43d-4899-a01d-3a5efc817dcd",
      "name": "Advantages and Disadvantages"
    },
    {
      "id": "8a29457e-972a-400f-9ae0-23e9ac9986ce",
      "name": "Ethics and Responsible AI"
    },
    {
      "id": "a59574a4-97fc-4ab8-9db1-ebf70d5899da",
      "name": "Historical Context"
    },
    {
      "id": "189be6a1-21bc-47d9-9dd5-c6f2744e9c74",
      "name": "Illustration or Diagram"
    },
    {
      "id": "b1125811-ee9c-4fdc-a655-033c9ce4496a",
      "name": "Related Concepts"
    },
    {
      "id": "cd6808c5-f907-4f4c-9793-37fdb00629d8",
      "name": "Case Studies"
    },
    {
      "id": "ea805204-8113-483e-a1e8-560cd745881a",
      "name": "Interviews with Experts"
    },
    {
      "id": "d270ed4b-b8ab-468a-9079-4afaa6758499",
      "name": "Hands-on Tutorials"
    },
    {
      "id": "690df4a4-49e9-4a9f-b86c-77def3890da2",
      "name": "Interactive Elements"
    },
    {
      "id": "6da585a6-5ebd-428c-9710-5f9fd7210662",
      "name": "Industry Insights"
    },
    {
      "id": "57730464-1937-4a3b-a113-96a870a61492",
      "name": "Common Challenges and Pitfalls"
    },
    {
      "id": "8e3431cd-a6d3-4f62-89d8-1053bec1866f",
      "name": "Real-world Datasets and Benchmarks"
    },
    {
      "id": "d6ab448a-c040-4b1c-8e05-45d2d6e35590",
      "name": "Tools and Frameworks"
    },
    {
      "id": "4c2ce4c2-ca66-4f91-8eef-742bca9327dd",
      "name": "Did You Know?"
    },
    {
      "id": "4d512327-cd99-4656-b13e-836cec6a1d79",
      "name": "Quick Quiz"
    },
    {
      "id": "b280a4e7-7ed6-4fa3-b76e-f344a9cfb1be",
      "name": "Further Reading"
    },
    {
      "id": "66338c82-fdfe-4cb7-a1e1-9dc067242254",
      "name": "Project Suggestions"
    },
    {
      "id": "7b9ae68c-0604-4f69-951a-cca2f79606b5",
      "name": "Recommended Websites and Courses"
    },
    {
      "id": "912160af-3480-473c-b8bf-ef9245a5a05e",
      "name": "Collaboration and Community"
    },
    {
      "id": "57aeca25-517f-47d4-958b-4d9c61376e40",
      "name": "Research Papers"
    },
    {
      "id": "4297fbc1-3b75-4e45-9f54-64c6e42e3080",
      "name": "Career Guidance"
    },
    {
      "id": "79f12979-7077-4778-a1c4-678a3f32c933",
      "name": "Future Directions"
    },
    {
      "id": "e2d47876-82c6-4eb5-8b9d-f3b21a41da49",
      "name": "Glossary"
    },
    {
      "id": "adb85807-4cca-46cc-b1ab-6585de9f690a",
      "name": "FAQs"
    },
    {
      "id": "5f5a20a5-3845-499d-9f84-2c3a39a57dfe",
      "name": "Tags and Keywords"
    },
    {
      "id": "614b70da-55ce-4f3c-bd58-095bee26ac7f",
      "name": "Appendices"
    },
    {
      "id": "890ef9d7-66bb-4301-b98c-e6a5ca6d2309",
      "name": "Index"
    },
    {
      "id": "46852e32-44cb-44f3-9e78-7c3e12b0a386",
      "name": "References"
    },
    {
      "id": "5f10f322-d014-49bd-bf22-92d9a05ba448",
      "name": "Conclusion"
    },
    {
      "id": "3785f776-2a54-4b4c-87d4-a6111fae2b6d",
      "name": "Metadata"
    },
    {
      "id": "ac34bb87-e597-44e8-b56b-89ab3d8b2eb9",
      "name": "Best Practices"
    },
    {
      "id": "91867644-fd93-42bb-9beb-9dffc35db062",
      "name": "Security Considerations"
    },
    {
      "id": "af37039e-368b-45e3-8f9e-d445ee07a63c",
      "name": "Optimization Techniques"
    },
    {
      "id": "1b926b90-8e6c-44b7-8491-1f19e9560685",
      "name": "Comparison with Alternatives"
    },
    {
      "id": "24430edb-10c0-43cb-9b75-8fdbdc45840a",
      "name": "Probability Theory, Mathematical Functions, Fourier Analysis, Random Variables, Distribution Characterization, Limit Theorems, Statistical Inference, Signal Processing"
    },
    {
      "id": "d62019f9-c4a2-4dac-bf32-19c7b17d3511",
      "name": "distance metrics, Chebyshev Distance, L\u221e norm, maximum metric, ML algorithms, data analysis, spatial measurement, vector distance, pathfinding, clustering, similarity measures"
    },
    {
      "id": "84f64004-4381-4e35-8046-d42c8bfffdd6",
      "name": "Neural Networks, Polynomial Approximation, Chebyshev Polynomials, Spectral Methods, Numerical Analysis, Function Approximation, Orthogonal Polynomials, Machine Learning Architectures, Spectral Neural Networks, Numerical Methods in AI"
    },
    {
      "id": "8c0e1c2e-eb30-460a-97b2-0797d71996cd",
      "name": "Neural Networks, Polynomial Approximation, Spectral Methods, Chebyshev Polynomials, Machine Learning, Numerical Analysis, Function Approximation, Orthogonal Polynomials, Scientific Computing, Spectral Neural Networks"
    },
    {
      "id": "3f71e9b9-bb0b-4036-87eb-bc44b0c3c5da",
      "name": "Machine Learning, Deep Learning, Neural Networks, Approximation Theory, Spectral Methods"
    },
    {
      "id": "9492d189-a19a-49cc-a1e6-46cc2e992fbd",
      "name": "Machine Learning"
    },
    {
      "id": "318494f6-733c-4be8-85a2-d4be1f934dff",
      "name": "Deep Learning, Neural Networks, Generative Models, GANs, Image Processing, Upsampling Techniques, Convolutional Layers, Image Artifacts, Computer Vision, AI Image Generation"
    },
    {
      "id": "d4762a61-7adc-436f-873e-25c13a01da66",
      "name": "Machine Learning, Neural Networks, Model Optimization, Checkpoint Averaging, Model Ensembling, Training Techniques, Regularization, Deep Learning, Model Checkpointing"
    },
    {
      "id": "8deff07a-6590-4a5a-9069-4b995d98f743",
      "name": "machine learning"
    },
    {
      "id": "dd8ebb43-0c92-420a-baaa-a4cc713818d2",
      "name": "Artificial Intelligence, Machine Learning, Cheminformatics, Computational Chemistry, Chemical Data Analysis, Molecular Modeling, Data Science in Chemistry, Drug Discovery, Chemical Informatics Tools, Data Mining in Chemistry"
    },
    {
      "id": "e4b7a0a6-4954-42e8-8fd8-f3a8835c53fe",
      "name": "Statistics, Hypothesis Testing, Categorical Data Analysis, Statistical Tests, Data Science, Machine Learning, Data Analysis, Chi-Square Test"
    },
    {
      "id": "4a584d60-b7fc-408a-953d-1145285d0408",
      "name": "Statistics, Hypothesis Testing, Categorical Data Analysis, Chi-Square Test, Contingency Tables, Goodness-of-Fit, Statistical Inference, Data Science, Machine Learning, Data Analysis"
    },
    {
      "id": "735a2dd8-6fc3-4bd6-a899-852cbdf23c99",
      "name": "Linear Algebra, Matrix Decomposition, Numerical Methods, Machine Learning, Statistical Computing, Optimization, Covariance Matrices, Probabilistic Models, Scientific Computing"
    },
    {
      "id": "7e9c0771-3e57-4601-8772-4357a34d7bba",
      "name": "Matrix Factorization, Numerical Linear Algebra, Optimization Algorithms, Machine Learning, Quadratic Programming, Linear Systems, Computational Mathematics"
    },
    {
      "id": "48eee011-823f-46be-8f3b-9feca7df5778",
      "name": "Computer Vision, Image Processing, Digital Photography, Lens Optics, Optical Aberrations, Color Correction, Post-Processing Algorithms, Machine Learning in Imaging, Photography Software, Visual Quality Improvement"
    },
    {
      "id": "e7ce8e8b-1e14-485b-95f2-8fffc742834b",
      "name": "Graph Theory, Network Science, Random Graph Models, Complex Networks, Scale-Free Networks, Degree Distribution, Probabilistic Models, Network Modeling, Chung\u2013Lu Model, Graph Algorithms"
    },
    {
      "id": "b40e6a87-616a-4670-a592-0f497a51851d",
      "name": "Machine Learning, Data Preprocessing, Natural Language Processing, Sequence Modeling, Data Segmentation, Hierarchical Structures, Data Management, NLP Techniques, Data Chunking, AI Data Handling"
    },
    {
      "id": "dbd57fe6-631d-48dd-ada6-5e05c05ed81b",
      "name": "Natural Language Processing (NLP), Text Processing, Machine Learning, Artificial Intelligence, Language Modeling"
    },
    {
      "id": "48cf7045-f678-452c-af24-2af663372278",
      "name": "AI/ML, Evaluation Metrics, Image Captioning, CIDEr Score, Natural Language Processing, Computer Vision, Machine Learning, Deep Learning, Caption Generation, Model Assessment"
    },
    {
      "id": "786a9a94-7a56-4185-a591-b22a21025404",
      "name": "machine learning, computer vision, image classification, datasets, CIFAR-10, neural networks, deep learning, image datasets, pattern recognition, AI datasets"
    },
    {
      "id": "5032c5e9-c216-4409-b331-6956f5df4c8f",
      "name": "computer vision, image classification, deep learning, datasets, convolutional neural networks, transfer learning, machine learning education, AI datasets, pattern recognition"
    },
    {
      "id": "8a32ca49-a730-42ed-9b0e-ff477cbaedb0",
      "name": "Machine Learning, Incremental Learning, Continual Learning, Classification, Artificial Intelligence, Model Adaptation, Online Learning, Lifelong Learning, Neural Networks, Data Streams"
    },
    {
      "id": "2ee5dd7e-b360-4cd3-a7c5-64294a8eedd6",
      "name": "Electrical Engineering, Circuit Analysis, Electrical Circuits, Network Theorems, Ohm's Law, Kirchhoff's Laws, AC/DC Circuits, Electrical Principles, Circuit Theorems, Electronic Design"
    },
    {
      "id": "93554169-5d1b-40f0-8055-a66f5ccab707",
      "name": "Computational Complexity, Circuit Complexity, Boolean Circuits, Digital Circuit Design, Computational Theory, Complexity Classes, Hardware Optimization, Theoretical Computer Science, Algorithm Efficiency, Lower Bounds"
    },
    {
      "id": "a36dd3a1-7144-4917-a772-4719bfaba07b",
      "name": "Circuit analysis, semiconductor devices, transistor modeling, VLSI design, electronics fundamentals, circuit simulation, SPICE, device physics, integrated circuits, electrical engineering"
    },
    {
      "id": "39be3d34-0ca3-4a3e-9043-67f635a219ad",
      "name": "Signal Processing, Digital Signal Processing, Convolution, Circular Convolution, Fourier Transform, FFT, Discrete-Time Signals, MATLAB, Python, Signal Analysis"
    },
    {
      "id": "0dfcee6a-536d-4ef4-a0de-559d865483b1",
      "name": "Convolutional Neural Networks, Padding Techniques, Circular Padding, Data Preprocessing, Periodic Data, Image Processing, Signal Analysis, Deep Learning Fundamentals, Neural Network Architecture, Edge Effects"
    },
    {
      "id": "8736cab5-b049-49ba-8ecb-d6adf52db283",
      "name": "Convolutional Neural Networks, CNN, Padding Techniques, Circular Padding, Periodic Data Processing, Deep Learning, Neural Network Architecture, Signal Processing, Data Continuity, Machine Learning, AI"
    },
    {
      "id": "770275c8-501e-43f4-9122-a75655ed7702",
      "name": "Machine Learning, Deep Learning, Explainability, Model Interpretability, Visualization, CNN, Convolutional Neural Networks, CAM, Grad-CAM, Score-CAM, Neural Network Explanations, AI Transparency"
    },
    {
      "id": "e0e205da-d6bb-4974-a029-a7874bb8fbb9",
      "name": "machine learning, computer vision, deep learning, CNN, interpretability, visualization, image classification, model explanation"
    },
    {
      "id": "0908d6eb-5bba-4add-bb6e-b82240de00c4",
      "name": "Machine Learning, Data Imbalance, Classification, Data Preprocessing, Resampling Techniques, SMOTE, Model Bias, Model Evaluation, Data Science, AI Challenges"
    },
    {
      "id": "64b1cb6c-0424-4d85-9ddb-cfaa727c482e",
      "name": "Machine Learning, Class Imbalance, Class Weighting, Data Preprocessing, Model Optimization, Supervised Learning, Imbalanced Dataset Handling, Sklearn, TensorFlow, Model Tuning"
    },
    {
      "id": "16a15cef-10ad-4515-8117-d55207019792",
      "name": "Machine Learning, Loss Functions, Class Imbalance, Data Imbalance, Classification, Model Optimization, Deep Learning, Cost-sensitive Learning, Imbalanced Datasets, Model Training Techniques"
    },
    {
      "id": "cf218244-1683-4c33-a1a1-d49146732ac2",
      "name": "Machine Learning, Data Preprocessing, Data Sampling, Class Imbalance, Imbalanced Datasets, Sampling Techniques, Data Augmentation, Model Training Strategies, AI Data Handling"
    },
    {
      "id": "eb5dbbce-e8ae-43b2-8571-74697de70585",
      "name": "Machine Learning, Loss Functions, Class Imbalance, Class-weighted Loss, Cost-sensitive Learning, Imbalanced Data, Model Optimization, Classification, Data Augmentation, Model Training Techniques"
    },
    {
      "id": "4cd7a78e-22b9-4a6f-92c8-fec5215dd5ca",
      "name": "Machine Learning, Classification, Supervised Learning, Data Science, Pattern Recognition, AI Algorithms, Data Classification, Predictive Modeling, Machine Learning Algorithms, Model Evaluation"
    },
    {
      "id": "4e43c1a3-acc6-4d34-b276-32b8da3cb08e",
      "name": "Machine Learning, Decision Trees, Classification, Regression, CART, Supervised Learning, Data Mining, Predictive Modeling, Data Science, Ensemble Methods"
    },
    {
      "id": "79ba7f32-fdd2-44b9-bd97-b00865bb917f",
      "name": "Machine Learning, Classification, Model Evaluation, Performance Metrics, Data Science, Supervised Learning, Model Validation, ROC Curve, Precision, Recall, F1-Score, Confusion Matrix"
    },
    {
      "id": "6a5b4220-758f-46c3-903d-a19f8c1fca15",
      "name": "Supervised Learning, Machine Learning, Classification, Data Science, Pattern Recognition, AI, Model Training, Algorithms, Data Classification, Predictive Modeling"
    },
    {
      "id": "cb6a0d23-dd1e-4a42-aeb4-4e0cd863dc82",
      "name": "machine learning, classification, model evaluation, metrics, sklearn, classification report, precision, recall, F1-score, support, supervised learning, model assessment, performance metrics"
    },
    {
      "id": "e1f090cb-48c8-45b1-aedf-b83a8fd93f54",
      "name": "Multi-Label Classification, Machine Learning, Classifier Chains, Dependency Modeling, Multi-Output Models, Ensemble Methods, Supervised Learning, AI, Data Science"
    },
    {
      "id": "d933572d-ce55-41ce-8049-2f630032e5b1",
      "name": "Generative Models, Diffusion Models, Machine Learning, AI Art Generation, Neural Networks, Model Guidance Techniques, AI Creativity, Unsupervised Learning, AI Sampling Methods, Deep Learning"
    },
    {
      "id": "735e4475-77a8-44e0-93d6-73b5d712a5e5",
      "name": "AI Security, Sentiment Analysis, Claude Model, Machine Learning Security, NLP Security, Adversarial Attacks, AI Ethics, Data Privacy, Model Robustness, AI Safety"
    },
    {
      "id": "842a056b-d568-4c6a-b997-7e3878be579b",
      "name": "AI, Machine Learning, Thermodynamics, Clausius-Clapeyron Relation, Phase Transitions, Materials Science, Thermal Modeling, Data Analysis, AI in Physics, Educational Resources"
    },
    {
      "id": "3efc32f9-535b-46af-b5db-48762ecfb4e1",
      "name": "Artificial Intelligence, Machine Learning, MLOps, Experiment Tracking, Model Management, Data Science Tools, Automation, AI Infrastructure, Open-Source, Workflow Orchestration"
    },
    {
      "id": "338ee975-7f21-4bc9-a2c0-cd6f6e575fb6",
      "name": "Artificial Intelligence, Machine Learning, Vision-Language Models, Multimodal AI, Contrastive Learning, Neural Networks, Embedding Spaces, Zero-Shot Classification, OpenAI, Deep Learning, Computer Vision, Natural Language Processing"
    },
    {
      "id": "29861353-f354-406d-b64b-c1255eb0bc79",
      "name": "AI"
    },
    {
      "id": "4e19ff42-f774-4f1a-aae9-ee741a2f033f",
      "name": "Machine Learning, Neural Networks, Optimization, Gradient Descent, Gradient Clipping, Training Stability, Deep Learning Techniques, Regularization"
    },
    {
      "id": "132f71da-5411-4af4-8707-39e1d829d524",
      "name": "Machine Learning, Deep Learning, Neural Networks, Optimization Techniques, Gradient Descent, Model Training, Regularization, Exploding Gradients, Gradient Clipping, AI Training Methods"
    },
    {
      "id": "31e5e921-c0ea-446c-b277-d0e5087f429e",
      "name": "Machine Learning, Neural Networks, Optimization Techniques, Gradient Clipping, Deep Learning, Training Stability, Exploding Gradients, Model Regularization, AI Training Strategies"
    },
    {
      "id": "7851dab6-0159-4632-b1a8-2727b621239e",
      "name": "Machine Learning, Deep Learning, Neural Networks, Optimization Techniques, Gradient Clipping, Training Stability, Recurrent Neural Networks, Exploding Gradients, Gradient Norms, Model Regularization"
    },
    {
      "id": "08a9ddbc-4d8c-4169-b290-ed00d67cac62",
      "name": "Machine Learning, Optimization, Gradient Descent, Regularization, Neural Networks, Training Stability, Gradient Clipping, Deep Learning, Model Regularization Techniques, Training Optimization"
    },
    {
      "id": "f37bc20e-3988-4a7a-8f7e-67706018b22a",
      "name": "Graph Theory, Network Analysis, Community Detection, Social Networks, Clusters, Data Science, Graph Algorithms, Machine Learning, Network Structures, Clique Detection"
    },
    {
      "id": "c3149487-ed2e-48a6-bd04-df8f2b3fbe43",
      "name": "Data Mining, Pattern Mining, Frequent Itemsets, Closed Itemsets, Association Rules, Market Basket Analysis, Machine Learning, Pattern Recognition, Data Analytics, Knowledge Discovery"
    },
    {
      "id": "84112320-ad22-42f2-9735-c85511c0f915",
      "name": "Graph Theory, Network Analysis, Centrality Measures, Social Network Analysis, Data Science, Network Metrics, Machine Learning, Data Visualization"
    },
    {
      "id": "59376e95-8def-47a5-9da6-5a794a7efff1",
      "name": "Time-series Analysis, Clustering, Machine Learning, Data Mining, Unsupervised Learning, Pattern Recognition"
    },
    {
      "id": "5a4142a9-9691-40a0-9063-8f11bd0a5d29",
      "name": "Semi-supervised learning, Clustering, Unsupervised learning, Data segmentation, Machine learning assumptions, Data clustering algorithms, Decision boundaries, Data visualization"
    },
    {
      "id": "20a457f0-417c-4066-ac64-615d61e8be8f",
      "name": "Clustering, Evaluation Metrics, Machine Learning, Data Science, Unsupervised Learning, Cluster Purity, Data Analysis, Clustering Validation, Classification"
    },
    {
      "id": "ff6dd850-f324-4a1a-ab5f-4fa6b16af311",
      "name": "Statistics, Data Collection, Sampling Methods, Cluster Sampling, Data Science, Survey Design, Data Analysis, Research Methods, Probability Theory"
    },
    {
      "id": "5ba93cee-718b-45bb-b10d-3485d6fdfaa5",
      "name": "Machine Learning, Unsupervised Learning, Clustering, Data Analysis, Data Mining, Pattern Recognition, Data Segmentation, K-Means, Hierarchical Clustering, Density-Based Clustering, Model Evaluation, Data Science"
    },
    {
      "id": "7bca72b2-ccb3-4792-9a4b-a3e0b5c70f0e",
      "name": "Machine Learning, Unsupervised Learning, Clustering Algorithms, Data Mining, Data Clustering, K-Means, Hierarchical Clustering, Density-Based Clustering, Data Segmentation, Pattern Recognition"
    },
    {
      "id": "5394ac47-fef5-4f9f-b0da-0b99ae41111c",
      "name": "Machine Learning, Unsupervised Learning, Clustering Algorithms, K-means, Hierarchical Clustering, Data Science, Pattern Recognition, Data Mining"
    },
    {
      "id": "a975a25a-a3a5-4596-99a9-862442cccce1",
      "name": "Machine Learning, Clustering, Model Evaluation, Unsupervised Learning, Data Science"
    },
    {
      "id": "44cfac13-dfd8-4ca6-ad99-b41ec0e161f5",
      "name": "Clustering, Unsupervised Learning, Data Mining, Clustering Validation, Stability Analysis, Machine Learning, Data Science, Pattern Recognition, Algorithm Robustness, Consensus Clustering"
    },
    {
      "id": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7",
      "name": "Artificial Intelligence"
    },
    {
      "id": "6c0a135e-5723-414c-8eca-4553332e06a6",
      "name": "Artificial Intelligence, Machine Learning, Affective Computing, Emotion Recognition, Sentiment Analysis, Multimodal Data, Human-Computer Interaction, Behavioral Computing, Emotional Intelligence, Neural Networks"
    },
    {
      "id": "b5f3852a-42f1-409f-8c33-3ebf90322065",
      "name": "Artificial Intelligence, Machine Learning, Emotion Recognition, Affective Computing, Human-Computer Interaction, Sentiment Analysis, Behavioral Analytics, Emotional AI, Computer Vision, Speech Processing, Physiological Signal Analysis"
    },
    {
      "id": "16001270-4117-4055-bac1-24aa99217acc",
      "name": "Artificial Intelligence, Machine Learning, Affective Computing, Human-Computer Interaction, Emotional Intelligence in AI"
    },
    {
      "id": "15b2cdf2-e2a1-427f-acea-cfab1ae3ee2a",
      "name": "Natural Language Processing, Affective Computing, Sentiment Analysis, Emotional AI, Human-Computer Interaction, Machine Learning, Deep Learning, Language Models, AI Ethics"
    },
    {
      "id": "5f9e90a7-6ff5-4684-ac26-6214dad5d2f8",
      "name": "Artificial Intelligence, Machine Learning, Affective Computing, Human-Computer Interaction, AI Technologies"
    },
    {
      "id": "3b965a30-30b0-4ffd-9f6e-2db43fd41dd7",
      "name": "artificial intelligence, emotional intelligence, affective computing, human-computer interaction, machine learning, emotion recognition, AI ethics, user experience, natural language processing, psychology of emotions"
    },
    {
      "id": "c6abdafa-cc24-471f-92fc-852c8a5955a3",
      "name": "Bayesian Regression, Empirical Bayes, Hierarchical Models, Statistical Learning, Data-Driven Priors, Regularization Techniques, High-Dimensional Data, Machine Learning, Probabilistic Modeling, Bayesian Inference"
    },
    {
      "id": "c8e0b57e-b1ec-4230-96a2-c87039468c58",
      "name": "Probability, Empirical Probability, Data Analysis, Statistics, Data Science, Machine Learning, Data-Driven Decision Making, Statistical Estimation, Probabilistic Models"
    },
    {
      "id": "0cc93a0f-09d5-48af-a538-f2cdc749c5ba",
      "name": "AI, Machine Learning, Empowerment, Reinforcement Learning, Human-AI Interaction, Autonomous Systems, Ethical AI, AI Systems, Data-Driven Decision Making, AI Education"
    },
    {
      "id": "36ac7ae2-674b-4f49-ab52-5044c7cf59ce",
      "name": "Machine Learning, Deep Learning, Neural Networks, Autoencoders, Sequence Modeling, Natural Language Processing, Transformers, Embeddings, Data Compression, AI Architectures, Representation Learning, Encoder-Decoder Models"
    },
    {
      "id": "7acda575-f117-43da-a398-ae116ac3b8be",
      "name": "Machine Learning, Deep Learning, Neural Networks, Attention Mechanisms, Transformers, Natural Language Processing, Sequence Models, Self-Attention, Encoder-Decoder Architecture, AI Interpretability"
    },
    {
      "id": "f48b8da7-416f-4bf5-9d8a-4638ff6f7a39",
      "name": "Artificial Intelligence, Machine Learning, Deep Learning, Neural Networks, Sequence Modeling"
    },
    {
      "id": "5a0ec7db-6b3a-4e39-ac6d-b851adc590a8",
      "name": "Artificial Intelligence, Machine Learning, Neural Networks, Sequence-to-Sequence Models, NLP, Deep Learning, Attention Mechanisms, Transformer Models, Language Translation, Model Architectures, AI Applications"
    },
    {
      "id": "3f53aefa-f781-4d9f-b5d8-cc8cd9933ca0",
      "name": "AI, Machine Learning, Neural Networks, Sequence-to-Sequence Models, Encoder-Decoder Architecture, Attention Mechanisms, Transformers, NLP, Deep Learning, Model Extensions, Natural Language Processing"
    },
    {
      "id": "16e6d0ac-ce65-4d4d-9576-9987b3def357",
      "name": "Machine Learning, Natural Language Processing, Sequence-to-Sequence Models, Neural Networks, Attention Mechanisms, Transformers, Deep Learning Extensions, AI Model Architectures, Language Modeling, Model Optimization"
    },
    {
      "id": "78fd06a3-b168-4f92-91b5-d402ba3bebb2",
      "name": "Neural Networks, Sequence-to-Sequence Models, Attention Mechanisms, Transformer Architecture, Natural Language Processing, Deep Learning, Model Enhancements, Machine Learning Techniques, AI Model Optimization, Transfer Learning"
    },
    {
      "id": "e9c6dc15-77d2-4a96-8ac0-231e7f8065d0",
      "name": "Artificial Intelligence, Machine Learning, Neural Networks, Sequence Models, Encoder-Decoder Architectures, Attention Mechanisms, Transformer Models, Deep Learning Techniques, Natural Language Processing (NLP), Model Extensions, Model Optimization, AI Research, Educational Resources"
    },
    {
      "id": "2ea05092-e306-4d8c-a752-f9d04a2b2810",
      "name": "Artificial Intelligence, Machine Learning, Natural Language Processing, Neural Networks, Deep Learning, Encoder-Decoder Architecture, Pretraining, Transformers, NLP Models, Language Models, AI Training Techniques"
    },
    {
      "id": "c3dc9eea-c0a5-43b6-8e06-1c2e238927e1",
      "name": "Machine Learning, Data Preprocessing, Feature Engineering, Data Transformation, Categorical Data, Encoding Techniques, Data Preparation, Data Science"
    },
    {
      "id": "4b0507ca-c08c-413d-b21d-fcd5dd7e515a",
      "name": "AI, Machine Learning, Natural Language Processing, Dialogue Systems, End-to-End Systems, Neural Networks, Conversational AI, Deep Learning, NLP Architectures, AI in Human-Computer Interaction"
    },
    {
      "id": "a9561565-4162-4df7-9ded-b102c1f03d66",
      "name": "Artificial Intelligence, Machine Learning, Model Compression, Knowledge Distillation, Deep Learning, Neural Networks, Model Optimization"
    },
    {
      "id": "512e1bf0-d1b6-4015-b768-875b1d3b19e6",
      "name": "Generative Adversarial Networks, GANs, Energy-Based Models, Autoencoders, Deep Learning, Unsupervised Learning, Generative Models, Machine Learning, Neural Networks, EBGANs"
    },
    {
      "id": "bae25fb5-0be2-4b34-b716-dcdb45299ae1",
      "name": "Energy-Based Models (EBMs) are a class of probabilistic models that assign an energy score to each configuration of their input variables. Key tags associated with EBMs include machine learning, probabilistic modeling, energy functions, unsupervised learning, generative models, Boltzmann Machines, Restricted Boltzmann Machines, deep learning, optimization, and statistical mechanics. These models are often utilized for unsupervised feature learning, density estimation, and generative tasks, leveraging energy functions to define probability distributions over data. Related concepts include Markov Random Fields, contrastive divergence, and deep energy models, which highlight their connections to physics-inspired approaches and neural network architectures."
    },
    {
      "id": "6120da77-9162-49b0-8d06-e2affbf6368b",
      "name": "Machine Learning, Deep Learning, Probabilistic Models, Generative Models, Energy-Based Models, EBMs, Unsupervised Learning, AI Modeling, Generative AI, Probabilistic Inference, Contrastive Divergence, Markov Chain Monte Carlo, Feature Learning, Anomaly Detection"
    },
    {
      "id": "969e5af5-df4f-4149-a078-161d08490472",
      "name": "Machine Learning, Probabilistic Models, Representation Learning, Unsupervised Learning, Artificial Intelligence, Pattern Recognition"
    },
    {
      "id": "99457e6b-e884-42ed-ba3d-a7395d94a4c2",
      "name": "Reinforcement Learning"
    },
    {
      "id": "e2289c8c-e79b-4bd0-8a7d-3dc127a1309a",
      "name": "Ensemble Methods, Machine Learning, Model Averaging, Bagging, Ensemble Techniques, Prediction Models, Data Science, Supervised Learning, Model Robustness, Variance Reduction"
    },
    {
      "id": "1de445c8-b813-4cbc-9f75-a5a97a746487",
      "name": "Machine Learning, Model Compression, Ensemble Methods, Knowledge Distillation, Deep Learning, Model Optimization, AI Techniques, Neural Networks, Transfer Learning"
    },
    {
      "id": "944bb1ca-fa35-4433-81f5-6b852ab72f13",
      "name": "Ensemble Learning, Model Diversity, Machine Learning Techniques, Ensemble Methods, Bagging, Boosting, Random Forest, Classifier Performance, Ensemble Optimization, Model Variance"
    },
    {
      "id": "25863d08-512d-43c1-a19b-2bd7767cf470",
      "name": "Machine Learning, Ensemble Methods, Diversity Techniques, Bagging, Boosting, Random Forests, Model Ensemble, Model Diversity, Ensemble Learning Strategies, Supervised Learning"
    },
    {
      "id": "f02f4855-4f1b-482c-b37d-48eb3ed9985b",
      "name": "Machine Learning, Ensemble Methods, Diversity Techniques, Ensemble Extensions, Advanced Ensemble Strategies, Model Robustness, Classification, Regression, Boosting, Bagging, Heterogeneous Ensembles"
    },
    {
      "id": "78e07f25-31b4-4a98-a921-7638e74bf57a",
      "name": "Artificial Intelligence, Machine Learning, Data Science, Predictive Modeling, Ensemble Methods"
    },
    {
      "id": "714319b2-d242-4389-b6bc-0e0b75344899",
      "name": "Statistical Estimation, Information Theory, Parameter Estimation, Machine Learning, Data Analysis, Cram\u00e9r-Rao Bound, Likelihood Function, Variance, Statistical Inference, Model Optimization"
    },
    {
      "id": "54657172-948c-4c95-892c-db97877bd6b4",
      "name": "Statistics, Information Theory, Estimation Theory, Machine Learning, Data Science, Parameter Estimation, Fisher Information, Statistical Inference, Optimization, Neural Networks, Natural Gradient, Information Geometry"
    },
    {
      "id": "24d9cc18-577d-412b-b205-fdb83f4a243e",
      "name": "Computer Vision, Feature Encoding, Fisher Vector, Machine Learning, Image Classification, Pattern Recognition, Generative Models, Visual Features, Image Retrieval, Data Representation"
    },
    {
      "id": "02ab2145-e941-490d-8eee-8ec589e9b859",
      "name": "Machine Learning, Computer Vision, Feature Encoding, Fisher Vector, Pattern Recognition, Image Classification, GMM, Local Descriptors, SIFT, Visual Recognition, Feature Extraction"
    },
    {
      "id": "d9bb06da-c538-40e6-bda6-1c82daa49aba",
      "name": "statistics, hypothesis testing, categorical data analysis, Fisher's Exact Test, contingency tables, small sample analysis, biomedical research, genetics, data science, probability, statistical significance"
    },
    {
      "id": "4e903654-196d-4f4c-b9fb-8d532eb1df9a",
      "name": "Machine Learning, Optimization, Evolutionary Algorithms, Genetic Algorithms, Fitness Function, AI, Optimization Techniques, Search Algorithms, Evolutionary Computation"
    },
    {
      "id": "6c645899-ecab-4301-942b-765c54ceb964",
      "name": "AI, Machine Learning, Deep Learning, Transformer Models, Attention Mechanisms, Model Optimization, Efficient Computing, NLP, Large-Scale Models, Kernel Fusion"
    },
    {
      "id": "2ce7f3e4-418e-4479-8ed3-b7b072e43bc4",
      "name": "Chemical Engineering, Separation Processes, Distillation, Vapor-Liquid Equilibrium, Petroleum Refining, Process Engineering, Separation Technologies, Thermodynamics, Fluid Mechanics, Industrial Chemistry"
    },
    {
      "id": "a9d6d3a1-5af7-48a2-961e-af5c3b79af4d",
      "name": "Neural Networks, Adaptive Learning, Machine Learning, Deep Learning, Dynamic Architectures, AI Model Flexibility, Transfer Learning, Neural Architecture Search, Online Learning, AI Research, Model Optimization"
    },
    {
      "id": "4aac71e7-1c4f-4c40-a0e8-561dfaf8815c",
      "name": "Generative Models, Deep Learning, Probabilistic Models, Normalizing Flows, Machine Learning, Artificial Intelligence, Data Modeling, Deep Generative Modeling, Neural Networks, Unsupervised Learning"
    },
    {
      "id": "6fd51f9a-c4ce-46ba-b80e-d22987891638",
      "name": "Generative Models, Flow-Based Models, Normalizing Flows, Machine Learning, Deep Learning, Generative Architecture Enhancements, Invertible Neural Networks, Model Optimization, Probabilistic Modeling, AI Research"
    },
    {
      "id": "ce17e4a6-9194-4757-b9b3-89571f5b4b89",
      "name": "Generative Models, Flow-based Models, Neural Invertible Networks, Deep Learning, Probabilistic Modeling, Variational Methods, Machine Learning Extensions, Neural Architectures, Generative AI, Advanced Modeling Techniques"
    },
    {
      "id": "e6eee2f4-4a75-4bc5-9417-a01e69186236",
      "name": "Generative Models, Flow-based Models, Normalizing Flows, Invertible Neural Networks, Probabilistic Modeling, Deep Learning, AI, Machine Learning, Neural ODEs, Image Synthesis, Data Generation, Deep Generative Models"
    },
    {
      "id": "4272bf25-2ab7-41ca-b9d5-336a0dc25db2",
      "name": "Generative Models, Machine Learning, Deep Learning, Probabilistic Modeling, Normalizing Flows, Invertible Neural Networks, Density Estimation, Deep Generative Models, AI Architecture"
    },
    {
      "id": "c4c86b52-e5d5-49d1-bb14-e949f7b44d3a",
      "name": "Generative Models, Flow-Based Models, Normalizing Flows, Deep Learning, Artificial Intelligence, Invertible Neural Networks, Model Enhancement, Density Estimation, Machine Learning, Neural Architectures, AI Research"
    },
    {
      "id": "e59325d7-7709-44b4-978e-c02403a92210",
      "name": "Artificial Intelligence, Machine Learning, Generative Models, Flow-Based Models, Deep Learning, Neural Networks, Model Optimization, Model Enhancement, Invertible Transformations, RealNVP, Glow, Density Estimation, Unsupervised Learning"
    },
    {
      "id": "843a89a2-8af1-4dda-9327-69c5c76d0cc2",
      "name": "Generative Models, Flow-Based Models, Normalizing Flows, Model Enhancements, Deep Learning, Density Estimation, Invertible Neural Networks, Model Optimization, AI Research, Machine Learning Techniques, Generative AI"
    },
    {
      "id": "ecc8f434-102e-4398-aac2-975c763d83c1",
      "name": "Generative Models, Flow-Based Models, Normalizing Flows, Invertible Neural Networks, Density Estimation, Deep Learning, Probabilistic Models, Computer Vision, Machine Learning, AI"
    },
    {
      "id": "d4518c8e-94a3-4dd5-afca-2b05dd659da5",
      "name": "Generative Models"
    },
    {
      "id": "957f2139-1efb-4a66-a185-38ede62f8f54",
      "name": "AI/ML, Neural Networks, Deep Learning, Machine Learning Techniques, Data Modeling"
    },
    {
      "id": "973d890b-a84d-4a5a-b44c-a716c6dead14",
      "name": "Natural Language Processing, Language Models, Model Evaluation, Fluency Metrics, Perplexity, BLEU Score, Text Coherence, NLP Metrics, Model Performance"
    },
    {
      "id": "42e40f84-c9b0-4f25-b5d4-0c34790af60f",
      "name": "Machine Learning, Deep Learning, Loss Functions, Object Detection, Class Imbalance, Focal Loss, Computer Vision, Neural Networks, Model Optimization"
    },
    {
      "id": "df739862-bae0-4210-9f66-9b055113586a",
      "name": "Machine Learning, Deep Learning, Loss Functions, Object Detection, Class Imbalance, Neural Networks, Computer Vision, Focal Loss, AI Algorithms, Model Optimization"
    },
    {
      "id": "4fa9a208-7d11-437c-befa-fffe78f99a86",
      "name": "Machine Learning, Deep Learning, Loss Functions, Focal Loss, Class Imbalance, Object Detection, Computer Vision, Loss Extensions, Model Optimization, AI Education"
    },
    {
      "id": "39cfd723-0190-4e71-8217-138dace0895f",
      "name": "Machine Learning, Deep Learning, Loss Functions, Class Imbalance, Focal Loss, Model Optimization, Computer Vision, Object Detection, Loss Function Extensions, Enhancements, Adaptive Loss, Multi-scale Focal Loss"
    },
    {
      "id": "78dc0827-64c0-4774-aec4-dc8f9e055ff7",
      "name": "AI/ML, Loss Functions, Focal Loss, Model Optimization, Class Imbalance, Machine Learning Techniques, Object Detection, Extension Techniques, Deep Learning, Loss Function Extensions"
    },
    {
      "id": "fcab9090-3a37-4c25-9007-ee92aade01ca",
      "name": "Machine Learning, Deep Learning, Loss Functions, Object Detection, Class Imbalance, Focal Loss Variants, Neural Networks, Model Optimization, Computer Vision, Advanced Loss Functions"
    },
    {
      "id": "c3957990-579c-4aea-a9bf-fb099c300202",
      "name": "Machine Learning, Deep Learning, Loss Functions, Class Imbalance, Focal Loss, Object Detection, Computer Vision, Model Optimization, Loss Function Variants, Extensions"
    },
    {
      "id": "939cf1aa-be0d-494f-942e-5ce8fd4c0cac",
      "name": "Deep Learning, Loss Functions, Focal Loss, Class Imbalance, Object Detection, Machine Learning Extensions, Model Optimization, Neural Networks, Computer Vision, Extension Techniques"
    },
    {
      "id": "cd89f926-dc73-4f45-8d67-50e79ce24bfb",
      "name": "Machine Learning, Deep Learning, Loss Functions, Focal Loss, Focal Loss Variants, Class Imbalance, Computer Vision, Object Detection, Image Segmentation, Advanced Loss Techniques"
    },
    {
      "id": "419675d7-ae0a-4c0f-96ba-054f283f98b4",
      "name": "Natural Language Processing, Sequence Modeling, Machine Learning Techniques, Model Training, Deep Learning"
    },
    {
      "id": "bbb72a6f-b434-4e52-a24b-f27f88bbd3b3",
      "name": "Machine Learning, Data Science, Time Series Analysis, Forecasting, Predictive Modeling, Deep Learning, Regression, Sequence Prediction, Data Analysis, AI Applications"
    },
    {
      "id": "5baa0f49-4426-4a94-b834-3a383880e600",
      "name": "Machine Learning, Spatial Modeling, Cellular Automata, Simulation, Environmental Modeling, Fire Spread, Climate Modeling, Disaster Prediction, Pattern Recognition"
    },
    {
      "id": "16aaf306-d2c1-4e9d-a38c-7491db5206f2",
      "name": "Formal Concept Analysis, FCA, lattice theory, knowledge representation, data analysis, conceptual structures, pattern discovery, attribute-object relationships, information retrieval, concept lattices, data mining, formal contexts, ontology engineering, hierarchical clustering"
    },
    {
      "id": "67b9e9a4-e629-4c13-99d4-8f8276a45b8c",
      "name": "Reinforcement Learning, Machine Learning, AI, IRL, Forward Reinforcement Learning, Inverse Reinforcement Learning, Behavioral Cloning, Reward Functions, Policy Learning, AI Applications"
    },
    {
      "id": "ec67470b-edfe-42a3-89b8-85670f52d1cf",
      "name": "AI, Machine Learning, Expert Systems, Inference Engines, Rule-Based Systems, Knowledge Representation, Forward Chaining, Reasoning Methods, Artificial Intelligence Algorithms"
    },
    {
      "id": "82b1c223-ea8a-4d43-af4f-39ad20e7708b",
      "name": "Generative Models, Diffusion Processes, Machine Learning, AI, Deep Learning, Probabilistic Models, Data Generation, Neural Networks, Uncertainty Modeling, Probabilistic Programming"
    },
    {
      "id": "f32b4ce5-e751-440e-800e-0e6245cb1033",
      "name": "Artificial Intelligence, Machine Learning, Neural Networks, Deep Learning, Forward Pass, Neural Network Architecture, Supervised Learning, Model Inference, Activation Functions, Backpropagation, AI Education"
    },
    {
      "id": "37f413f4-2e00-48ec-99e6-8eac4f70df87",
      "name": "Artificial Intelligence, Machine Learning, Deep Learning, Foundation Models, Pretraining, Large-Scale Models, Transformers, Language Models, Computer Vision, AI Architecture"
    },
    {
      "id": "8f374a2a-5e60-472f-bb50-83656c4b798f",
      "name": "Artificial Intelligence, Machine Learning, Deep Learning, Computer Vision, Data Science, Representation Learning, Natural Language Processing, AI Foundations"
    },
    {
      "id": "6e3eea6d-6338-44f4-8991-3e73a0747f57",
      "name": "Artificial Intelligence, Machine Learning, Deep Learning, Foundation Models, Pre-trained Models, Transfer Learning, NLP, Transformer Architecture, AI Research, Large-Scale Models, Model Fine-Tuning, AI Ethics, AI Applications"
    },
    {
      "id": "e0597348-9c6f-44f3-8e63-0a3d655bcaea",
      "name": "Artificial Intelligence, Machine Learning, Deep Learning, Neural Networks, Pre-trained Models, Natural Language Processing, Computer Vision, Transfer Learning, AI Model Architecture, OpenAI, BERT, GPT, Model Fine-tuning"
    },
    {
      "id": "193aa14f-9991-4cf7-9ce5-b852f98b7cbb",
      "name": "Machine Learning, Neural Networks, Feature Engineering, Signal Processing, Fourier Transform, Positional Encoding, Spectral Methods, High-Frequency Functions, Neural Implicit Representations, 3D Rendering, Neural Architecture, Signal Analysis"
    },
    {
      "id": "b7c35577-03d9-4f63-bb37-54771c921f5b",
      "name": "Fourier Features, Neural Network embeddings, Positional Encoding, Feature Mapping, Spectral Methods, Kernel Methods, Signal Processing, Frequency Representation, Embedding Techniques"
    },
    {
      "id": "a23a0fb2-b968-42dd-9eb7-950e8cb66d93",
      "name": "Machine Learning, Scientific Computing, Neural Networks, Fourier Transform, Partial Differential Equations, Deep Learning, AI in Physics, Mathematical Modeling, Function Approximation, Computational Physics"
    },
    {
      "id": "68ad24ff-10c9-4528-8cf4-90e1fced8c2f",
      "name": "Machine Learning, Deep Learning, Neural Networks, Operator Learning, Fourier Transforms, PDE Solvers, Scientific Computing, Data-Driven Modeling, Function Approximation, Neural Operators"
    },
    {
      "id": "1a28632c-3afc-41d1-a337-8229d387d2ef",
      "name": "Neural Networks, Fourier Transform, Spectral Methods, Neural Operators, PDE Solvers, Machine Learning, Deep Learning, Scientific Computing, Spectral Neural Networks, Function Approximation, AI in Physics, Data-Driven Modeling"
    },
    {
      "id": "4af4314e-f98c-49a8-ab66-4db689665013",
      "name": "Machine Learning, Deep Learning, Neural Networks, Scientific Computing, Computational Mathematics"
    },
    {
      "id": "44ee7168-0e06-4906-92da-c4c16c8f3dbb",
      "name": "Neural Networks, Machine Learning, Scientific Computing, Spectral Methods, Partial Differential Equations, Neural Operator Techniques, Model Optimization, Deep Learning Enhancements, Functional Mappings, Mathematical Modeling"
    },
    {
      "id": "d9632ffa-d344-412c-91fa-612311a084fd",
      "name": "Artificial Intelligence, Machine Learning, Neural Networks, Operator Learning, Fourier Neural Operators, PDE Solvers, Scientific Machine Learning, Deep Learning Extensions, Multi-Resolution Analysis, Fourier Transform, Neural PDE Solutions, Computational Physics, AI for Physical Sciences"
    },
    {
      "id": "4cdc6590-04bd-4428-b186-d0180bae17a5",
      "name": "AI, Machine Learning, Neural Networks, Fourier Neural Operators, Spectral Methods, Scientific Computing, Deep Learning, PDE Solvers, Neural Operator Extensions, AI Research"
    },
    {
      "id": "20ffb055-e2ec-409b-9c61-fb1e86158272",
      "name": "Artificial Intelligence, Machine Learning, Neural Networks, Mathematical Modeling, Scientific Computing"
    },
    {
      "id": "bb9827c8-518a-4dae-ba99-ef114de5a35f",
      "name": "AI, Machine Learning, Deep Learning, Convolutional Neural Networks, Fourier Transform, Signal Processing, Frequency Domain, Spectral Methods, CNN Optimization, Fourier Analysis"
    },
    {
      "id": "67e320dd-1113-4cb1-b52a-f1b9e1fe06d9",
      "name": "Clustering, Cluster Validation, Unsupervised Learning, Evaluation Metrics, Machine Learning, Data Science, Fowlkes-Mallows Index, FMI, Similarity Measures"
    },
    {
      "id": "4935a6fe-6ca3-4fe0-9dbe-b9813d81ed6e",
      "name": "Data Mining, Frequent Pattern Mining, Association Rule Learning, Machine Learning Algorithms, FP-Growth Algorithm, Data Analysis, Pattern Discovery, Large Dataset Mining, AI/ML Education, Data Science"
    },
    {
      "id": "0f76ba94-08bc-41eb-b63a-5705db90e221",
      "name": "AI/ML, Model Compression, Quantization, Deep Learning Optimization, Hardware Acceleration, Efficient Inference, FP16, Mixed Precision, Neural Networks, Model Deployment"
    },
    {
      "id": "51215db2-fd1d-40fe-b551-e2e05fa03457",
      "name": "AI hardware, FPGA, machine learning acceleration, neural network hardware, embedded AI, hardware design, reconfigurable computing, AI edge devices, hardware optimization, digital logic design"
    },
    {
      "id": "5445f1f8-954a-48c1-b83f-5ab771ffdefa",
      "name": "Fractional Calculus, Fractional Derivatives, Fractional Integrals, Non-Integer Calculus, Mathematical Analysis, Differential Equations, Anomalous Dynamics, Memory Effects, Mathematical Modeling, Applied Mathematics, Special Functions"
    },
    {
      "id": "c772f870-7b52-4777-b60a-c3dc0d394d53",
      "name": "machine learning, reinforcement learning, data preprocessing, sequence modeling, deep learning, neural networks, video analysis, temporal data, CNN, audio processing"
    },
    {
      "id": "ee2f3a89-50db-4d87-a0ce-6745e7f25d99",
      "name": "AI, Machine Learning, Knowledge Representation, Frame-based Systems, Semantic Networks, Expert Systems, AI Knowledge Modeling, Structured Data, Cognitive Architectures, AI Education"
    },
    {
      "id": "a2f160cb-c882-4fc0-8e76-7a20a28f347c",
      "name": "Machine Learning, Deep Learning, Computer Vision, Generative Models, Image Synthesis"
    },
    {
      "id": "3fe5ddd5-daa7-493d-9ff3-95fbe4bfe43b",
      "name": "Feature Engineering, Data Preprocessing, Categorical Data Encoding, Machine Learning Techniques, Data Science, Model Optimization"
    },
    {
      "id": "04371312-beca-4cb2-8360-ec20748cdaae",
      "name": "AI, Machine Learning, Natural Language Processing, Text Generation, Language Models, Hyperparameters, Control Parameters, Repetition Penalty, Prompt Engineering"
    },
    {
      "id": "dc763446-344a-45ed-8361-8982b166ce2a",
      "name": "Machine Learning, NLP, Feature Engineering, Text Processing, Dimensionality Reduction, Feature Selection, Data Preprocessing, Text Mining"
    },
    {
      "id": "15163f57-df7e-45f9-b10f-4306045ff1c9",
      "name": "Machine Learning, Data Analysis, Frequency-Based Algorithms, Statistical Methods, Pattern Recognition, Anomaly Detection, NLP, Data Mining, Probability Distributions, Classification Techniques"
    },
    {
      "id": "a16f1228-794f-400e-b347-5b108094d53f",
      "name": "Machine Learning, Data Sampling, Frequency-Based Sampling, Data Preprocessing, Class Imbalance, Data Augmentation, Imbalanced Datasets, Sampling Strategies, Data Science Techniques"
    },
    {
      "id": "618807d6-9f71-412e-a016-f6f4377fcc34",
      "name": "Machine Learning, Deep Learning, Model Training, Data Augmentation, Supervised Learning"
    },
    {
      "id": "b4ffc370-1d98-4c88-a8a7-f8ab7121501c",
      "name": "Machine Learning, Data Quality, Noise Robustness, Supervised Learning, Data Preprocessing, Model Evaluation, Data Cleaning, Label Correction, Robust Algorithms, Data Annotation"
    },
    {
      "id": "05a932c8-c094-4cc4-a95e-c454d56ad8ca",
      "name": "Semi-supervised learning, Graph algorithms, Clustering methods, Data labeling, Network analysis, Graph theory, Spectral clustering, Machine learning algorithms, Data science, AI techniques"
    },
    {
      "id": "3474fe82-93a5-4ccd-96a8-7cf1326920f7",
      "name": "Semi-supervised Learning"
    },
    {
      "id": "369340b8-283b-4b8a-8ad5-723e48cf9fa1",
      "name": "Artificial Intelligence, Machine Learning, Deep Learning, Data Science"
    },
    {
      "id": "d87737eb-4f8f-4978-a432-d782df021d96",
      "name": "Machine Learning, Deep Learning, Classification, Loss Functions, Regularization, Model Calibration, Neural Networks, Overfitting Prevention, Label Smoothing, AI Education"
    },
    {
      "id": "5333e89e-2492-4d6f-b6b1-e72dc32f5208",
      "name": "Neural Networks"
    },
    {
      "id": "3cf62c13-b26d-412c-9323-d849e20110c1",
      "name": "Neural Networks, Ladder Networks, Deep Learning, Hierarchical Feature Learning, Semi-Supervised Learning, Neural Architecture Improvements, Machine Learning Enhancements, Computer Vision, Model Optimization, Advanced Neural Network Techniques"
    },
    {
      "id": "8036fb15-70a5-4cbd-b917-a0846835fd10",
      "name": "Deep Learning, Neural Networks, Ladder Networks, Residual Connections, Hierarchical Model Enhancement, Neural Network Optimization, Model Regularization, Hierarchical Feature Learning, Advanced AI Techniques"
    },
    {
      "id": "b5fd6ba2-5581-4576-b2d8-ca4382e4019b",
      "name": "Deep Learning, Neural Networks, Semi-Supervised Learning, Ladder Networks, Neural Network Architectures, Model Extensions, Machine Learning Techniques, Hierarchical Learning, Representation Learning, AI Research"
    },
    {
      "id": "b017525a-0826-4881-9223-ee79ca9969a1",
      "name": "Deep Learning"
    },
    {
      "id": "1540d631-e09d-4ed0-bbc4-631a933f8ac4",
      "name": "Machine Learning, Data Engineering, Big Data Architecture, Data Processing Architectures, Distributed Systems"
    },
    {
      "id": "dd7ed944-5362-4778-9b2c-00a657481e3f",
      "name": "Artificial Intelligence, Natural Language Processing, Robotics, Language Generation, Human-Robot Interaction, Machine Learning, NLP Models, Deep Learning, Dialogue Systems, Robotics Communication Tools"
    },
    {
      "id": "c7c67f26-e995-4ed5-92a0-6ed12ae458bd",
      "name": "Natural Language Processing, Machine Learning, Language Models, Model Evaluation, NLP Metrics, AI Model Assessment, Deep Learning, Model Performance, Benchmark Datasets, Evaluation Techniques"
    },
    {
      "id": "c25cc053-793f-446d-904f-fc6f51f14422",
      "name": "AI, Machine Learning, Natural Language Processing, Language Models, Transfer Learning, Fine-Tuning, Deep Learning, NLP Applications, Model Training, AI Techniques"
    },
    {
      "id": "83f17289-a385-485d-a871-d0b2aa12f325",
      "name": "Artificial Intelligence, Machine Learning, Natural Language Processing, NLP, Language Models, Deep Learning, Pretraining, BERT, GPT, Transformer Models, AI Education, Language Model Training, AI Techniques"
    },
    {
      "id": "68a34110-1aef-4dee-a219-19cac6ec7ed0",
      "name": "Natural Language Processing, NLP, Machine Learning, Deep Learning, Language Models, AI, Transformer Models, GPT, BERT, Text Generation, AI Ethics, Neural Networks, Artificial Intelligence, Language Understanding"
    },
    {
      "id": "1b39fd05-f939-483a-97b7-76ac4fac7094",
      "name": "Artificial Intelligence, Machine Learning, Natural Language Processing, Language Models, Deep Learning, NLP Applications, GPT, BERT, AI Algorithms, Text Generation, Neural Networks"
    },
    {
      "id": "7ce04689-9d02-4038-9353-68d11c54b9fd",
      "name": "Natural Language Processing"
    },
    {
      "id": "d40eb624-31ec-434b-9e62-1aff69486ca6",
      "name": "Probability Distributions, Laplacian Distribution, Double Exponential, Signal Processing, Outlier Detection, Statistical Modeling, Machine Learning Distributions, Data Analysis"
    },
    {
      "id": "e5f197c3-e00a-4c39-8e04-cb47c529ef8b",
      "name": "Machine Learning, Regularization Techniques, Graph-Based Methods, Semi-Supervised Learning, Manifold Learning, Spectral Methods, Clustering, Dimensionality Reduction"
    },
    {
      "id": "8ba0c392-1499-48d0-9d26-b9db4d846921",
      "name": "Artificial Intelligence, Machine Learning, Deep Learning, Large Language Models, Foundation Models, Transformer Architecture, NLP, Model Scaling, AI Research, AI Education"
    },
    {
      "id": "3ee61d83-32ba-4e14-a555-571c40195b78",
      "name": "Artificial Intelligence, Machine Learning, Natural Language Processing, Deep Learning, Transformer Models, Language Models, GPT, BERT, Neural Networks, AI Applications, NLP Technologies, AI Research, AI Ethics"
    },
    {
      "id": "081dd52e-9610-43a8-9200-f32b30349251",
      "name": "Artificial Intelligence, Machine Learning, Deep Learning, Neural Networks, Large Models, AI Architectures"
    },
    {
      "id": "b70b98c0-09e1-4cb5-b0f2-a3b03b850e7e",
      "name": "Machine Learning, Regression, Regularization, Feature Selection, Lasso, Sparsity, Statistical Modeling, Data Science, Predictive Modeling, Elastic Net, Ridge Regression, Supervised Learning"
    },
    {
      "id": "738a6bae-54b8-4fff-98c8-b9f6bf96477f",
      "name": "Regression, Regularization, Supervised Learning, Feature Selection, Machine Learning, Linear Models, L1 Regularization, Sparse Models, High-Dimensional Data"
    },
    {
      "id": "293d145e-3b41-4bd3-bdf8-d8aae6a49633",
      "name": "Machine Learning, Regression, Regularization, Lasso, Ridge, Feature Selection, Overfitting Prevention, Supervised Learning, Data Science, Model Tuning"
    },
    {
      "id": "623343fe-a47b-418b-9c99-4f89338c2e57",
      "name": "Machine Learning, Regression, Regularization, Lasso Regression, Ridge Regression, Feature Selection, Overfitting Prevention, Supervised Learning, Statistical Learning"
    },
    {
      "id": "be926310-7863-4039-80de-38cdc305d7a7",
      "name": "AI/ML, Model Optimization, Inference Speed, Latency Reduction, Hardware Acceleration, Real-time Processing, Edge Computing, Model Pruning, Quantization, Neural Network Optimization"
    },
    {
      "id": "13d6cfbf-6802-4c47-ad77-d9e42552b977",
      "name": "Machine Learning Optimization, Real-Time Inference, Model Compression, Low-Latency AI, Model Deployment, Efficient Neural Networks, Performance Profiling, Edge AI, AI Systems Architecture, Latency Reduction Techniques"
    },
    {
      "id": "3e8a0f67-698b-4ccf-9438-e31ac1cd3ab5",
      "name": "Artificial Intelligence, Machine Learning, Generative Models, Diffusion Models, Latent Space, Deep Learning, Image Synthesis, Generative AI, Computer Vision, AI Research"
    },
    {
      "id": "3211afce-2d2a-4bd7-8220-ed642e49b2b5",
      "name": "Generative Models, Diffusion Models, Deep Learning, Artificial Intelligence, Computer Vision, Image Synthesis, Machine Learning, Latent Space, Neural Networks, AI Research"
    },
    {
      "id": "6bd59b84-978b-4ae6-a812-c596d49a29aa",
      "name": "Machine Learning, Natural Language Processing, Topic Modeling, Unsupervised Learning, Probabilistic Models, Text Analysis, Data Mining, LDA, Dimensionality Reduction, Statistical Modeling"
    },
    {
      "id": "07424377-51ad-489f-a046-e4e860551930",
      "name": "Machine Learning, Natural Language Processing, Topic Modeling, Probabilistic Models, Unsupervised Learning, Text Mining, Data Science, AI Algorithms"
    },
    {
      "id": "2ed7b5c6-e7ef-4b58-aafa-176349399b9b",
      "name": "Machine Learning, Information Theory, Representation Learning, Deep Neural Networks, Data Compression, Variational Methods, Unsupervised Learning, Latent Space, Feature Extraction, Neural Network Optimization"
    },
    {
      "id": "14867a94-bcae-4075-8ee4-7154def1ed01",
      "name": "Natural Language Processing, Text Analytics, Dimensionality Reduction, Matrix Factorization, NLP Techniques, Semantic Analysis, Machine Learning, Information Retrieval, Unsupervised Learning, Text Mining"
    },
    {
      "id": "e439aa10-143d-4c8d-bc4f-0f87e833d241",
      "name": "Natural Language Processing, Information Retrieval, Text Mining, Machine Learning, Data Science"
    },
    {
      "id": "b1839f82-076b-4d1e-a2a0-824fe015be59",
      "name": "Natural Language Processing, Semantic Analysis, Information Retrieval, Dimensionality Reduction, Topic Modeling, Machine Learning, NLP Techniques, Text Mining, SVD, Latent Semantic Indexing"
    },
    {
      "id": "6fdaf690-f56b-4be7-9530-8c1a06b84b99",
      "name": "Natural Language Processing, Semantic Analysis, Machine Learning, Text Similarity, Embedding Models, Latent Semantic Analysis, Dimensionality Reduction, NLP Techniques, Text Mining, Deep Learning in NLP"
    },
    {
      "id": "f626050b-7b3e-4633-bd6b-c4e7583cd021",
      "name": "Machine Learning, Deep Learning, Generative Models, Unsupervised Learning, Dimensionality Reduction"
    },
    {
      "id": "42ca4030-93f8-49f7-9508-9dc5f2cc3cb5",
      "name": "Artificial Intelligence, Machine Learning, Generative Models, Latent Space, Variational Autoencoders (VAEs), Generative Adversarial Networks (GANs), Deep Learning, Representation Learning, Data Visualization, Model Interpretability, Interpolation, Dimensionality Reduction, Creative AI, Model Explainability"
    },
    {
      "id": "4b3b6d86-b112-4598-91bb-97ba6c587215",
      "name": "Artificial Intelligence, Machine Learning, Generative Models, Latent Space, Variational Autoencoders, Generative Adversarial Networks, Model Interpretability, Feature Disentanglement, Data Representation, Deep Learning"
    },
    {
      "id": "132a1d10-78d6-47e0-aaed-db18d4661196",
      "name": "Artificial Intelligence, Machine Learning, Generative Models, Latent Space, Variational Autoencoders, GANs, Latent Space Exploration, Extensions Techniques, Model Interpretability, Data Generation, Deep Learning, Representation Learning"
    },
    {
      "id": "fdb982a0-2ecb-4ab2-995e-ff18122d816d",
      "name": "Artificial Intelligence, Machine Learning, Generative Models, Latent Space, Deep Learning, Variational Autoencoders, Generative Adversarial Networks, Latent Space Manipulation, Data Representation, Model Extensions, Neural Network Enhancements, Image Synthesis, Data Augmentation, Disentangled Representations"
    },
    {
      "id": "14b2607b-fd5f-4c2d-be29-eaf24b185168",
      "name": "Generative Models, Latent Space, Variational Autoencoders, GANs, Dimensionality Reduction, Model Interpretability, Deep Learning, Data Generation, Feature Manipulation, Unsupervised Learning"
    },
    {
      "id": "0b980795-0e8c-4a88-9558-3dc165b50901",
      "name": "Artificial Intelligence, Machine Learning, Generative Models, Deep Learning, Latent Space, GAN, VAE, Data Generation, Model Interpretability, AI Creativity, Neural Networks, Model Manipulation"
    },
    {
      "id": "220f5104-cf02-4b0b-a4b6-d9a319f1a437",
      "name": "Artificial Intelligence, Machine Learning, Deep Learning, Generative Models, Latent Space, Variational Autoencoders, Generative Adversarial Networks, Interpretable ML, Model Manipulation, Data Generation, Representation Learning"
    },
    {
      "id": "aa173205-a10d-488d-b501-8f87aa6d6681",
      "name": "Machine Learning, Generative Models, Latent Space, GANs, Variational Autoencoders, Deep Learning, Data Synthesis, Attribute Editing, Latent Space Arithmetic, Representation Learning"
    },
    {
      "id": "c8a1736a-8549-4e98-ab91-480924788bd1",
      "name": "Machine Learning, Deep Learning, Generative Models, Latent Space, Autoencoders, Variational Autoencoders, GANs, Representation Learning, Unsupervised Learning, Data Generation"
    },
    {
      "id": "90759216-9938-4255-ae89-97f048035020",
      "name": "Artificial Intelligence, Machine Learning, Generative Models, Latent Space, Neural Networks, Deep Learning, Data Visualization, Autoencoders, GANs, Variational Autoencoders, Dimensionality Reduction, Model Interpretability, AI Explainability"
    },
    {
      "id": "6361e606-eaca-45f3-a223-7115c8e9e752",
      "name": "Machine Learning, Network Analysis, Probabilistic Models, Latent Space Models, Graph Theory, Data Visualization, Bayesian Inference, Social Network Analysis, Unsupervised Learning, Graph Embedding"
    },
    {
      "id": "c340d5b2-b41f-47f7-a9d5-31290268f9e6",
      "name": "Reinforcement Learning, Policy Gradient, Text Generation, NLP, Machine Learning, Deep Learning, Language Models, AI Applications, Reinforcement Learning in NLP, RL Algorithms, Policy Optimization"
    },
    {
      "id": "f6e32c03-e555-47c2-9c98-da6ea9354710",
      "name": "Reinforcement Learning, Policy Gradient Methods, Policy Optimization, Actor-Critic, Deep Reinforcement Learning, Stochastic Policies, Machine Learning Algorithms, RL Training Techniques"
    },
    {
      "id": "f88d4ab8-8049-4580-a679-1194e7da77ab",
      "name": "Reinforcement Learning, Policy Optimization, Machine Learning, Artificial Intelligence, Sequential Decision Making, Markov Decision Processes"
    },
    {
      "id": "02ce6114-e7b2-4852-95d4-20b9efa8c190",
      "name": "Reinforcement Learning, Policy Optimization, Dynamic Programming, Markov Decision Processes, Machine Learning Algorithms, Policy Iteration, Value Functions, Policy Evaluation, Policy Improvement, Sequential Decision-Making"
    },
    {
      "id": "11a5291c-c524-452b-b523-37508ff2092a",
      "name": "Reinforcement Learning, Policy Networks, Neural Networks, Policy Gradient, Actor-Critic Methods, Deep Learning, Machine Learning, AI, Continuous Action Spaces, Policy Optimization"
    },
    {
      "id": "6b97ea5d-cfff-4435-a8fd-4940a2594e0a",
      "name": "Optimization Algorithms, Stochastic Optimization, Variance Reduction, Machine Learning, Deep Learning, Convergence Techniques, Gradient Descent, Polyak Averaging, Model Stability, Training Techniques"
    },
    {
      "id": "4e4487a8-5959-4646-802e-980132212f3f",
      "name": "Machine Learning, Neural Network Optimization, Stochastic Gradient Descent, Polyak Averaging, Variance Reduction, Training Stabilization, Deep Learning, Optimization Algorithms, Enhancements, Convergence Speed"
    },
    {
      "id": "8758d7ed-9b34-4580-a3e9-6baabc5d4782",
      "name": "Machine Learning, Optimization Algorithms, Neural Network Training, Parameter Averaging, Polyak Averaging, Extensions, Advanced Techniques, Deep Learning, Model Generalization, Training Stability"
    },
    {
      "id": "36a05ba2-b50b-49c6-a989-56e398faf855",
      "name": "Optimization, Machine Learning, Neural Networks, Stochastic Gradient Descent, Model Averaging, Polyak Averaging, Advanced Optimization Techniques, Variance Reduction, Deep Learning, Training Algorithms"
    },
    {
      "id": "fedc536b-aff8-46b7-97b4-1a665d485f50",
      "name": "Machine Learning Optimization, Stochastic Optimization, Variance Reduction, Polyak Averaging, Algorithm Extensions, Deep Learning, Numerical Stability, Adaptive Methods, Model Training Techniques, Advanced Optimization Strategies"
    },
    {
      "id": "40fe59b1-0726-4e49-b792-04394279af82",
      "name": "Machine Learning, Optimization Algorithms, Neural Network Training, Polyak Averaging, Variance Reduction, Convergence Techniques, Model Generalization, Stochastic Gradient Methods, Extensions and Enhancements, Deep Learning Optimization"
    },
    {
      "id": "193c441c-0d53-488d-b730-5029bdfdd470",
      "name": "Machine Learning, Optimization Techniques, Model Averaging, Stochastic Gradient Methods, Training Stabilization, Neural Network Training, Variance Reduction, Convergence Improvement, Advanced Optimization, Educational Resources"
    },
    {
      "id": "eb60f725-cd3b-42fb-8264-a708ee582c93",
      "name": "Machine Learning, Optimization Algorithms, Stochastic Gradient Descent, Polyak Averaging, Variance Reduction, Deep Learning, Neural Network Training, Advanced Optimization Techniques, Model Convergence, Algorithm Extensions"
    },
    {
      "id": "1516c0ec-8acc-4d4d-b3ab-bd75ba42392a",
      "name": "Machine Learning, Optimization, Stochastic Gradient Descent, Polyak Averaging, Variance Reduction Techniques, Deep Learning Optimization, Adaptive Averaging, Gradient Methods, Model Stability, Convergence Acceleration"
    },
    {
      "id": "d82a717a-5aed-483a-985c-31daec95cb81",
      "name": "Machine Learning, Optimization Algorithms, Neural Network Training, Polyak Averaging, Variance Reduction, Stochastic Gradient Descent, Deep Learning, Convergence Techniques, Adaptive Optimization, Model Stability, Advanced ML Techniques"
    },
    {
      "id": "3f72f147-f36e-4a6b-ba3d-8be862ab91b3",
      "name": "Machine Learning, Optimization Techniques, Stochastic Gradient Descent, Polyak Averaging, Enhancement Methods, Deep Learning, Model Convergence, Variance Reduction, Training Stabilization, Adaptive Algorithms"
    },
    {
      "id": "0238721b-3693-4f2c-81a2-ddaa11fad71d",
      "name": "Feature Engineering, Polynomial Features, Nonlinear Models, Data Transformation, Machine Learning Techniques, Regression, Feature Expansion, Overfitting, Model Complexity"
    },
    {
      "id": "25fb22cf-839b-4373-afe3-14b1b7f75e55",
      "name": "Machine Learning, Neural Networks, Polynomial Networks, Nonlinear Models, Feature Engineering, Polynomial Regression, Kernel Methods, Supervised Learning, Deep Learning, Data Modeling"
    },
    {
      "id": "54457308-8214-4333-868f-259d5bed7d25",
      "name": "Regression, Polynomial Regression, Nonlinear Modeling, Machine Learning, Supervised Learning, Data Fitting, Overfitting, Regression Algorithms, Polynomial Features, Model Complexity"
    },
    {
      "id": "b398ed36-5c3f-4aad-aafd-21421e6c3a30",
      "name": "Convolutional Neural Networks, Pooling Layer, Max Pooling, Average Pooling, Spatial Dimensionality Reduction, Feature Extraction, Deep Learning, Image Processing, Neural Network Layers, CNN Architecture"
    },
    {
      "id": "a14cfc34-aca7-4cfd-9482-2b1d5b5559d5",
      "name": "Deep Learning, Convolutional Neural Networks, CNN, Pooling Layers, Max Pooling, Average Pooling, Image Processing, Feature Extraction, Neural Network Components, AI Education"
    },
    {
      "id": "254cf1d5-ad68-42ea-8f45-76e4372a7117",
      "name": "AI, Machine Learning, Data Science, Data Sampling, Data Collection, Model Training, Data Analysis, Statistical Inference, Data Population, Data Sets"
    },
    {
      "id": "342ac1a3-a364-4416-a936-860e0936c195",
      "name": "Machine Learning, Optimization Techniques, Hyperparameter Tuning, Evolutionary Algorithms, Population-Based Training, Automated ML, Neural Networks, Model Training Strategies, Adaptive Learning, AI Optimization Methods"
    },
    {
      "id": "602c83f9-44b1-40ec-b3fa-ec4a0eefb9e1",
      "name": "Machine Learning, Hyperparameter Optimization, Population-Based Training, Deep Learning, Automated Tuning, Evolutionary Algorithms, Reinforcement Learning, Model Optimization, AI Frameworks, Research Methods"
    },
    {
      "id": "ffdb9d1f-02d8-4c6c-b49b-6e3343d4b51d",
      "name": "Computer Vision, Pattern Recognition, Human-Computer Interaction, AI Perception"
    },
    {
      "id": "8a721960-fff7-4813-a4f2-8f77e254e8db",
      "name": "Computer Vision, Pose Estimation, Human Motion Analysis, Deep Learning, Convolutional Neural Networks, 2D Pose Estimation, 3D Pose Estimation, Face Landmark Detection, Human Pose Recognition, AI in Healthcare and Fitness, Augmented Reality, Motion Tracking, Machine Learning, Image Processing"
    },
    {
      "id": "f34d19d0-a386-44a1-8827-fdbb79251700",
      "name": "Natural Language Processing, Neural Networks, Transformer Models, Sequence Modeling, Attention Mechanisms, Machine Learning, Deep Learning, Positional Encoding, AI Architecture"
    },
    {
      "id": "23715765-4079-4d61-b87a-247d3c78c7a9",
      "name": "Artificial Intelligence, Machine Learning, Deep Learning, Transformers, Sequence Modeling, Positional Encoding, Self-Attention, NLP, Neural Networks, Embeddings"
    },
    {
      "id": "3b2fdf5c-5393-45ad-90a7-ad7f56f591d1",
      "name": "Machine Learning, Classification Metrics, Evaluation Metrics, Data Science, Predictive Modeling, Model Validation, Confusion Matrix, Precision, Recall, F1 Score, Binary Classification"
    },
    {
      "id": "e6628bfb-ee12-497e-b253-1a3f8b959dcf",
      "name": "Machine Learning, Semi-supervised Learning, Weakly Supervised Learning, Classification, Data Sampling, Imbalanced Datasets, Positive-Unlabeled Learning, PU Learning, Data Labeling Techniques, ML Algorithms"
    },
    {
      "id": "b2f02031-5e66-4570-b8da-ba3f0443f1e3",
      "name": "Artificial Intelligence, Machine Learning, Model Interpretability, Explainability, Post-hoc Methods, LIME, SHAP, Model Transparency, Black-box Models, Explainable AI, AI Ethics, Data Science"
    },
    {
      "id": "0caf7b8c-8da8-4375-b22f-895c516668cc",
      "name": "Machine Learning, Model Optimization, Quantization, Model Compression, Deep Learning, AI Deployment, Resource-Constrained Devices, TensorFlow, PyTorch, Hardware Acceleration"
    },
    {
      "id": "0c4cce23-7ea5-44bc-beda-411af30e330b",
      "name": "Machine Learning, AI Model Optimization, Model Compression, Quantization Techniques, Neural Networks, Deployment, Edge Computing, Model Efficiency, Inference Speed, Resource-Constrained Devices"
    },
    {
      "id": "0ea3390d-96ff-42b2-bef7-c0076524920a",
      "name": "Bayesian Inference, Probability, Statistics, Machine Learning, Data Science"
    },
    {
      "id": "44b99a4d-6562-472e-abca-2c13e9503d1f",
      "name": "Statistics, Research Methods, Experimental Design, Sample Size Calculation, Hypothesis Testing, Power Analysis, Statistical Significance, Effect Size, Data Analysis, Research Planning"
    },
    {
      "id": "fdccc823-9f42-4e83-8af3-614834277df4",
      "name": "Eigenvalues, Eigenvectors, Power Iteration, Spectral Methods, Linear Algebra, Matrix Computations, Numerical Algorithms, Machine Learning, Principal Component Analysis, Spectral Clustering"
    },
    {
      "id": "0f61dbd9-d17b-4dc4-afe8-50e26577fae3",
      "name": "Machine Learning, Data Preprocessing, Signal Processing, Feature Normalization, Neural Networks, Signal Power, Data Scaling, Feature Engineering"
    },
    {
      "id": "5e878ac9-6c86-4cd7-a5ae-8f2817780720",
      "name": "statistical hypothesis testing, statistical power, Type II error, effect size, sample size determination, significance level, data analysis, experimental design, inferential statistics, hypothesis testing concepts"
    },
    {
      "id": "a21ebbb6-559b-4556-bf43-82f68c6ffd5c",
      "name": "Network Science, Complex Networks, Power-Law Distribution, Graph Theory, Cluster Graphs, Scale-Free Networks, Social Network Analysis, Structural Properties of Graphs, Network Modeling, Data Science"
    },
    {
      "id": "e5dbd346-fd12-437c-9370-43110d575dbb",
      "name": "Graph Theory, Complex Networks, Scale-Free Networks, Power-Law Distributions, Network Science, Data Analysis, Big Data, Social Networks, Biological Networks, Information Theory"
    },
    {
      "id": "af8462e9-347c-4046-97e4-10c6a5dd0262",
      "name": "Evaluation Metrics, Machine Learning, Classification, Precision-Recall Curve, Model Performance, Data Science, Imbalanced Data, Model Selection, Python, scikit-learn"
    },
    {
      "id": "fbc93b19-5a13-47da-a46d-5c870b28f358",
      "name": "Statistics, Data Analysis, Effect Size, Practical Significance, Research Methods, Applied Statistics, Effectiveness, Data Interpretation, Significance Testing, Effect Size Benchmarks"
    },
    {
      "id": "0e7685d9-3956-4b90-85d5-c9dcddadfbe2",
      "name": "Natural Language Processing, NLP, Word Embeddings, Pre-trained Models, Transfer Learning, Machine Learning, Deep Learning, BERT, Word2Vec, GloVe, Text Representation, Embedding Techniques"
    },
    {
      "id": "01d46999-1f9b-49e8-a572-2fbf2e928780",
      "name": "Artificial Intelligence, Machine Learning, Natural Language Processing, Deep Learning, Language Models"
    },
    {
      "id": "897c2c2e-937b-4766-86c1-76802d7edaa8",
      "name": "Artificial Intelligence, Machine Learning, Deep Learning, Pre-trained Models, NLP, Computer Vision, Transfer Learning"
    },
    {
      "id": "a1e1de27-1094-4660-88be-3b3e14f6996a",
      "name": "Artificial Intelligence, Machine Learning, Deep Learning, Pre-training, Transfer Learning, Language Models, Neural Networks, Self-supervised Learning, Model Training, AI Foundations"
    },
    {
      "id": "92657e19-1bbe-499b-ad86-900e5df98be5",
      "name": "Artificial Intelligence, Machine Learning, Legal Aspects, Ethics, Case Studies, AI Policy, Compliance, Technology Law"
    },
    {
      "id": "593c069f-2068-41c7-a64d-ca30ca5d4bb9",
      "name": "Machine Learning, Classification, Model Evaluation, Precision, Performance Metrics, Data Science, AI, Model Validation, Predictive Modeling"
    },
    {
      "id": "04764e46-ed48-4cfb-a223-c4c9f52888fc",
      "name": "Machine Learning, Classification, Model Evaluation, Performance Metrics, Precision, Recall, F1 Score, Data Analysis, AI Metrics, Supervised Learning"
    },
    {
      "id": "40f4817f-5014-4bf7-9918-d6ee35b5476b",
      "name": "Model Optimization"
    },
    {
      "id": "54144812-b5c6-47e9-a2b9-c1b4eaece433",
      "name": "Machine Learning, Model Evaluation, Classification Metrics, Precision, Recall, PR Curve, Imbalanced Datasets, Data Science, Performance Metrics, Binary Classification"
    },
    {
      "id": "869423ad-aa97-4e5e-a138-35a40720da9d",
      "name": "Machine Learning, Model Evaluation, Classification Metrics, Precision, Recall, Tradeoff Analysis, Threshold Tuning, Data Science"
    },
    {
      "id": "d35134fe-74d5-4c52-8a55-b846c7dfb9e6",
      "name": "Predictive Coding, Neuroscience, Machine Learning, Cognitive Science, Unsupervised Learning, Brain Modeling, Predictive Algorithms, Hierarchical Models, Sensory Processing, AI Theory"
    },
    {
      "id": "3c0d64d6-9e10-475e-8d53-bf7f060921de",
      "name": "Data Mining, Predictive Analytics, Machine Learning, Data Science, Predictive Modeling, Supervised Learning, Data Analysis, Pattern Recognition, Business Analytics, AI Applications"
    },
    {
      "id": "92ab1c3c-a858-434f-80fc-338a184c3d67",
      "name": "Machine Learning, Predictive Modeling, Data Science, Supervised Learning, Statistical Modeling, AI, Data Analysis, Machine Learning Algorithms, Data Prediction, Forecasting, Classification, Regression"
    },
    {
      "id": "c2e50132-7174-4331-a50e-bed60c0dbe0c",
      "name": "Machine Learning, AI Assessment Techniques, Predictive Analytics, Data Science, Model Evaluation"
    },
    {
      "id": "d90c8e4d-13d2-43fb-9e31-b459a14372de",
      "name": "Machine Learning, Data Science, Predictive Modeling, Feature Engineering, Data Analysis"
    },
    {
      "id": "47aadffe-07c5-4d14-a9af-f735545fdd0c",
      "name": "Network Theory, Graph Theory, Complex Networks, Scale-Free Networks, Power-Law Distribution, Network Growth Models, Barab\u00e1si-Albert Model, Preferential Attachment, Network Science, Data Science"
    },
    {
      "id": "05f2a543-5a39-4f64-a14c-0d93475106c6",
      "name": "Network Theory, Scale-Free Networks, Complex Systems, Graph Theory, Network Modeling, Preferential Attachment, Barab\u00e1si-Albert Model, Power-Law Degree Distribution, Complex Networks, Systems Science"
    },
    {
      "id": "92e8f341-0ee0-43e7-8fd4-090d9642bff0",
      "name": "AI, Machine Learning, Natural Language Processing, Language Models, Fine-Tuning, Prompt Engineering, Prefix Tuning, Model Adaptation, NLP Techniques, Deep Learning"
    },
    {
      "id": "c1b289fc-1fcb-4d24-a770-fc528e43d6ee",
      "name": "AI/ML, Natural Language Processing, Text Generation, Language Models, Presence Penalty, Model Tuning, AI Parameters, Diversifying Outputs, Chatbot, GPT"
    },
    {
      "id": "8954a6e5-05c9-4f6c-98c8-a9f60179badc",
      "name": "Machine Learning, Deep Learning, Pretraining, Transfer Learning, Natural Language Processing, Neural Networks, Transformer Models, Self-Supervised Learning, AI Techniques, Data Science"
    },
    {
      "id": "064f4ae6-0b6b-4972-b926-5577e8ba4472",
      "name": "Machine Learning, Deep Learning, Transfer Learning, Pretraining, Fine-Tuning, Neural Networks, Natural Language Processing, Computer Vision, AI Education, Transfer Learning Paradigm"
    },
    {
      "id": "73064999-8c6b-46d0-9348-504e41976f45",
      "name": "Dimensionality Reduction, PCA, Principal Components, Unsupervised Learning, Data Visualization, Machine Learning Preprocessing, Feature Extraction, Data Analysis, Statistical Techniques"
    },
    {
      "id": "2433bd03-6d3a-4bd2-8695-cbc38078bf91",
      "name": "Dimensionality Reduction, Embeddings, PCA, Machine Learning, Data Visualization, Feature Extraction, High-Dimensional Data, Unsupervised Learning, Representation Learning"
    },
    {
      "id": "659f680a-5d62-4775-b990-ede10c2b51e2",
      "name": "Machine Learning, Dimensionality Reduction, Principal Component Analysis, Regression, Feature Engineering, Data Preprocessing, Supervised Learning, Unsupervised Learning, Data Analysis, Model Optimization"
    }
  ],
  "subcategories": [
    {
      "id": "6c47bd37-2db1-40bd-adae-9aa30501ca29",
      "name": "Probability Theory",
      "categoryId": "24430edb-10c0-43cb-9b75-8fdbdc45840a"
    },
    {
      "id": "129a4108-dd6a-434e-88be-b88062582846",
      "name": "Characteristic Function",
      "categoryId": "24430edb-10c0-43cb-9b75-8fdbdc45840a"
    },
    {
      "id": "e4a65769-fac3-4068-ac78-633cf5d19295",
      "name": "Distribution Functions",
      "categoryId": "24430edb-10c0-43cb-9b75-8fdbdc45840a"
    },
    {
      "id": "3f103c61-15f1-4bbb-ab32-25dc4b87c8fd",
      "name": "Random Variables",
      "categoryId": "24430edb-10c0-43cb-9b75-8fdbdc45840a"
    },
    {
      "id": "e7c190e4-3b0a-4339-a8da-a2c0e750699b",
      "name": "Fourier Analysis",
      "categoryId": "24430edb-10c0-43cb-9b75-8fdbdc45840a"
    },
    {
      "id": "be0600ab-9716-46b9-88f2-dd75cf423bd5",
      "name": "Fourier Transform",
      "categoryId": "24430edb-10c0-43cb-9b75-8fdbdc45840a"
    },
    {
      "id": "2c458641-363d-4f24-a343-314e260c149a",
      "name": "Complex-Valued Functions",
      "categoryId": "24430edb-10c0-43cb-9b75-8fdbdc45840a"
    },
    {
      "id": "070f4405-f8cf-4767-964c-02239a7afeb4",
      "name": "Moment Generating Functions",
      "categoryId": "24430edb-10c0-43cb-9b75-8fdbdc45840a"
    },
    {
      "id": "040592a3-8dcd-4572-ba79-434385d2bf78",
      "name": "Statistical Characterization",
      "categoryId": "24430edb-10c0-43cb-9b75-8fdbdc45840a"
    },
    {
      "id": "34023b8c-934c-49d0-bfb9-1f23817ab605",
      "name": "Distance Metrics",
      "categoryId": "d62019f9-c4a2-4dac-bf32-19c7b17d3511"
    },
    {
      "id": "467f276f-e9af-44f0-918d-c5cf5aea5304",
      "name": "Geometric Measures",
      "categoryId": "d62019f9-c4a2-4dac-bf32-19c7b17d3511"
    },
    {
      "id": "7824a821-e907-44e3-8698-5a48d6695bf5",
      "name": "Mathematical Foundations",
      "categoryId": "d62019f9-c4a2-4dac-bf32-19c7b17d3511"
    },
    {
      "id": "77205f67-efda-45ee-925e-cc4f68bb3aaf",
      "name": "High-Dimensional Spaces",
      "categoryId": "d62019f9-c4a2-4dac-bf32-19c7b17d3511"
    },
    {
      "id": "f15e99de-ecf1-443a-b512-26126a5fe70e",
      "name": "Quantitative Analysis",
      "categoryId": "d62019f9-c4a2-4dac-bf32-19c7b17d3511"
    },
    {
      "id": "fa8f3824-92f3-4de1-9f6f-8d8d47c50679",
      "name": "Norms and Metrics",
      "categoryId": "d62019f9-c4a2-4dac-bf32-19c7b17d3511"
    },
    {
      "id": "15877e0d-8b09-4ebc-af71-24a4200e86cd",
      "name": "Machine Learning Foundations",
      "categoryId": "d62019f9-c4a2-4dac-bf32-19c7b17d3511"
    },
    {
      "id": "85a76467-7619-4c18-aa37-421ac7a1301b",
      "name": "Data Similarity Measures",
      "categoryId": "d62019f9-c4a2-4dac-bf32-19c7b17d3511"
    },
    {
      "id": "60d6bd0d-bc22-4868-85b0-bd6c422437f4",
      "name": "Neural Networks",
      "categoryId": "84f64004-4381-4e35-8046-d42c8bfffdd6"
    },
    {
      "id": "9c3c68f6-94a0-43ba-bf06-003391a4eb8c",
      "name": "Approximation Theory",
      "categoryId": "84f64004-4381-4e35-8046-d42c8bfffdd6"
    },
    {
      "id": "3c28777d-f943-4f3b-aa62-188083f799d2",
      "name": "Learning Algorithms",
      "categoryId": "84f64004-4381-4e35-8046-d42c8bfffdd6"
    },
    {
      "id": "0fa8e7b3-3387-476a-8bed-8c363fec32b0",
      "name": "Function Approximation",
      "categoryId": "84f64004-4381-4e35-8046-d42c8bfffdd6"
    },
    {
      "id": "4e7d7774-a7f2-4430-83da-02da3d30a7b0",
      "name": "Polynomial Approximation",
      "categoryId": "84f64004-4381-4e35-8046-d42c8bfffdd6"
    },
    {
      "id": "34e1d7da-5e7c-471f-baff-a02284aed23b",
      "name": "Basis Functions",
      "categoryId": "84f64004-4381-4e35-8046-d42c8bfffdd6"
    },
    {
      "id": "e12a2544-cb39-4659-adf6-262534a5c6fa",
      "name": "Nonlinear Networks",
      "categoryId": "84f64004-4381-4e35-8046-d42c8bfffdd6"
    },
    {
      "id": "8c78428e-541c-44f4-9b6c-4aea4edaf5e2",
      "name": "Active Learning",
      "categoryId": "84f64004-4381-4e35-8046-d42c8bfffdd6"
    },
    {
      "id": "c692a9ee-fc1d-4ce2-928b-d8b4690452a9",
      "name": "Adaptive Systems",
      "categoryId": "84f64004-4381-4e35-8046-d42c8bfffdd6"
    },
    {
      "id": "1f166ca4-8073-469a-ae9d-6f78ea6797f0",
      "name": "Approximation Theory",
      "categoryId": "8c0e1c2e-eb30-460a-97b2-0797d71996cd"
    },
    {
      "id": "234c3d94-e212-4819-9792-86f3c48ca6ec",
      "name": "Polynomial Approximation",
      "categoryId": "8c0e1c2e-eb30-460a-97b2-0797d71996cd"
    },
    {
      "id": "f83b3d41-7919-49d6-8336-0785c13f700a",
      "name": "Spectral Methods",
      "categoryId": "8c0e1c2e-eb30-460a-97b2-0797d71996cd"
    },
    {
      "id": "85526b76-ab8a-40bb-8645-2a4cc7f88fc0",
      "name": "Neural Network Architectures",
      "categoryId": "8c0e1c2e-eb30-460a-97b2-0797d71996cd"
    },
    {
      "id": "a12939c1-2b27-4b61-8e58-6f1c1b586b41",
      "name": "Function Approximation",
      "categoryId": "8c0e1c2e-eb30-460a-97b2-0797d71996cd"
    },
    {
      "id": "9d2a1fd9-f138-4046-9d0f-c36dfd142efc",
      "name": "Orthogonal Polynomials",
      "categoryId": "8c0e1c2e-eb30-460a-97b2-0797d71996cd"
    },
    {
      "id": "93ed3b0d-9653-48f7-809d-58c832e01b4d",
      "name": "Chebyshev Polynomials",
      "categoryId": "8c0e1c2e-eb30-460a-97b2-0797d71996cd"
    },
    {
      "id": "c67938dc-949a-4d9f-aff7-f7eb5aaf7608",
      "name": "Polynomial Bases",
      "categoryId": "8c0e1c2e-eb30-460a-97b2-0797d71996cd"
    },
    {
      "id": "861bdce6-c6b4-4356-ae88-4a3b716216e2",
      "name": "Kernel Methods",
      "categoryId": "8c0e1c2e-eb30-460a-97b2-0797d71996cd"
    },
    {
      "id": "a00f01a9-7893-41c7-802e-1f52ce3819c8",
      "name": "Function Spaces",
      "categoryId": "8c0e1c2e-eb30-460a-97b2-0797d71996cd"
    },
    {
      "id": "661d400d-a8ea-488d-8583-1dc911d3c9c9",
      "name": "Polynomial Approximation",
      "categoryId": "3f71e9b9-bb0b-4036-87eb-bc44b0c3c5da"
    },
    {
      "id": "8fa6603f-4d76-41a4-b086-468e7bb1ab78",
      "name": "Spectral Neural Networks",
      "categoryId": "3f71e9b9-bb0b-4036-87eb-bc44b0c3c5da"
    },
    {
      "id": "e7382829-1d71-4d8e-bf0c-940ab3b4ee28",
      "name": "Orthogonal Polynomials",
      "categoryId": "3f71e9b9-bb0b-4036-87eb-bc44b0c3c5da"
    },
    {
      "id": "789a8b3a-f5bd-4888-87dc-d1544b425272",
      "name": "Activation Functions",
      "categoryId": "3f71e9b9-bb0b-4036-87eb-bc44b0c3c5da"
    },
    {
      "id": "d98d1b85-8641-4693-be2e-6cbcc4ef92a7",
      "name": "Function Approximation in ML",
      "categoryId": "3f71e9b9-bb0b-4036-87eb-bc44b0c3c5da"
    },
    {
      "id": "54a720bd-17fb-4cad-bf47-3dccb1679e2b",
      "name": "Model Checkpointing",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "32db80b0-0ef2-47c9-b227-3e63cebf2db2",
      "name": "Training Checkpoints",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "cb69d289-f1a0-4cd5-8148-a64fccff19f8",
      "name": "Model Saving",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "7b476f9d-7967-407d-a30a-f2f3de2b1a94",
      "name": "Training Resilience",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "e22a322b-c857-4f79-8c60-fe68bdde682c",
      "name": "Memory Management in ML",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "0a8a68b9-5cc7-4512-b4da-69167657435d",
      "name": "Model State Preservation",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "30ce13ba-9142-4d4e-aa54-aede57ae2fde",
      "name": "Iteration Snapshots",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "11a99ad8-dd0f-4eda-ab71-d6adaeded918",
      "name": "Training Progress Saving",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "a2d89ad8-6052-4d6b-81e8-08247610a145",
      "name": "Fault Tolerance in ML",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "b49489ec-0d3f-4bfc-804f-ad9b2508fde8",
      "name": "Model Versioning",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "c15871bc-184b-4201-97c3-86d6090fdc6f",
      "name": "AI",
      "categoryId": "318494f6-733c-4be8-85a2-d4be1f934dff"
    },
    {
      "id": "a864922f-3b7b-41af-b453-d3095a365705",
      "name": "model optimization",
      "categoryId": "d4762a61-7adc-436f-873e-25c13a01da66"
    },
    {
      "id": "2719ef0e-d520-49da-a8ed-6fbcef4409a0",
      "name": "training techniques",
      "categoryId": "d4762a61-7adc-436f-873e-25c13a01da66"
    },
    {
      "id": "e44bb249-0cc4-470c-9c4a-c7fbed6f1be1",
      "name": "neural network training",
      "categoryId": "d4762a61-7adc-436f-873e-25c13a01da66"
    },
    {
      "id": "5224a462-802d-4a6f-b4a0-9c5c391a4679",
      "name": "model ensemble methods",
      "categoryId": "d4762a61-7adc-436f-873e-25c13a01da66"
    },
    {
      "id": "00999fa0-7b6e-4dda-8dd0-a41ca58638d3",
      "name": "quality model selection",
      "categoryId": "d4762a61-7adc-436f-873e-25c13a01da66"
    },
    {
      "id": "41880e1e-ef8b-482d-96f4-69197f9d6e1d",
      "name": "Model Checkpoints",
      "categoryId": "8deff07a-6590-4a5a-9069-4b995d98f743"
    },
    {
      "id": "b778e25b-e6eb-44fd-b387-ef034943f36d",
      "name": "Training Progress",
      "categoryId": "8deff07a-6590-4a5a-9069-4b995d98f743"
    },
    {
      "id": "4a5a1cf5-efd7-428a-bcc1-2459af4736cd",
      "name": "Model Saving",
      "categoryId": "8deff07a-6590-4a5a-9069-4b995d98f743"
    },
    {
      "id": "39b44b1d-2d5e-4b1e-b460-481afac47ba8",
      "name": "Model Restoration",
      "categoryId": "8deff07a-6590-4a5a-9069-4b995d98f743"
    },
    {
      "id": "ed6430f6-5372-4a94-b3b9-740cc018904e",
      "name": "Model Versioning",
      "categoryId": "8deff07a-6590-4a5a-9069-4b995d98f743"
    },
    {
      "id": "df55dc63-b88b-4bad-be3a-b167ced4f23f",
      "name": "Checkpoint Files",
      "categoryId": "8deff07a-6590-4a5a-9069-4b995d98f743"
    },
    {
      "id": "ac341139-44b0-4176-babb-816267ae621c",
      "name": "Training States",
      "categoryId": "8deff07a-6590-4a5a-9069-4b995d98f743"
    },
    {
      "id": "292a8972-61a1-43dc-a671-571f5db0ee63",
      "name": "Model Management",
      "categoryId": "8deff07a-6590-4a5a-9069-4b995d98f743"
    },
    {
      "id": "c788e192-7f51-45c8-a7fe-77ae9715558a",
      "name": "Transfer Learning Checkpoints",
      "categoryId": "8deff07a-6590-4a5a-9069-4b995d98f743"
    },
    {
      "id": "e7cea6ec-511f-41f2-9164-39b49f65d2cd",
      "name": "Fine-tuning Checkpoints",
      "categoryId": "8deff07a-6590-4a5a-9069-4b995d98f743"
    },
    {
      "id": "3c7c2b09-fd9f-4f58-a7a1-d6fef3731426",
      "name": "Cheminformatics",
      "categoryId": "dd8ebb43-0c92-420a-baaa-a4cc713818d2"
    },
    {
      "id": "6aadce8e-6db7-4d0b-983b-bda36429dfd2",
      "name": "Chemical Data Analysis",
      "categoryId": "dd8ebb43-0c92-420a-baaa-a4cc713818d2"
    },
    {
      "id": "15f20fe5-6016-4c0e-b608-8903fa28b420",
      "name": "Molecular Modeling",
      "categoryId": "dd8ebb43-0c92-420a-baaa-a4cc713818d2"
    },
    {
      "id": "19ccb3e7-d73c-49f9-9e8a-e48c7fe7a8cf",
      "name": "Quantitative Structure-Activity Relationship (QSAR)",
      "categoryId": "dd8ebb43-0c92-420a-baaa-a4cc713818d2"
    },
    {
      "id": "d30538df-d43b-43d3-a7a9-ff18bd1a37a4",
      "name": "Chemoinformatics",
      "categoryId": "dd8ebb43-0c92-420a-baaa-a4cc713818d2"
    },
    {
      "id": "ffbd43dd-c9ce-49e2-a4c3-dec10f0c8419",
      "name": "Chemical Databases",
      "categoryId": "dd8ebb43-0c92-420a-baaa-a4cc713818d2"
    },
    {
      "id": "b3fb4322-bf35-4f2d-8227-74bee8bfdbcb",
      "name": "Structure-Based Drug Design",
      "categoryId": "dd8ebb43-0c92-420a-baaa-a4cc713818d2"
    },
    {
      "id": "f16f8c4e-2ed5-4b2f-a723-0e7d27de2371",
      "name": "Chemical Informatics",
      "categoryId": "dd8ebb43-0c92-420a-baaa-a4cc713818d2"
    },
    {
      "id": "755d15b6-f6eb-4964-8de8-9146f85ea4c7",
      "name": "Chemical Information Science",
      "categoryId": "dd8ebb43-0c92-420a-baaa-a4cc713818d2"
    },
    {
      "id": "08d0c847-b084-41ea-b1ce-211d5710c73e",
      "name": "Statistical Hypothesis Testing",
      "categoryId": "e4b7a0a6-4954-42e8-8fd8-f3a8835c53fe"
    },
    {
      "id": "8ef09230-c21f-4d47-b5cd-165effc20578",
      "name": "Categorical Data Analysis",
      "categoryId": "e4b7a0a6-4954-42e8-8fd8-f3a8835c53fe"
    },
    {
      "id": "425d62e3-72a0-4e29-a2ab-920d70d73b58",
      "name": "Contingency Tables",
      "categoryId": "e4b7a0a6-4954-42e8-8fd8-f3a8835c53fe"
    },
    {
      "id": "cb7efa9c-96d0-4520-a6ae-0728a057faa6",
      "name": "Independence Testing",
      "categoryId": "e4b7a0a6-4954-42e8-8fd8-f3a8835c53fe"
    },
    {
      "id": "f3db8a84-a411-4169-bd84-f61b644d0dbc",
      "name": "Goodness-of-Fit Tests",
      "categoryId": "e4b7a0a6-4954-42e8-8fd8-f3a8835c53fe"
    },
    {
      "id": "a841c5c8-4e22-4b0e-aafd-803106ac63cd",
      "name": "Non-parametric Testing",
      "categoryId": "e4b7a0a6-4954-42e8-8fd8-f3a8835c53fe"
    },
    {
      "id": "1437017e-cccd-4e1f-96e4-6b9a4acea8a4",
      "name": "Chi-Square Distribution",
      "categoryId": "e4b7a0a6-4954-42e8-8fd8-f3a8835c53fe"
    },
    {
      "id": "c3a51864-a3d4-4aeb-a484-3fda89663159",
      "name": "Statistical Significance",
      "categoryId": "e4b7a0a6-4954-42e8-8fd8-f3a8835c53fe"
    },
    {
      "id": "37dfbdc7-7875-45e8-9d31-7d7eca61c156",
      "name": "p-Values",
      "categoryId": "e4b7a0a6-4954-42e8-8fd8-f3a8835c53fe"
    },
    {
      "id": "462e906f-4a28-4031-ad2e-10f0861203f0",
      "name": "Statistical Hypothesis Testing",
      "categoryId": "4a584d60-b7fc-408a-953d-1145285d0408"
    },
    {
      "id": "0690e099-277c-4725-ab55-31d79cc8f44f",
      "name": "Categorical Data Analysis",
      "categoryId": "4a584d60-b7fc-408a-953d-1145285d0408"
    },
    {
      "id": "d22e4df0-7139-4feb-8252-331c32e0f5c9",
      "name": "Goodness-of-Fit Tests",
      "categoryId": "4a584d60-b7fc-408a-953d-1145285d0408"
    },
    {
      "id": "ba51d876-501a-477e-b61a-7aa69a530ca3",
      "name": "Independence Tests",
      "categoryId": "4a584d60-b7fc-408a-953d-1145285d0408"
    },
    {
      "id": "59847c90-1ee5-4d7b-a1d1-c12beb384399",
      "name": "Chi-Square Distribution",
      "categoryId": "4a584d60-b7fc-408a-953d-1145285d0408"
    },
    {
      "id": "85f41635-c790-4208-904c-9a0ccb88e41c",
      "name": "Data Distributions",
      "categoryId": "4a584d60-b7fc-408a-953d-1145285d0408"
    },
    {
      "id": "a7f2deab-4771-4a38-a350-328abe874b19",
      "name": "Non-parametric Tests",
      "categoryId": "4a584d60-b7fc-408a-953d-1145285d0408"
    },
    {
      "id": "85842a69-6acd-4042-80d5-1b3c184ad4b2",
      "name": "Contingency Tables",
      "categoryId": "4a584d60-b7fc-408a-953d-1145285d0408"
    },
    {
      "id": "ab17754a-d9ed-4690-b6e5-aa662cdca485",
      "name": "Assumption Checks",
      "categoryId": "4a584d60-b7fc-408a-953d-1145285d0408"
    },
    {
      "id": "1243d634-a4ca-4032-b833-2a2a6fbe7d5d",
      "name": "Linear Algebra",
      "categoryId": "735a2dd8-6fc3-4bd6-a899-852cbdf23c99"
    },
    {
      "id": "a4628d48-7610-4b65-b676-2571ae6044c9",
      "name": "Matrix Decomposition",
      "categoryId": "735a2dd8-6fc3-4bd6-a899-852cbdf23c99"
    },
    {
      "id": "10d5197f-39b2-4ba9-9af8-921002878a87",
      "name": "Numerical Methods",
      "categoryId": "735a2dd8-6fc3-4bd6-a899-852cbdf23c99"
    },
    {
      "id": "2e2a265b-7c08-4aac-bcca-af1b9133d00e",
      "name": "Matrix Factorization",
      "categoryId": "735a2dd8-6fc3-4bd6-a899-852cbdf23c99"
    },
    {
      "id": "7df808c1-1b55-4fe7-9328-d72ec328eabb",
      "name": "Numerical Linear Algebra",
      "categoryId": "735a2dd8-6fc3-4bd6-a899-852cbdf23c99"
    },
    {
      "id": "a4d527bd-826e-4ea7-b214-897592c131db",
      "name": "Advanced Matrix Techniques",
      "categoryId": "735a2dd8-6fc3-4bd6-a899-852cbdf23c99"
    },
    {
      "id": "ba25f462-bbd4-4a27-af39-9f26f054c6fc",
      "name": "Optimization Techniques",
      "categoryId": "7e9c0771-3e57-4601-8772-4357a34d7bba"
    },
    {
      "id": "c7e0ec75-dda6-40ca-bf13-e14d1c42d336",
      "name": "Numerical Methods",
      "categoryId": "7e9c0771-3e57-4601-8772-4357a34d7bba"
    },
    {
      "id": "8610311e-2751-48d1-bb4c-d35cde4c7785",
      "name": "Matrix Decomposition",
      "categoryId": "7e9c0771-3e57-4601-8772-4357a34d7bba"
    },
    {
      "id": "fafb901f-600c-49c0-91bc-c52eb7be810f",
      "name": "Linear Algebra",
      "categoryId": "7e9c0771-3e57-4601-8772-4357a34d7bba"
    },
    {
      "id": "493194ba-7686-42b5-ba7a-5b3d4473513c",
      "name": "Convex Optimization",
      "categoryId": "7e9c0771-3e57-4601-8772-4357a34d7bba"
    },
    {
      "id": "1ef856b2-3d96-488e-afb0-1d48127688f3",
      "name": "Machine Learning Algorithms",
      "categoryId": "7e9c0771-3e57-4601-8772-4357a34d7bba"
    },
    {
      "id": "9ac4f4a5-930a-4b5e-992a-94db60c2c8de",
      "name": "Numerical Stability",
      "categoryId": "7e9c0771-3e57-4601-8772-4357a34d7bba"
    },
    {
      "id": "39be0018-920a-4311-a209-f0d61a5d04e9",
      "name": "Positive Definite Matrices",
      "categoryId": "7e9c0771-3e57-4601-8772-4357a34d7bba"
    },
    {
      "id": "abcd3fe0-e817-4944-bee2-396de4de9cbd",
      "name": "Computational Mathematics",
      "categoryId": "7e9c0771-3e57-4601-8772-4357a34d7bba"
    },
    {
      "id": "ca8f7f5e-cad6-4bbc-8ab9-dd172342bf19",
      "name": "Image Processing",
      "categoryId": "48eee011-823f-46be-8f3b-9feca7df5778"
    },
    {
      "id": "6fb43a79-1f52-4f9f-beec-81de704b3ca0",
      "name": "Computational Photography",
      "categoryId": "48eee011-823f-46be-8f3b-9feca7df5778"
    },
    {
      "id": "cc1b6ce4-ac19-4f62-9980-1ab697c26d0c",
      "name": "Optical Corrections",
      "categoryId": "48eee011-823f-46be-8f3b-9feca7df5778"
    },
    {
      "id": "3eae8a88-3c20-4253-a3a5-0ed90853ba53",
      "name": "Digital Imaging",
      "categoryId": "48eee011-823f-46be-8f3b-9feca7df5778"
    },
    {
      "id": "b26da4c0-cf76-4b0e-b01e-6e98690ad842",
      "name": "Image Enhancement",
      "categoryId": "48eee011-823f-46be-8f3b-9feca7df5778"
    },
    {
      "id": "88e96a98-5bd7-4f6c-8559-b3b971b150b9",
      "name": "Photography Techniques",
      "categoryId": "48eee011-823f-46be-8f3b-9feca7df5778"
    },
    {
      "id": "40ec2e38-4882-4296-9f87-146e8b27ca15",
      "name": "Computer Vision",
      "categoryId": "48eee011-823f-46be-8f3b-9feca7df5778"
    },
    {
      "id": "3f09bb9e-509d-43ca-8590-2a61b2591614",
      "name": "Sensor Calibration",
      "categoryId": "48eee011-823f-46be-8f3b-9feca7df5778"
    },
    {
      "id": "18d67120-bfa6-49a7-be24-b5ecb239fdea",
      "name": "Graph Theory",
      "categoryId": "e7ce8e8b-1e14-485b-95f2-8fffc742834b"
    },
    {
      "id": "053f3e66-667b-4b2a-8560-4c69b7d95c2d",
      "name": "Random Graph Models",
      "categoryId": "e7ce8e8b-1e14-485b-95f2-8fffc742834b"
    },
    {
      "id": "70108c4e-1e0b-433e-8347-187ce3a0a7d9",
      "name": "Network Science",
      "categoryId": "e7ce8e8b-1e14-485b-95f2-8fffc742834b"
    },
    {
      "id": "fabb2418-8f89-4ddd-8daf-f2d275b0b10c",
      "name": "Probability Theory",
      "categoryId": "e7ce8e8b-1e14-485b-95f2-8fffc742834b"
    },
    {
      "id": "355fccbb-b2b4-4304-9233-c453b76010ca",
      "name": "Complex Networks",
      "categoryId": "e7ce8e8b-1e14-485b-95f2-8fffc742834b"
    },
    {
      "id": "a7f175da-a4e4-4553-9435-cb7172800a55",
      "name": "Scale-Free Networks",
      "categoryId": "e7ce8e8b-1e14-485b-95f2-8fffc742834b"
    },
    {
      "id": "5ee5f190-e618-4d21-83d7-d6467ba53d5b",
      "name": "Network Topology",
      "categoryId": "e7ce8e8b-1e14-485b-95f2-8fffc742834b"
    },
    {
      "id": "40f65e4d-5ecd-4f16-92bb-9cddc3fb329b",
      "name": "Stochastic Processes",
      "categoryId": "e7ce8e8b-1e14-485b-95f2-8fffc742834b"
    },
    {
      "id": "5f8023a9-efdb-44f8-819f-5b928ee7e3fa",
      "name": "Degree Distribution",
      "categoryId": "e7ce8e8b-1e14-485b-95f2-8fffc742834b"
    },
    {
      "id": "d05ad420-77a6-4985-b68a-532c4d7de485",
      "name": "Network Modeling",
      "categoryId": "e7ce8e8b-1e14-485b-95f2-8fffc742834b"
    },
    {
      "id": "eaf3b6d7-b11b-40c1-8ab7-395ac90a81a7",
      "name": "Natural Language Processing (NLP)",
      "categoryId": "b40e6a87-616a-4670-a592-0f497a51851d"
    },
    {
      "id": "8e3b1a95-023e-4e8f-8a83-882fe8c99405",
      "name": "Data Preprocessing",
      "categoryId": "b40e6a87-616a-4670-a592-0f497a51851d"
    },
    {
      "id": "1b8e4fb2-306f-4625-bbf8-371b1c83cd3e",
      "name": "Sequence Modeling",
      "categoryId": "b40e6a87-616a-4670-a592-0f497a51851d"
    },
    {
      "id": "965d30c7-032f-40a9-a5dc-551cb89d91fe",
      "name": "Embedding Techniques",
      "categoryId": "b40e6a87-616a-4670-a592-0f497a51851d"
    },
    {
      "id": "852eb2eb-a9df-4aa1-a3b9-25682992208b",
      "name": "Hierarchical Clustering",
      "categoryId": "b40e6a87-616a-4670-a592-0f497a51851d"
    },
    {
      "id": "42f0a72d-c01b-4dde-ba2a-65e1241c15d8",
      "name": "Tokenization Methods",
      "categoryId": "b40e6a87-616a-4670-a592-0f497a51851d"
    },
    {
      "id": "5852fd65-47db-4c8f-9ff8-ca6ccde1060c",
      "name": "Contextual Analysis",
      "categoryId": "b40e6a87-616a-4670-a592-0f497a51851d"
    },
    {
      "id": "0749f99c-f658-4ed4-912b-d3a5492a76a5",
      "name": "Memory Networks",
      "categoryId": "b40e6a87-616a-4670-a592-0f497a51851d"
    },
    {
      "id": "18212fb9-17b9-4460-8cbe-8c79a70877d3",
      "name": "Neural Networks",
      "categoryId": "b40e6a87-616a-4670-a592-0f497a51851d"
    },
    {
      "id": "30c3e320-e190-4b18-a0bb-5a203ab4b4da",
      "name": "Deep Learning.",
      "categoryId": "b40e6a87-616a-4670-a592-0f497a51851d"
    },
    {
      "id": "274c2045-864c-4ebd-94b2-bcbcbd9f65c8",
      "name": "Tokenization",
      "categoryId": "dbd57fe6-631d-48dd-ada6-5e05c05ed81b"
    },
    {
      "id": "f021f5f5-b46e-413f-bc8b-2f6a79fbf496",
      "name": "Text Segmentation",
      "categoryId": "dbd57fe6-631d-48dd-ada6-5e05c05ed81b"
    },
    {
      "id": "319379e0-e362-4024-b584-3feb5817046c",
      "name": "Sequence Modeling",
      "categoryId": "dbd57fe6-631d-48dd-ada6-5e05c05ed81b"
    },
    {
      "id": "dcbeec32-62b5-4cc3-b87e-79f2d0c92d43",
      "name": "Linguistic Features",
      "categoryId": "dbd57fe6-631d-48dd-ada6-5e05c05ed81b"
    },
    {
      "id": "6e7c7e9a-29bc-454b-ad6a-eed7bbf3e8f9",
      "name": "Contextual Embedding",
      "categoryId": "dbd57fe6-631d-48dd-ada6-5e05c05ed81b"
    },
    {
      "id": "d4628219-df88-4cae-8ba1-0b33072801d5",
      "name": "Natural Language Processing (NLP)",
      "categoryId": "48cf7045-f678-452c-af24-2af663372278"
    },
    {
      "id": "826ac484-7fb2-4191-926b-2dce323c3436",
      "name": "Automatic Image Captioning",
      "categoryId": "48cf7045-f678-452c-af24-2af663372278"
    },
    {
      "id": "fc5451d7-a277-4a50-93ef-8927d188662f",
      "name": "Image Caption Evaluation",
      "categoryId": "48cf7045-f678-452c-af24-2af663372278"
    },
    {
      "id": "eb106bb0-7af4-4614-98c0-ddfc06697c39",
      "name": "Text Similarity Metrics",
      "categoryId": "48cf7045-f678-452c-af24-2af663372278"
    },
    {
      "id": "ec09cd8d-3943-4258-94cc-9acf66adbe66",
      "name": "Evaluation Criteria for Generated Content",
      "categoryId": "48cf7045-f678-452c-af24-2af663372278"
    },
    {
      "id": "3649ba56-03d1-4d8e-b1d3-8d3b857b27a8",
      "name": "Caption Quality Assessment",
      "categoryId": "48cf7045-f678-452c-af24-2af663372278"
    },
    {
      "id": "c5e03689-1391-49f8-a791-88adf22f1f4e",
      "name": "Image Classification",
      "categoryId": "786a9a94-7a56-4185-a591-b22a21025404"
    },
    {
      "id": "4f47ba87-799d-47cd-9ad5-c44e1544be0e",
      "name": "Computer Vision",
      "categoryId": "786a9a94-7a56-4185-a591-b22a21025404"
    },
    {
      "id": "1b5d75d7-b539-4d49-8e9c-ed16f8548c82",
      "name": "Dataset",
      "categoryId": "786a9a94-7a56-4185-a591-b22a21025404"
    },
    {
      "id": "0577c12a-8cc2-41e1-b92d-a2aa6be34fa1",
      "name": "CIFAR-10",
      "categoryId": "786a9a94-7a56-4185-a591-b22a21025404"
    },
    {
      "id": "e5c7380d-4def-4a1b-8bdc-b69415a7288d",
      "name": "Deep Learning",
      "categoryId": "786a9a94-7a56-4185-a591-b22a21025404"
    },
    {
      "id": "31e52cf6-2a53-4120-ba34-12fbd80df6ed",
      "name": "Machine Learning",
      "categoryId": "786a9a94-7a56-4185-a591-b22a21025404"
    },
    {
      "id": "70c22687-d182-4a52-97a5-bd6039e62ea5",
      "name": "Dataset Benchmark",
      "categoryId": "786a9a94-7a56-4185-a591-b22a21025404"
    },
    {
      "id": "a75a1cad-ce3e-440e-9912-6cd73ea54fc2",
      "name": "Visual Recognition",
      "categoryId": "786a9a94-7a56-4185-a591-b22a21025404"
    },
    {
      "id": "75fa8c2a-7309-4452-92ef-79e645524080",
      "name": "Supervised Learning",
      "categoryId": "786a9a94-7a56-4185-a591-b22a21025404"
    },
    {
      "id": "0d955c26-ae39-4462-9772-f5050f060792",
      "name": "Data Augmentation",
      "categoryId": "786a9a94-7a56-4185-a591-b22a21025404"
    },
    {
      "id": "c371ea5b-ccb9-483b-b022-b53fea61e61c",
      "name": "Image Classification",
      "categoryId": "5032c5e9-c216-4409-b331-6956f5df4c8f"
    },
    {
      "id": "852f6281-f6d1-42d6-9fc7-7c87edaa5ea5",
      "name": "Dataset",
      "categoryId": "5032c5e9-c216-4409-b331-6956f5df4c8f"
    },
    {
      "id": "de5026de-9a6a-4bcc-bc04-5385747cc109",
      "name": "Computer Vision",
      "categoryId": "5032c5e9-c216-4409-b331-6956f5df4c8f"
    },
    {
      "id": "b1294857-06c7-4655-b30d-7e26a5bba257",
      "name": "Multiclass Classification",
      "categoryId": "5032c5e9-c216-4409-b331-6956f5df4c8f"
    },
    {
      "id": "b8a9a437-a7d3-4be8-8df5-aff884c11b73",
      "name": "Benchmark Dataset",
      "categoryId": "5032c5e9-c216-4409-b331-6956f5df4c8f"
    },
    {
      "id": "d3fa8795-10f3-4cea-952e-eac0ba000c43",
      "name": "Visual Recognition",
      "categoryId": "5032c5e9-c216-4409-b331-6956f5df4c8f"
    },
    {
      "id": "3d16b948-e030-4159-9e53-f1580b55b6b7",
      "name": "Dataset Annotation",
      "categoryId": "5032c5e9-c216-4409-b331-6956f5df4c8f"
    },
    {
      "id": "90dc9c35-05a3-4162-bf54-0693296f23a3",
      "name": "CNN Training",
      "categoryId": "5032c5e9-c216-4409-b331-6956f5df4c8f"
    },
    {
      "id": "548275d6-b6b1-46aa-b0fb-e57c15bccb4a",
      "name": "Data Augmentation",
      "categoryId": "5032c5e9-c216-4409-b331-6956f5df4c8f"
    },
    {
      "id": "990cd93b-f999-49bd-bc6b-53bd3e27f6c0",
      "name": "Dataset Curation",
      "categoryId": "5032c5e9-c216-4409-b331-6956f5df4c8f"
    },
    {
      "id": "91bd5334-959f-4e3b-9ae9-4e9b0bd29b21",
      "name": "Class Incremental Learning (CIL) falls under the broader categories of Continual Learning",
      "categoryId": "8a32ca49-a730-42ed-9b0e-ff477cbaedb0"
    },
    {
      "id": "75e15e6f-6aff-42cb-8de3-4392b25dca84",
      "name": "Lifelong Learning",
      "categoryId": "8a32ca49-a730-42ed-9b0e-ff477cbaedb0"
    },
    {
      "id": "4cd03244-8511-43f6-9a09-f6e3b5d390bc",
      "name": "and Incremental Learning. It is a subfield dedicated to enabling models to learn from new data streams incrementally while retaining previously acquired knowledge",
      "categoryId": "8a32ca49-a730-42ed-9b0e-ff477cbaedb0"
    },
    {
      "id": "0464a548-f4e7-4924-a027-9627258f6f0e",
      "name": "thus addressing issues like catastrophic forgetting. Related sub-category tags include Online Learning",
      "categoryId": "8a32ca49-a730-42ed-9b0e-ff477cbaedb0"
    },
    {
      "id": "86ba27da-40a2-4c21-8d1e-498531487836",
      "name": "Adaptive Learning",
      "categoryId": "8a32ca49-a730-42ed-9b0e-ff477cbaedb0"
    },
    {
      "id": "39ec3cba-3139-4940-a7d9-37b2b9ee91b4",
      "name": "and Dynamic Model Updating.",
      "categoryId": "8a32ca49-a730-42ed-9b0e-ff477cbaedb0"
    },
    {
      "id": "a78b9ccc-36dd-4b5d-a390-80d4da62f7f3",
      "name": "Circuit Analysis",
      "categoryId": "2ee5dd7e-b360-4cd3-a7c5-64294a8eedd6"
    },
    {
      "id": "b7df4158-8dd3-4d0f-ac19-53e7fe5cf19e",
      "name": "Electrical Engineering",
      "categoryId": "2ee5dd7e-b360-4cd3-a7c5-64294a8eedd6"
    },
    {
      "id": "f6e67462-7e55-42ae-8046-93cf73cb9278",
      "name": "Electronics",
      "categoryId": "2ee5dd7e-b360-4cd3-a7c5-64294a8eedd6"
    },
    {
      "id": "57f67967-be74-4dc9-9b14-03193d6534c2",
      "name": "Circuit Theory",
      "categoryId": "2ee5dd7e-b360-4cd3-a7c5-64294a8eedd6"
    },
    {
      "id": "4a37d945-2beb-4cde-a1c8-bcc0637c7ae5",
      "name": "Circuit Simulation",
      "categoryId": "2ee5dd7e-b360-4cd3-a7c5-64294a8eedd6"
    },
    {
      "id": "ac9ce9b9-867e-45ce-bbe2-36b00913b833",
      "name": "Signal Processing",
      "categoryId": "2ee5dd7e-b360-4cd3-a7c5-64294a8eedd6"
    },
    {
      "id": "ff9e011a-09cd-4c23-b55a-c8c77ee226a2",
      "name": "Power Systems",
      "categoryId": "2ee5dd7e-b360-4cd3-a7c5-64294a8eedd6"
    },
    {
      "id": "27ecd275-8b81-4956-8073-dc689d51bc37",
      "name": "Analog Circuits",
      "categoryId": "2ee5dd7e-b360-4cd3-a7c5-64294a8eedd6"
    },
    {
      "id": "eeaec218-eb91-42ba-9ee4-a3798e0d779a",
      "name": "Digital Circuits",
      "categoryId": "2ee5dd7e-b360-4cd3-a7c5-64294a8eedd6"
    },
    {
      "id": "16395455-79d4-43fc-84ba-d12187bf32bd",
      "name": "Transient Analysis",
      "categoryId": "2ee5dd7e-b360-4cd3-a7c5-64294a8eedd6"
    },
    {
      "id": "e934ddcc-03bf-46e6-8b90-3b44988b3e49",
      "name": "Steady-State Analysis",
      "categoryId": "2ee5dd7e-b360-4cd3-a7c5-64294a8eedd6"
    },
    {
      "id": "a7da6a21-c17f-41f3-8325-73c323f10e8f",
      "name": "Complexity Theory",
      "categoryId": "93554169-5d1b-40f0-8055-a66f5ccab707"
    },
    {
      "id": "09d6e802-385c-46eb-8c9e-09194810febe",
      "name": "Computational Complexity",
      "categoryId": "93554169-5d1b-40f0-8055-a66f5ccab707"
    },
    {
      "id": "fc3a4ed9-fe59-4975-93fc-03e14db9145c",
      "name": "Boolean Circuits",
      "categoryId": "93554169-5d1b-40f0-8055-a66f5ccab707"
    },
    {
      "id": "bb2d90da-6ac0-47c7-a178-c49859d78b3e",
      "name": "Logical Circuits",
      "categoryId": "93554169-5d1b-40f0-8055-a66f5ccab707"
    },
    {
      "id": "7034591d-8a68-45e9-9a8f-08228ba57201",
      "name": "Algorithm Analysis",
      "categoryId": "93554169-5d1b-40f0-8055-a66f5ccab707"
    },
    {
      "id": "104c8ca5-fa05-4603-bda8-033956c2fc2b",
      "name": "Circuit Optimization",
      "categoryId": "93554169-5d1b-40f0-8055-a66f5ccab707"
    },
    {
      "id": "cf9bf69f-b4b1-4ea2-8b1d-028f3f431835",
      "name": "NP-Completeness",
      "categoryId": "93554169-5d1b-40f0-8055-a66f5ccab707"
    },
    {
      "id": "766628db-5d29-454b-b00d-37a68d8f675a",
      "name": "Circuit Depth",
      "categoryId": "93554169-5d1b-40f0-8055-a66f5ccab707"
    },
    {
      "id": "6edab30f-6684-4aae-90ba-d66cf65d52ad",
      "name": "Circuit Size",
      "categoryId": "93554169-5d1b-40f0-8055-a66f5ccab707"
    },
    {
      "id": "e8e5be7e-f04d-4c6c-bfa8-26f54707a832",
      "name": "Boolean Function Complexity",
      "categoryId": "93554169-5d1b-40f0-8055-a66f5ccab707"
    },
    {
      "id": "fb87a3c4-8c8e-4c70-9be7-4840db7531bc",
      "name": "Circuit-level Analysis",
      "categoryId": "a36dd3a1-7144-4917-a772-4719bfaba07b"
    },
    {
      "id": "6a345bc7-3a3a-48f1-8a54-6d1efc751b58",
      "name": "Digital Circuits",
      "categoryId": "a36dd3a1-7144-4917-a772-4719bfaba07b"
    },
    {
      "id": "762de29f-9a34-4943-8a93-e2500e5f78e9",
      "name": "Analog Circuits",
      "categoryId": "a36dd3a1-7144-4917-a772-4719bfaba07b"
    },
    {
      "id": "836aa276-8a31-4a00-ad1a-8252330f3b89",
      "name": "Circuit Simulation",
      "categoryId": "a36dd3a1-7144-4917-a772-4719bfaba07b"
    },
    {
      "id": "66589c39-63a2-4496-868b-e04e1645b436",
      "name": "Electrical Engineering",
      "categoryId": "a36dd3a1-7144-4917-a772-4719bfaba07b"
    },
    {
      "id": "0bcbb600-46c9-4ae7-b562-ec7dfd6fc678",
      "name": "SPICE Modeling",
      "categoryId": "a36dd3a1-7144-4917-a772-4719bfaba07b"
    },
    {
      "id": "e82e1ba7-8308-4c74-9190-09af35ffbf1a",
      "name": "Circuit Testing",
      "categoryId": "a36dd3a1-7144-4917-a772-4719bfaba07b"
    },
    {
      "id": "b30a82f6-a0f7-4745-9012-26839c03fa88",
      "name": "Transistor Models",
      "categoryId": "a36dd3a1-7144-4917-a772-4719bfaba07b"
    },
    {
      "id": "e32657f3-48cc-4381-8fa8-cf0db43a6000",
      "name": "Circuit Optimization",
      "categoryId": "a36dd3a1-7144-4917-a772-4719bfaba07b"
    },
    {
      "id": "a2177c51-ce9b-4b53-9b9c-be9cd36b1334",
      "name": "Electrical Design",
      "categoryId": "a36dd3a1-7144-4917-a772-4719bfaba07b"
    },
    {
      "id": "9f6a86e7-a75e-4d4d-9107-b55507ba4b6c",
      "name": "Signal Processing",
      "categoryId": "39be3d34-0ca3-4a3e-9043-67f635a219ad"
    },
    {
      "id": "068c335a-539f-4d2d-8e57-9a88e9dc2ed4",
      "name": "Digital Signal Processing (DSP)",
      "categoryId": "39be3d34-0ca3-4a3e-9043-67f635a219ad"
    },
    {
      "id": "ae96917d-d1d6-47d5-8cbb-01ec973227ba",
      "name": "Discrete Mathematics",
      "categoryId": "39be3d34-0ca3-4a3e-9043-67f635a219ad"
    },
    {
      "id": "ba018d72-0c28-43df-b55e-308be4cb9690",
      "name": "Fourier Transform",
      "categoryId": "39be3d34-0ca3-4a3e-9043-67f635a219ad"
    },
    {
      "id": "32443b84-f383-47d5-b5e3-1c9cf7cb2212",
      "name": "Time Series Analysis",
      "categoryId": "39be3d34-0ca3-4a3e-9043-67f635a219ad"
    },
    {
      "id": "2c7cd79c-b0d3-4562-b280-a8526e5badd3",
      "name": "Linear Systems",
      "categoryId": "39be3d34-0ca3-4a3e-9043-67f635a219ad"
    },
    {
      "id": "b1cd60a9-d3d7-497f-b3e3-cbb3dcf45e56",
      "name": "Spectral Analysis",
      "categoryId": "39be3d34-0ca3-4a3e-9043-67f635a219ad"
    },
    {
      "id": "cffdfdb9-44a2-4fa6-893d-a89e74b76238",
      "name": "Fourier Convolution",
      "categoryId": "39be3d34-0ca3-4a3e-9043-67f635a219ad"
    },
    {
      "id": "b25bdc9c-895d-4cc4-be8b-e7ab3ecc519c",
      "name": "Periodic Signals",
      "categoryId": "39be3d34-0ca3-4a3e-9043-67f635a219ad"
    },
    {
      "id": "99803fc0-b4d6-4a2f-8f82-672db91aa90f",
      "name": "Convolutional Neural Networks (CNNs)",
      "categoryId": "0dfcee6a-536d-4ef4-a0de-559d865483b1"
    },
    {
      "id": "f07c5938-e5fb-46d7-a3a4-1dc5091bb2a8",
      "name": "Padding Techniques",
      "categoryId": "0dfcee6a-536d-4ef4-a0de-559d865483b1"
    },
    {
      "id": "afdd16b2-d26b-473f-8656-8cf0007d40d8",
      "name": "Zero Padding",
      "categoryId": "0dfcee6a-536d-4ef4-a0de-559d865483b1"
    },
    {
      "id": "59b08657-0894-4af2-bf46-f29c4006bd9a",
      "name": "Spatial Padding",
      "categoryId": "0dfcee6a-536d-4ef4-a0de-559d865483b1"
    },
    {
      "id": "90dcc8c5-23e7-4344-969f-5bf606390e90",
      "name": "Edge Handling",
      "categoryId": "0dfcee6a-536d-4ef4-a0de-559d865483b1"
    },
    {
      "id": "2dcdf16b-beb0-45ef-9168-ad71201b9b76",
      "name": "Data Augmentation",
      "categoryId": "0dfcee6a-536d-4ef4-a0de-559d865483b1"
    },
    {
      "id": "0fa71e0c-b543-4d49-beec-29dd983ab33d",
      "name": "Image Processing",
      "categoryId": "0dfcee6a-536d-4ef4-a0de-559d865483b1"
    },
    {
      "id": "098e416a-cb46-4b80-94dc-b5850ec839d9",
      "name": "Deep Learning Architectures",
      "categoryId": "0dfcee6a-536d-4ef4-a0de-559d865483b1"
    },
    {
      "id": "53ae827d-bb7e-4aa1-a8aa-786650f18f0d",
      "name": "Convolutional Neural Networks",
      "categoryId": "8736cab5-b049-49ba-8ecb-d6adf52db283"
    },
    {
      "id": "d71f2724-25c5-4aff-89b9-1019fac34837",
      "name": "Padding Techniques",
      "categoryId": "8736cab5-b049-49ba-8ecb-d6adf52db283"
    },
    {
      "id": "ba41131b-5f1a-4f78-aff5-b3ca0483ccd9",
      "name": "Circular Padding",
      "categoryId": "8736cab5-b049-49ba-8ecb-d6adf52db283"
    },
    {
      "id": "2b4f013d-d911-40f4-99e8-1ec825eb76b2",
      "name": "Image Processing",
      "categoryId": "8736cab5-b049-49ba-8ecb-d6adf52db283"
    },
    {
      "id": "1e513e4a-9908-45d5-a048-0758dd7e10d7",
      "name": "Deep Learning Architectures",
      "categoryId": "8736cab5-b049-49ba-8ecb-d6adf52db283"
    },
    {
      "id": "822005a8-cbee-4d1b-b428-7685d814e004",
      "name": "Data Augmentation",
      "categoryId": "8736cab5-b049-49ba-8ecb-d6adf52db283"
    },
    {
      "id": "562f0c21-0104-4c67-9852-4dc7d61901f6",
      "name": "Feature Extraction",
      "categoryId": "8736cab5-b049-49ba-8ecb-d6adf52db283"
    },
    {
      "id": "f0a478b6-ee0a-481d-89ba-64d33a762812",
      "name": "Convolution Operations",
      "categoryId": "8736cab5-b049-49ba-8ecb-d6adf52db283"
    },
    {
      "id": "cefc4c28-db9d-4bde-963f-8cbedf61839b",
      "name": "Computer Vision",
      "categoryId": "770275c8-501e-43f4-9122-a75655ed7702"
    },
    {
      "id": "c68ccb81-ea6c-4f96-b490-02f203a5c05d",
      "name": "Deep Learning",
      "categoryId": "770275c8-501e-43f4-9122-a75655ed7702"
    },
    {
      "id": "77aeb250-c61f-47c4-90f9-8bf009329a2a",
      "name": "Model Interpretability",
      "categoryId": "770275c8-501e-43f4-9122-a75655ed7702"
    },
    {
      "id": "b1d6116d-48fc-427d-9140-fdbbdea21915",
      "name": "Convolutional Neural Networks (CNNs)",
      "categoryId": "770275c8-501e-43f4-9122-a75655ed7702"
    },
    {
      "id": "6c2b839b-1f55-41c3-9b1f-a2bc9038b010",
      "name": "Visualization Techniques",
      "categoryId": "770275c8-501e-43f4-9122-a75655ed7702"
    },
    {
      "id": "44aa0380-e7d2-4023-a19e-7fb13df50010",
      "name": "Explanation Methods",
      "categoryId": "770275c8-501e-43f4-9122-a75655ed7702"
    },
    {
      "id": "4c8069ee-53a8-4ef4-94c2-a36c6e96f45d",
      "name": "Feature Localization",
      "categoryId": "770275c8-501e-43f4-9122-a75655ed7702"
    },
    {
      "id": "6ad06b00-86ca-48dc-bdde-847eee23b4c1",
      "name": "Class Activation Maps (CAM)",
      "categoryId": "e0e205da-d6bb-4974-a029-a7874bb8fbb9"
    },
    {
      "id": "ebb4ee88-b3c8-41e4-9578-b3607e4b1399",
      "name": "visualization",
      "categoryId": "e0e205da-d6bb-4974-a029-a7874bb8fbb9"
    },
    {
      "id": "b6b58096-5423-43b0-932c-6b3ebf6abd79",
      "name": "CNN interpretability",
      "categoryId": "e0e205da-d6bb-4974-a029-a7874bb8fbb9"
    },
    {
      "id": "478d7314-410d-4143-af6b-892364bdec98",
      "name": "image classification",
      "categoryId": "e0e205da-d6bb-4974-a029-a7874bb8fbb9"
    },
    {
      "id": "639a9e7a-d4b2-4563-b4d1-7247517d7be9",
      "name": "deep learning explainability",
      "categoryId": "e0e205da-d6bb-4974-a029-a7874bb8fbb9"
    },
    {
      "id": "989fc5db-194f-4789-9a95-f0a462ab04e0",
      "name": "feature localization",
      "categoryId": "e0e205da-d6bb-4974-a029-a7874bb8fbb9"
    },
    {
      "id": "77cc7b22-7de4-411b-bb0d-a0bc0e1a7cb8",
      "name": "model transparency",
      "categoryId": "e0e205da-d6bb-4974-a029-a7874bb8fbb9"
    },
    {
      "id": "5cf8a927-8feb-48cd-9320-225dfc9102e9",
      "name": "heatmaps",
      "categoryId": "e0e205da-d6bb-4974-a029-a7874bb8fbb9"
    },
    {
      "id": "0a5e30b6-df7d-4e4f-ac81-d1fb122e6d21",
      "name": "neural network visualization",
      "categoryId": "e0e205da-d6bb-4974-a029-a7874bb8fbb9"
    },
    {
      "id": "9dbdb4dd-4d99-4ee2-88bc-238da52bedb4",
      "name": "spatial attention",
      "categoryId": "e0e205da-d6bb-4974-a029-a7874bb8fbb9"
    },
    {
      "id": "fd6ee4dd-8d34-4f24-9460-c4646b1c9276",
      "name": "Data Sampling",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "dcc46fa0-54dd-4658-b6b7-b6a55428e1bd",
      "name": "Class Balancing",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "9f55c405-c2e2-4474-8242-f2e770ab3cb5",
      "name": "Imbalanced Datasets",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "7014656d-e428-4f6c-8ca2-444896468b65",
      "name": "Data Augmentation",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "657fe139-3202-40fb-8316-ef6ab4d25d5b",
      "name": "Data Resampling",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "c011bef1-a7e6-418c-af21-bcbc17155a23",
      "name": "Synthetic Data Generation",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "b8ae509c-d63e-4acc-b6cf-bf856f0b7296",
      "name": "Oversampling",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "427e4b56-0011-471f-9317-c58110cbc8af",
      "name": "Undersampling",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "4615ea88-6d9e-48c3-aa87-48b769100862",
      "name": "Data Preprocessing",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "2bf35fa7-0554-4bbd-86f1-3b5c56b7d15b",
      "name": "Class Imbalance",
      "categoryId": "0908d6eb-5bba-4add-bb6e-b82240de00c4"
    },
    {
      "id": "73a155e3-8766-49f5-982a-f2296e2b6698",
      "name": "Data Imbalance",
      "categoryId": "0908d6eb-5bba-4add-bb6e-b82240de00c4"
    },
    {
      "id": "2ca2835d-40b3-47d7-bbef-bbd1c581865e",
      "name": "Skewed Data",
      "categoryId": "0908d6eb-5bba-4add-bb6e-b82240de00c4"
    },
    {
      "id": "5d2da559-c9e4-400e-8da4-555bdfc24fa8",
      "name": "Imbalanced Datasets",
      "categoryId": "0908d6eb-5bba-4add-bb6e-b82240de00c4"
    },
    {
      "id": "a6542fdb-c757-4372-ba7e-8ae4e0ca6adf",
      "name": "Classification Challenges",
      "categoryId": "0908d6eb-5bba-4add-bb6e-b82240de00c4"
    },
    {
      "id": "40cd1335-7af5-49a7-bf31-5621435a1926",
      "name": "Minority Class",
      "categoryId": "0908d6eb-5bba-4add-bb6e-b82240de00c4"
    },
    {
      "id": "8e2f5c52-e028-413e-9805-73bc3292d022",
      "name": "Majority Class",
      "categoryId": "0908d6eb-5bba-4add-bb6e-b82240de00c4"
    },
    {
      "id": "6f9a0ff6-94a5-4c2a-a65d-3172d9480214",
      "name": "Data Distribution",
      "categoryId": "0908d6eb-5bba-4add-bb6e-b82240de00c4"
    },
    {
      "id": "fe66d1d1-d784-4111-a027-8959686a63e5",
      "name": "Dataset Bias",
      "categoryId": "0908d6eb-5bba-4add-bb6e-b82240de00c4"
    },
    {
      "id": "37f89ee0-98d6-4bd1-9c54-3d29b8bc2ebe",
      "name": "Machine Learning Data Issues",
      "categoryId": "0908d6eb-5bba-4add-bb6e-b82240de00c4"
    },
    {
      "id": "a35c0d6c-aca0-4e68-b0de-f64a5ac565eb",
      "name": "Supervised Learning",
      "categoryId": "64b1cb6c-0424-4d85-9ddb-cfaa727c482e"
    },
    {
      "id": "5ebcb93c-600f-4d63-9dcd-2821769e7e6c",
      "name": "Imbalanced Datasets",
      "categoryId": "64b1cb6c-0424-4d85-9ddb-cfaa727c482e"
    },
    {
      "id": "4779a425-44ab-4be2-9ad4-a8b38cdf03db",
      "name": "Model Optimization",
      "categoryId": "64b1cb6c-0424-4d85-9ddb-cfaa727c482e"
    },
    {
      "id": "a0397b3a-5390-4355-884f-053d3750e926",
      "name": "Cost-sensitive Learning",
      "categoryId": "64b1cb6c-0424-4d85-9ddb-cfaa727c482e"
    },
    {
      "id": "2da28884-fde8-4983-9297-6e1fa0971730",
      "name": "Loss Function Customization",
      "categoryId": "64b1cb6c-0424-4d85-9ddb-cfaa727c482e"
    },
    {
      "id": "d80a09bc-5d5b-416d-84c1-398badf9483e",
      "name": "Class Imbalance Handling",
      "categoryId": "64b1cb6c-0424-4d85-9ddb-cfaa727c482e"
    },
    {
      "id": "4f623fff-ab20-4286-8d54-ee90918e522c",
      "name": "Machine Learning Techniques",
      "categoryId": "64b1cb6c-0424-4d85-9ddb-cfaa727c482e"
    },
    {
      "id": "8a2beb20-22b9-4e36-9f1f-1196ce90c69e",
      "name": "Model Evaluation Strategies",
      "categoryId": "64b1cb6c-0424-4d85-9ddb-cfaa727c482e"
    },
    {
      "id": "c50da3a6-7488-4cd5-ad5d-747a201ee147",
      "name": "Class-balanced Loss",
      "categoryId": "16a15cef-10ad-4515-8117-d55207019792"
    },
    {
      "id": "c43a45a9-f124-42ab-9039-fa1a97e04623",
      "name": "Loss Functions",
      "categoryId": "16a15cef-10ad-4515-8117-d55207019792"
    },
    {
      "id": "99fb2d53-bdf3-4b99-ba40-0bb1190cc6da",
      "name": "Imbalanced Data",
      "categoryId": "16a15cef-10ad-4515-8117-d55207019792"
    },
    {
      "id": "5b10b478-4f78-400f-90e1-2a57eb66d852",
      "name": "Machine Learning",
      "categoryId": "16a15cef-10ad-4515-8117-d55207019792"
    },
    {
      "id": "0fb66f7b-3c7e-44fc-814d-ca3600bb4cc4",
      "name": "Deep Learning",
      "categoryId": "16a15cef-10ad-4515-8117-d55207019792"
    },
    {
      "id": "b923b4be-fa5f-4115-b62b-f318b73286f2",
      "name": "Class Imbalance",
      "categoryId": "16a15cef-10ad-4515-8117-d55207019792"
    },
    {
      "id": "219a5812-b3bf-45a0-9ce2-30c244e1f53f",
      "name": "Data Sampling",
      "categoryId": "16a15cef-10ad-4515-8117-d55207019792"
    },
    {
      "id": "9794cf81-5856-497a-8ecb-a3726f333fd4",
      "name": "Loss Weighting",
      "categoryId": "16a15cef-10ad-4515-8117-d55207019792"
    },
    {
      "id": "0a687f38-2da7-47f5-8242-1c7c9abaec79",
      "name": "Cost-sensitive Learning",
      "categoryId": "16a15cef-10ad-4515-8117-d55207019792"
    },
    {
      "id": "42304231-905a-4c51-a537-acd81e651a65",
      "name": "Model Optimization",
      "categoryId": "16a15cef-10ad-4515-8117-d55207019792"
    },
    {
      "id": "6c97db1a-3406-4140-a6f7-7488e058f026",
      "name": "Machine Learning",
      "categoryId": "cf218244-1683-4c33-a1a1-d49146732ac2"
    },
    {
      "id": "1c3fd716-627a-4822-a339-ee6e34d071f6",
      "name": "Data Sampling",
      "categoryId": "cf218244-1683-4c33-a1a1-d49146732ac2"
    },
    {
      "id": "0abc31de-bfe9-4dd5-a1c6-8af88d029834",
      "name": "Class Imbalance",
      "categoryId": "cf218244-1683-4c33-a1a1-d49146732ac2"
    },
    {
      "id": "cd9b6b6b-4533-49b5-9481-6b64ebfda008",
      "name": "Data Balancing Techniques",
      "categoryId": "cf218244-1683-4c33-a1a1-d49146732ac2"
    },
    {
      "id": "f90c1e7e-02da-4e83-9771-06da91390a28",
      "name": "Supervised Learning",
      "categoryId": "cf218244-1683-4c33-a1a1-d49146732ac2"
    },
    {
      "id": "d676a47c-8356-4e84-bc8d-e890979bafd4",
      "name": "Dataset Preparation",
      "categoryId": "cf218244-1683-4c33-a1a1-d49146732ac2"
    },
    {
      "id": "bcdf0a78-c033-4871-94a7-3f5d4a8166d1",
      "name": "Supervised Learning",
      "categoryId": "eb5dbbce-e8ae-43b2-8571-74697de70585"
    },
    {
      "id": "c34d1443-ac6f-4392-8471-5db3f2095870",
      "name": "Loss Functions",
      "categoryId": "eb5dbbce-e8ae-43b2-8571-74697de70585"
    },
    {
      "id": "44f99bd9-6ff5-4e4a-b466-6a348444ea93",
      "name": "Class Imbalance",
      "categoryId": "eb5dbbce-e8ae-43b2-8571-74697de70585"
    },
    {
      "id": "28212bfb-b91c-4b45-930b-89a4fc05dbef",
      "name": "Model Optimization",
      "categoryId": "eb5dbbce-e8ae-43b2-8571-74697de70585"
    },
    {
      "id": "f6f7ab0a-8668-49e3-a990-e48f529902a4",
      "name": "Cost-sensitive Learning",
      "categoryId": "eb5dbbce-e8ae-43b2-8571-74697de70585"
    },
    {
      "id": "ca3ba83b-6e26-4f96-b594-8aa4ced27be7",
      "name": "Data Sampling Strategies",
      "categoryId": "eb5dbbce-e8ae-43b2-8571-74697de70585"
    },
    {
      "id": "1403bea6-a9ba-4ff1-837b-f9ab6b6387ff",
      "name": "Classification",
      "categoryId": "4cd7a78e-22b9-4a6f-92c8-fec5215dd5ca"
    },
    {
      "id": "55a0e243-1f9b-406f-820a-6c4f42352ddb",
      "name": "Supervised Learning",
      "categoryId": "4cd7a78e-22b9-4a6f-92c8-fec5215dd5ca"
    },
    {
      "id": "d40b6333-2f70-43d0-8053-7b78bfeb3620",
      "name": "Binary Classification",
      "categoryId": "4cd7a78e-22b9-4a6f-92c8-fec5215dd5ca"
    },
    {
      "id": "275ddcf4-34c4-4cf0-b595-f97334d08e5e",
      "name": "Multiclass Classification",
      "categoryId": "4cd7a78e-22b9-4a6f-92c8-fec5215dd5ca"
    },
    {
      "id": "66c85043-cd1c-4fb9-a94a-f51957d27942",
      "name": "Multi-label Classification",
      "categoryId": "4cd7a78e-22b9-4a6f-92c8-fec5215dd5ca"
    },
    {
      "id": "c3422152-5aba-41af-a64c-14ccfa6ac248",
      "name": "Logistic Regression",
      "categoryId": "4cd7a78e-22b9-4a6f-92c8-fec5215dd5ca"
    },
    {
      "id": "87fb5bb1-25db-4cef-ba01-aa32536c70a0",
      "name": "Decision Trees",
      "categoryId": "4cd7a78e-22b9-4a6f-92c8-fec5215dd5ca"
    },
    {
      "id": "5ff98483-b47d-47d8-afa3-b9e655003aac",
      "name": "Support Vector Machines",
      "categoryId": "4cd7a78e-22b9-4a6f-92c8-fec5215dd5ca"
    },
    {
      "id": "9099fc24-6497-4a44-b5f9-7aac929621a7",
      "name": "Neural Networks",
      "categoryId": "4cd7a78e-22b9-4a6f-92c8-fec5215dd5ca"
    },
    {
      "id": "aedc4a52-7555-49bc-9034-d424f3608502",
      "name": "Probabilistic Models",
      "categoryId": "4cd7a78e-22b9-4a6f-92c8-fec5215dd5ca"
    },
    {
      "id": "ea511476-b2d3-4ebe-ba7e-bce338494060",
      "name": "Pattern Recognition",
      "categoryId": "4cd7a78e-22b9-4a6f-92c8-fec5215dd5ca"
    },
    {
      "id": "56d086f4-defb-4263-9814-9158a21a5d4e",
      "name": "Data Labeling",
      "categoryId": "4cd7a78e-22b9-4a6f-92c8-fec5215dd5ca"
    },
    {
      "id": "9d386735-b193-4aec-bd32-05fe6070ad67",
      "name": "Feature Extraction",
      "categoryId": "4cd7a78e-22b9-4a6f-92c8-fec5215dd5ca"
    },
    {
      "id": "45547030-2353-48de-b273-dd457ecc7eec",
      "name": "Model Evaluation",
      "categoryId": "4cd7a78e-22b9-4a6f-92c8-fec5215dd5ca"
    },
    {
      "id": "dfa82ecc-72c5-4f1b-9898-cbd0301c6bb7",
      "name": "Confusion Matrix",
      "categoryId": "4cd7a78e-22b9-4a6f-92c8-fec5215dd5ca"
    },
    {
      "id": "6df5175c-0d25-4c01-adbd-b2e080490328",
      "name": "Supervised Learning",
      "categoryId": "4e43c1a3-acc6-4d34-b276-32b8da3cb08e"
    },
    {
      "id": "7f1c7c0e-260b-4f85-907a-04375eb48743",
      "name": "Decision Trees",
      "categoryId": "4e43c1a3-acc6-4d34-b276-32b8da3cb08e"
    },
    {
      "id": "46103924-eef7-4e65-8b0e-f3fd829cfb29",
      "name": "Classification and Regression",
      "categoryId": "4e43c1a3-acc6-4d34-b276-32b8da3cb08e"
    },
    {
      "id": "b59457fb-12a5-458f-84bd-6c01b5f2986c",
      "name": "Predictive Modeling",
      "categoryId": "4e43c1a3-acc6-4d34-b276-32b8da3cb08e"
    },
    {
      "id": "4c07456d-abdf-41fd-8bb4-2fd417cf805c",
      "name": "Machine Learning Algorithms",
      "categoryId": "4e43c1a3-acc6-4d34-b276-32b8da3cb08e"
    },
    {
      "id": "05d49ef6-f8cc-44f1-9b6d-a3762962ca2c",
      "name": "Tree-Based Methods",
      "categoryId": "4e43c1a3-acc6-4d34-b276-32b8da3cb08e"
    },
    {
      "id": "338d828f-5be0-4051-94f5-898e29c8b7c7",
      "name": "Data Mining",
      "categoryId": "4e43c1a3-acc6-4d34-b276-32b8da3cb08e"
    },
    {
      "id": "6e450527-3d8e-4d37-b36d-75a3dfc0ff91",
      "name": "Pattern Recognition",
      "categoryId": "4e43c1a3-acc6-4d34-b276-32b8da3cb08e"
    },
    {
      "id": "6c505fd8-c25c-4326-9b2e-f173ff89e6da",
      "name": "Data Analysis",
      "categoryId": "4e43c1a3-acc6-4d34-b276-32b8da3cb08e"
    },
    {
      "id": "b081d55c-fa1f-489e-b9f1-dff91d294f66",
      "name": "Machine Learning Techniques",
      "categoryId": "4e43c1a3-acc6-4d34-b276-32b8da3cb08e"
    },
    {
      "id": "def9a902-8545-4876-8f99-c306d64c3584",
      "name": "supervised learning",
      "categoryId": "79ba7f32-fdd2-44b9-bd97-b00865bb917f"
    },
    {
      "id": "046f2b4c-f77e-45ce-b8e5-8160e8135dc4",
      "name": "model evaluation",
      "categoryId": "79ba7f32-fdd2-44b9-bd97-b00865bb917f"
    },
    {
      "id": "ad530c7a-cf92-4219-ae26-8966be21348c",
      "name": "model performance metrics",
      "categoryId": "79ba7f32-fdd2-44b9-bd97-b00865bb917f"
    },
    {
      "id": "7119d0bc-5b1b-4fd0-9368-a98983b0888d",
      "name": "confusion matrix",
      "categoryId": "79ba7f32-fdd2-44b9-bd97-b00865bb917f"
    },
    {
      "id": "6809adf5-6162-4a50-b226-9e2b95f2ffb2",
      "name": "precision",
      "categoryId": "79ba7f32-fdd2-44b9-bd97-b00865bb917f"
    },
    {
      "id": "571e05d2-21de-4010-89ef-203a44368a54",
      "name": "recall",
      "categoryId": "79ba7f32-fdd2-44b9-bd97-b00865bb917f"
    },
    {
      "id": "48d1832b-6b17-4148-8c7c-34e808254b07",
      "name": "F1 score",
      "categoryId": "79ba7f32-fdd2-44b9-bd97-b00865bb917f"
    },
    {
      "id": "97150dea-4543-4f7e-a907-69027361063c",
      "name": "ROC curve",
      "categoryId": "79ba7f32-fdd2-44b9-bd97-b00865bb917f"
    },
    {
      "id": "94ebc067-9077-456c-8abb-4de79df7b1bf",
      "name": "AUC",
      "categoryId": "79ba7f32-fdd2-44b9-bd97-b00865bb917f"
    },
    {
      "id": "f7fd1069-b209-434b-b676-9dba7e2bc105",
      "name": "cross-validation",
      "categoryId": "79ba7f32-fdd2-44b9-bd97-b00865bb917f"
    },
    {
      "id": "a83552cb-d2db-4e92-b1a0-3c699ad7a1bf",
      "name": "accuracy",
      "categoryId": "79ba7f32-fdd2-44b9-bd97-b00865bb917f"
    },
    {
      "id": "5b69a638-b482-41d6-ad43-5bf2efffdbdb",
      "name": "hypothesis testing",
      "categoryId": "79ba7f32-fdd2-44b9-bd97-b00865bb917f"
    },
    {
      "id": "af12bb0c-804a-44e3-b1b1-7dee6a3de9af",
      "name": "bias-variance tradeoff",
      "categoryId": "79ba7f32-fdd2-44b9-bd97-b00865bb917f"
    },
    {
      "id": "756d2a6e-ecfc-40e9-8c9e-9082c5080c62",
      "name": "Classification Problems",
      "categoryId": "6a5b4220-758f-46c3-903d-a19f8c1fca15"
    },
    {
      "id": "02e9c202-223b-4242-b59f-b2ef3d0577f1",
      "name": "Supervised Learning",
      "categoryId": "6a5b4220-758f-46c3-903d-a19f8c1fca15"
    },
    {
      "id": "069fe3d5-729d-46b5-a16c-4bab63e88c4d",
      "name": "Pattern Recognition",
      "categoryId": "6a5b4220-758f-46c3-903d-a19f8c1fca15"
    },
    {
      "id": "484a4a1b-915b-44d7-bd7c-82014821b6a6",
      "name": "Discrete Labels",
      "categoryId": "6a5b4220-758f-46c3-903d-a19f8c1fca15"
    },
    {
      "id": "1d00fa5d-79c4-4fb2-9db6-67f2b1f09704",
      "name": "Binary Classification",
      "categoryId": "6a5b4220-758f-46c3-903d-a19f8c1fca15"
    },
    {
      "id": "f1ece903-ae1f-4551-b3e7-38033874d0fb",
      "name": "Multi-class Classification",
      "categoryId": "6a5b4220-758f-46c3-903d-a19f8c1fca15"
    },
    {
      "id": "77d5e538-e072-4cfb-85be-842b92dc7c4c",
      "name": "Supervised Algorithms",
      "categoryId": "6a5b4220-758f-46c3-903d-a19f8c1fca15"
    },
    {
      "id": "58caebb7-6e3d-4589-8dd3-8f087c8d256a",
      "name": "Label Prediction",
      "categoryId": "6a5b4220-758f-46c3-903d-a19f8c1fca15"
    },
    {
      "id": "7231e8ec-9679-470b-9dd5-a908747b3572",
      "name": "Data Labels",
      "categoryId": "6a5b4220-758f-46c3-903d-a19f8c1fca15"
    },
    {
      "id": "4a8a486c-656a-4000-852c-5cf0f73b35fa",
      "name": "Categorization",
      "categoryId": "6a5b4220-758f-46c3-903d-a19f8c1fca15"
    },
    {
      "id": "9a9d4451-ea63-48cd-820f-67dd889f83e1",
      "name": "Classification report",
      "categoryId": "cb6a0d23-dd1e-4a42-aeb4-4e0cd863dc82"
    },
    {
      "id": "3d61b3fa-0b84-40b3-b46d-9fa25358bcb2",
      "name": "performance metrics",
      "categoryId": "cb6a0d23-dd1e-4a42-aeb4-4e0cd863dc82"
    },
    {
      "id": "9c5c5e8c-7ba0-4b07-b097-32861aeeca3c",
      "name": "model evaluation",
      "categoryId": "cb6a0d23-dd1e-4a42-aeb4-4e0cd863dc82"
    },
    {
      "id": "ba9a1086-d95a-4293-a30b-d2dbdd252abb",
      "name": "precision",
      "categoryId": "cb6a0d23-dd1e-4a42-aeb4-4e0cd863dc82"
    },
    {
      "id": "81970d60-c427-4bb4-888b-da3caaecf0ea",
      "name": "recall",
      "categoryId": "cb6a0d23-dd1e-4a42-aeb4-4e0cd863dc82"
    },
    {
      "id": "64dd26f5-8292-4186-83d3-9c466beaaf28",
      "name": "F1-score",
      "categoryId": "cb6a0d23-dd1e-4a42-aeb4-4e0cd863dc82"
    },
    {
      "id": "4e437b7c-ea78-48a6-82e2-2f882e1d9346",
      "name": "confusion matrix",
      "categoryId": "cb6a0d23-dd1e-4a42-aeb4-4e0cd863dc82"
    },
    {
      "id": "f4be5dc0-3361-4e05-abbf-fc1a4fca90c9",
      "name": "accuracy",
      "categoryId": "cb6a0d23-dd1e-4a42-aeb4-4e0cd863dc82"
    },
    {
      "id": "9151f609-6a52-409c-bfc1-13605fe39eb2",
      "name": "multi-class classification",
      "categoryId": "cb6a0d23-dd1e-4a42-aeb4-4e0cd863dc82"
    },
    {
      "id": "a2712890-42c4-445c-bc9e-9b7de1de4b14",
      "name": "binary classification",
      "categoryId": "cb6a0d23-dd1e-4a42-aeb4-4e0cd863dc82"
    },
    {
      "id": "a09d66ce-d835-40bf-9215-0269f22423b3",
      "name": "model assessment",
      "categoryId": "cb6a0d23-dd1e-4a42-aeb4-4e0cd863dc82"
    },
    {
      "id": "eeabe272-7a5d-4fb4-9059-affb0fcbb8ba",
      "name": "Multi-label Classification",
      "categoryId": "e1f090cb-48c8-45b1-aedf-b83a8fd93f54"
    },
    {
      "id": "baedb52a-1f65-4c67-9339-71b579dafb50",
      "name": "Chain-Based Methods",
      "categoryId": "e1f090cb-48c8-45b1-aedf-b83a8fd93f54"
    },
    {
      "id": "7bfab04f-365e-413c-a7aa-d5c11765230a",
      "name": "Sequential Modeling",
      "categoryId": "e1f090cb-48c8-45b1-aedf-b83a8fd93f54"
    },
    {
      "id": "a518d45c-9f80-4864-b8fe-f8d38a99c05d",
      "name": "Ensemble Techniques",
      "categoryId": "e1f090cb-48c8-45b1-aedf-b83a8fd93f54"
    },
    {
      "id": "8e5c822f-7e2a-47aa-9c88-ebb23549b9a3",
      "name": "Multi-Output Classification",
      "categoryId": "e1f090cb-48c8-45b1-aedf-b83a8fd93f54"
    },
    {
      "id": "f5583359-aa05-4a5b-b3c1-3789d24e69ac",
      "name": "Multi-Label Learning",
      "categoryId": "e1f090cb-48c8-45b1-aedf-b83a8fd93f54"
    },
    {
      "id": "7bee405a-23f4-42bc-b1e2-d8dfb2fbd2eb",
      "name": "Dependency Modeling",
      "categoryId": "e1f090cb-48c8-45b1-aedf-b83a8fd93f54"
    },
    {
      "id": "cca57a83-6346-4eb9-b099-fe8718bd51a5",
      "name": "Predictive Modeling",
      "categoryId": "e1f090cb-48c8-45b1-aedf-b83a8fd93f54"
    },
    {
      "id": "55957176-6bf9-41cb-bd7a-982bbd378d2e",
      "name": "Structured Prediction",
      "categoryId": "e1f090cb-48c8-45b1-aedf-b83a8fd93f54"
    },
    {
      "id": "749a0dff-a55e-4148-a702-123e8bd0b2e1",
      "name": "Machine Learning",
      "categoryId": "d933572d-ce55-41ce-8049-2f630032e5b1"
    },
    {
      "id": "28c323ce-af45-4352-87f4-413673f61f87",
      "name": "Deep Learning",
      "categoryId": "d933572d-ce55-41ce-8049-2f630032e5b1"
    },
    {
      "id": "1d84b63c-b83d-497e-b065-b16563a9221f",
      "name": "Generative Models",
      "categoryId": "d933572d-ce55-41ce-8049-2f630032e5b1"
    },
    {
      "id": "7390497e-4264-4c05-b620-d9f85d7cd9fa",
      "name": "Diffusion Models",
      "categoryId": "d933572d-ce55-41ce-8049-2f630032e5b1"
    },
    {
      "id": "04d3f8b4-4b73-4056-8a5b-fc8236418b16",
      "name": "Text-to-Image Synthesis",
      "categoryId": "d933572d-ce55-41ce-8049-2f630032e5b1"
    },
    {
      "id": "b72cbcda-e275-478c-b9d5-8deacef4f123",
      "name": "Guidance Techniques",
      "categoryId": "d933572d-ce55-41ce-8049-2f630032e5b1"
    },
    {
      "id": "dd2f27f4-1e7f-4a07-a982-50bd0c96234d",
      "name": "Conditional Generation",
      "categoryId": "d933572d-ce55-41ce-8049-2f630032e5b1"
    },
    {
      "id": "e24e3405-0424-468f-a755-35d9a0efa6a9",
      "name": "Score-Based Models",
      "categoryId": "d933572d-ce55-41ce-8049-2f630032e5b1"
    },
    {
      "id": "9b6c7531-ca69-40e8-ad38-803d454c76cc",
      "name": "Model Conditioning",
      "categoryId": "d933572d-ce55-41ce-8049-2f630032e5b1"
    },
    {
      "id": "951aeb43-8008-4399-af1e-d40ab05c1958",
      "name": "Unconditional Generation",
      "categoryId": "d933572d-ce55-41ce-8049-2f630032e5b1"
    },
    {
      "id": "2b30ccc5-8b43-4b6e-b67d-7a50278b22ad",
      "name": "Sentiment Analysis",
      "categoryId": "735e4475-77a8-44e0-93d6-73b5d712a5e5"
    },
    {
      "id": "f444cf0e-95fe-40fc-8d62-097c8b4ca8bf",
      "name": "AI Security",
      "categoryId": "735e4475-77a8-44e0-93d6-73b5d712a5e5"
    },
    {
      "id": "8fcacbed-fc2d-451c-8fe6-2bdd994b408a",
      "name": "Model Robustness",
      "categoryId": "735e4475-77a8-44e0-93d6-73b5d712a5e5"
    },
    {
      "id": "713db711-a14c-4a84-bbc2-9381fdb64076",
      "name": "Privacy Risks",
      "categoryId": "735e4475-77a8-44e0-93d6-73b5d712a5e5"
    },
    {
      "id": "10727c44-2588-4be9-aece-1d9fd5649a2d",
      "name": "Adversarial Attacks",
      "categoryId": "735e4475-77a8-44e0-93d6-73b5d712a5e5"
    },
    {
      "id": "87ed3b59-3693-442e-aa45-b2203823a398",
      "name": "Data Integrity",
      "categoryId": "735e4475-77a8-44e0-93d6-73b5d712a5e5"
    },
    {
      "id": "0cbefed9-5086-4f97-9c53-e9f35aaabaae",
      "name": "Classification Models",
      "categoryId": "735e4475-77a8-44e0-93d6-73b5d712a5e5"
    },
    {
      "id": "037a3a21-4475-4d13-ab04-2ed9918cc2a6",
      "name": "Ethical AI",
      "categoryId": "735e4475-77a8-44e0-93d6-73b5d712a5e5"
    },
    {
      "id": "1f49b699-ae63-48e3-97de-48cfe71748ed",
      "name": "Bias Detection",
      "categoryId": "735e4475-77a8-44e0-93d6-73b5d712a5e5"
    },
    {
      "id": "fb338b5e-7d17-4bf8-ba11-926415398cc4",
      "name": "Model Explainability",
      "categoryId": "735e4475-77a8-44e0-93d6-73b5d712a5e5"
    },
    {
      "id": "be561b7a-a322-4df3-9923-900f4c9480c8",
      "name": "Data Privacy",
      "categoryId": "735e4475-77a8-44e0-93d6-73b5d712a5e5"
    },
    {
      "id": "2dcb1458-b481-423d-9c54-add1d57b6da6",
      "name": "AI Safety",
      "categoryId": "735e4475-77a8-44e0-93d6-73b5d712a5e5"
    },
    {
      "id": "f845faa9-8ace-4dc9-afc0-be45649f540d",
      "name": "Trustworthy AI",
      "categoryId": "735e4475-77a8-44e0-93d6-73b5d712a5e5"
    },
    {
      "id": "a0f4fdc6-bebe-45d3-b12f-24e8166244cf",
      "name": "Natural Language Processing (NLP)",
      "categoryId": "735e4475-77a8-44e0-93d6-73b5d712a5e5"
    },
    {
      "id": "0b8fc966-c2ec-4272-93ec-3c6c9f8e4e66",
      "name": "AI Security Protocols",
      "categoryId": "735e4475-77a8-44e0-93d6-73b5d712a5e5"
    },
    {
      "id": "87898fad-b1a1-48c7-9198-2cbf30294823",
      "name": "Thermodynamics",
      "categoryId": "842a056b-d568-4c6a-b997-7e3878be579b"
    },
    {
      "id": "330e42c1-cba9-4271-b477-5a028821700b",
      "name": "Climate Modeling",
      "categoryId": "842a056b-d568-4c6a-b997-7e3878be579b"
    },
    {
      "id": "3f0b150d-94da-468b-bd8a-65a87f1f467e",
      "name": "Data-Driven Simulations",
      "categoryId": "842a056b-d568-4c6a-b997-7e3878be579b"
    },
    {
      "id": "442ea14d-ceef-44b7-9351-e83febf2b17d",
      "name": "Fluid Mechanics",
      "categoryId": "842a056b-d568-4c6a-b997-7e3878be579b"
    },
    {
      "id": "74d3fcb8-27f1-4e19-a47e-729e1c17d6bc",
      "name": "Phase Transitions",
      "categoryId": "842a056b-d568-4c6a-b997-7e3878be579b"
    },
    {
      "id": "305de64b-bf50-4b3e-974b-a8fec2c69a4f",
      "name": "Material Science",
      "categoryId": "842a056b-d568-4c6a-b997-7e3878be579b"
    },
    {
      "id": "6e961d82-1b7b-43b6-9610-8b58ab995c98",
      "name": "Computational Thermodynamics",
      "categoryId": "842a056b-d568-4c6a-b997-7e3878be579b"
    },
    {
      "id": "52b253b3-c288-4814-9d9c-71c4d9924fa5",
      "name": "Statistical Mechanics",
      "categoryId": "842a056b-d568-4c6a-b997-7e3878be579b"
    },
    {
      "id": "0408db7b-583c-435f-8b38-74dfe1c79d4d",
      "name": "Physical Chemistry",
      "categoryId": "842a056b-d568-4c6a-b997-7e3878be579b"
    },
    {
      "id": "e497da26-3634-4233-81e3-8f9e13090871",
      "name": "Energy Systems",
      "categoryId": "842a056b-d568-4c6a-b997-7e3878be579b"
    },
    {
      "id": "65924ac7-dea0-4456-b27f-4d336d5c6713",
      "name": "Artificial Intelligence",
      "categoryId": "3efc32f9-535b-46af-b5db-48762ecfb4e1"
    },
    {
      "id": "1e559057-9567-46a1-a704-953fd54f3db0",
      "name": "Machine Learning",
      "categoryId": "3efc32f9-535b-46af-b5db-48762ecfb4e1"
    },
    {
      "id": "b99ed36c-e629-4e47-9193-4822bd7e3467",
      "name": "Automated Machine Learning",
      "categoryId": "3efc32f9-535b-46af-b5db-48762ecfb4e1"
    },
    {
      "id": "7235aedd-2d9e-48d1-a732-eb0a1a990170",
      "name": "MLOps",
      "categoryId": "3efc32f9-535b-46af-b5db-48762ecfb4e1"
    },
    {
      "id": "951f80ac-b468-4ff1-abb6-78ecf5708cdd",
      "name": "Experiment Management",
      "categoryId": "3efc32f9-535b-46af-b5db-48762ecfb4e1"
    },
    {
      "id": "deb688e5-dc3e-4902-b225-65c85bbb75c5",
      "name": "Workflow Orchestration",
      "categoryId": "3efc32f9-535b-46af-b5db-48762ecfb4e1"
    },
    {
      "id": "3a1c6dba-2cc2-4751-8ab4-f75cb3d6c774",
      "name": "Model Training",
      "categoryId": "3efc32f9-535b-46af-b5db-48762ecfb4e1"
    },
    {
      "id": "6d088c0f-8b83-4a57-b6e1-de3c85d87395",
      "name": "Model Deployment",
      "categoryId": "3efc32f9-535b-46af-b5db-48762ecfb4e1"
    },
    {
      "id": "3ec0886c-e9fe-42aa-a0b6-7029a838d757",
      "name": "Model Monitoring",
      "categoryId": "3efc32f9-535b-46af-b5db-48762ecfb4e1"
    },
    {
      "id": "c782168c-b407-4935-9348-6b986046f08a",
      "name": "AI Platform",
      "categoryId": "3efc32f9-535b-46af-b5db-48762ecfb4e1"
    },
    {
      "id": "4a9ea3e7-2868-40cc-913e-4e0776d7446b",
      "name": "Reproducibility",
      "categoryId": "3efc32f9-535b-46af-b5db-48762ecfb4e1"
    },
    {
      "id": "aad3b1a0-83ee-4667-a480-be3416637994",
      "name": "Collaboration Tools",
      "categoryId": "3efc32f9-535b-46af-b5db-48762ecfb4e1"
    },
    {
      "id": "4366df86-1b73-4951-a4a3-a4cd9f0ba9b3",
      "name": "Computer Vision",
      "categoryId": "338ee975-7f21-4bc9-a2c0-cd6f6e575fb6"
    },
    {
      "id": "0086522e-b9e7-4808-8c1f-b58c8cc9f9c1",
      "name": "Natural Language Processing",
      "categoryId": "338ee975-7f21-4bc9-a2c0-cd6f6e575fb6"
    },
    {
      "id": "8c508a86-0c50-44a5-bade-6ef82b3ce596",
      "name": "Multimodal Learning",
      "categoryId": "338ee975-7f21-4bc9-a2c0-cd6f6e575fb6"
    },
    {
      "id": "37775fbe-a7d9-4b62-bdca-3fb7181cc6d1",
      "name": "Representation Learning",
      "categoryId": "338ee975-7f21-4bc9-a2c0-cd6f6e575fb6"
    },
    {
      "id": "b0c0b75f-c5f7-4278-9166-5e8490f21e3f",
      "name": "Contrastive Learning",
      "categoryId": "338ee975-7f21-4bc9-a2c0-cd6f6e575fb6"
    },
    {
      "id": "72918302-afb5-4e76-aa75-d38e5f03f449",
      "name": "Pretraining",
      "categoryId": "338ee975-7f21-4bc9-a2c0-cd6f6e575fb6"
    },
    {
      "id": "fdacea9b-7f78-46e8-8391-1be3254e8fb3",
      "name": "Visual Understanding",
      "categoryId": "338ee975-7f21-4bc9-a2c0-cd6f6e575fb6"
    },
    {
      "id": "c9a46e32-dd32-459d-8b77-dc35815ea271",
      "name": "Language Models",
      "categoryId": "338ee975-7f21-4bc9-a2c0-cd6f6e575fb6"
    },
    {
      "id": "69497ceb-0707-434a-bf74-947fd01fddca",
      "name": "Deep Learning",
      "categoryId": "338ee975-7f21-4bc9-a2c0-cd6f6e575fb6"
    },
    {
      "id": "ffed9715-58dd-4ebf-93e0-55045b2fe59f",
      "name": "Embeddings",
      "categoryId": "338ee975-7f21-4bc9-a2c0-cd6f6e575fb6"
    },
    {
      "id": "fcfa290f-a571-4009-8af8-bd94e1d70441",
      "name": "Natural Language Processing",
      "categoryId": "29861353-f354-406d-b64b-c1255eb0bc79"
    },
    {
      "id": "3b16d54f-5662-48fc-8045-fc12879ea45d",
      "name": "Computer Vision",
      "categoryId": "29861353-f354-406d-b64b-c1255eb0bc79"
    },
    {
      "id": "03f19420-1cae-4c50-867e-758cda1b0ae6",
      "name": "Multimodal Learning",
      "categoryId": "29861353-f354-406d-b64b-c1255eb0bc79"
    },
    {
      "id": "c3e1a4f7-12cf-4896-a8a9-6e299bda90a9",
      "name": "Representation Learning",
      "categoryId": "29861353-f354-406d-b64b-c1255eb0bc79"
    },
    {
      "id": "714e5029-0842-4b0f-b480-487899cda169",
      "name": "Deep Learning",
      "categoryId": "29861353-f354-406d-b64b-c1255eb0bc79"
    },
    {
      "id": "8423663d-ccc0-402c-ad68-fd7e9201ceb5",
      "name": "Contrastive Learning",
      "categoryId": "29861353-f354-406d-b64b-c1255eb0bc79"
    },
    {
      "id": "2e6370b5-1720-4609-9ca9-d51081960cdd",
      "name": "Embedding Models",
      "categoryId": "29861353-f354-406d-b64b-c1255eb0bc79"
    },
    {
      "id": "ac18f352-cf61-4f6b-b2c8-e7f8a90d2ddb",
      "name": "Visual Language Models",
      "categoryId": "29861353-f354-406d-b64b-c1255eb0bc79"
    },
    {
      "id": "e95de642-e062-462d-ab72-8cc697cac54f",
      "name": "Pretraining",
      "categoryId": "29861353-f354-406d-b64b-c1255eb0bc79"
    },
    {
      "id": "ae097d10-749b-4fc2-869f-e07c2c6b756a",
      "name": "Zero-shot Recognition",
      "categoryId": "29861353-f354-406d-b64b-c1255eb0bc79"
    },
    {
      "id": "7fd3376e-ffa4-4747-bd1f-0a0ab6503f34",
      "name": "Optimization Techniques",
      "categoryId": "4e19ff42-f774-4f1a-aae9-ee741a2f033f"
    },
    {
      "id": "1ce4e162-06b4-46bd-947e-eb5a7792d454",
      "name": "Gradient Clipping",
      "categoryId": "4e19ff42-f774-4f1a-aae9-ee741a2f033f"
    },
    {
      "id": "034eb329-c0ce-4f41-8e38-4a1b3247082c",
      "name": "Regularization Methods",
      "categoryId": "4e19ff42-f774-4f1a-aae9-ee741a2f033f"
    },
    {
      "id": "6bd36fe2-cfe8-425e-8e60-99586f45430b",
      "name": "Deep Learning Optimization",
      "categoryId": "4e19ff42-f774-4f1a-aae9-ee741a2f033f"
    },
    {
      "id": "aef56896-4250-4857-88f6-5706e16d67ba",
      "name": "Gradient Management",
      "categoryId": "4e19ff42-f774-4f1a-aae9-ee741a2f033f"
    },
    {
      "id": "37b010a4-06ad-44a3-98fe-2f154ee96771",
      "name": "Training Stabilization",
      "categoryId": "4e19ff42-f774-4f1a-aae9-ee741a2f033f"
    },
    {
      "id": "ff4a4af6-a3d2-4d46-b43e-3ebae96ce99c",
      "name": "Optimization Techniques",
      "categoryId": "132f71da-5411-4af4-8707-39e1d829d524"
    },
    {
      "id": "60cee353-defb-4c4a-ba58-97e4e1bfddd4",
      "name": "Gradient Descent",
      "categoryId": "132f71da-5411-4af4-8707-39e1d829d524"
    },
    {
      "id": "d61a4972-2531-45c4-b8af-c16c47cafe93",
      "name": "Regularization",
      "categoryId": "132f71da-5411-4af4-8707-39e1d829d524"
    },
    {
      "id": "1e84a3e2-e56c-4910-99b9-f7710385f963",
      "name": "Neural Network Training",
      "categoryId": "132f71da-5411-4af4-8707-39e1d829d524"
    },
    {
      "id": "4bfabe03-d265-494a-b474-b091daca3ef5",
      "name": "Deep Learning",
      "categoryId": "132f71da-5411-4af4-8707-39e1d829d524"
    },
    {
      "id": "5f843708-9186-4f32-a682-5f3212280a38",
      "name": "Backpropagation",
      "categoryId": "132f71da-5411-4af4-8707-39e1d829d524"
    },
    {
      "id": "fb2e92da-c616-4045-a266-c0d266516b0f",
      "name": "Loss Function",
      "categoryId": "132f71da-5411-4af4-8707-39e1d829d524"
    },
    {
      "id": "913d05f2-0c32-4a64-bced-3deca8639e6d",
      "name": "Model Stability",
      "categoryId": "132f71da-5411-4af4-8707-39e1d829d524"
    },
    {
      "id": "201bd87f-0364-4583-9710-efbe06c02ded",
      "name": "Gradient Clipping",
      "categoryId": "31e5e921-c0ea-446c-b277-d0e5087f429e"
    },
    {
      "id": "1f9bbaeb-7068-48e8-ac51-80862781ecb6",
      "name": "Norm Clipping",
      "categoryId": "31e5e921-c0ea-446c-b277-d0e5087f429e"
    },
    {
      "id": "60b41a1e-698d-4b3b-a22c-f47f05d10732",
      "name": "Value Clipping",
      "categoryId": "31e5e921-c0ea-446c-b277-d0e5087f429e"
    },
    {
      "id": "36f19103-70d9-48c7-87b8-a8d0f491cdbb",
      "name": "Optimization Techniques",
      "categoryId": "31e5e921-c0ea-446c-b277-d0e5087f429e"
    },
    {
      "id": "a9b59f56-e831-43bf-98ef-e341324c2473",
      "name": "Training Stability",
      "categoryId": "31e5e921-c0ea-446c-b277-d0e5087f429e"
    },
    {
      "id": "15be79f4-5f8b-4d15-8785-416cb4cdc0bf",
      "name": "Deep Learning Regularization",
      "categoryId": "31e5e921-c0ea-446c-b277-d0e5087f429e"
    },
    {
      "id": "05c193fd-3a56-4209-a27b-4c511e967e36",
      "name": "Convergence Acceleration",
      "categoryId": "31e5e921-c0ea-446c-b277-d0e5087f429e"
    },
    {
      "id": "35cf59bc-c7ff-4061-a897-ded695937579",
      "name": "Optimization Techniques",
      "categoryId": "7851dab6-0159-4632-b1a8-2727b621239e"
    },
    {
      "id": "5d498705-5b6a-43c3-b634-876f00a82eb6",
      "name": "Gradient Clipping",
      "categoryId": "7851dab6-0159-4632-b1a8-2727b621239e"
    },
    {
      "id": "d23dffbb-6bd3-46ce-9b69-c0deea65e02d",
      "name": "Neural Network Training",
      "categoryId": "7851dab6-0159-4632-b1a8-2727b621239e"
    },
    {
      "id": "baf99f5b-05c7-4715-a1fd-3479cb9a4677",
      "name": "Regularization Methods",
      "categoryId": "7851dab6-0159-4632-b1a8-2727b621239e"
    },
    {
      "id": "30c01681-435e-486d-bee6-5497e2fb7911",
      "name": "Deep Learning Optimization",
      "categoryId": "7851dab6-0159-4632-b1a8-2727b621239e"
    },
    {
      "id": "4e0d3398-9b0c-4f73-95e9-4e33c685ce26",
      "name": "Stability Enhancements",
      "categoryId": "7851dab6-0159-4632-b1a8-2727b621239e"
    },
    {
      "id": "51b936bc-7b33-4610-a031-9f8f45335f5a",
      "name": "Model Training Techniques",
      "categoryId": "7851dab6-0159-4632-b1a8-2727b621239e"
    },
    {
      "id": "7ab1f490-d38e-431e-95e1-162dc2f99e70",
      "name": "Gradient Clipping",
      "categoryId": "08a9ddbc-4d8c-4169-b290-ed00d67cac62"
    },
    {
      "id": "fd1aa10a-5907-41e6-b859-593497b3f381",
      "name": "Norm Clipping",
      "categoryId": "08a9ddbc-4d8c-4169-b290-ed00d67cac62"
    },
    {
      "id": "f04134a0-b35c-4aa0-a55a-2b5783fbfaba",
      "name": "Training Stability",
      "categoryId": "08a9ddbc-4d8c-4169-b290-ed00d67cac62"
    },
    {
      "id": "adf0c19e-5324-4919-8dba-54252ba31aac",
      "name": "Optimization Techniques",
      "categoryId": "08a9ddbc-4d8c-4169-b290-ed00d67cac62"
    },
    {
      "id": "11a1bd26-ae6b-4ae5-b7cd-e0b762574113",
      "name": "Gradient Regularization",
      "categoryId": "08a9ddbc-4d8c-4169-b290-ed00d67cac62"
    },
    {
      "id": "9b32c61b-e182-4c0e-ad0d-42d3105f5f72",
      "name": "Graph theory",
      "categoryId": "f37bc20e-3988-4a7a-8f7e-67706018b22a"
    },
    {
      "id": "cef86594-250c-4a7f-b650-287b04411842",
      "name": "Community detection",
      "categoryId": "f37bc20e-3988-4a7a-8f7e-67706018b22a"
    },
    {
      "id": "c856731e-2bf8-4dff-85a3-0b0232fe7bba",
      "name": "Network analysis",
      "categoryId": "f37bc20e-3988-4a7a-8f7e-67706018b22a"
    },
    {
      "id": "32167212-d593-4f63-b98e-3fa31d1c7b27",
      "name": "Clustering",
      "categoryId": "f37bc20e-3988-4a7a-8f7e-67706018b22a"
    },
    {
      "id": "a44d1f1b-5858-4f59-9b3f-46108dce4473",
      "name": "Subgraphs",
      "categoryId": "f37bc20e-3988-4a7a-8f7e-67706018b22a"
    },
    {
      "id": "b2c4d1f7-9ce8-4843-8b31-c995ff81fd06",
      "name": "Graph partitions",
      "categoryId": "f37bc20e-3988-4a7a-8f7e-67706018b22a"
    },
    {
      "id": "e32d431b-f1bc-49fa-b307-b80aad393916",
      "name": "Structural analysis",
      "categoryId": "f37bc20e-3988-4a7a-8f7e-67706018b22a"
    },
    {
      "id": "d4a1ea50-b33c-47d3-b0ff-cf44f0ebd43e",
      "name": "Social network analysis",
      "categoryId": "f37bc20e-3988-4a7a-8f7e-67706018b22a"
    },
    {
      "id": "415faf8a-ce63-43cc-baa7-e5d32e9e655c",
      "name": "Topology",
      "categoryId": "f37bc20e-3988-4a7a-8f7e-67706018b22a"
    },
    {
      "id": "e837ffde-60dc-4075-833f-e25ac75e0fbb",
      "name": "Combinatorics",
      "categoryId": "f37bc20e-3988-4a7a-8f7e-67706018b22a"
    },
    {
      "id": "39eb75e6-710b-4d5e-82a2-f86f0b2e7757",
      "name": "Data Mining",
      "categoryId": "c3149487-ed2e-48a6-bd04-df8f2b3fbe43"
    },
    {
      "id": "3fd73781-7083-4a3f-abbc-073f015fd606",
      "name": "Frequent Itemset Mining",
      "categoryId": "c3149487-ed2e-48a6-bd04-df8f2b3fbe43"
    },
    {
      "id": "53c286e8-ca51-4cae-9530-6dcb43d98f06",
      "name": "Association Rule Learning",
      "categoryId": "c3149487-ed2e-48a6-bd04-df8f2b3fbe43"
    },
    {
      "id": "01825527-4827-4268-bb31-03ebde8e12d4",
      "name": "Pattern Discovery",
      "categoryId": "c3149487-ed2e-48a6-bd04-df8f2b3fbe43"
    },
    {
      "id": "12bf043b-8b26-46d9-8867-6a12a05be2c1",
      "name": "Market Basket Analysis",
      "categoryId": "c3149487-ed2e-48a6-bd04-df8f2b3fbe43"
    },
    {
      "id": "f3dbebdf-6370-4b26-9365-325398f96216",
      "name": "Unsupervised Learning",
      "categoryId": "c3149487-ed2e-48a6-bd04-df8f2b3fbe43"
    },
    {
      "id": "5b37a58f-6e0f-4dda-809e-4b891cd55416",
      "name": "Transaction Data",
      "categoryId": "c3149487-ed2e-48a6-bd04-df8f2b3fbe43"
    },
    {
      "id": "ec68221f-f336-4fbb-8c51-63c724377be1",
      "name": "Itemset Mining",
      "categoryId": "c3149487-ed2e-48a6-bd04-df8f2b3fbe43"
    },
    {
      "id": "941fa2c3-a8f0-4939-8cba-87bdc56dbaeb",
      "name": "Support",
      "categoryId": "c3149487-ed2e-48a6-bd04-df8f2b3fbe43"
    },
    {
      "id": "86a4a5fa-8b6a-4e67-a4fb-3cc20f2fc70f",
      "name": "Confidence",
      "categoryId": "c3149487-ed2e-48a6-bd04-df8f2b3fbe43"
    },
    {
      "id": "12bb8154-3c85-45c0-ada1-967d73ff3071",
      "name": "Apriori Algorithm",
      "categoryId": "c3149487-ed2e-48a6-bd04-df8f2b3fbe43"
    },
    {
      "id": "aca4f14e-9294-4aab-874d-85cf51449a24",
      "name": "FP-Growth Algorithm",
      "categoryId": "c3149487-ed2e-48a6-bd04-df8f2b3fbe43"
    },
    {
      "id": "51eda58c-7e3c-4a4a-a383-f2e0748c57a0",
      "name": "Network Analysis",
      "categoryId": "84112320-ad22-42f2-9735-c85511c0f915"
    },
    {
      "id": "2555b002-ef73-448b-a195-d24d3eb2e3e2",
      "name": "Centrality Measures",
      "categoryId": "84112320-ad22-42f2-9735-c85511c0f915"
    },
    {
      "id": "379ce0ce-630c-49d5-8b66-090eadb317a0",
      "name": "Graph Theory",
      "categoryId": "84112320-ad22-42f2-9735-c85511c0f915"
    },
    {
      "id": "f3d2afa5-0967-4b0a-836d-50c9043b7017",
      "name": "Data Science",
      "categoryId": "84112320-ad22-42f2-9735-c85511c0f915"
    },
    {
      "id": "2722416a-bf0b-4ba6-afff-384462ffb445",
      "name": "Social Network Analysis",
      "categoryId": "84112320-ad22-42f2-9735-c85511c0f915"
    },
    {
      "id": "c25fba21-6ae1-429f-a5c2-4a6ac10fa518",
      "name": "Complex Networks",
      "categoryId": "84112320-ad22-42f2-9735-c85511c0f915"
    },
    {
      "id": "9d8d64e6-962e-4fd8-a280-46f1444a0250",
      "name": "Node Importance",
      "categoryId": "84112320-ad22-42f2-9735-c85511c0f915"
    },
    {
      "id": "a9d3736a-f471-49c9-8b27-5f910ff28b76",
      "name": "Graph Metrics",
      "categoryId": "84112320-ad22-42f2-9735-c85511c0f915"
    },
    {
      "id": "86dd30a4-af02-4fb2-aa61-e061e239abd5",
      "name": "Structural Time-series",
      "categoryId": "59376e95-8def-47a5-9da6-5a794a7efff1"
    },
    {
      "id": "439b03c9-1312-4050-8ed7-be05b82bbc44",
      "name": "Temporal Data Mining",
      "categoryId": "59376e95-8def-47a5-9da6-5a794a7efff1"
    },
    {
      "id": "4a8ee780-3dff-4ebb-a291-922295f356c0",
      "name": "Dynamic Clustering",
      "categoryId": "59376e95-8def-47a5-9da6-5a794a7efff1"
    },
    {
      "id": "52396076-2eb7-49a8-b72b-5eb0372861dd",
      "name": "Structural Pattern Recognition",
      "categoryId": "59376e95-8def-47a5-9da6-5a794a7efff1"
    },
    {
      "id": "1eb319d9-4eee-49d0-b98b-68f9df08deed",
      "name": "Time-series Segmentation",
      "categoryId": "59376e95-8def-47a5-9da6-5a794a7efff1"
    },
    {
      "id": "67d0d3a8-2bf7-4c52-8b67-11281cfdbed6",
      "name": "Ubiquitous Data Analysis",
      "categoryId": "59376e95-8def-47a5-9da6-5a794a7efff1"
    },
    {
      "id": "ba5e7125-a0b9-4c9d-8fbd-b9bdff14c56b",
      "name": "Semi-supervised Learning",
      "categoryId": "5a4142a9-9691-40a0-9063-8f11bd0a5d29"
    },
    {
      "id": "6448f50f-5de9-42f3-9e12-793f77ec3454",
      "name": "Unsupervised Learning",
      "categoryId": "5a4142a9-9691-40a0-9063-8f11bd0a5d29"
    },
    {
      "id": "5de04d54-039e-40c0-8dff-ef7072f63380",
      "name": "Representation Learning",
      "categoryId": "5a4142a9-9691-40a0-9063-8f11bd0a5d29"
    },
    {
      "id": "abf74358-c944-46d0-8426-3dc200fe79fe",
      "name": "Data Clustering",
      "categoryId": "5a4142a9-9691-40a0-9063-8f11bd0a5d29"
    },
    {
      "id": "6a08d032-60a0-45bd-ac59-b2b07a2b870e",
      "name": "Manifold Assumption",
      "categoryId": "5a4142a9-9691-40a0-9063-8f11bd0a5d29"
    },
    {
      "id": "778c028a-1a3e-4f46-ab88-0305bc18b2af",
      "name": "Label Propagation",
      "categoryId": "5a4142a9-9691-40a0-9063-8f11bd0a5d29"
    },
    {
      "id": "5d378e97-507f-49e8-8fd7-daa50aa5e09f",
      "name": "Pseudo-labeling",
      "categoryId": "5a4142a9-9691-40a0-9063-8f11bd0a5d29"
    },
    {
      "id": "0e907fa3-4541-484d-a43e-7ae0923c92ee",
      "name": "Dimensionality Reduction",
      "categoryId": "5a4142a9-9691-40a0-9063-8f11bd0a5d29"
    },
    {
      "id": "9806c5d7-a273-492a-a01b-120ee2ef2d79",
      "name": "Density Estimation",
      "categoryId": "5a4142a9-9691-40a0-9063-8f11bd0a5d29"
    },
    {
      "id": "58c0d6fa-2a8c-46b1-af2a-8cd0575882f4",
      "name": "Clustering",
      "categoryId": "20a457f0-417c-4066-ac64-615d61e8be8f"
    },
    {
      "id": "72003ed7-7579-411f-be50-22e9a89a41c8",
      "name": "Unsupervised Learning",
      "categoryId": "20a457f0-417c-4066-ac64-615d61e8be8f"
    },
    {
      "id": "32a65952-f12f-4119-819b-7a70ed6ba2be",
      "name": "Data Validation",
      "categoryId": "20a457f0-417c-4066-ac64-615d61e8be8f"
    },
    {
      "id": "1fa6568b-8378-4413-a3f1-7f457788135b",
      "name": "Model Evaluation",
      "categoryId": "20a457f0-417c-4066-ac64-615d61e8be8f"
    },
    {
      "id": "50a6c3ac-913e-4c83-85ad-6233a25c4679",
      "name": "Data Quality",
      "categoryId": "20a457f0-417c-4066-ac64-615d61e8be8f"
    },
    {
      "id": "47c62f0b-2408-4cdb-ba5c-68d2f059163b",
      "name": "Intrinsic Cluster Quality Metrics",
      "categoryId": "20a457f0-417c-4066-ac64-615d61e8be8f"
    },
    {
      "id": "58807af5-f61c-4620-a00c-d42b405f550c",
      "name": "Machine Learning Metrics",
      "categoryId": "20a457f0-417c-4066-ac64-615d61e8be8f"
    },
    {
      "id": "248911d8-479d-4139-ae5f-287d20db8574",
      "name": "Sampling Techniques",
      "categoryId": "ff6dd850-f324-4a1a-ab5f-4fa6b16af311"
    },
    {
      "id": "898650b4-0060-4f20-91d2-cf6eeb6b727f",
      "name": "Probability Sampling",
      "categoryId": "ff6dd850-f324-4a1a-ab5f-4fa6b16af311"
    },
    {
      "id": "e836e78f-36a5-4301-a529-d12e7cd1673c",
      "name": "Data Collection Methods",
      "categoryId": "ff6dd850-f324-4a1a-ab5f-4fa6b16af311"
    },
    {
      "id": "bf0c84ac-1ac2-48ed-94a2-ec276eb6cc37",
      "name": "Statistical Sampling",
      "categoryId": "ff6dd850-f324-4a1a-ab5f-4fa6b16af311"
    },
    {
      "id": "468afc5a-d4ae-4093-a4d6-962ce659f354",
      "name": "Data Sampling in Machine Learning",
      "categoryId": "ff6dd850-f324-4a1a-ab5f-4fa6b16af311"
    },
    {
      "id": "21af501a-4133-47eb-858b-04657da186d8",
      "name": "Data Representation",
      "categoryId": "ff6dd850-f324-4a1a-ab5f-4fa6b16af311"
    },
    {
      "id": "cc07459f-19f9-4b51-ab0d-5edce9e8a7d0",
      "name": "Data Subsets",
      "categoryId": "ff6dd850-f324-4a1a-ab5f-4fa6b16af311"
    },
    {
      "id": "7b8ccd90-117c-4cad-8c74-9d47cc8035ad",
      "name": "Statistical Methods",
      "categoryId": "ff6dd850-f324-4a1a-ab5f-4fa6b16af311"
    },
    {
      "id": "bf89511d-f5a3-4833-8222-544c5cb86dfa",
      "name": "Data Analytics",
      "categoryId": "ff6dd850-f324-4a1a-ab5f-4fa6b16af311"
    },
    {
      "id": "ef71cfe5-14bc-4cb0-b43d-8a987a5f34ca",
      "name": "Data Sampling Strategies",
      "categoryId": "ff6dd850-f324-4a1a-ab5f-4fa6b16af311"
    },
    {
      "id": "a1343fcb-e805-4144-b419-a7fd39eff1dd",
      "name": "Clustering",
      "categoryId": "5ba93cee-718b-45bb-b10d-3485d6fdfaa5"
    },
    {
      "id": "82fb0b77-aa32-47ef-8765-fcd58b84cd14",
      "name": "Unsupervised Learning",
      "categoryId": "5ba93cee-718b-45bb-b10d-3485d6fdfaa5"
    },
    {
      "id": "244f808a-da96-43d6-83f2-bb1180cea54b",
      "name": "Data Segmentation",
      "categoryId": "5ba93cee-718b-45bb-b10d-3485d6fdfaa5"
    },
    {
      "id": "eb774660-7ae9-4852-a9d3-f42dcd269681",
      "name": "Pattern Recognition",
      "categoryId": "5ba93cee-718b-45bb-b10d-3485d6fdfaa5"
    },
    {
      "id": "2851cb7c-51d1-4602-bc9e-6b63a9199194",
      "name": "Grouping",
      "categoryId": "5ba93cee-718b-45bb-b10d-3485d6fdfaa5"
    },
    {
      "id": "f68d550c-02ff-4211-a4cc-2dfcf23e6ba2",
      "name": "Density-Based Clustering",
      "categoryId": "5ba93cee-718b-45bb-b10d-3485d6fdfaa5"
    },
    {
      "id": "6556665c-2400-41bf-b711-6172a7be1f92",
      "name": "Hierarchical Clustering",
      "categoryId": "5ba93cee-718b-45bb-b10d-3485d6fdfaa5"
    },
    {
      "id": "2a84ad9c-bd0c-4373-9450-917d0fc76a13",
      "name": "Partitioning Methods",
      "categoryId": "5ba93cee-718b-45bb-b10d-3485d6fdfaa5"
    },
    {
      "id": "39f5a0d5-0b61-4796-81db-94d50b77b7a6",
      "name": "Centroid-Based Clustering",
      "categoryId": "5ba93cee-718b-45bb-b10d-3485d6fdfaa5"
    },
    {
      "id": "80c7b06b-d146-4b35-b765-4e7b8ef0df4a",
      "name": "Unsupervised Learning",
      "categoryId": "7bca72b2-ccb3-4792-9a4b-a3e0b5c70f0e"
    },
    {
      "id": "cfa6898f-825e-42e1-90b3-944be73afaed",
      "name": "Data Clustering",
      "categoryId": "7bca72b2-ccb3-4792-9a4b-a3e0b5c70f0e"
    },
    {
      "id": "afd69127-9038-47e5-9118-4c2e8d672d6c",
      "name": "Pattern Recognition",
      "categoryId": "7bca72b2-ccb3-4792-9a4b-a3e0b5c70f0e"
    },
    {
      "id": "73ce5bee-f669-4ce9-abd7-701f7819f14f",
      "name": "Similarity Measures",
      "categoryId": "7bca72b2-ccb3-4792-9a4b-a3e0b5c70f0e"
    },
    {
      "id": "63cfaf61-b5fc-462a-9e49-e20cc0735947",
      "name": "Data Segmentation",
      "categoryId": "7bca72b2-ccb3-4792-9a4b-a3e0b5c70f0e"
    },
    {
      "id": "e2fe69e7-9944-4e45-bbb3-28e526f3ccae",
      "name": "Density-Based Clustering",
      "categoryId": "7bca72b2-ccb3-4792-9a4b-a3e0b5c70f0e"
    },
    {
      "id": "5dc8280a-9d6e-46d1-ad23-0ed7491e0023",
      "name": "Partitioning Methods",
      "categoryId": "7bca72b2-ccb3-4792-9a4b-a3e0b5c70f0e"
    },
    {
      "id": "1c029ef8-f048-498a-9c88-588b969c216f",
      "name": "Hierarchical Clustering",
      "categoryId": "7bca72b2-ccb3-4792-9a4b-a3e0b5c70f0e"
    },
    {
      "id": "25bf3837-2c0e-4c81-b814-2decd72c6427",
      "name": "Model-Based Clustering",
      "categoryId": "7bca72b2-ccb3-4792-9a4b-a3e0b5c70f0e"
    },
    {
      "id": "893bffe3-b10e-43b0-b017-8da602001c6a",
      "name": "Clustering Algorithms",
      "categoryId": "5394ac47-fef5-4f9f-b0da-0b99ae41111c"
    },
    {
      "id": "57391bce-6426-413a-b3ba-e8e79dd1a800",
      "name": "Unsupervised Learning",
      "categoryId": "5394ac47-fef5-4f9f-b0da-0b99ae41111c"
    },
    {
      "id": "3df37f91-6f05-4239-81d8-9863cd116b0c",
      "name": "Data Segmentation",
      "categoryId": "5394ac47-fef5-4f9f-b0da-0b99ae41111c"
    },
    {
      "id": "1690a188-2dbb-4501-a2c2-5dde94851aa4",
      "name": "K-means",
      "categoryId": "5394ac47-fef5-4f9f-b0da-0b99ae41111c"
    },
    {
      "id": "a0c216b9-7c57-4e3c-8379-0f7308c405f6",
      "name": "Hierarchical Clustering",
      "categoryId": "5394ac47-fef5-4f9f-b0da-0b99ae41111c"
    },
    {
      "id": "a643332f-587f-4b06-a937-1821d7c8de73",
      "name": "Pattern Recognition",
      "categoryId": "5394ac47-fef5-4f9f-b0da-0b99ae41111c"
    },
    {
      "id": "7d48ab81-1c7a-4ed8-b974-e1bfad01964c",
      "name": "Data Mining",
      "categoryId": "5394ac47-fef5-4f9f-b0da-0b99ae41111c"
    },
    {
      "id": "1955350b-4ae4-4cf2-aa60-c20f61d94bf6",
      "name": "Grouping Methods",
      "categoryId": "5394ac47-fef5-4f9f-b0da-0b99ae41111c"
    },
    {
      "id": "9b58a542-3db9-46e4-b938-f33ac58819b8",
      "name": "Similarity Measures",
      "categoryId": "5394ac47-fef5-4f9f-b0da-0b99ae41111c"
    },
    {
      "id": "724cfc99-5213-4b14-8fcb-2b979121ac7b",
      "name": "Distance Metrics",
      "categoryId": "5394ac47-fef5-4f9f-b0da-0b99ae41111c"
    },
    {
      "id": "1e61356a-24d0-44a3-9496-73dbf1d1d62f",
      "name": "Clustering Metrics",
      "categoryId": "a975a25a-a3a5-4596-99a9-862442cccce1"
    },
    {
      "id": "b00dbc91-8848-4aa6-9b5a-e646ff700de4",
      "name": "Silhouette Score",
      "categoryId": "a975a25a-a3a5-4596-99a9-862442cccce1"
    },
    {
      "id": "34275f6a-8755-4206-9d4e-10f35f830c72",
      "name": "Davies-Bouldin Index",
      "categoryId": "a975a25a-a3a5-4596-99a9-862442cccce1"
    },
    {
      "id": "8aad9ded-5a91-4215-8b71-560bd03ce5a0",
      "name": "Cluster Validation",
      "categoryId": "a975a25a-a3a5-4596-99a9-862442cccce1"
    },
    {
      "id": "d480e653-9e90-46dc-9f33-70389b30bcd6",
      "name": "Cluster Quality Metrics",
      "categoryId": "a975a25a-a3a5-4596-99a9-862442cccce1"
    },
    {
      "id": "bb83d4ac-de54-4e06-953e-94852d96d68b",
      "name": "Data Analysis",
      "categoryId": "a975a25a-a3a5-4596-99a9-862442cccce1"
    },
    {
      "id": "acab43d8-6ce9-4684-8c4f-e6ccd3ba7c21",
      "name": "Model Selection",
      "categoryId": "a975a25a-a3a5-4596-99a9-862442cccce1"
    },
    {
      "id": "7982894b-f2ef-4bf2-9a62-4598ec11f256",
      "name": "Unsupervised Learning",
      "categoryId": "44cfac13-dfd8-4ca6-ad99-b41ec0e161f5"
    },
    {
      "id": "33755ca6-1e0c-48b7-b885-b6ae702973cb",
      "name": "Pattern Recognition",
      "categoryId": "44cfac13-dfd8-4ca6-ad99-b41ec0e161f5"
    },
    {
      "id": "5e0ee60d-d4fd-4e7e-ae7c-16b036843bd5",
      "name": "Data Clustering",
      "categoryId": "44cfac13-dfd8-4ca6-ad99-b41ec0e161f5"
    },
    {
      "id": "25d1cd53-baab-4af8-a12b-f269aedf5f17",
      "name": "Stability Analysis",
      "categoryId": "44cfac13-dfd8-4ca6-ad99-b41ec0e161f5"
    },
    {
      "id": "9f340f39-4184-4946-a880-845bd4e2b380",
      "name": "Validation Techniques",
      "categoryId": "44cfac13-dfd8-4ca6-ad99-b41ec0e161f5"
    },
    {
      "id": "fa084d2f-6ebf-4599-9d6b-4e1f66ccfd3c",
      "name": "Cluster Consistency",
      "categoryId": "44cfac13-dfd8-4ca6-ad99-b41ec0e161f5"
    },
    {
      "id": "c06d4f13-9f8d-4690-8bfd-f8f48c22c461",
      "name": "Robustness Metrics",
      "categoryId": "44cfac13-dfd8-4ca6-ad99-b41ec0e161f5"
    },
    {
      "id": "c2c07c7b-75b6-42f5-8aee-516d66a76d0f",
      "name": "Emotion Generation",
      "categoryId": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7"
    },
    {
      "id": "4cffe854-5641-451b-9619-04c8315add28",
      "name": "Affective Computing",
      "categoryId": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7"
    },
    {
      "id": "56c497b0-b034-4e87-b92f-88b383cca0f9",
      "name": "Sentiment Synthesis",
      "categoryId": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7"
    },
    {
      "id": "4eee277c-6125-445a-aa7d-3ee83f0d0f19",
      "name": "Emotional AI",
      "categoryId": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7"
    },
    {
      "id": "05c792b3-14d2-4699-8341-93dcb377a217",
      "name": "Human-Computer Interaction",
      "categoryId": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7"
    },
    {
      "id": "d1cf2058-08b8-49d1-84f6-5b06ccecd26a",
      "name": "Emotional Response Modeling",
      "categoryId": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7"
    },
    {
      "id": "1943ab8f-404d-4f24-b873-ead1cc6ead16",
      "name": "Affective Signal Processing",
      "categoryId": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7"
    },
    {
      "id": "9c1d06c3-c218-4963-b8cb-810e1d073238",
      "name": "Multimodal Emotion Recognition",
      "categoryId": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7"
    },
    {
      "id": "a4841aa2-5031-49b0-a879-d6249295656c",
      "name": "Generative Emotional Content",
      "categoryId": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7"
    },
    {
      "id": "02c54c7f-87a2-4396-8181-89fbcf5f53d4",
      "name": "Computer-Generated Emotions",
      "categoryId": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7"
    },
    {
      "id": "195ec9c1-13d0-4fca-a516-199f12cba964",
      "name": "Emotion Modeling",
      "categoryId": "6c0a135e-5723-414c-8eca-4553332e06a6"
    },
    {
      "id": "75a88342-9cb9-4a5e-90c1-6ebb9793e4ce",
      "name": "Affective Computing",
      "categoryId": "6c0a135e-5723-414c-8eca-4553332e06a6"
    },
    {
      "id": "10b72751-b2b9-4e02-9e5e-b60ad1185dee",
      "name": "Sentiment Analysis",
      "categoryId": "6c0a135e-5723-414c-8eca-4553332e06a6"
    },
    {
      "id": "1b9664e9-804b-413b-9b47-c82da4bcecd4",
      "name": "Mood Detection",
      "categoryId": "6c0a135e-5723-414c-8eca-4553332e06a6"
    },
    {
      "id": "2cc88727-ab9a-42c4-92d6-33eacfb65ea4",
      "name": "Affect Recognition",
      "categoryId": "6c0a135e-5723-414c-8eca-4553332e06a6"
    },
    {
      "id": "d16093cb-f54d-4de4-b0d2-360472c37453",
      "name": "Emotional Intelligence in AI",
      "categoryId": "6c0a135e-5723-414c-8eca-4553332e06a6"
    },
    {
      "id": "92dfe109-5c50-4454-bfac-71926bfd1c9b",
      "name": "Human-Computer Interaction",
      "categoryId": "6c0a135e-5723-414c-8eca-4553332e06a6"
    },
    {
      "id": "b68fafaa-43e3-4a9b-9bbd-1a6b5e479b2d",
      "name": "User State Estimation",
      "categoryId": "6c0a135e-5723-414c-8eca-4553332e06a6"
    },
    {
      "id": "d09fcc71-f594-4012-8427-2808c9b2a533",
      "name": "Emotional Response Modeling",
      "categoryId": "6c0a135e-5723-414c-8eca-4553332e06a6"
    },
    {
      "id": "bc91897f-f364-4beb-b981-629cba812284",
      "name": "Psychophysiological Signal Processing",
      "categoryId": "6c0a135e-5723-414c-8eca-4553332e06a6"
    },
    {
      "id": "b4e7a5de-98c5-4721-ac3d-33687a3ebfb3",
      "name": "Emotion Recognition",
      "categoryId": "b5f3852a-42f1-409f-8c33-3ebf90322065"
    },
    {
      "id": "0487175b-1ee0-465e-afa0-0e1f026b2381",
      "name": "Affective Computing",
      "categoryId": "b5f3852a-42f1-409f-8c33-3ebf90322065"
    },
    {
      "id": "5429f511-d650-46bb-a616-1c11ba2df9ca",
      "name": "Sentiment Analysis",
      "categoryId": "b5f3852a-42f1-409f-8c33-3ebf90322065"
    },
    {
      "id": "b3f385c1-1586-48ce-a04d-72ee5508ce51",
      "name": "Facial Expression Analysis",
      "categoryId": "b5f3852a-42f1-409f-8c33-3ebf90322065"
    },
    {
      "id": "e4acc021-3c9e-43d0-b327-a8104dfc6522",
      "name": "Voice Emotion Detection",
      "categoryId": "b5f3852a-42f1-409f-8c33-3ebf90322065"
    },
    {
      "id": "4db73c2d-0075-4cab-b44c-2ac3ef670795",
      "name": "Multimodal Emotion Recognition",
      "categoryId": "b5f3852a-42f1-409f-8c33-3ebf90322065"
    },
    {
      "id": "2461d205-8f18-4365-b256-df60f5624e8c",
      "name": "Human-Computer Interaction",
      "categoryId": "b5f3852a-42f1-409f-8c33-3ebf90322065"
    },
    {
      "id": "acb5b0e2-7d5b-429a-b15a-66f7e54343e2",
      "name": "Computational Psychology",
      "categoryId": "b5f3852a-42f1-409f-8c33-3ebf90322065"
    },
    {
      "id": "ceb141e9-9901-4d3c-b0f6-a0ac9597acc1",
      "name": "Emotion Recognition",
      "categoryId": "16001270-4117-4055-bac1-24aa99217acc"
    },
    {
      "id": "28619885-ba82-475b-935a-af6533fb4d32",
      "name": "Sentiment Analysis",
      "categoryId": "16001270-4117-4055-bac1-24aa99217acc"
    },
    {
      "id": "edaf8729-09f9-4844-88da-cecc6f41b1b9",
      "name": "Multimodal Data",
      "categoryId": "16001270-4117-4055-bac1-24aa99217acc"
    },
    {
      "id": "48b3e2c1-510a-4c99-84e4-d990d631e62d",
      "name": "Data Collection",
      "categoryId": "16001270-4117-4055-bac1-24aa99217acc"
    },
    {
      "id": "497c64ee-9717-4ef0-90df-fb156ab322ac",
      "name": "Feature Extraction",
      "categoryId": "16001270-4117-4055-bac1-24aa99217acc"
    },
    {
      "id": "c6b9d7b2-9241-4b4e-bcd1-ea730c66ec46",
      "name": "Ethical AI",
      "categoryId": "16001270-4117-4055-bac1-24aa99217acc"
    },
    {
      "id": "cd7f7786-542c-4a56-b5e5-80577bc5a7f5",
      "name": "Deep Learning for Emotions",
      "categoryId": "16001270-4117-4055-bac1-24aa99217acc"
    },
    {
      "id": "ef91de5b-a459-48e1-9f7b-6d80307fc117",
      "name": "Affective Signal Processing",
      "categoryId": "16001270-4117-4055-bac1-24aa99217acc"
    },
    {
      "id": "9e0203ff-ada2-4302-a912-b2cbdffb7d70",
      "name": "Emotion-Aware Text Generation",
      "categoryId": "15b2cdf2-e2a1-427f-acea-cfab1ae3ee2a"
    },
    {
      "id": "6c9eb0ed-53ed-4f89-a60f-22a8751bbd38",
      "name": "Sentiment-Driven NLP",
      "categoryId": "15b2cdf2-e2a1-427f-acea-cfab1ae3ee2a"
    },
    {
      "id": "57b1393e-df09-433a-b7e8-2297f082656e",
      "name": "Affective Computing",
      "categoryId": "15b2cdf2-e2a1-427f-acea-cfab1ae3ee2a"
    },
    {
      "id": "54406bc9-7a6b-44fb-b92f-6bddd5d5df69",
      "name": "Emotion Recognition",
      "categoryId": "15b2cdf2-e2a1-427f-acea-cfab1ae3ee2a"
    },
    {
      "id": "e934a42b-41f8-42d1-b589-ed651ccfdc65",
      "name": "Emotional Language Modeling",
      "categoryId": "15b2cdf2-e2a1-427f-acea-cfab1ae3ee2a"
    },
    {
      "id": "47467dda-6c93-4461-be5c-3d6bd9f870ed",
      "name": "Contextual Sentiment Analysis",
      "categoryId": "15b2cdf2-e2a1-427f-acea-cfab1ae3ee2a"
    },
    {
      "id": "7f4beb49-5eb3-40ff-a039-ac4499b55207",
      "name": "Human-Like Text Generation",
      "categoryId": "15b2cdf2-e2a1-427f-acea-cfab1ae3ee2a"
    },
    {
      "id": "ea4020e6-1d94-417f-a665-54a845a33612",
      "name": "Affective Language Models.",
      "categoryId": "15b2cdf2-e2a1-427f-acea-cfab1ae3ee2a"
    },
    {
      "id": "75c266cb-4e73-44d6-9e6a-c929e5c93f71",
      "name": "Emotion Recognition",
      "categoryId": "5f9e90a7-6ff5-4684-ac26-6214dad5d2f8"
    },
    {
      "id": "33dd7829-233a-4afe-8c62-fbcf1c8f7d9f",
      "name": "Sentiment Analysis",
      "categoryId": "5f9e90a7-6ff5-4684-ac26-6214dad5d2f8"
    },
    {
      "id": "40361f4c-d55c-4476-a7e3-bfcd0bd1669e",
      "name": "affective computing",
      "categoryId": "5f9e90a7-6ff5-4684-ac26-6214dad5d2f8"
    },
    {
      "id": "0267707f-0b8e-412c-a6c4-093e0cd39fc6",
      "name": "Affective Computing",
      "categoryId": "5f9e90a7-6ff5-4684-ac26-6214dad5d2f8"
    },
    {
      "id": "63f149e3-6066-46ae-93fa-5d3eb0e52c6b",
      "name": "Emotion AI Frameworks",
      "categoryId": "5f9e90a7-6ff5-4684-ac26-6214dad5d2f8"
    },
    {
      "id": "3c661cc3-16a2-4419-8a6c-cc37c166cf0a",
      "name": "Emotion Recognition",
      "categoryId": "3b965a30-30b0-4ffd-9f6e-2db43fd41dd7"
    },
    {
      "id": "c198b285-3484-4a1b-b341-252b15a6bf60",
      "name": "Affective Computing",
      "categoryId": "3b965a30-30b0-4ffd-9f6e-2db43fd41dd7"
    },
    {
      "id": "fd1d7c8e-92fe-42bd-8f7a-268fbb6351e3",
      "name": "Sentiment Analysis",
      "categoryId": "3b965a30-30b0-4ffd-9f6e-2db43fd41dd7"
    },
    {
      "id": "6670e3e1-7ba4-4ef4-80ce-26d502dfa7b2",
      "name": "Human-Computer Interaction",
      "categoryId": "3b965a30-30b0-4ffd-9f6e-2db43fd41dd7"
    },
    {
      "id": "24d2b379-02c5-4372-a93c-460aa22cad43",
      "name": "Emotion Detection",
      "categoryId": "3b965a30-30b0-4ffd-9f6e-2db43fd41dd7"
    },
    {
      "id": "80251df4-fbee-46b9-981c-148f0981902b",
      "name": "Empathy in AI",
      "categoryId": "3b965a30-30b0-4ffd-9f6e-2db43fd41dd7"
    },
    {
      "id": "5233eca0-441f-4eba-9359-e8c283724132",
      "name": "Social Intelligence",
      "categoryId": "3b965a30-30b0-4ffd-9f6e-2db43fd41dd7"
    },
    {
      "id": "ebc867ea-7f71-4c25-a2eb-700afe3480bd",
      "name": "Facial Expression Analysis",
      "categoryId": "3b965a30-30b0-4ffd-9f6e-2db43fd41dd7"
    },
    {
      "id": "ae5bae0a-9b65-4d3d-b493-0810abdabfb2",
      "name": "Voice Emotion Analysis",
      "categoryId": "3b965a30-30b0-4ffd-9f6e-2db43fd41dd7"
    },
    {
      "id": "3d6adda5-709f-44f7-adb2-560701e6aeec",
      "name": "Behavioral Signal Processing",
      "categoryId": "3b965a30-30b0-4ffd-9f6e-2db43fd41dd7"
    },
    {
      "id": "634f8580-c704-4703-aa7d-b41499bd8b65",
      "name": "Bayesian Statistics",
      "categoryId": "c6abdafa-cc24-471f-92fc-852c8a5955a3"
    },
    {
      "id": "c7a3b438-bc26-4682-b48a-ffd0ccd4eee7",
      "name": "Empirical Bayes",
      "categoryId": "c6abdafa-cc24-471f-92fc-852c8a5955a3"
    },
    {
      "id": "6473308b-3949-4188-ade3-336f8a3420cf",
      "name": "Regression Analysis",
      "categoryId": "c6abdafa-cc24-471f-92fc-852c8a5955a3"
    },
    {
      "id": "46c19fd6-a28b-4160-92f0-2fcecafd1c86",
      "name": "Hierarchical Models",
      "categoryId": "c6abdafa-cc24-471f-92fc-852c8a5955a3"
    },
    {
      "id": "4d38bbec-695e-4eaf-b202-80f8755b1c87",
      "name": "Statistical Estimation",
      "categoryId": "c6abdafa-cc24-471f-92fc-852c8a5955a3"
    },
    {
      "id": "431c2176-4095-4f26-8022-2bbd0106dd16",
      "name": "Shrinkage Methods",
      "categoryId": "c6abdafa-cc24-471f-92fc-852c8a5955a3"
    },
    {
      "id": "6b885947-1f43-4fdd-af20-1490f8d929ad",
      "name": "Regularization Techniques",
      "categoryId": "c6abdafa-cc24-471f-92fc-852c8a5955a3"
    },
    {
      "id": "84511211-466a-4436-846d-2741d4300c1a",
      "name": "Statistics",
      "categoryId": "c8e0b57e-b1ec-4230-96a2-c87039468c58"
    },
    {
      "id": "d2a500cd-0f69-4e7e-b047-0712223c2d4b",
      "name": "Probability Theory",
      "categoryId": "c8e0b57e-b1ec-4230-96a2-c87039468c58"
    },
    {
      "id": "ee686539-660b-439c-b773-d7f712c3879f",
      "name": "Data Analysis",
      "categoryId": "c8e0b57e-b1ec-4230-96a2-c87039468c58"
    },
    {
      "id": "1067cd76-8dd0-4dfd-88a1-608e32a0c20a",
      "name": "Empirical Methods",
      "categoryId": "c8e0b57e-b1ec-4230-96a2-c87039468c58"
    },
    {
      "id": "430891fe-fb00-44b2-af87-a0cb3592274a",
      "name": "Probabilistic Modeling",
      "categoryId": "c8e0b57e-b1ec-4230-96a2-c87039468c58"
    },
    {
      "id": "8804e026-4d25-42e2-8141-8909f65541cf",
      "name": "AI/ML Sub-category Tags: Reinforcement Learning",
      "categoryId": "0cc93a0f-09d5-48af-a538-f2cdc749c5ba"
    },
    {
      "id": "da2dd8d2-a015-44b4-89cc-2b4342fb2080",
      "name": "Autonomous Agents",
      "categoryId": "0cc93a0f-09d5-48af-a538-f2cdc749c5ba"
    },
    {
      "id": "2ddae9d0-4eb5-4d48-b6b9-ac198948a2b2",
      "name": "Decision-Making Systems",
      "categoryId": "0cc93a0f-09d5-48af-a538-f2cdc749c5ba"
    },
    {
      "id": "7e8fe9ad-b044-4279-bb52-318f67493694",
      "name": "Policy Optimization",
      "categoryId": "0cc93a0f-09d5-48af-a538-f2cdc749c5ba"
    },
    {
      "id": "46e1ad1a-bc50-40ce-931c-ea695f7e3bc3",
      "name": "Reward Functions",
      "categoryId": "0cc93a0f-09d5-48af-a538-f2cdc749c5ba"
    },
    {
      "id": "3b6dcbcf-6057-4699-874b-a020c9edcfd8",
      "name": "Autonomous Systems",
      "categoryId": "0cc93a0f-09d5-48af-a538-f2cdc749c5ba"
    },
    {
      "id": "9abbb42c-d626-4767-8e4e-9cc783290dd1",
      "name": "Multi-Agent Systems",
      "categoryId": "0cc93a0f-09d5-48af-a538-f2cdc749c5ba"
    },
    {
      "id": "0d9020b9-2872-487e-9f55-7c323a06bfee",
      "name": "Adaptive Control",
      "categoryId": "0cc93a0f-09d5-48af-a538-f2cdc749c5ba"
    },
    {
      "id": "90afc993-9b3d-4dbb-8c6f-75a126164954",
      "name": "Behavioral Cloning",
      "categoryId": "0cc93a0f-09d5-48af-a538-f2cdc749c5ba"
    },
    {
      "id": "d3b8ddcd-51ef-49cc-a592-76b7d1d2d8ff",
      "name": "Hierarchical Reinforcement Learning",
      "categoryId": "0cc93a0f-09d5-48af-a538-f2cdc749c5ba"
    },
    {
      "id": "906afea9-77d3-4958-a838-5882818bf542",
      "name": "Dimensionality reduction",
      "categoryId": "36ac7ae2-674b-4f49-ab52-5044c7cf59ce"
    },
    {
      "id": "45fa3c14-906f-4cc4-acd4-0eb43fdb9086",
      "name": "feature extraction",
      "categoryId": "36ac7ae2-674b-4f49-ab52-5044c7cf59ce"
    },
    {
      "id": "54b967fb-6e7d-4d20-9b07-5ba6ea32ab0c",
      "name": "deep learning",
      "categoryId": "36ac7ae2-674b-4f49-ab52-5044c7cf59ce"
    },
    {
      "id": "c19d89e5-29ce-407a-b1ad-72e798ba93e8",
      "name": "sequence modeling",
      "categoryId": "36ac7ae2-674b-4f49-ab52-5044c7cf59ce"
    },
    {
      "id": "9ca53ef4-7b78-4c49-a946-484069a5263e",
      "name": "neural networks",
      "categoryId": "36ac7ae2-674b-4f49-ab52-5044c7cf59ce"
    },
    {
      "id": "69add8c6-a1c2-44a6-9986-60e084393cc1",
      "name": "representation learning",
      "categoryId": "36ac7ae2-674b-4f49-ab52-5044c7cf59ce"
    },
    {
      "id": "c4eb5a6b-0168-4206-b693-a29521284584",
      "name": "natural language processing (NLP)",
      "categoryId": "36ac7ae2-674b-4f49-ab52-5044c7cf59ce"
    },
    {
      "id": "dae3f131-e14b-4c3f-b6b0-77174d3939de",
      "name": "computer vision",
      "categoryId": "36ac7ae2-674b-4f49-ab52-5044c7cf59ce"
    },
    {
      "id": "8fe56e89-0719-44f7-b927-f6621dee5a5b",
      "name": "autoencoders",
      "categoryId": "36ac7ae2-674b-4f49-ab52-5044c7cf59ce"
    },
    {
      "id": "b0cfafae-ecfd-4360-8028-ea23c8fecb9a",
      "name": "variational autoencoders (VAEs)",
      "categoryId": "36ac7ae2-674b-4f49-ab52-5044c7cf59ce"
    },
    {
      "id": "6c89e3f5-b313-4f33-8239-c09111cad8e6",
      "name": "sequence encoders",
      "categoryId": "36ac7ae2-674b-4f49-ab52-5044c7cf59ce"
    },
    {
      "id": "b73b6e20-7153-4ab7-b786-68903216e673",
      "name": "transformer encoders",
      "categoryId": "36ac7ae2-674b-4f49-ab52-5044c7cf59ce"
    },
    {
      "id": "a9b0ca12-fe72-478c-8f95-2811090bd9cd",
      "name": "convolutional encoders.",
      "categoryId": "36ac7ae2-674b-4f49-ab52-5044c7cf59ce"
    },
    {
      "id": "19a861fb-718e-475a-be37-21f1dd203388",
      "name": "Natural Language Processing (NLP)",
      "categoryId": "7acda575-f117-43da-a398-ae116ac3b8be"
    },
    {
      "id": "1f1aa4ce-c415-4352-b2ba-865c5198f80d",
      "name": "Deep Learning",
      "categoryId": "7acda575-f117-43da-a398-ae116ac3b8be"
    },
    {
      "id": "3eb07ada-2765-48cd-a86b-5f8a3090d5fd",
      "name": "Neural Networks",
      "categoryId": "7acda575-f117-43da-a398-ae116ac3b8be"
    },
    {
      "id": "2ae21979-c3b3-42cd-84d9-2d3f9f5995ad",
      "name": "Attention Mechanisms",
      "categoryId": "7acda575-f117-43da-a398-ae116ac3b8be"
    },
    {
      "id": "091072b9-b296-44fe-9e17-4f3b1c36d7a1",
      "name": "Sequence-to-Sequence Models",
      "categoryId": "7acda575-f117-43da-a398-ae116ac3b8be"
    },
    {
      "id": "2cc477ee-40d2-4ed3-a5e9-4f217a875da7",
      "name": "Transformer Architecture",
      "categoryId": "7acda575-f117-43da-a398-ae116ac3b8be"
    },
    {
      "id": "72c8fe94-2719-4914-8d43-c3c9dad8266c",
      "name": "Machine Translation",
      "categoryId": "7acda575-f117-43da-a398-ae116ac3b8be"
    },
    {
      "id": "9cdaa5f8-7c1f-4d3a-bb3f-b910fd0aeef1",
      "name": "Contextual Embeddings",
      "categoryId": "7acda575-f117-43da-a398-ae116ac3b8be"
    },
    {
      "id": "5de64c15-c877-4e9c-a334-e1974d2f1e44",
      "name": "Encoder-Decoder Architecture",
      "categoryId": "f48b8da7-416f-4bf5-9d8a-4638ff6f7a39"
    },
    {
      "id": "082904c6-8be2-4ed7-8340-c922c26fb465",
      "name": "Sequence-to-Sequence Models",
      "categoryId": "f48b8da7-416f-4bf5-9d8a-4638ff6f7a39"
    },
    {
      "id": "89ca30a3-1a41-4c7d-8bb1-cfed9356b6fa",
      "name": "Recurrent Neural Networks (RNN)",
      "categoryId": "f48b8da7-416f-4bf5-9d8a-4638ff6f7a39"
    },
    {
      "id": "4c020ab3-e75d-44cc-8dd3-d3418ef16ff7",
      "name": "Long Short-Term Memory (LSTM)",
      "categoryId": "f48b8da7-416f-4bf5-9d8a-4638ff6f7a39"
    },
    {
      "id": "5b60d46a-62f6-48a3-8018-2db974196fa2",
      "name": "Gated Recurrent Units (GRU)",
      "categoryId": "f48b8da7-416f-4bf5-9d8a-4638ff6f7a39"
    },
    {
      "id": "6bdb618e-aa02-4deb-8055-ff7592c2f02b",
      "name": "Attention Mechanisms",
      "categoryId": "f48b8da7-416f-4bf5-9d8a-4638ff6f7a39"
    },
    {
      "id": "704ffe15-3065-40df-b120-27a17d39d5dc",
      "name": "Transformer Models",
      "categoryId": "f48b8da7-416f-4bf5-9d8a-4638ff6f7a39"
    },
    {
      "id": "77810795-2b89-43ae-a1a2-b6021b4b4b9f",
      "name": "Encoder-Decoder Models",
      "categoryId": "5a0ec7db-6b3a-4e39-ac6d-b851adc590a8"
    },
    {
      "id": "93dfc528-6d52-4947-8d68-73006623e4c1",
      "name": "Sequence-to-Sequence Models",
      "categoryId": "5a0ec7db-6b3a-4e39-ac6d-b851adc590a8"
    },
    {
      "id": "ae3f9912-0fd5-470a-a06a-f0a0e76aaf35",
      "name": "Neural Network Architectures",
      "categoryId": "5a0ec7db-6b3a-4e39-ac6d-b851adc590a8"
    },
    {
      "id": "ab3c0651-0cdf-46a7-a882-15967b25b3d9",
      "name": "Recurrent Neural Networks",
      "categoryId": "5a0ec7db-6b3a-4e39-ac6d-b851adc590a8"
    },
    {
      "id": "70cb21f5-0562-491b-a309-205220b737b7",
      "name": "Transformers",
      "categoryId": "5a0ec7db-6b3a-4e39-ac6d-b851adc590a8"
    },
    {
      "id": "3913b623-e6d1-43fb-aac2-bf432ed0112a",
      "name": "Attention Mechanisms",
      "categoryId": "5a0ec7db-6b3a-4e39-ac6d-b851adc590a8"
    },
    {
      "id": "de7de3bf-a780-4067-a5d3-660627611a66",
      "name": "Deep Learning",
      "categoryId": "5a0ec7db-6b3a-4e39-ac6d-b851adc590a8"
    },
    {
      "id": "e712490f-71c4-4f72-869c-d70a7c49f24b",
      "name": "Natural Language Processing",
      "categoryId": "5a0ec7db-6b3a-4e39-ac6d-b851adc590a8"
    },
    {
      "id": "0829b084-5e21-4363-970f-e8930633e0c7",
      "name": "Machine Translation",
      "categoryId": "5a0ec7db-6b3a-4e39-ac6d-b851adc590a8"
    },
    {
      "id": "a618e317-c819-405b-a70e-c9d381f358f1",
      "name": "Language Modeling",
      "categoryId": "5a0ec7db-6b3a-4e39-ac6d-b851adc590a8"
    },
    {
      "id": "c6f5f24d-5807-47bf-8e76-2895fbea9d8b",
      "name": "Encoder-Decoder Models Extensions",
      "categoryId": "3f53aefa-f781-4d9f-b5d8-cc8cd9933ca0"
    },
    {
      "id": "63265821-0634-4b76-acf2-e859068e1d8f",
      "name": "Sequence-to-Sequence Models",
      "categoryId": "3f53aefa-f781-4d9f-b5d8-cc8cd9933ca0"
    },
    {
      "id": "360fb862-1d4f-4b6a-93f0-1f7f275ceb69",
      "name": "Transformers",
      "categoryId": "3f53aefa-f781-4d9f-b5d8-cc8cd9933ca0"
    },
    {
      "id": "296a9093-e9db-4e16-8154-f0b45e49d554",
      "name": "Attention Mechanisms",
      "categoryId": "3f53aefa-f781-4d9f-b5d8-cc8cd9933ca0"
    },
    {
      "id": "a6e89843-8b5a-49d2-9897-035cae5a5c90",
      "name": "Multi-head Attention",
      "categoryId": "3f53aefa-f781-4d9f-b5d8-cc8cd9933ca0"
    },
    {
      "id": "5e7aa69d-94cb-4680-93cf-1982568e787d",
      "name": "Positional Encodings",
      "categoryId": "3f53aefa-f781-4d9f-b5d8-cc8cd9933ca0"
    },
    {
      "id": "65fb52ac-1ccf-43d5-99ba-7160cba85567",
      "name": "Modular Architectures",
      "categoryId": "3f53aefa-f781-4d9f-b5d8-cc8cd9933ca0"
    },
    {
      "id": "193a254c-6356-4a74-bfad-123cf77fea8a",
      "name": "Hierarchical Encodings",
      "categoryId": "3f53aefa-f781-4d9f-b5d8-cc8cd9933ca0"
    },
    {
      "id": "2ba79f8f-3a71-4e4d-84fe-51c1cbb794ef",
      "name": "Hybrid Models",
      "categoryId": "3f53aefa-f781-4d9f-b5d8-cc8cd9933ca0"
    },
    {
      "id": "e67e8940-e9e5-4644-8572-775a477a1857",
      "name": "Dynamic Memory Networks",
      "categoryId": "3f53aefa-f781-4d9f-b5d8-cc8cd9933ca0"
    },
    {
      "id": "43940ebb-9d7e-4f00-b570-bdd588d4a248",
      "name": "Encoder-Decoder Models Extensions",
      "categoryId": "16e6d0ac-ce65-4d4d-9576-9987b3def357"
    },
    {
      "id": "0bbb35c2-9793-4dea-ab12-7a9097497bed",
      "name": "Sequence-to-Sequence Models",
      "categoryId": "16e6d0ac-ce65-4d4d-9576-9987b3def357"
    },
    {
      "id": "c12fe7f9-04e8-4ed8-b6db-24cff3b9cdbf",
      "name": "Attention Mechanisms",
      "categoryId": "16e6d0ac-ce65-4d4d-9576-9987b3def357"
    },
    {
      "id": "1f3b0274-9b13-49cd-a7de-9f3741d3b8f7",
      "name": "Transformer Architectures",
      "categoryId": "16e6d0ac-ce65-4d4d-9576-9987b3def357"
    },
    {
      "id": "bf959b0a-0540-4e4d-a39a-fd5d16659b04",
      "name": "Variants of Encoder-Decoder",
      "categoryId": "16e6d0ac-ce65-4d4d-9576-9987b3def357"
    },
    {
      "id": "9462a58a-00da-4b29-83c9-356b698d9ece",
      "name": "Adaptive Attention",
      "categoryId": "16e6d0ac-ce65-4d4d-9576-9987b3def357"
    },
    {
      "id": "5e17cb98-5d20-4a28-a08c-87d55270f6ae",
      "name": "Multi-Head Attention",
      "categoryId": "16e6d0ac-ce65-4d4d-9576-9987b3def357"
    },
    {
      "id": "1b0d9bea-d219-4efb-97a6-2d039f0e2b8d",
      "name": "Convolutional Encoders",
      "categoryId": "16e6d0ac-ce65-4d4d-9576-9987b3def357"
    },
    {
      "id": "82794aa4-c445-4e50-9844-e497fc8f25e9",
      "name": "Recurrent Encoders",
      "categoryId": "16e6d0ac-ce65-4d4d-9576-9987b3def357"
    },
    {
      "id": "9fe34b61-6168-40ad-8e77-6063c553d9d0",
      "name": "Dynamic Routing",
      "categoryId": "16e6d0ac-ce65-4d4d-9576-9987b3def357"
    },
    {
      "id": "ab30186f-fe85-4a1b-a5fa-aa05014c2511",
      "name": "Hierarchical Encoders",
      "categoryId": "16e6d0ac-ce65-4d4d-9576-9987b3def357"
    },
    {
      "id": "75f4cb0a-b898-46a7-875d-fe830cfea2fd",
      "name": "Contextual Embeddings",
      "categoryId": "16e6d0ac-ce65-4d4d-9576-9987b3def357"
    },
    {
      "id": "37e95053-0bd1-49ca-970c-2d3918d66495",
      "name": "Model Compression Techniques",
      "categoryId": "16e6d0ac-ce65-4d4d-9576-9987b3def357"
    },
    {
      "id": "347ca840-0e65-413b-b578-c04dbaca1ec8",
      "name": "Fine-tuning Strategies",
      "categoryId": "16e6d0ac-ce65-4d4d-9576-9987b3def357"
    },
    {
      "id": "20aaff3b-2bb4-4a8a-bba5-ad5575c4be97",
      "name": "Encoder-Decoder Models Extensions",
      "categoryId": "78fd06a3-b168-4f92-91b5-d402ba3bebb2"
    },
    {
      "id": "f7e0211c-88be-4e89-9704-3a3cc8e4474e",
      "name": "Transformer Variants",
      "categoryId": "78fd06a3-b168-4f92-91b5-d402ba3bebb2"
    },
    {
      "id": "e5c48b39-350c-477e-aa77-032498d573da",
      "name": "Sequence-to-Sequence Architectures",
      "categoryId": "78fd06a3-b168-4f92-91b5-d402ba3bebb2"
    },
    {
      "id": "b829f598-c4af-486b-a144-26f3a8eb601f",
      "name": "Attention Mechanisms",
      "categoryId": "78fd06a3-b168-4f92-91b5-d402ba3bebb2"
    },
    {
      "id": "aa2c26db-f5e2-43ab-b6cd-811138aadce9",
      "name": "Residual Connections",
      "categoryId": "78fd06a3-b168-4f92-91b5-d402ba3bebb2"
    },
    {
      "id": "4ea56eb5-f930-443e-a53f-dd3ed277e860",
      "name": "Convolutional Encoders/Decoders",
      "categoryId": "78fd06a3-b168-4f92-91b5-d402ba3bebb2"
    },
    {
      "id": "5a7f5b3e-8d7a-4993-b8c3-fdbd581e45c5",
      "name": "Variational Extensions",
      "categoryId": "78fd06a3-b168-4f92-91b5-d402ba3bebb2"
    },
    {
      "id": "79778c57-ac08-4984-bee4-75a7d26de084",
      "name": "Multi-head Attention",
      "categoryId": "78fd06a3-b168-4f92-91b5-d402ba3bebb2"
    },
    {
      "id": "4138f6fe-7cbb-4f4e-91ad-ea2011f08d02",
      "name": "Adaptive Encoding",
      "categoryId": "78fd06a3-b168-4f92-91b5-d402ba3bebb2"
    },
    {
      "id": "b9aec470-e31f-4ff0-b9b0-14004bde800a",
      "name": "Cross-Attention Techniques",
      "categoryId": "78fd06a3-b168-4f92-91b5-d402ba3bebb2"
    },
    {
      "id": "94c45be1-d01c-4772-b3b4-6aa5253ff255",
      "name": "Fine-tuning Strategies",
      "categoryId": "78fd06a3-b168-4f92-91b5-d402ba3bebb2"
    },
    {
      "id": "55ebf19c-935f-461a-b85e-bad66a8b72da",
      "name": "Model Compression",
      "categoryId": "78fd06a3-b168-4f92-91b5-d402ba3bebb2"
    },
    {
      "id": "c318cabf-11e7-432a-b00b-0ac5c720cd49",
      "name": "Transfer Learning in Encoders-Decoders",
      "categoryId": "78fd06a3-b168-4f92-91b5-d402ba3bebb2"
    },
    {
      "id": "2fea7433-e3b1-43fd-a671-e92c0417f759",
      "name": "Encoder-Decoder Models Extensions Techniques",
      "categoryId": "e9c6dc15-77d2-4a96-8ac0-231e7f8065d0"
    },
    {
      "id": "6abe589e-9109-4a24-90e7-141630e8e41f",
      "name": "Sequence-to-Sequence Learning",
      "categoryId": "e9c6dc15-77d2-4a96-8ac0-231e7f8065d0"
    },
    {
      "id": "754db3fe-2e28-49b9-a3cb-0f6fd7a8bef0",
      "name": "Attention Mechanisms",
      "categoryId": "e9c6dc15-77d2-4a96-8ac0-231e7f8065d0"
    },
    {
      "id": "8653ea23-a2b5-4828-a67b-deda859b12b7",
      "name": "Transformer Architectures",
      "categoryId": "e9c6dc15-77d2-4a96-8ac0-231e7f8065d0"
    },
    {
      "id": "61b9b684-73f6-4246-bce2-0ed1de7a0fff",
      "name": "Model Optimization",
      "categoryId": "e9c6dc15-77d2-4a96-8ac0-231e7f8065d0"
    },
    {
      "id": "c5388222-8a9c-4990-81e9-24f6b23061c1",
      "name": "Transfer Learning",
      "categoryId": "e9c6dc15-77d2-4a96-8ac0-231e7f8065d0"
    },
    {
      "id": "672881c6-6c60-45ee-9731-cd35d02046ee",
      "name": "Multi-head Attention",
      "categoryId": "e9c6dc15-77d2-4a96-8ac0-231e7f8065d0"
    },
    {
      "id": "b0212338-e70f-4f22-9c4c-412b8b87b93e",
      "name": "Self-Attention",
      "categoryId": "e9c6dc15-77d2-4a96-8ac0-231e7f8065d0"
    },
    {
      "id": "9afe9eac-20cf-4cf0-ac25-b00c3da60731",
      "name": "Bidirectional Encoders",
      "categoryId": "e9c6dc15-77d2-4a96-8ac0-231e7f8065d0"
    },
    {
      "id": "c24210b0-803f-4958-acfa-cab866de3c6e",
      "name": "Data Augmentation for Sequence Models",
      "categoryId": "e9c6dc15-77d2-4a96-8ac0-231e7f8065d0"
    },
    {
      "id": "e91489a6-5104-4e2a-883d-e88507d03aad",
      "name": "Natural Language Processing",
      "categoryId": "2ea05092-e306-4d8c-a752-f9d04a2b2810"
    },
    {
      "id": "4b55a054-2f35-49a1-8d6c-e8367df9ce7a",
      "name": "Deep Learning",
      "categoryId": "2ea05092-e306-4d8c-a752-f9d04a2b2810"
    },
    {
      "id": "c05268f3-d43d-47ea-8b33-e9e983eb53cb",
      "name": "Representation Learning",
      "categoryId": "2ea05092-e306-4d8c-a752-f9d04a2b2810"
    },
    {
      "id": "d54820be-d967-4c67-992a-58d0288d1faa",
      "name": "Sequence-to-Sequence Models",
      "categoryId": "2ea05092-e306-4d8c-a752-f9d04a2b2810"
    },
    {
      "id": "24b65279-8ed1-4213-a3c5-35845ae55883",
      "name": "Self-supervised Learning",
      "categoryId": "2ea05092-e306-4d8c-a752-f9d04a2b2810"
    },
    {
      "id": "bb5a8925-dca4-4a3b-a6b9-f9c61e3b736a",
      "name": "Pretraining",
      "categoryId": "2ea05092-e306-4d8c-a752-f9d04a2b2810"
    },
    {
      "id": "0b6cbaa5-9a95-4403-b6f6-4c14ed444d3c",
      "name": "Transformers",
      "categoryId": "2ea05092-e306-4d8c-a752-f9d04a2b2810"
    },
    {
      "id": "11fdfa50-178b-42b1-83b8-be41b448fc49",
      "name": "Language Models",
      "categoryId": "2ea05092-e306-4d8c-a752-f9d04a2b2810"
    },
    {
      "id": "1bb4dbe1-ac1a-4b13-9e54-017d633f451c",
      "name": "Contextual Embeddings",
      "categoryId": "2ea05092-e306-4d8c-a752-f9d04a2b2810"
    },
    {
      "id": "0d36489c-a132-4707-b480-81ab44dcd39c",
      "name": "Unsupervised Learning Techniques",
      "categoryId": "2ea05092-e306-4d8c-a752-f9d04a2b2810"
    },
    {
      "id": "5e34ad7f-f4e3-40ff-a507-7a9f3a692df4",
      "name": "Encoding in machine learning primarily relates to data preprocessing techniques used to convert categorical",
      "categoryId": "c3dc9eea-c0a5-43b6-8e06-1c2e238927e1"
    },
    {
      "id": "a0f4b5ec-9f75-4cbe-a8d2-e60ad6e5c300",
      "name": "textual",
      "categoryId": "c3dc9eea-c0a5-43b6-8e06-1c2e238927e1"
    },
    {
      "id": "1789f423-01f3-4221-b8da-fe1bc6a40a7f",
      "name": "or complex data formats into numerical representations suitable for model ingestion. Common sub-category tags include 'One-Hot Encoding'",
      "categoryId": "c3dc9eea-c0a5-43b6-8e06-1c2e238927e1"
    },
    {
      "id": "2cc4b890-1569-44b5-a20b-7b7aa2643cac",
      "name": "'Label Encoding'",
      "categoryId": "c3dc9eea-c0a5-43b6-8e06-1c2e238927e1"
    },
    {
      "id": "710fbfd1-9dcb-4dc3-9b4c-efdd80070484",
      "name": "'Ordinal Encoding'",
      "categoryId": "c3dc9eea-c0a5-43b6-8e06-1c2e238927e1"
    },
    {
      "id": "1dfd22c5-ddc4-4368-9d7e-400c05bfe6ab",
      "name": "'Binary Encoding'",
      "categoryId": "c3dc9eea-c0a5-43b6-8e06-1c2e238927e1"
    },
    {
      "id": "ddc333ba-dff8-469b-85bf-0b8ba20cc265",
      "name": "'Feature Hashing'",
      "categoryId": "c3dc9eea-c0a5-43b6-8e06-1c2e238927e1"
    },
    {
      "id": "b9ab7654-4327-4d0a-b6b2-88af8079c2cb",
      "name": "and 'Embedding'. These methods help machine learning algorithms interpret non-numeric data and capture the underlying relationships within categorical variables.",
      "categoryId": "c3dc9eea-c0a5-43b6-8e06-1c2e238927e1"
    },
    {
      "id": "1ed26969-d740-47dc-95a2-8debaa21bdf6",
      "name": "Natural Language Processing",
      "categoryId": "4b0507ca-c08c-413d-b21d-fcd5dd7e515a"
    },
    {
      "id": "c75ab5cd-2913-45ff-b719-106caf62c3e1",
      "name": "Dialogue Management",
      "categoryId": "4b0507ca-c08c-413d-b21d-fcd5dd7e515a"
    },
    {
      "id": "a3adf8cc-c096-4836-8a26-464fb09c2850",
      "name": "Speech Recognition",
      "categoryId": "4b0507ca-c08c-413d-b21d-fcd5dd7e515a"
    },
    {
      "id": "21253aa9-4c4c-4b7a-ad0a-60a72947d842",
      "name": "Language Understanding",
      "categoryId": "4b0507ca-c08c-413d-b21d-fcd5dd7e515a"
    },
    {
      "id": "f5a7f1c1-7d1d-44b6-a407-031bc9427d46",
      "name": "Sequence-to-Sequence Models",
      "categoryId": "4b0507ca-c08c-413d-b21d-fcd5dd7e515a"
    },
    {
      "id": "32e4061f-8242-4625-9df1-87ef41b22acc",
      "name": "Reinforcement Learning",
      "categoryId": "4b0507ca-c08c-413d-b21d-fcd5dd7e515a"
    },
    {
      "id": "e9a477df-6898-42cf-8d5a-5269f86ef357",
      "name": "Deep Learning",
      "categoryId": "4b0507ca-c08c-413d-b21d-fcd5dd7e515a"
    },
    {
      "id": "7aee1761-b275-42f5-8f03-f765b41a8cbb",
      "name": "Conversational AI",
      "categoryId": "4b0507ca-c08c-413d-b21d-fcd5dd7e515a"
    },
    {
      "id": "e642a5fa-6e3c-4965-8187-16ff9a3d1a7f",
      "name": "Context-Aware Systems",
      "categoryId": "4b0507ca-c08c-413d-b21d-fcd5dd7e515a"
    },
    {
      "id": "717245df-7243-4e68-bd48-af164b734e18",
      "name": "Transformer Models",
      "categoryId": "4b0507ca-c08c-413d-b21d-fcd5dd7e515a"
    },
    {
      "id": "c349a650-3ef2-4ad8-a9d8-57cec2bb6258",
      "name": "Model Distillation",
      "categoryId": "a9561565-4162-4df7-9ded-b102c1f03d66"
    },
    {
      "id": "298920d9-3ec3-4085-8ab0-e5637d25dd39",
      "name": "Energy-Based Models",
      "categoryId": "a9561565-4162-4df7-9ded-b102c1f03d66"
    },
    {
      "id": "839f299c-3efb-48f4-818d-de605d4fe04a",
      "name": "Energy Functions",
      "categoryId": "a9561565-4162-4df7-9ded-b102c1f03d66"
    },
    {
      "id": "28b36fef-2005-438d-b42a-8f9fb21cca0d",
      "name": "Probabilistic Frameworks",
      "categoryId": "a9561565-4162-4df7-9ded-b102c1f03d66"
    },
    {
      "id": "124b9dc7-30d7-498c-89b1-32362c5323ea",
      "name": "Representation Learning",
      "categoryId": "a9561565-4162-4df7-9ded-b102c1f03d66"
    },
    {
      "id": "e31aeaff-71dd-4495-be7a-0c39543f5d06",
      "name": "Teacher-Student Models",
      "categoryId": "a9561565-4162-4df7-9ded-b102c1f03d66"
    },
    {
      "id": "df7e4c06-0ce4-4cf1-81a6-497754a67e81",
      "name": "Energy-Based Regularization",
      "categoryId": "a9561565-4162-4df7-9ded-b102c1f03d66"
    },
    {
      "id": "5b09eec1-5ac0-45cb-95b2-9b426e4e67b4",
      "name": "Energy-Based GANs (EBGANs)",
      "categoryId": "512e1bf0-d1b6-4015-b768-875b1d3b19e6"
    },
    {
      "id": "a58b1dca-5ff8-487b-a128-fd5aaf05d33c",
      "name": "Generative Adversarial Networks",
      "categoryId": "512e1bf0-d1b6-4015-b768-875b1d3b19e6"
    },
    {
      "id": "dbe6a900-86e3-435d-98e5-5df57effa953",
      "name": "Energy-Based Models",
      "categoryId": "512e1bf0-d1b6-4015-b768-875b1d3b19e6"
    },
    {
      "id": "4bdeac16-49e0-498e-99e4-68cb3eadd768",
      "name": "Deep Learning",
      "categoryId": "512e1bf0-d1b6-4015-b768-875b1d3b19e6"
    },
    {
      "id": "92434764-b319-45b0-82b7-d44feec3d57a",
      "name": "Unsupervised Learning",
      "categoryId": "512e1bf0-d1b6-4015-b768-875b1d3b19e6"
    },
    {
      "id": "7f21d26a-c852-4f47-84d7-e37adeedaa4f",
      "name": "Generative Modeling",
      "categoryId": "512e1bf0-d1b6-4015-b768-875b1d3b19e6"
    },
    {
      "id": "4b013ae5-ce3f-4a87-9542-94f264b0b0cc",
      "name": "Neural Networks",
      "categoryId": "512e1bf0-d1b6-4015-b768-875b1d3b19e6"
    },
    {
      "id": "e52bd599-7ab1-4acd-9c57-2e1a6e5139b1",
      "name": "Contrastive Divergence",
      "categoryId": "512e1bf0-d1b6-4015-b768-875b1d3b19e6"
    },
    {
      "id": "b4cd2712-5453-4665-bd5c-5a5399aa9b2e",
      "name": "Energy-Based Models (EBMs)",
      "categoryId": "bae25fb5-0be2-4b34-b716-dcdb45299ae1"
    },
    {
      "id": "800c3a66-d80e-4193-a3ad-add52bd9a068",
      "name": "Probabilistic Graphical Models",
      "categoryId": "bae25fb5-0be2-4b34-b716-dcdb45299ae1"
    },
    {
      "id": "ed561405-7b23-4ea0-9329-370e2c36f43a",
      "name": "Generative Models",
      "categoryId": "bae25fb5-0be2-4b34-b716-dcdb45299ae1"
    },
    {
      "id": "42d4a71f-2a42-4626-b63e-def98aabc851",
      "name": "Energy Functions",
      "categoryId": "bae25fb5-0be2-4b34-b716-dcdb45299ae1"
    },
    {
      "id": "504c5bae-79cb-4019-9c7b-6132f7cf31a8",
      "name": "Markov Random Fields",
      "categoryId": "bae25fb5-0be2-4b34-b716-dcdb45299ae1"
    },
    {
      "id": "998f2046-4635-41f6-8fa0-8be9776c8287",
      "name": "Restricted Boltzmann Machines",
      "categoryId": "bae25fb5-0be2-4b34-b716-dcdb45299ae1"
    },
    {
      "id": "2c1257c3-eaf2-4012-804b-5d2c09bb8266",
      "name": "Deep Energy Models",
      "categoryId": "bae25fb5-0be2-4b34-b716-dcdb45299ae1"
    },
    {
      "id": "d8d4854d-7749-4272-b072-25c6310f0d47",
      "name": "Variational Autoencoders",
      "categoryId": "bae25fb5-0be2-4b34-b716-dcdb45299ae1"
    },
    {
      "id": "5c312b6d-c261-4808-8789-2b34e69eed97",
      "name": "Energy-Based Deep Learning",
      "categoryId": "bae25fb5-0be2-4b34-b716-dcdb45299ae1"
    },
    {
      "id": "5cc41e4b-5b70-4ae9-a87b-fcde50d2b66d",
      "name": "Latent Space Models",
      "categoryId": "bae25fb5-0be2-4b34-b716-dcdb45299ae1"
    },
    {
      "id": "e73cbccd-cc08-4fb8-a7d2-afda94a45abc",
      "name": "Energy-Based Models (EBMs)",
      "categoryId": "6120da77-9162-49b0-8d06-e2affbf6368b"
    },
    {
      "id": "17afd917-2c1b-4947-8202-1fb6ca01efe8",
      "name": "Probabilistic Models",
      "categoryId": "6120da77-9162-49b0-8d06-e2affbf6368b"
    },
    {
      "id": "76fba6d6-c063-488c-b8a9-17649d43857f",
      "name": "Energy Functions",
      "categoryId": "6120da77-9162-49b0-8d06-e2affbf6368b"
    },
    {
      "id": "586b969b-e47b-4524-ad38-650005e17501",
      "name": "Energy Landscape",
      "categoryId": "6120da77-9162-49b0-8d06-e2affbf6368b"
    },
    {
      "id": "0c4b2da4-b226-4a5b-a7a1-5bf03ef7fb2a",
      "name": "Generative Models",
      "categoryId": "6120da77-9162-49b0-8d06-e2affbf6368b"
    },
    {
      "id": "3f4c714c-f633-41af-9984-e07f1f70b084",
      "name": "Neural Energy Models",
      "categoryId": "6120da77-9162-49b0-8d06-e2affbf6368b"
    },
    {
      "id": "83a5c83d-7118-42ec-9ebf-f7c747c9510a",
      "name": "Deep Learning",
      "categoryId": "6120da77-9162-49b0-8d06-e2affbf6368b"
    },
    {
      "id": "e0eb2b77-b2ef-4241-93ab-253fb9abfbfc",
      "name": "Representation Learning",
      "categoryId": "6120da77-9162-49b0-8d06-e2affbf6368b"
    },
    {
      "id": "5a79a72b-8d6f-4569-8d60-afa9d0a614d2",
      "name": "Contrastive Divergence",
      "categoryId": "6120da77-9162-49b0-8d06-e2affbf6368b"
    },
    {
      "id": "09ae481f-f05f-42b0-99e7-1891a265fc26",
      "name": "Markov Random Fields",
      "categoryId": "6120da77-9162-49b0-8d06-e2affbf6368b"
    },
    {
      "id": "0f2fcad0-6521-4da1-9f64-e9b3aa8334bc",
      "name": "Energy-Based Models",
      "categoryId": "969e5af5-df4f-4149-a078-161d08490472"
    },
    {
      "id": "4caa6b48-ef3e-4214-969c-30b9b7015509",
      "name": "Energy Functions",
      "categoryId": "969e5af5-df4f-4149-a078-161d08490472"
    },
    {
      "id": "685edbb0-e6ec-4f95-9c97-ca40ac795afa",
      "name": "Deep Energy Models",
      "categoryId": "969e5af5-df4f-4149-a078-161d08490472"
    },
    {
      "id": "6715e3ab-815b-47f1-9580-0e0fc130f2c6",
      "name": "Generative Models",
      "categoryId": "969e5af5-df4f-4149-a078-161d08490472"
    },
    {
      "id": "953681cd-1eaa-47ea-94ba-5d1e56ff141b",
      "name": "Markov Random Fields",
      "categoryId": "969e5af5-df4f-4149-a078-161d08490472"
    },
    {
      "id": "11a5cad9-3cb3-4c28-94b4-037aea5cb74e",
      "name": "Energy-Based Deep Learning",
      "categoryId": "969e5af5-df4f-4149-a078-161d08490472"
    },
    {
      "id": "398ff695-4778-42a3-bd6a-d8dfbddb1cd0",
      "name": "Contrastive Divergence",
      "categoryId": "969e5af5-df4f-4149-a078-161d08490472"
    },
    {
      "id": "96d0ddb5-f13e-41a0-ae21-843e335f4eb2",
      "name": "Variational Energy Models",
      "categoryId": "969e5af5-df4f-4149-a078-161d08490472"
    },
    {
      "id": "1a1bc431-1319-4d6d-b92c-1146acc30a52",
      "name": "Reinforcement Learning",
      "categoryId": "99457e6b-e884-42ed-ba3d-a7395d94a4c2"
    },
    {
      "id": "2e242b6f-4536-439f-ab94-9b80b8fc084c",
      "name": "Energy-Based Models",
      "categoryId": "99457e6b-e884-42ed-ba3d-a7395d94a4c2"
    },
    {
      "id": "22c84b2e-28e4-4643-a343-568adae50d2d",
      "name": "Unsupervised Learning",
      "categoryId": "99457e6b-e884-42ed-ba3d-a7395d94a4c2"
    },
    {
      "id": "c3d705b4-5782-493d-a569-db4c9e12e95a",
      "name": "Deep Learning",
      "categoryId": "99457e6b-e884-42ed-ba3d-a7395d94a4c2"
    },
    {
      "id": "95197374-21c5-4544-af48-8f16a7a668b8",
      "name": "Representation Learning",
      "categoryId": "99457e6b-e884-42ed-ba3d-a7395d94a4c2"
    },
    {
      "id": "c9edc101-8614-484c-95d6-999638347e27",
      "name": "Probabilistic Modeling",
      "categoryId": "99457e6b-e884-42ed-ba3d-a7395d94a4c2"
    },
    {
      "id": "21b378f0-4b22-4700-9caf-1263f8f71d77",
      "name": "Variational Methods",
      "categoryId": "99457e6b-e884-42ed-ba3d-a7395d94a4c2"
    },
    {
      "id": "e6df9889-a011-4ddf-ab18-1aa5c509be59",
      "name": "Ensemble Averaging",
      "categoryId": "e2289c8c-e79b-4bd0-8a7d-3dc127a1309a"
    },
    {
      "id": "fa676f91-395e-40bc-9ae7-5e8c0a5977a2",
      "name": "Ensemble Methods",
      "categoryId": "e2289c8c-e79b-4bd0-8a7d-3dc127a1309a"
    },
    {
      "id": "88b2bf2b-20e3-4a97-8e93-c78c54e2b61e",
      "name": "Aggregation Techniques",
      "categoryId": "e2289c8c-e79b-4bd0-8a7d-3dc127a1309a"
    },
    {
      "id": "186815d1-9683-48cc-823d-d7e152fad8cc",
      "name": "Voting",
      "categoryId": "e2289c8c-e79b-4bd0-8a7d-3dc127a1309a"
    },
    {
      "id": "b69a5442-a6be-4eea-8e7a-e8bd8a715c99",
      "name": "Bagging",
      "categoryId": "e2289c8c-e79b-4bd0-8a7d-3dc127a1309a"
    },
    {
      "id": "464e0379-4d26-4ea2-a117-079b6f403895",
      "name": "Boosting",
      "categoryId": "e2289c8c-e79b-4bd0-8a7d-3dc127a1309a"
    },
    {
      "id": "1dfbd33c-dcdb-4677-a255-0769a382e16e",
      "name": "Random Forests",
      "categoryId": "e2289c8c-e79b-4bd0-8a7d-3dc127a1309a"
    },
    {
      "id": "eddf0a08-46a7-4536-8ddd-9205e9380b2f",
      "name": "Model Averaging",
      "categoryId": "e2289c8c-e79b-4bd0-8a7d-3dc127a1309a"
    },
    {
      "id": "febedeb8-8545-400a-9b85-af8ef2ae2a03",
      "name": "Prediction Aggregation",
      "categoryId": "e2289c8c-e79b-4bd0-8a7d-3dc127a1309a"
    },
    {
      "id": "fdd9ad1c-3957-4b96-9ec6-71993eb7cfec",
      "name": "Ensemble Learning Techniques",
      "categoryId": "e2289c8c-e79b-4bd0-8a7d-3dc127a1309a"
    },
    {
      "id": "f6fb417c-612d-4734-8c95-fdd1f80b2184",
      "name": "Ensemble distillation",
      "categoryId": "1de445c8-b813-4cbc-9f75-a5a97a746487"
    },
    {
      "id": "c25e4b67-8135-43a4-8cec-0c6b04ba1a95",
      "name": "model compression",
      "categoryId": "1de445c8-b813-4cbc-9f75-a5a97a746487"
    },
    {
      "id": "27b2110e-a0ae-4918-82a8-c96fc3d14546",
      "name": "knowledge distillation",
      "categoryId": "1de445c8-b813-4cbc-9f75-a5a97a746487"
    },
    {
      "id": "a4572711-e527-4c02-86e5-49f168e70871",
      "name": "neural network compression",
      "categoryId": "1de445c8-b813-4cbc-9f75-a5a97a746487"
    },
    {
      "id": "bfbe2e8e-fda2-4915-a93d-cdfbe15aaf81",
      "name": "ensemble learning",
      "categoryId": "1de445c8-b813-4cbc-9f75-a5a97a746487"
    },
    {
      "id": "b5f9a416-c324-406e-86ee-9a64a132b7f1",
      "name": "model optimization",
      "categoryId": "1de445c8-b813-4cbc-9f75-a5a97a746487"
    },
    {
      "id": "e5b67d1f-a062-4c69-95a3-0242f469ca16",
      "name": "AI model efficiency",
      "categoryId": "1de445c8-b813-4cbc-9f75-a5a97a746487"
    },
    {
      "id": "ec607c93-7b2c-4035-b9cd-e3a4e2d9e63d",
      "name": "student-teacher models",
      "categoryId": "1de445c8-b813-4cbc-9f75-a5a97a746487"
    },
    {
      "id": "1eb4d2fb-3672-45e5-9dca-71598d768355",
      "name": "model simplification",
      "categoryId": "1de445c8-b813-4cbc-9f75-a5a97a746487"
    },
    {
      "id": "473aa82c-0441-4181-86fe-4bd8b2898374",
      "name": "distillation techniques",
      "categoryId": "1de445c8-b813-4cbc-9f75-a5a97a746487"
    },
    {
      "id": "94bb6346-8b89-4b7c-9a60-109fe5495062",
      "name": "Ensemble Diversity",
      "categoryId": "944bb1ca-fa35-4433-81f5-6b852ab72f13"
    },
    {
      "id": "117cea17-15b3-45a7-9314-64749303bad0",
      "name": "Model Diversity",
      "categoryId": "944bb1ca-fa35-4433-81f5-6b852ab72f13"
    },
    {
      "id": "7a4f8b68-d61d-48b6-b818-30f235381c79",
      "name": "Ensemble Learning",
      "categoryId": "944bb1ca-fa35-4433-81f5-6b852ab72f13"
    },
    {
      "id": "fceda41b-06f2-4fb1-9c20-8ebc22a6d670",
      "name": "Bagging",
      "categoryId": "944bb1ca-fa35-4433-81f5-6b852ab72f13"
    },
    {
      "id": "5ee4fbe7-303f-4e1f-a831-c9c299c03c54",
      "name": "Boosting",
      "categoryId": "944bb1ca-fa35-4433-81f5-6b852ab72f13"
    },
    {
      "id": "390765ba-ff94-4788-8a39-44ab8ea352a3",
      "name": "Random Forest",
      "categoryId": "944bb1ca-fa35-4433-81f5-6b852ab72f13"
    },
    {
      "id": "9db2408c-dc15-4d86-90d4-42cdd6c6cdeb",
      "name": "AdaBoost",
      "categoryId": "944bb1ca-fa35-4433-81f5-6b852ab72f13"
    },
    {
      "id": "daa1ae47-d0a7-4e46-9ac6-c1e0f05be59e",
      "name": "Stacking",
      "categoryId": "944bb1ca-fa35-4433-81f5-6b852ab72f13"
    },
    {
      "id": "ffda6c5a-c5a1-47ef-86f7-79fcc49650a8",
      "name": "Voting",
      "categoryId": "944bb1ca-fa35-4433-81f5-6b852ab72f13"
    },
    {
      "id": "e5106d10-c369-4d25-a649-61b6ab40811b",
      "name": "Weak Learners",
      "categoryId": "944bb1ca-fa35-4433-81f5-6b852ab72f13"
    },
    {
      "id": "cd4cd33a-5b6d-4552-b3e7-197832b00a55",
      "name": "Variance Reduction",
      "categoryId": "944bb1ca-fa35-4433-81f5-6b852ab72f13"
    },
    {
      "id": "a74f1e70-880e-476d-8b0d-cc9d4bc0da02",
      "name": "Bias-Variance Tradeoff",
      "categoryId": "944bb1ca-fa35-4433-81f5-6b852ab72f13"
    },
    {
      "id": "06cc5c16-4a03-4706-98d5-b6a27fde5edf",
      "name": "Ensemble Diversity Techniques",
      "categoryId": "25863d08-512d-43c1-a19b-2bd7767cf470"
    },
    {
      "id": "86ad7be1-1831-4a51-b476-b92f32cbc32d",
      "name": "Bagging",
      "categoryId": "25863d08-512d-43c1-a19b-2bd7767cf470"
    },
    {
      "id": "e0a47b8a-45b0-4dbb-8fa7-fcb585383567",
      "name": "Boosting",
      "categoryId": "25863d08-512d-43c1-a19b-2bd7767cf470"
    },
    {
      "id": "1a33021d-4693-496a-ae82-8c7b51f74e04",
      "name": "Stacking",
      "categoryId": "25863d08-512d-43c1-a19b-2bd7767cf470"
    },
    {
      "id": "5df926d7-785f-42f2-9cab-50ed799f59ca",
      "name": "Random Forests",
      "categoryId": "25863d08-512d-43c1-a19b-2bd7767cf470"
    },
    {
      "id": "2f8bda75-894e-40d5-a9ba-bcaec3dcb037",
      "name": "Gradient Boosting",
      "categoryId": "25863d08-512d-43c1-a19b-2bd7767cf470"
    },
    {
      "id": "49a351f9-fd72-421f-b2de-5e067639e1b4",
      "name": "Model Variance",
      "categoryId": "25863d08-512d-43c1-a19b-2bd7767cf470"
    },
    {
      "id": "af86ba8d-5255-4c4c-b0b6-72a4c25188e6",
      "name": "Model Correlation",
      "categoryId": "25863d08-512d-43c1-a19b-2bd7767cf470"
    },
    {
      "id": "6e200c29-b277-4fc3-8ec6-f81170197490",
      "name": "Base Learners",
      "categoryId": "25863d08-512d-43c1-a19b-2bd7767cf470"
    },
    {
      "id": "270b03a3-2d0d-4f07-9580-b6ccec2d2a57",
      "name": "Ensemble Methods",
      "categoryId": "25863d08-512d-43c1-a19b-2bd7767cf470"
    },
    {
      "id": "a53d35f6-3133-4995-a495-853ba768e1c4",
      "name": "Model Diversity",
      "categoryId": "25863d08-512d-43c1-a19b-2bd7767cf470"
    },
    {
      "id": "b1313bae-789c-40f7-b055-b053c20739bc",
      "name": "Ensemble Stability",
      "categoryId": "25863d08-512d-43c1-a19b-2bd7767cf470"
    },
    {
      "id": "a22a3f0b-141b-4d70-a7fa-bdecfb69992f",
      "name": "Ensemble Diversity Techniques Extensions",
      "categoryId": "f02f4855-4f1b-482c-b37d-48eb3ed9985b"
    },
    {
      "id": "b76775fc-8b85-4cd1-93c2-ebdc4d60e306",
      "name": "Ensemble Methods",
      "categoryId": "f02f4855-4f1b-482c-b37d-48eb3ed9985b"
    },
    {
      "id": "701413fc-ab3b-4492-a799-a191994e87da",
      "name": "Diversity Strategies",
      "categoryId": "f02f4855-4f1b-482c-b37d-48eb3ed9985b"
    },
    {
      "id": "238cd09b-e5c7-4eed-91fd-5b7fd9e1e9f6",
      "name": "Bagging",
      "categoryId": "f02f4855-4f1b-482c-b37d-48eb3ed9985b"
    },
    {
      "id": "29083773-63ca-4e5d-a139-21d8946f30c8",
      "name": "Boosting",
      "categoryId": "f02f4855-4f1b-482c-b37d-48eb3ed9985b"
    },
    {
      "id": "646dfdfa-ffcb-4732-9df7-98e0a4313caf",
      "name": "Random Forest",
      "categoryId": "f02f4855-4f1b-482c-b37d-48eb3ed9985b"
    },
    {
      "id": "230e8fe7-0e9f-4e6c-a192-020e363ad30b",
      "name": "Stacking",
      "categoryId": "f02f4855-4f1b-482c-b37d-48eb3ed9985b"
    },
    {
      "id": "53e60e98-3555-4561-9987-5eda40ff8d07",
      "name": "Model Diversity",
      "categoryId": "f02f4855-4f1b-482c-b37d-48eb3ed9985b"
    },
    {
      "id": "a160babc-5241-4c99-9fbe-b58adda1b33d",
      "name": "Error Correlation",
      "categoryId": "f02f4855-4f1b-482c-b37d-48eb3ed9985b"
    },
    {
      "id": "fc2c7a73-7a1f-4bf8-a2b0-818824aa3131",
      "name": "Ensemble Pruning",
      "categoryId": "f02f4855-4f1b-482c-b37d-48eb3ed9985b"
    },
    {
      "id": "a0027f51-8858-4144-b904-a537ac843b22",
      "name": "Dynamic Ensembles",
      "categoryId": "f02f4855-4f1b-482c-b37d-48eb3ed9985b"
    },
    {
      "id": "0a529784-cfaf-40dd-ab67-567e8297ba2d",
      "name": "Diversity Metrics",
      "categoryId": "f02f4855-4f1b-482c-b37d-48eb3ed9985b"
    },
    {
      "id": "62efac06-91b3-466e-9e6b-8ed28e571b64",
      "name": "Variance Reduction",
      "categoryId": "f02f4855-4f1b-482c-b37d-48eb3ed9985b"
    },
    {
      "id": "f8ee0aec-549a-402d-89d5-fb2f8290828c",
      "name": "Error Decomposition",
      "categoryId": "f02f4855-4f1b-482c-b37d-48eb3ed9985b"
    },
    {
      "id": "bcf8c119-9d94-41ec-98f3-890214f15391",
      "name": "Gradient Boosting",
      "categoryId": "78e07f25-31b4-4a98-a921-7638e74bf57a"
    },
    {
      "id": "492da1ad-0abf-4009-ab45-f85df635a460",
      "name": "Ensemble Learning",
      "categoryId": "78e07f25-31b4-4a98-a921-7638e74bf57a"
    },
    {
      "id": "a101a37b-8ccc-41b9-95c6-98765f5f1d0d",
      "name": "Supervised Learning",
      "categoryId": "78e07f25-31b4-4a98-a921-7638e74bf57a"
    },
    {
      "id": "c2a4fc3a-84a7-4d78-8eec-d215ed0bf6df",
      "name": "Decision Trees",
      "categoryId": "78e07f25-31b4-4a98-a921-7638e74bf57a"
    },
    {
      "id": "03d045ca-ad9f-4d3e-9c85-85369213f6ca",
      "name": "Boosting Algorithms",
      "categoryId": "78e07f25-31b4-4a98-a921-7638e74bf57a"
    },
    {
      "id": "35724c5a-a932-46da-b78d-72945fd5e06b",
      "name": "Fisher Information",
      "categoryId": "714319b2-d242-4389-b6bc-0e0b75344899"
    },
    {
      "id": "96ef18e4-e513-4ec3-bbf0-75fb6e256a5b",
      "name": "Statistical Estimation",
      "categoryId": "714319b2-d242-4389-b6bc-0e0b75344899"
    },
    {
      "id": "1b2d912f-0d1c-41ac-98eb-b8e01e34118f",
      "name": "Information Theory",
      "categoryId": "714319b2-d242-4389-b6bc-0e0b75344899"
    },
    {
      "id": "05275a2c-126e-4272-b31d-5d962bd4dd8a",
      "name": "Parameter Estimation",
      "categoryId": "714319b2-d242-4389-b6bc-0e0b75344899"
    },
    {
      "id": "95d4fc7f-3132-4f2b-bd48-9477a6fb8592",
      "name": "Variance Bound",
      "categoryId": "714319b2-d242-4389-b6bc-0e0b75344899"
    },
    {
      "id": "5aed19f7-8a38-43f2-a209-27a2bd1262b2",
      "name": "Fisher Matrix",
      "categoryId": "714319b2-d242-4389-b6bc-0e0b75344899"
    },
    {
      "id": "75f8cdf2-ab39-42cd-a1f6-1e471af0fcf4",
      "name": "Information Content",
      "categoryId": "714319b2-d242-4389-b6bc-0e0b75344899"
    },
    {
      "id": "d4ae7c25-277b-4ef6-a7c8-1a43f14544b8",
      "name": "Estimator Efficiency",
      "categoryId": "714319b2-d242-4389-b6bc-0e0b75344899"
    },
    {
      "id": "153ffbc6-c548-4025-a4c0-e70f0acfd646",
      "name": "Optical Fisher Information",
      "categoryId": "714319b2-d242-4389-b6bc-0e0b75344899"
    },
    {
      "id": "c5a99d93-f707-4815-9739-46082aa80977",
      "name": "Data Sensitivity",
      "categoryId": "714319b2-d242-4389-b6bc-0e0b75344899"
    },
    {
      "id": "662f37ba-374d-4848-9fdc-bcee114c3b4d",
      "name": "Statistical Estimation",
      "categoryId": "54657172-948c-4c95-892c-db97877bd6b4"
    },
    {
      "id": "e239da8a-04e8-43b7-b5a4-5bf3390f644d",
      "name": "Information Theory",
      "categoryId": "54657172-948c-4c95-892c-db97877bd6b4"
    },
    {
      "id": "9aa421bf-b2d3-4923-adcd-960e07f5c9d4",
      "name": "Parameter Estimation",
      "categoryId": "54657172-948c-4c95-892c-db97877bd6b4"
    },
    {
      "id": "8abffc8f-15fc-4f69-b405-dc3a7ecde333",
      "name": "Fisher Information",
      "categoryId": "54657172-948c-4c95-892c-db97877bd6b4"
    },
    {
      "id": "1e70007e-128f-48eb-b29a-fbc46baba4a8",
      "name": "Covariance Matrices",
      "categoryId": "54657172-948c-4c95-892c-db97877bd6b4"
    },
    {
      "id": "0479bb53-9c7b-4f23-bb7d-948ed37bc86c",
      "name": "Variance Bound",
      "categoryId": "54657172-948c-4c95-892c-db97877bd6b4"
    },
    {
      "id": "439e22f6-9e4c-45d6-a1ec-f2642e1785e7",
      "name": "Asymptotic Theory",
      "categoryId": "54657172-948c-4c95-892c-db97877bd6b4"
    },
    {
      "id": "52f47fe3-eccd-431c-9228-516a6375f065",
      "name": "Maximum Likelihood Estimation",
      "categoryId": "54657172-948c-4c95-892c-db97877bd6b4"
    },
    {
      "id": "5be94237-8781-45ad-b2e0-7e1faedeffe1",
      "name": "Regularity Conditions",
      "categoryId": "54657172-948c-4c95-892c-db97877bd6b4"
    },
    {
      "id": "d0b0090c-8d1a-4b1e-9804-dd611885417b",
      "name": "Sensitivity Analysis",
      "categoryId": "54657172-948c-4c95-892c-db97877bd6b4"
    },
    {
      "id": "4ab1d589-4953-40ef-b23b-7b4f3bd6a9da",
      "name": "Computer Vision",
      "categoryId": "24d9cc18-577d-412b-b205-fdb83f4a243e"
    },
    {
      "id": "9e5599b5-b45a-4b5a-b3e9-ab7d0cd17d3d",
      "name": "Feature Extraction",
      "categoryId": "24d9cc18-577d-412b-b205-fdb83f4a243e"
    },
    {
      "id": "3322b975-f08b-4d19-b62f-edfa05393083",
      "name": "Image Classification",
      "categoryId": "24d9cc18-577d-412b-b205-fdb83f4a243e"
    },
    {
      "id": "7c4103cf-9afe-4add-924b-88e899818f7b",
      "name": "Pattern Recognition",
      "categoryId": "24d9cc18-577d-412b-b205-fdb83f4a243e"
    },
    {
      "id": "d783816d-a6e3-4a7e-ac44-a7b79070f70a",
      "name": "Machine Learning",
      "categoryId": "24d9cc18-577d-412b-b205-fdb83f4a243e"
    },
    {
      "id": "b2e1e413-56e5-4d91-b96e-ee6eed2c692d",
      "name": "Unsupervised Learning",
      "categoryId": "24d9cc18-577d-412b-b205-fdb83f4a243e"
    },
    {
      "id": "7d62b8d7-dd0e-4f6c-9e38-012f23ba3903",
      "name": "Local Features",
      "categoryId": "24d9cc18-577d-412b-b205-fdb83f4a243e"
    },
    {
      "id": "58420cd8-2f9e-4659-a97e-ab745597f4cc",
      "name": "Feature Encoding",
      "categoryId": "02ab2145-e941-490d-8eee-8ec589e9b859"
    },
    {
      "id": "dde2174d-6121-420c-8670-b27100b636c2",
      "name": "Visual Recognition",
      "categoryId": "02ab2145-e941-490d-8eee-8ec589e9b859"
    },
    {
      "id": "29d46347-5740-421d-8948-41687b470feb",
      "name": "Image Processing",
      "categoryId": "02ab2145-e941-490d-8eee-8ec589e9b859"
    },
    {
      "id": "1018f1f4-fae6-4f11-ac33-1b75dbe57c1b",
      "name": "High-Dimensional Descriptors",
      "categoryId": "02ab2145-e941-490d-8eee-8ec589e9b859"
    },
    {
      "id": "0145ecba-91be-40d3-a495-d30e4981711d",
      "name": "Bag-of-Features",
      "categoryId": "02ab2145-e941-490d-8eee-8ec589e9b859"
    },
    {
      "id": "1713b1f9-f710-4086-9dbb-153f9e87763d",
      "name": "Representation Learning",
      "categoryId": "02ab2145-e941-490d-8eee-8ec589e9b859"
    },
    {
      "id": "6e965eb6-08e3-4358-954b-119bae62121c",
      "name": "Computer Vision",
      "categoryId": "02ab2145-e941-490d-8eee-8ec589e9b859"
    },
    {
      "id": "a750d6f6-d516-44e0-bf5a-9ea233eef3fe",
      "name": "Image Classification",
      "categoryId": "02ab2145-e941-490d-8eee-8ec589e9b859"
    },
    {
      "id": "b91d8775-74b2-4f9a-ae89-97ab875bba02",
      "name": "Pattern Recognition",
      "categoryId": "02ab2145-e941-490d-8eee-8ec589e9b859"
    },
    {
      "id": "35651d15-bfe4-4a28-b1a3-72fd7cf984ee",
      "name": "Statistical Tests",
      "categoryId": "d9bb06da-c538-40e6-bda6-1c82daa49aba"
    },
    {
      "id": "0732cd35-e0f7-47e7-84aa-32ae20794022",
      "name": "Hypothesis Testing",
      "categoryId": "d9bb06da-c538-40e6-bda6-1c82daa49aba"
    },
    {
      "id": "6b5ea34b-4e4e-41cc-b694-494b549aea3f",
      "name": "Contingency Tables",
      "categoryId": "d9bb06da-c538-40e6-bda6-1c82daa49aba"
    },
    {
      "id": "ef22c8ac-84ef-4868-b85c-ab5f6a19d91a",
      "name": "Non-parametric Tests",
      "categoryId": "d9bb06da-c538-40e6-bda6-1c82daa49aba"
    },
    {
      "id": "54d93b6f-4656-4b57-9090-2987c3bb020a",
      "name": "Categorical Data Analysis",
      "categoryId": "d9bb06da-c538-40e6-bda6-1c82daa49aba"
    },
    {
      "id": "5bca7cbb-db1c-4562-82eb-60c561af428d",
      "name": "Small Sample Tests",
      "categoryId": "d9bb06da-c538-40e6-bda6-1c82daa49aba"
    },
    {
      "id": "df08ab0c-732c-4ae4-8084-bd3a5b528997",
      "name": "Optimization",
      "categoryId": "4e903654-196d-4f4c-b9fb-8d532eb1df9a"
    },
    {
      "id": "fa80ee8d-05b2-40b3-879f-d028e90b7272",
      "name": "Evolutionary Algorithms",
      "categoryId": "4e903654-196d-4f4c-b9fb-8d532eb1df9a"
    },
    {
      "id": "4064b5f3-5f96-4990-ab8f-25cab3547296",
      "name": "Genetic Algorithms",
      "categoryId": "4e903654-196d-4f4c-b9fb-8d532eb1df9a"
    },
    {
      "id": "27ccc73b-ea6d-43d0-887d-0d887a800eb7",
      "name": "Search",
      "categoryId": "4e903654-196d-4f4c-b9fb-8d532eb1df9a"
    },
    {
      "id": "9a8fcd5f-08b2-45e7-87c7-313baf3d6a6f",
      "name": "Evaluation Metrics",
      "categoryId": "4e903654-196d-4f4c-b9fb-8d532eb1df9a"
    },
    {
      "id": "aab702b5-654d-472c-bcc6-db78595b26d8",
      "name": "Transformer architectures",
      "categoryId": "6c645899-ecab-4301-942b-765c54ceb964"
    },
    {
      "id": "29d248f8-85f0-4f97-8e72-8c4fa29de47c",
      "name": "Attention mechanisms",
      "categoryId": "6c645899-ecab-4301-942b-765c54ceb964"
    },
    {
      "id": "98dcf5da-b243-4843-822a-371144eddd57",
      "name": "Model optimization",
      "categoryId": "6c645899-ecab-4301-942b-765c54ceb964"
    },
    {
      "id": "90be9248-af4a-4458-87da-f4e54252e98e",
      "name": "Efficient neural networks",
      "categoryId": "6c645899-ecab-4301-942b-765c54ceb964"
    },
    {
      "id": "bbf96e62-eeda-46b0-a4c0-d058fffab6f5",
      "name": "Sequence modeling",
      "categoryId": "6c645899-ecab-4301-942b-765c54ceb964"
    },
    {
      "id": "c73adb84-1a57-426c-afc3-b0b1b6a1d5d6",
      "name": "Separation Processes",
      "categoryId": "2ce7f3e4-418e-4479-8ed3-b7b072e43bc4"
    },
    {
      "id": "094f68f7-c4ac-4c5a-b350-5b9a4879c2ac",
      "name": "Distillation",
      "categoryId": "2ce7f3e4-418e-4479-8ed3-b7b072e43bc4"
    },
    {
      "id": "d13de930-20ee-4736-8f8e-d82975bd7f36",
      "name": "Chemical Engineering",
      "categoryId": "2ce7f3e4-418e-4479-8ed3-b7b072e43bc4"
    },
    {
      "id": "1fbcebfe-2ce8-4804-b3c5-e1b891f151d1",
      "name": "Fluid Dynamics",
      "categoryId": "2ce7f3e4-418e-4479-8ed3-b7b072e43bc4"
    },
    {
      "id": "6066af39-26d1-4727-b29c-5d8af7ee4b9b",
      "name": "Separation Techniques",
      "categoryId": "2ce7f3e4-418e-4479-8ed3-b7b072e43bc4"
    },
    {
      "id": "fea3bbcc-13d7-411f-84bf-4e2636cd1a5b",
      "name": "Continuous Processes",
      "categoryId": "2ce7f3e4-418e-4479-8ed3-b7b072e43bc4"
    },
    {
      "id": "c14dd674-d29c-4a0e-bbec-fc20181d46f8",
      "name": "Volatile Compounds",
      "categoryId": "2ce7f3e4-418e-4479-8ed3-b7b072e43bc4"
    },
    {
      "id": "bd7d8aaa-5d96-4c71-abc0-d512947b4e73",
      "name": "Process Optimization",
      "categoryId": "2ce7f3e4-418e-4479-8ed3-b7b072e43bc4"
    },
    {
      "id": "83ecad5f-8403-4499-b028-1ff66dba8711",
      "name": "Process Engineering",
      "categoryId": "2ce7f3e4-418e-4479-8ed3-b7b072e43bc4"
    },
    {
      "id": "96a8f087-f742-48f6-be65-49fec0f09aa0",
      "name": "Petroleum Refining",
      "categoryId": "2ce7f3e4-418e-4479-8ed3-b7b072e43bc4"
    },
    {
      "id": "2813303d-86ce-4466-b2fb-46b6d71bb574",
      "name": "Neural Network Architecture",
      "categoryId": "a9d6d3a1-5af7-48a2-961e-af5c3b79af4d"
    },
    {
      "id": "6ded9fba-dd91-49ea-971d-792b3e184ab9",
      "name": "Model Flexibility",
      "categoryId": "a9d6d3a1-5af7-48a2-961e-af5c3b79af4d"
    },
    {
      "id": "9387d6cf-c939-4165-9016-80dfc0071c76",
      "name": "Adaptive Neural Networks",
      "categoryId": "a9d6d3a1-5af7-48a2-961e-af5c3b79af4d"
    },
    {
      "id": "9e898181-c9c6-48c4-ad5a-0bd8471d12b1",
      "name": "Dynamic Network Structures",
      "categoryId": "a9d6d3a1-5af7-48a2-961e-af5c3b79af4d"
    },
    {
      "id": "263dbb60-7575-41d0-afe6-dd503e42cf95",
      "name": "Parameter Efficiency",
      "categoryId": "a9d6d3a1-5af7-48a2-961e-af5c3b79af4d"
    },
    {
      "id": "1124e7f2-ebfe-4ec4-aa49-b3d7fc104e39",
      "name": "Modular Neural Networks",
      "categoryId": "a9d6d3a1-5af7-48a2-961e-af5c3b79af4d"
    },
    {
      "id": "9a2e4c6b-d0f9-4270-a5f9-b3d76fbfaaae",
      "name": "Customizable Architectures",
      "categoryId": "a9d6d3a1-5af7-48a2-961e-af5c3b79af4d"
    },
    {
      "id": "930d2f10-e40d-460b-858d-6f05864aa8bb",
      "name": "Structural Optimization",
      "categoryId": "a9d6d3a1-5af7-48a2-961e-af5c3b79af4d"
    },
    {
      "id": "d4107d82-a172-43d1-a90f-2d286bcbfb6a",
      "name": "Neural Network Design",
      "categoryId": "a9d6d3a1-5af7-48a2-961e-af5c3b79af4d"
    },
    {
      "id": "d36bbe3f-c25c-4770-ace0-fbc2e5dd7cac",
      "name": "Deep Learning Flexibility",
      "categoryId": "a9d6d3a1-5af7-48a2-961e-af5c3b79af4d"
    },
    {
      "id": "92aeca13-e773-425a-9eb2-5109cdd0fcda",
      "name": "Flow-based Generative Models",
      "categoryId": "4aac71e7-1c4f-4c40-a0e8-561dfaf8815c"
    },
    {
      "id": "85cae706-2d69-4815-820f-73b504e4827e",
      "name": "Normalizing Flows",
      "categoryId": "4aac71e7-1c4f-4c40-a0e8-561dfaf8815c"
    },
    {
      "id": "3cb99a3f-2cc2-4819-b0f7-1ab66841514c",
      "name": "Variational Flows",
      "categoryId": "4aac71e7-1c4f-4c40-a0e8-561dfaf8815c"
    },
    {
      "id": "4bd2e42d-254a-442e-adff-8bc74ae5590d",
      "name": "Continuous Latent Variable Models",
      "categoryId": "4aac71e7-1c4f-4c40-a0e8-561dfaf8815c"
    },
    {
      "id": "80f917f8-6a27-4faa-81d1-a23bfdd54537",
      "name": "Bijective Transformations",
      "categoryId": "4aac71e7-1c4f-4c40-a0e8-561dfaf8815c"
    },
    {
      "id": "5462719f-3f41-4589-a36d-8e410dff5d0a",
      "name": "Density Estimation",
      "categoryId": "4aac71e7-1c4f-4c40-a0e8-561dfaf8815c"
    },
    {
      "id": "d76c0783-52a1-4b24-9813-9271259d3091",
      "name": "Deep Generative Models",
      "categoryId": "4aac71e7-1c4f-4c40-a0e8-561dfaf8815c"
    },
    {
      "id": "8590fbdb-7e83-4b5f-bf2d-89b93475d678",
      "name": "Invertible Neural Networks",
      "categoryId": "4aac71e7-1c4f-4c40-a0e8-561dfaf8815c"
    },
    {
      "id": "cc4d9ec4-e309-4833-ab20-eeeec21fa083",
      "name": "Flow-Based Generative Models Enhancements",
      "categoryId": "6fd51f9a-c4ce-46ba-b80e-d22987891638"
    },
    {
      "id": "08b581e2-e2d0-48c6-8b87-6286634f018c",
      "name": "Variational Flows",
      "categoryId": "6fd51f9a-c4ce-46ba-b80e-d22987891638"
    },
    {
      "id": "d9c2e5af-ab20-40aa-a92a-a7c42bb61de7",
      "name": "Normalizing Flows",
      "categoryId": "6fd51f9a-c4ce-46ba-b80e-d22987891638"
    },
    {
      "id": "96c167f6-93f7-4919-826b-325c613bb0ab",
      "name": "Autoregressive Flows",
      "categoryId": "6fd51f9a-c4ce-46ba-b80e-d22987891638"
    },
    {
      "id": "036aa319-c6c0-4d62-ab7b-cd833ca8acbe",
      "name": "Residual Flows",
      "categoryId": "6fd51f9a-c4ce-46ba-b80e-d22987891638"
    },
    {
      "id": "c7cc0370-bb6a-4f82-b948-3cb0ca9bdcb2",
      "name": "Stacked Flows",
      "categoryId": "6fd51f9a-c4ce-46ba-b80e-d22987891638"
    },
    {
      "id": "0e19518d-03db-4c8e-909b-85d00914589d",
      "name": "Coupling Layers",
      "categoryId": "6fd51f9a-c4ce-46ba-b80e-d22987891638"
    },
    {
      "id": "ffd9a9cc-9bf5-4329-a9f5-6cfabe54537d",
      "name": "Invertible Neural Networks",
      "categoryId": "6fd51f9a-c4ce-46ba-b80e-d22987891638"
    },
    {
      "id": "4ceacd94-7d03-4997-aa2b-5502af401d60",
      "name": "Transformation-based Generative Models",
      "categoryId": "6fd51f9a-c4ce-46ba-b80e-d22987891638"
    },
    {
      "id": "5a32e1de-73d4-4025-a01e-40eb10ddbac0",
      "name": "Density Estimation Improvements",
      "categoryId": "6fd51f9a-c4ce-46ba-b80e-d22987891638"
    },
    {
      "id": "cee9f6bf-890d-4c02-b6e2-78531552bc05",
      "name": "Flow-based Generative Models Extensions",
      "categoryId": "ce17e4a6-9194-4757-b9b3-89571f5b4b89"
    },
    {
      "id": "1497788d-ba6e-4124-a665-6dc8b5e86206",
      "name": "Variational Flows",
      "categoryId": "ce17e4a6-9194-4757-b9b3-89571f5b4b89"
    },
    {
      "id": "ca328beb-cb67-43d6-894c-182bf237c8bf",
      "name": "Continuous Flows",
      "categoryId": "ce17e4a6-9194-4757-b9b3-89571f5b4b89"
    },
    {
      "id": "07d182e4-d79c-4f98-87ed-e37cab95509b",
      "name": "Discrete Flows",
      "categoryId": "ce17e4a6-9194-4757-b9b3-89571f5b4b89"
    },
    {
      "id": "e37f5b8b-e42a-4eb5-9fde-e77d2711c36b",
      "name": "Neural Autoregressive Flows",
      "categoryId": "ce17e4a6-9194-4757-b9b3-89571f5b4b89"
    },
    {
      "id": "120c5d0b-e0a5-47d0-8e94-2e64d7bd37cc",
      "name": "Invertible Neural Networks",
      "categoryId": "ce17e4a6-9194-4757-b9b3-89571f5b4b89"
    },
    {
      "id": "f6c2e4ee-882a-485e-b8a8-846dd4d42b35",
      "name": "Deep Normalizing Flows",
      "categoryId": "ce17e4a6-9194-4757-b9b3-89571f5b4b89"
    },
    {
      "id": "74e5eca9-2749-446a-a117-ce49aaa4e2d2",
      "name": "Coupling Layers",
      "categoryId": "ce17e4a6-9194-4757-b9b3-89571f5b4b89"
    },
    {
      "id": "fc48450f-9d4c-48b7-8461-84cd4f7f09ba",
      "name": "Volume-preserving Flows",
      "categoryId": "ce17e4a6-9194-4757-b9b3-89571f5b4b89"
    },
    {
      "id": "c640c5d2-f511-4c10-977a-85e18e543be4",
      "name": "Residual Flows",
      "categoryId": "ce17e4a6-9194-4757-b9b3-89571f5b4b89"
    },
    {
      "id": "050ca11a-22f6-43a3-9a06-f99ae437a981",
      "name": "Multi-scale Flows",
      "categoryId": "ce17e4a6-9194-4757-b9b3-89571f5b4b89"
    },
    {
      "id": "15a0e153-647c-4283-9e3a-d215470ee359",
      "name": "Conditional Flows",
      "categoryId": "ce17e4a6-9194-4757-b9b3-89571f5b4b89"
    },
    {
      "id": "d765fe0d-2533-44cb-9aca-19e0864b8400",
      "name": "Stochastic Flows",
      "categoryId": "ce17e4a6-9194-4757-b9b3-89571f5b4b89"
    },
    {
      "id": "b5258d98-d68e-4e60-9fe8-7feb519a021b",
      "name": "Time-series Flows",
      "categoryId": "ce17e4a6-9194-4757-b9b3-89571f5b4b89"
    },
    {
      "id": "9bca3162-7bbe-436b-a5b3-18c2e15cca9a",
      "name": "Flow-based Generative Models Techniques",
      "categoryId": "e6eee2f4-4a75-4bc5-9417-a01e69186236"
    },
    {
      "id": "62d258d7-b94c-4ccc-9c64-a1b951f3349c",
      "name": "Normalizing Flows",
      "categoryId": "e6eee2f4-4a75-4bc5-9417-a01e69186236"
    },
    {
      "id": "6ffbf7a5-b500-46f2-bc8f-3b0924fc63c7",
      "name": "Variational Flows",
      "categoryId": "e6eee2f4-4a75-4bc5-9417-a01e69186236"
    },
    {
      "id": "f9d8f6dd-a564-421e-bda4-684df3f0ba4a",
      "name": "Continuous Flow Models",
      "categoryId": "e6eee2f4-4a75-4bc5-9417-a01e69186236"
    },
    {
      "id": "45b4f56c-d502-4986-9415-8feac6b16599",
      "name": "Invertible Neural Networks",
      "categoryId": "e6eee2f4-4a75-4bc5-9417-a01e69186236"
    },
    {
      "id": "8b2881bd-5380-431f-b063-dfce03a1f230",
      "name": "Implicit Density Models",
      "categoryId": "e6eee2f4-4a75-4bc5-9417-a01e69186236"
    },
    {
      "id": "37672243-2471-4d37-ac8b-a647773f1206",
      "name": "Flow-based Models",
      "categoryId": "4272bf25-2ab7-41ca-b9d5-336a0dc25db2"
    },
    {
      "id": "35841a53-ca05-48e9-9b25-90ead685c07e",
      "name": "Generative Models",
      "categoryId": "4272bf25-2ab7-41ca-b9d5-336a0dc25db2"
    },
    {
      "id": "4b2ad471-0cc4-4e8a-b4f9-1120f3c851b3",
      "name": "Deep Learning",
      "categoryId": "4272bf25-2ab7-41ca-b9d5-336a0dc25db2"
    },
    {
      "id": "43d1b49f-2d06-4234-9ac7-b7e601daf2e8",
      "name": "Probabilistic Models",
      "categoryId": "4272bf25-2ab7-41ca-b9d5-336a0dc25db2"
    },
    {
      "id": "3ba42570-0303-4903-bbaa-f9742489f28d",
      "name": "Density Estimation",
      "categoryId": "4272bf25-2ab7-41ca-b9d5-336a0dc25db2"
    },
    {
      "id": "a117421f-d4a7-4924-ad06-b66857e6f17e",
      "name": "Normalizing Flows",
      "categoryId": "4272bf25-2ab7-41ca-b9d5-336a0dc25db2"
    },
    {
      "id": "c54d87c1-c4fa-4f69-a0d6-feab59389779",
      "name": "Variational Inference",
      "categoryId": "4272bf25-2ab7-41ca-b9d5-336a0dc25db2"
    },
    {
      "id": "4db5a521-298c-4c77-abfa-ab69e9b793a0",
      "name": "Flow-Based Models Enhancement",
      "categoryId": "c4c86b52-e5d5-49d1-bb14-e949f7b44d3a"
    },
    {
      "id": "3e9b5006-8ca1-476a-bf98-49d5ce0e1036",
      "name": "Probabilistic Flow Models",
      "categoryId": "c4c86b52-e5d5-49d1-bb14-e949f7b44d3a"
    },
    {
      "id": "f8883398-bc74-49ca-bf59-da3967925fb4",
      "name": "Normalizing Flows",
      "categoryId": "c4c86b52-e5d5-49d1-bb14-e949f7b44d3a"
    },
    {
      "id": "99e71975-1a1f-4949-a112-e5a5b1f6fa8c",
      "name": "Variational Flows",
      "categoryId": "c4c86b52-e5d5-49d1-bb14-e949f7b44d3a"
    },
    {
      "id": "4e714b20-e3ab-4d25-aac3-5e9cbd22c188",
      "name": "Invertible Neural Networks",
      "categoryId": "c4c86b52-e5d5-49d1-bb14-e949f7b44d3a"
    },
    {
      "id": "898cf850-24e4-4fe4-ad60-4ba429aa8e76",
      "name": "Continuous Latent Space",
      "categoryId": "c4c86b52-e5d5-49d1-bb14-e949f7b44d3a"
    },
    {
      "id": "6c9bce8b-f961-4fb7-aa5e-33616276c247",
      "name": "Density Estimation",
      "categoryId": "c4c86b52-e5d5-49d1-bb14-e949f7b44d3a"
    },
    {
      "id": "5a567a44-ce61-4305-ba1b-d75e94f0456b",
      "name": "Transformation-based Generative Models",
      "categoryId": "c4c86b52-e5d5-49d1-bb14-e949f7b44d3a"
    },
    {
      "id": "8ed6132b-e32c-4e07-8952-cced08408770",
      "name": "Model Optimization Techniques",
      "categoryId": "c4c86b52-e5d5-49d1-bb14-e949f7b44d3a"
    },
    {
      "id": "ef5e9210-9703-455d-b223-9915968d1c06",
      "name": "Latent Space Manipulation",
      "categoryId": "c4c86b52-e5d5-49d1-bb14-e949f7b44d3a"
    },
    {
      "id": "ee7c19f0-3062-4361-b21c-7cc57093d741",
      "name": "Flow-Based Models Enhancements",
      "categoryId": "e59325d7-7709-44b4-978e-c02403a92210"
    },
    {
      "id": "3594dfcf-8028-44c6-97d3-dd10cfd6ba1d",
      "name": "Normalizing Flows",
      "categoryId": "e59325d7-7709-44b4-978e-c02403a92210"
    },
    {
      "id": "912a4ba9-fa9f-4bc6-857f-2572626f0c13",
      "name": "Variational Flows",
      "categoryId": "e59325d7-7709-44b4-978e-c02403a92210"
    },
    {
      "id": "c0b94e41-47e5-4f85-bfc8-32c2e161a30b",
      "name": "Invertible Neural Networks",
      "categoryId": "e59325d7-7709-44b4-978e-c02403a92210"
    },
    {
      "id": "d0e1f4c2-2163-48e3-806a-0ed65c47774a",
      "name": "Conditional Flows",
      "categoryId": "e59325d7-7709-44b4-978e-c02403a92210"
    },
    {
      "id": "9671d548-cd2e-4bdd-9cfc-47a81e98c426",
      "name": "Coupling Layers",
      "categoryId": "e59325d7-7709-44b4-978e-c02403a92210"
    },
    {
      "id": "b1885fb7-f138-49c5-b398-295ea5ea1368",
      "name": "Residual Flows",
      "categoryId": "e59325d7-7709-44b4-978e-c02403a92210"
    },
    {
      "id": "e07be0ce-6264-488a-81d2-b5a810db484e",
      "name": "Continuous Normalizing Flows",
      "categoryId": "e59325d7-7709-44b4-978e-c02403a92210"
    },
    {
      "id": "922dcbbe-5b47-4703-a465-9bcc7bf86ce2",
      "name": "Discrete Flows",
      "categoryId": "e59325d7-7709-44b4-978e-c02403a92210"
    },
    {
      "id": "18ee9e69-2d20-4c76-806a-daa35862256d",
      "name": "Multi-scale Flows",
      "categoryId": "e59325d7-7709-44b4-978e-c02403a92210"
    },
    {
      "id": "bc6543ae-3d85-4c7f-b5f7-835e7db5376d",
      "name": "Flow-Based Models Techniques",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "38b25d6a-854b-4775-9d08-3f7dab22ac41",
      "name": "Generative Modeling",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "cb611912-3704-467c-a786-31e788ec184f",
      "name": "Probabilistic Graph Models",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "1564649f-e8ed-40f1-ab4f-fd27c95075a3",
      "name": "Normalizing Flows",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "74a7fab9-704c-40c5-8036-864ac883318f",
      "name": "Variational Flows",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "7c6c9491-e045-47e9-aeca-85f6979a52b7",
      "name": "Invertible Neural Networks",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "3baf6b9c-18e2-4df4-84fc-43c609ea3579",
      "name": "Deep Density Estimation",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "af1647ba-b09a-4b5a-9cb3-c72a50ed6cdf",
      "name": "Latent Variable Models",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "4579a975-e42e-4241-ab11-9eedd0d57db5",
      "name": "Transformations",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "76b08f10-511f-4a15-83c2-d42b8efeeec2",
      "name": "Continuous Density Estimation",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "8b955677-9615-40b5-96df-e91dd412c4fe",
      "name": "Flow-Based Models Techniques Enhancements",
      "categoryId": "843a89a2-8af1-4dda-9327-69c5c76d0cc2"
    },
    {
      "id": "4389b554-8ebb-4516-9fce-decf0e56f15a",
      "name": "Probabilistic Models",
      "categoryId": "843a89a2-8af1-4dda-9327-69c5c76d0cc2"
    },
    {
      "id": "9d713d4a-2e34-426e-9878-165971686b51",
      "name": "Generative Flows",
      "categoryId": "843a89a2-8af1-4dda-9327-69c5c76d0cc2"
    },
    {
      "id": "764144fc-52bb-4b2c-912b-34758dcda2bd",
      "name": "Normalizing Flows",
      "categoryId": "843a89a2-8af1-4dda-9327-69c5c76d0cc2"
    },
    {
      "id": "65251a2d-5a3e-4078-af69-07bb8c8b998c",
      "name": "Variational Inference",
      "categoryId": "843a89a2-8af1-4dda-9327-69c5c76d0cc2"
    },
    {
      "id": "74829be2-b6df-4488-93f3-b19d17009a00",
      "name": "Model Optimization",
      "categoryId": "843a89a2-8af1-4dda-9327-69c5c76d0cc2"
    },
    {
      "id": "b0feaf2e-81b7-4dec-8fee-f7066189c4cf",
      "name": "Density Estimation",
      "categoryId": "843a89a2-8af1-4dda-9327-69c5c76d0cc2"
    },
    {
      "id": "5625ae99-f34e-4138-b0a1-fc7e2194e1bd",
      "name": "Deep Learning",
      "categoryId": "843a89a2-8af1-4dda-9327-69c5c76d0cc2"
    },
    {
      "id": "fb639603-f116-4101-af73-cf80caae3eac",
      "name": "Probabilistic Programming",
      "categoryId": "843a89a2-8af1-4dda-9327-69c5c76d0cc2"
    },
    {
      "id": "817acac0-048c-4226-9be9-6761225ffb5e",
      "name": "Model Scalability",
      "categoryId": "843a89a2-8af1-4dda-9327-69c5c76d0cc2"
    },
    {
      "id": "e27eaeba-8bf2-4da0-852e-aa8910f26daf",
      "name": "Flow-Based Models Variants",
      "categoryId": "ecc8f434-102e-4398-aac2-975c763d83c1"
    },
    {
      "id": "79c94fbf-9d41-4ae5-9193-d4cbd23d9974",
      "name": "Variational Flows",
      "categoryId": "ecc8f434-102e-4398-aac2-975c763d83c1"
    },
    {
      "id": "dbd64ed2-ff17-4704-b4c0-b116e264548c",
      "name": "Normalizing Flows",
      "categoryId": "ecc8f434-102e-4398-aac2-975c763d83c1"
    },
    {
      "id": "e402bf0b-281c-4ff2-832d-c13089358cc5",
      "name": "Autoregressive Flows",
      "categoryId": "ecc8f434-102e-4398-aac2-975c763d83c1"
    },
    {
      "id": "ce13c8dd-ca31-4d6f-ba43-1a02fbff998a",
      "name": "Invertible Neural Networks",
      "categoryId": "ecc8f434-102e-4398-aac2-975c763d83c1"
    },
    {
      "id": "f129b99b-c604-45e1-b17f-877e9c2bb0c8",
      "name": "Real NVP",
      "categoryId": "ecc8f434-102e-4398-aac2-975c763d83c1"
    },
    {
      "id": "a5fe0948-f54e-4d05-b5e7-c7992ca31715",
      "name": "Glow",
      "categoryId": "ecc8f434-102e-4398-aac2-975c763d83c1"
    },
    {
      "id": "a1ee8849-1154-419f-a4d9-ef8ae2069b78",
      "name": "Masked Autoregressive Flow",
      "categoryId": "ecc8f434-102e-4398-aac2-975c763d83c1"
    },
    {
      "id": "caa190e3-0445-456d-963f-924818fc5853",
      "name": "Neural Spline Flows",
      "categoryId": "ecc8f434-102e-4398-aac2-975c763d83c1"
    },
    {
      "id": "8ce04018-b5fe-40d6-8201-b6f4f13aee21",
      "name": "Coupling Layers",
      "categoryId": "ecc8f434-102e-4398-aac2-975c763d83c1"
    },
    {
      "id": "969535aa-c827-4f74-86f6-ceded487ca02",
      "name": "Bijective Transformations",
      "categoryId": "ecc8f434-102e-4398-aac2-975c763d83c1"
    },
    {
      "id": "9f5c5975-2e1a-4c59-ab97-9d46402d7a2c",
      "name": "Density Estimation",
      "categoryId": "ecc8f434-102e-4398-aac2-975c763d83c1"
    },
    {
      "id": "59c80a85-dfc1-424f-9222-b13ee244d506",
      "name": "Probabilistic Modeling",
      "categoryId": "ecc8f434-102e-4398-aac2-975c763d83c1"
    },
    {
      "id": "07eb82bf-3d98-456a-819f-514b8515976f",
      "name": "Flow-Based Models Variants Techniques",
      "categoryId": "d4518c8e-94a3-4dd5-afca-2b05dd659da5"
    },
    {
      "id": "78d22f3b-1eb0-4eed-beed-a4c269fbec7b",
      "name": "Normalizing Flows",
      "categoryId": "d4518c8e-94a3-4dd5-afca-2b05dd659da5"
    },
    {
      "id": "0969e931-cb28-4949-bfd9-8e2a9ec80696",
      "name": "Variational Flows",
      "categoryId": "d4518c8e-94a3-4dd5-afca-2b05dd659da5"
    },
    {
      "id": "c698eb1a-4239-44f0-a5aa-f13cd5538488",
      "name": "Invertible Neural Networks",
      "categoryId": "d4518c8e-94a3-4dd5-afca-2b05dd659da5"
    },
    {
      "id": "24f452b9-547e-4408-bce0-f62deeb1afdd",
      "name": "Generative Flow Models",
      "categoryId": "d4518c8e-94a3-4dd5-afca-2b05dd659da5"
    },
    {
      "id": "04c2dbc5-8907-485a-b61e-3b7dfbadbac1",
      "name": "Continuous Normalizing Flows",
      "categoryId": "d4518c8e-94a3-4dd5-afca-2b05dd659da5"
    },
    {
      "id": "0203c61a-98a8-479e-a10a-5aba20f50dd8",
      "name": "Discrete Flows",
      "categoryId": "d4518c8e-94a3-4dd5-afca-2b05dd659da5"
    },
    {
      "id": "db63e1d4-8ee5-4b7e-9d7e-9b665b382f37",
      "name": "Coupling Layers",
      "categoryId": "d4518c8e-94a3-4dd5-afca-2b05dd659da5"
    },
    {
      "id": "77e75472-4aed-499e-a9c2-54b94e37226c",
      "name": "Masked Autoregressive Flows",
      "categoryId": "d4518c8e-94a3-4dd5-afca-2b05dd659da5"
    },
    {
      "id": "6fb725f4-b0da-4ad3-9d6a-e09c9c2629e7",
      "name": "Flow Architectures",
      "categoryId": "d4518c8e-94a3-4dd5-afca-2b05dd659da5"
    },
    {
      "id": "21435c36-9361-43d9-97c6-6291a52d8925",
      "name": "Density Estimation",
      "categoryId": "d4518c8e-94a3-4dd5-afca-2b05dd659da5"
    },
    {
      "id": "495b3a5c-3c28-4f98-bd5f-bae73ee84226",
      "name": "Generative Modeling",
      "categoryId": "d4518c8e-94a3-4dd5-afca-2b05dd659da5"
    },
    {
      "id": "b7b483ad-2995-441b-9647-89567b412bb0",
      "name": "Deep Learning Techniques",
      "categoryId": "d4518c8e-94a3-4dd5-afca-2b05dd659da5"
    },
    {
      "id": "1f1e7e39-5b70-4de2-9377-9022c126befe",
      "name": "Flow-based Neural Networks",
      "categoryId": "957f2139-1efb-4a66-a185-38ede62f8f54"
    },
    {
      "id": "d9494ac7-7f84-4d6e-a530-7b5c72245945",
      "name": "Normalizing Flows",
      "categoryId": "957f2139-1efb-4a66-a185-38ede62f8f54"
    },
    {
      "id": "2c9b28f3-9f97-45ab-9276-fa0046fd510d",
      "name": "Probabilistic Models",
      "categoryId": "957f2139-1efb-4a66-a185-38ede62f8f54"
    },
    {
      "id": "6d0f4a83-d466-4389-9054-c1ef51701753",
      "name": "Deep Generative Models",
      "categoryId": "957f2139-1efb-4a66-a185-38ede62f8f54"
    },
    {
      "id": "6651fd86-2a77-441c-a1ca-0cc005a93398",
      "name": "Continuous Density Estimation",
      "categoryId": "957f2139-1efb-4a66-a185-38ede62f8f54"
    },
    {
      "id": "dae4b247-7008-419c-8569-b45ebd81a218",
      "name": "Fluency Metrics",
      "categoryId": "973d890b-a84d-4a5a-b44c-a716c6dead14"
    },
    {
      "id": "e7e9a4d6-1119-4e33-a2f6-6e87091e5726",
      "name": "Language Quality Metrics",
      "categoryId": "973d890b-a84d-4a5a-b44c-a716c6dead14"
    },
    {
      "id": "fc9ab8f0-12bb-46b2-bfd0-5e1a072661e2",
      "name": "Speech and Text Fluency",
      "categoryId": "973d890b-a84d-4a5a-b44c-a716c6dead14"
    },
    {
      "id": "c7738f0f-f05f-44bb-8004-5478b49afac8",
      "name": "Natural Language Processing (NLP)",
      "categoryId": "973d890b-a84d-4a5a-b44c-a716c6dead14"
    },
    {
      "id": "1e0ca352-2cca-4860-ab8f-76d0cf220ba2",
      "name": "Language Proficiency Measurement",
      "categoryId": "973d890b-a84d-4a5a-b44c-a716c6dead14"
    },
    {
      "id": "92e01007-ca38-4adb-b69d-c4820329e8aa",
      "name": "Discourse Coherence",
      "categoryId": "973d890b-a84d-4a5a-b44c-a716c6dead14"
    },
    {
      "id": "1ff1b94f-ec7c-4a1d-a3fa-77d8ce646ecc",
      "name": "Language Modeling Evaluation",
      "categoryId": "973d890b-a84d-4a5a-b44c-a716c6dead14"
    },
    {
      "id": "7e54866a-fd41-41c5-8f80-b523c1beb2b0",
      "name": "Communication Effectiveness",
      "categoryId": "973d890b-a84d-4a5a-b44c-a716c6dead14"
    },
    {
      "id": "c83af698-a8aa-4a46-891e-8db7ca9be8e0",
      "name": "Focal Loss",
      "categoryId": "42e40f84-c9b0-4f25-b5d4-0c34790af60f"
    },
    {
      "id": "c0c78187-c6e7-4a0c-91ea-ba4142c7e48c",
      "name": "Loss Functions",
      "categoryId": "42e40f84-c9b0-4f25-b5d4-0c34790af60f"
    },
    {
      "id": "412e740a-42a9-4158-a0ff-c139d62ac5a2",
      "name": "Imbalanced Data",
      "categoryId": "42e40f84-c9b0-4f25-b5d4-0c34790af60f"
    },
    {
      "id": "d7f71540-98bf-4d9b-8613-80d79e555f07",
      "name": "Object Detection",
      "categoryId": "42e40f84-c9b0-4f25-b5d4-0c34790af60f"
    },
    {
      "id": "a8bc50dd-22d3-4afd-aa91-bb3e287f4ac7",
      "name": "Classification",
      "categoryId": "42e40f84-c9b0-4f25-b5d4-0c34790af60f"
    },
    {
      "id": "92b52cc9-bd0c-4be4-88ce-cf769a767c77",
      "name": "Deep Learning",
      "categoryId": "42e40f84-c9b0-4f25-b5d4-0c34790af60f"
    },
    {
      "id": "293dab50-c8ce-4091-9ee5-906c408919d4",
      "name": "Computer Vision",
      "categoryId": "42e40f84-c9b0-4f25-b5d4-0c34790af60f"
    },
    {
      "id": "f5c28473-3e99-4c57-93a8-38d63c8119db",
      "name": "Cost-sensitive Learning",
      "categoryId": "42e40f84-c9b0-4f25-b5d4-0c34790af60f"
    },
    {
      "id": "b3e6e8e9-edb6-456c-b02f-d2345491ff9d",
      "name": "Class Imbalance",
      "categoryId": "42e40f84-c9b0-4f25-b5d4-0c34790af60f"
    },
    {
      "id": "e7697985-5947-47d0-9a11-5194620f6fe5",
      "name": "Training Optimization",
      "categoryId": "42e40f84-c9b0-4f25-b5d4-0c34790af60f"
    },
    {
      "id": "0684941b-01e0-41b6-8b86-5bf8953317a3",
      "name": "Focal Loss",
      "categoryId": "df739862-bae0-4210-9f66-9b055113586a"
    },
    {
      "id": "394ba8cf-2acd-4da0-8852-5b1a938a9f15",
      "name": "class imbalance",
      "categoryId": "df739862-bae0-4210-9f66-9b055113586a"
    },
    {
      "id": "d58276f9-ebc0-4b5f-b6d9-10aff392bae7",
      "name": "object detection",
      "categoryId": "df739862-bae0-4210-9f66-9b055113586a"
    },
    {
      "id": "ad91daa1-18a9-42ad-b797-b50b3f394a52",
      "name": "image segmentation",
      "categoryId": "df739862-bae0-4210-9f66-9b055113586a"
    },
    {
      "id": "09e812f0-67ae-468a-bdc8-723c51bfbd81",
      "name": "softmax",
      "categoryId": "df739862-bae0-4210-9f66-9b055113586a"
    },
    {
      "id": "ea6ce5c5-3956-4004-b598-63bf1ac0ae0d",
      "name": "loss functions",
      "categoryId": "df739862-bae0-4210-9f66-9b055113586a"
    },
    {
      "id": "9b7f2d57-3a09-4e42-8805-aeb5440a4f70",
      "name": "regression models",
      "categoryId": "df739862-bae0-4210-9f66-9b055113586a"
    },
    {
      "id": "e5d972e6-feee-4562-9c1d-58fea9440819",
      "name": "deep learning",
      "categoryId": "df739862-bae0-4210-9f66-9b055113586a"
    },
    {
      "id": "d9ac3110-9416-4934-be9b-9d426f5933d3",
      "name": "CNN",
      "categoryId": "df739862-bae0-4210-9f66-9b055113586a"
    },
    {
      "id": "f2390170-2aa3-4747-9c6f-57f69b6a6e94",
      "name": "imbalance handling",
      "categoryId": "df739862-bae0-4210-9f66-9b055113586a"
    },
    {
      "id": "c798338f-dc42-4eb9-9143-7234e511ec89",
      "name": "hard example mining",
      "categoryId": "df739862-bae0-4210-9f66-9b055113586a"
    },
    {
      "id": "390cc0c9-5446-4cc6-bdbe-4cbcf38eb787",
      "name": "pixel classification",
      "categoryId": "df739862-bae0-4210-9f66-9b055113586a"
    },
    {
      "id": "00c758d7-5335-4e61-8f1a-402454b28c30",
      "name": "Focal Loss Extensions",
      "categoryId": "4fa9a208-7d11-437c-befa-fffe78f99a86"
    },
    {
      "id": "edaedcd1-4aa9-4202-8d71-669dc8381ca5",
      "name": "Loss Function Variants",
      "categoryId": "4fa9a208-7d11-437c-befa-fffe78f99a86"
    },
    {
      "id": "c0f30d68-c8d4-4554-a6d4-6542b0d98dbe",
      "name": "Class Imbalance Handling",
      "categoryId": "4fa9a208-7d11-437c-befa-fffe78f99a86"
    },
    {
      "id": "8df02740-5c51-4f77-8e60-a490257e0073",
      "name": "Deep Learning Optimization",
      "categoryId": "4fa9a208-7d11-437c-befa-fffe78f99a86"
    },
    {
      "id": "2773c7d9-cafb-4182-bb59-c59065806e7e",
      "name": "Cost-Sensitive Learning",
      "categoryId": "4fa9a208-7d11-437c-befa-fffe78f99a86"
    },
    {
      "id": "cae28a31-bf4f-4d2e-89ce-9ccf649f749a",
      "name": "Focal Loss Extensions Enhancements",
      "categoryId": "39cfd723-0190-4e71-8217-138dace0895f"
    },
    {
      "id": "a9bc3e5c-4c4c-4606-82e5-4632445c9ee4",
      "name": "Loss Function Improvements",
      "categoryId": "39cfd723-0190-4e71-8217-138dace0895f"
    },
    {
      "id": "9fb01d15-9a72-4ad6-84da-c0b5d1db3800",
      "name": "Class Imbalance Handling",
      "categoryId": "39cfd723-0190-4e71-8217-138dace0895f"
    },
    {
      "id": "8081668b-5534-45bf-b727-71c671df76da",
      "name": "Hard Example Mining",
      "categoryId": "39cfd723-0190-4e71-8217-138dace0895f"
    },
    {
      "id": "08bb7023-3b98-473e-b2ec-f5dc8cd212db",
      "name": "Adaptive Loss Functions",
      "categoryId": "39cfd723-0190-4e71-8217-138dace0895f"
    },
    {
      "id": "42578ef3-d57f-4e57-880b-4e9ac8c90f50",
      "name": "Custom Loss Variants",
      "categoryId": "39cfd723-0190-4e71-8217-138dace0895f"
    },
    {
      "id": "c44242dd-ea0b-4105-9e53-64260c1a6b90",
      "name": "Deep Learning Optimization",
      "categoryId": "39cfd723-0190-4e71-8217-138dace0895f"
    },
    {
      "id": "88ff4de2-fd7a-4d6d-a32e-b8885927a085",
      "name": "Performance Tuning",
      "categoryId": "39cfd723-0190-4e71-8217-138dace0895f"
    },
    {
      "id": "abc76939-d527-4366-ac69-8cb3d4b7a41e",
      "name": "Robustness in Imbalanced Tasks",
      "categoryId": "39cfd723-0190-4e71-8217-138dace0895f"
    },
    {
      "id": "5151712d-d0b1-4f0d-8d5d-c969a569871f",
      "name": "Focal Loss Extensions",
      "categoryId": "78dc0827-64c0-4774-aec4-dc8f9e055ff7"
    },
    {
      "id": "d495ce10-0eda-440f-b7ca-fab4c2958a98",
      "name": "Class Imbalance Handling",
      "categoryId": "78dc0827-64c0-4774-aec4-dc8f9e055ff7"
    },
    {
      "id": "a9768bff-0341-45b2-9f5d-effd378cbe47",
      "name": "Loss Function Improvements",
      "categoryId": "78dc0827-64c0-4774-aec4-dc8f9e055ff7"
    },
    {
      "id": "6ccdad98-fe5c-4e4f-b5a8-f2ce3cb4c26d",
      "name": "Adaptive Loss Functions",
      "categoryId": "78dc0827-64c0-4774-aec4-dc8f9e055ff7"
    },
    {
      "id": "dbd3e618-a43f-4b8b-a235-633615d80c2e",
      "name": "Hard Example Mining",
      "categoryId": "78dc0827-64c0-4774-aec4-dc8f9e055ff7"
    },
    {
      "id": "7d97eacc-ded0-4ce2-ac42-c16b9ec975ae",
      "name": "Focal Loss Variants",
      "categoryId": "78dc0827-64c0-4774-aec4-dc8f9e055ff7"
    },
    {
      "id": "c2c8bdce-e97e-4293-8233-0cb43f12a0bf",
      "name": "Robust Loss Functions",
      "categoryId": "78dc0827-64c0-4774-aec4-dc8f9e055ff7"
    },
    {
      "id": "c78ce56f-b5a1-4d2d-94c2-a1d10b20b44f",
      "name": "Imbalanced Data Techniques",
      "categoryId": "78dc0827-64c0-4774-aec4-dc8f9e055ff7"
    },
    {
      "id": "08a5f498-c4d3-4af3-a8a1-26e9a2d87d8b",
      "name": "Focal Loss Extensions Techniques Enhancements",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "2d916cf1-709f-41cb-a494-d0d77247835a",
      "name": "Loss Function Improvements",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "1d370d9e-acd1-44b1-9ffd-d722506949ed",
      "name": "Adaptive Loss Functions",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "50675867-c864-4095-adea-ca3922399d1a",
      "name": "Focal Loss Variants",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "d5d3bdef-dc1b-440c-9856-80e660936666",
      "name": "Loss Function Customization",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "b453e9e2-760a-4310-9bd1-dcc085dad16c",
      "name": "Class Imbalance Handling",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "9b01d2c2-ddb2-49b1-b665-f72a54412d02",
      "name": "PyTorch Focal Loss",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "8e200c99-4f53-4a95-b401-8ac67f4d93f8",
      "name": "TensorFlow Focal Loss",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "45c200f3-a790-4915-b77c-8edf688c1c52",
      "name": "Efficient Training Strategies",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "68dc94ce-b541-4911-978b-b1adc0501b7a",
      "name": "Model Optimization Methods",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "7f0d8673-04a2-4ffb-a0ff-35f778a5ba12",
      "name": "Object Detection",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "71f2aeee-1939-4dd1-8a3c-48dae5305c89",
      "name": "Loss Functions",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "4446a74b-8197-4c40-a261-de889d713d6b",
      "name": "Deep Learning",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "3b4f328d-7af4-4300-8787-93860575ae8f",
      "name": "Computer Vision",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "bdc60920-8b86-4702-b15d-4b59087d7f8d",
      "name": "Class Imbalance",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "a447d138-4f06-416f-9e19-c6ce5a432867",
      "name": "Weighted Losses",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "c2f2fbbf-e117-4cf2-8c4e-9a06663a565e",
      "name": "Focal Loss",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "1ad7b1fb-67e2-4d7c-b788-0bbd218726db",
      "name": "Detection Models",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "efce71a1-7084-4891-ba45-a561da7b03e9",
      "name": "Region Proposal Networks (RPN)",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "79469b15-18e1-4ed0-88f2-0ed61783d9ef",
      "name": "Single Shot Detectors (SSD)",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "da4ead74-3f0b-4429-812b-438471d1d425",
      "name": "RetinaNet",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "050ac1e4-5978-486f-813b-1904949d537b",
      "name": "Focal Loss Variants",
      "categoryId": "fcab9090-3a37-4c25-9007-ee92aade01ca"
    },
    {
      "id": "cf18afab-b72d-4c60-882f-ffdfcc078ff1",
      "name": "Object Detection",
      "categoryId": "fcab9090-3a37-4c25-9007-ee92aade01ca"
    },
    {
      "id": "4d84f93d-673c-4980-b955-a1c80ee2953f",
      "name": "Imbalanced Data",
      "categoryId": "fcab9090-3a37-4c25-9007-ee92aade01ca"
    },
    {
      "id": "fd86ce3d-ddbd-40a0-bafb-b225e45dd61f",
      "name": "Loss Functions",
      "categoryId": "fcab9090-3a37-4c25-9007-ee92aade01ca"
    },
    {
      "id": "f8e326af-a9fe-4275-a22e-7b7ebebe86ce",
      "name": "Class Imbalance",
      "categoryId": "fcab9090-3a37-4c25-9007-ee92aade01ca"
    },
    {
      "id": "f1130865-f628-4d92-be10-5831cb831e1e",
      "name": "Sigmoid Focal Loss",
      "categoryId": "fcab9090-3a37-4c25-9007-ee92aade01ca"
    },
    {
      "id": "6624906f-a732-4848-bb1a-ddd63be3bbdb",
      "name": "Adaptive Loss",
      "categoryId": "fcab9090-3a37-4c25-9007-ee92aade01ca"
    },
    {
      "id": "849deb73-4ece-45f0-a802-6247f7300e69",
      "name": "Weighted Focal Loss",
      "categoryId": "fcab9090-3a37-4c25-9007-ee92aade01ca"
    },
    {
      "id": "89aec7a7-a49b-4fef-be34-7b9c2bd0d0e0",
      "name": "Hard Example Mining",
      "categoryId": "fcab9090-3a37-4c25-9007-ee92aade01ca"
    },
    {
      "id": "0b19ba03-2613-433c-80de-c7fc12d0003c",
      "name": "Distribution-Calibrated Loss",
      "categoryId": "fcab9090-3a37-4c25-9007-ee92aade01ca"
    },
    {
      "id": "46591f87-b0a6-447e-944e-afd374d3c02c",
      "name": "Focal Loss Variants",
      "categoryId": "c3957990-579c-4aea-a9bf-fb099c300202"
    },
    {
      "id": "5fe3a877-4e45-423b-a969-6d7c055b3755",
      "name": "Focal Loss Extensions",
      "categoryId": "c3957990-579c-4aea-a9bf-fb099c300202"
    },
    {
      "id": "08e8d3fd-98e2-4b16-872f-631f4be5e260",
      "name": "Class Imbalance Handling",
      "categoryId": "c3957990-579c-4aea-a9bf-fb099c300202"
    },
    {
      "id": "15d7d275-b1c2-4095-8b5a-835e3d2c0751",
      "name": "Loss Function Modifications",
      "categoryId": "c3957990-579c-4aea-a9bf-fb099c300202"
    },
    {
      "id": "5be13538-ccc2-440d-a4c0-09289f147cd9",
      "name": "Deep Learning Techniques",
      "categoryId": "c3957990-579c-4aea-a9bf-fb099c300202"
    },
    {
      "id": "c28949c6-94d2-4d09-9002-cefb07fc2f5e",
      "name": "Object Detection Losses",
      "categoryId": "c3957990-579c-4aea-a9bf-fb099c300202"
    },
    {
      "id": "28c0745f-1df8-4402-9daf-c3b7e9c62da7",
      "name": "Hard Example Mining",
      "categoryId": "c3957990-579c-4aea-a9bf-fb099c300202"
    },
    {
      "id": "772851c0-92ee-40f9-89a4-692b4f45f1b9",
      "name": "Adaptive Loss Functions",
      "categoryId": "c3957990-579c-4aea-a9bf-fb099c300202"
    },
    {
      "id": "5f69963c-0c17-4ece-a5a5-c912f54c12c8",
      "name": "Imbalanced Data Strategies",
      "categoryId": "c3957990-579c-4aea-a9bf-fb099c300202"
    },
    {
      "id": "40914cde-af1a-406d-adc3-bc02e2da7857",
      "name": "Focal Loss Variants and Extensions",
      "categoryId": "939cf1aa-be0d-494f-942e-5ce8fd4c0cac"
    },
    {
      "id": "26cd2879-dfb5-4650-aa3d-eb1fca71f332",
      "name": "Loss Functions",
      "categoryId": "939cf1aa-be0d-494f-942e-5ce8fd4c0cac"
    },
    {
      "id": "d3f63400-39f5-408f-9c62-759cc0809ed8",
      "name": "Class Imbalance",
      "categoryId": "939cf1aa-be0d-494f-942e-5ce8fd4c0cac"
    },
    {
      "id": "ff000fca-9b8a-4ab5-9e58-d35a3c247c4e",
      "name": "Hard Example Mining",
      "categoryId": "939cf1aa-be0d-494f-942e-5ce8fd4c0cac"
    },
    {
      "id": "874e7ec1-93c8-4abd-9950-5885a49496dd",
      "name": "Focal Loss",
      "categoryId": "939cf1aa-be0d-494f-942e-5ce8fd4c0cac"
    },
    {
      "id": "247b9c7d-ed78-441a-8e56-c3887fa08d9c",
      "name": "Adaptive Loss Functions",
      "categoryId": "939cf1aa-be0d-494f-942e-5ce8fd4c0cac"
    },
    {
      "id": "b00b98c8-35c4-40d0-83bc-e6cf39830641",
      "name": "Margin-based Losses",
      "categoryId": "939cf1aa-be0d-494f-942e-5ce8fd4c0cac"
    },
    {
      "id": "a6e03008-9cf6-482e-b79e-32c47ffe936e",
      "name": "Cost-sensitive Learning",
      "categoryId": "939cf1aa-be0d-494f-942e-5ce8fd4c0cac"
    },
    {
      "id": "3588561e-5610-4aad-99be-bf445c716f95",
      "name": "Deep Learning Optimization",
      "categoryId": "939cf1aa-be0d-494f-942e-5ce8fd4c0cac"
    },
    {
      "id": "5ead222c-a5ce-43f3-a16a-fe597b2b318a",
      "name": "Object Detection Losses",
      "categoryId": "939cf1aa-be0d-494f-942e-5ce8fd4c0cac"
    },
    {
      "id": "2ff8f475-1e34-4f61-9a55-49c58dce43b7",
      "name": "Focal Loss Variants",
      "categoryId": "cd89f926-dc73-4f45-8d67-50e79ce24bfb"
    },
    {
      "id": "9cc0e005-6827-4922-a879-41a21ddc0ab3",
      "name": "Focal Loss Extensions",
      "categoryId": "cd89f926-dc73-4f45-8d67-50e79ce24bfb"
    },
    {
      "id": "511b8533-bc0b-450f-8bd3-167fd830d7c4",
      "name": "Class Imbalance Techniques",
      "categoryId": "cd89f926-dc73-4f45-8d67-50e79ce24bfb"
    },
    {
      "id": "7da9e308-f27b-41d8-81cb-2edafff636c2",
      "name": "Loss Function Modifications",
      "categoryId": "cd89f926-dc73-4f45-8d67-50e79ce24bfb"
    },
    {
      "id": "a264c767-6cfe-4b4c-9774-d176463db725",
      "name": "Hard Example Mining",
      "categoryId": "cd89f926-dc73-4f45-8d67-50e79ce24bfb"
    },
    {
      "id": "4017a3f6-87aa-471d-9580-f347fb398731",
      "name": "Adaptive Loss Functions",
      "categoryId": "cd89f926-dc73-4f45-8d67-50e79ce24bfb"
    },
    {
      "id": "94b02683-068c-47a0-99f2-8e03fbd5c9bc",
      "name": "Loss Functions for Object Detection",
      "categoryId": "cd89f926-dc73-4f45-8d67-50e79ce24bfb"
    },
    {
      "id": "c541dec6-884f-4c1b-969f-ebf86737aed5",
      "name": "Focal Loss in Deep Learning",
      "categoryId": "cd89f926-dc73-4f45-8d67-50e79ce24bfb"
    },
    {
      "id": "4067ec5f-064a-468e-aad7-70538d44ba96",
      "name": "Non-Convex Loss Variants",
      "categoryId": "cd89f926-dc73-4f45-8d67-50e79ce24bfb"
    },
    {
      "id": "9fda80c1-b1a8-4587-81fc-14ca26e3e596",
      "name": "Gradient Modulation Techniques",
      "categoryId": "cd89f926-dc73-4f45-8d67-50e79ce24bfb"
    },
    {
      "id": "74154382-f12b-47ab-bfe7-6415d692e6a4",
      "name": "Sequence-to-Sequence Models",
      "categoryId": "419675d7-ae0a-4c0f-96ba-054f283f98b4"
    },
    {
      "id": "52f956cc-98da-409d-ae5a-a12eeda21856",
      "name": "Decoding Strategies",
      "categoryId": "419675d7-ae0a-4c0f-96ba-054f283f98b4"
    },
    {
      "id": "56cbfb3b-2cf3-4b6a-8fb2-bdea957beea0",
      "name": "Teacher Forcing",
      "categoryId": "419675d7-ae0a-4c0f-96ba-054f283f98b4"
    },
    {
      "id": "d2706d47-e832-47c5-9b2d-e3ef458485f0",
      "name": "Model Debugging",
      "categoryId": "419675d7-ae0a-4c0f-96ba-054f283f98b4"
    },
    {
      "id": "3234e3af-d285-4f54-8765-abe74fbe114e",
      "name": "NLP Training Methods",
      "categoryId": "419675d7-ae0a-4c0f-96ba-054f283f98b4"
    },
    {
      "id": "56b91047-0024-4ad6-bd91-5d7dd1ea5047",
      "name": "Forecasting falls under the sub-category tags such as Time Series Analysis",
      "categoryId": "bbb72a6f-b434-4e52-a24b-f27f88bbd3b3"
    },
    {
      "id": "486a82a8-e7ba-4d41-9e86-1988cacc2880",
      "name": "Predictive Analytics",
      "categoryId": "bbb72a6f-b434-4e52-a24b-f27f88bbd3b3"
    },
    {
      "id": "fe565c30-d905-4b0a-83d8-84d50664e93a",
      "name": "Quantitative Analysis",
      "categoryId": "bbb72a6f-b434-4e52-a24b-f27f88bbd3b3"
    },
    {
      "id": "fae948c0-a63b-4b24-94b5-cfe74abeefe3",
      "name": "and Statistical Modeling. It involves techniques that analyze temporal data to make future predictions",
      "categoryId": "bbb72a6f-b434-4e52-a24b-f27f88bbd3b3"
    },
    {
      "id": "b43b2dba-eb26-41ab-814a-a0717f82dbc8",
      "name": "emphasizing patterns and trends over time.",
      "categoryId": "bbb72a6f-b434-4e52-a24b-f27f88bbd3b3"
    },
    {
      "id": "75b57e86-8fce-4203-a589-5a7dc71b4848",
      "name": "Cellular automata",
      "categoryId": "5baa0f49-4426-4a94-b834-3a383880e600"
    },
    {
      "id": "39696f9d-a7a6-4b46-8040-7e07a8bdab1c",
      "name": "percolation theory",
      "categoryId": "5baa0f49-4426-4a94-b834-3a383880e600"
    },
    {
      "id": "07940cf2-1e64-4df0-a600-b6ffbacd04ee",
      "name": "modeling",
      "categoryId": "5baa0f49-4426-4a94-b834-3a383880e600"
    },
    {
      "id": "2dd7ae5c-bd7f-48c1-9285-8df072192035",
      "name": "stochastic processes",
      "categoryId": "5baa0f49-4426-4a94-b834-3a383880e600"
    },
    {
      "id": "a2e46d98-ecd0-4087-841e-cb5d98a91d02",
      "name": "spatial dynamics",
      "categoryId": "5baa0f49-4426-4a94-b834-3a383880e600"
    },
    {
      "id": "4711bf82-a873-4777-a7e7-bea8e56f304d",
      "name": "natural disasters",
      "categoryId": "5baa0f49-4426-4a94-b834-3a383880e600"
    },
    {
      "id": "fa7986b9-5417-4267-beaa-f402b1a9d73b",
      "name": "simulation",
      "categoryId": "5baa0f49-4426-4a94-b834-3a383880e600"
    },
    {
      "id": "36bbbf59-b1e6-4dea-9b32-884a851d4b9e",
      "name": "wildfire spread",
      "categoryId": "5baa0f49-4426-4a94-b834-3a383880e600"
    },
    {
      "id": "122ffd8e-9267-4ec5-ab59-f5de962b49a3",
      "name": "complex systems",
      "categoryId": "5baa0f49-4426-4a94-b834-3a383880e600"
    },
    {
      "id": "2b80c746-9349-4c8d-ba55-834e27aa779d",
      "name": "environmental modeling",
      "categoryId": "5baa0f49-4426-4a94-b834-3a383880e600"
    },
    {
      "id": "b642beb3-0e50-4755-8c5a-fb6e0fbbcc64",
      "name": "Formal Concept Analysis (FCA)",
      "categoryId": "16aaf306-d2c1-4e9d-a38c-7491db5206f2"
    },
    {
      "id": "18cae8ff-c395-4909-b809-d16aadfedac1",
      "name": "Lattice Theory",
      "categoryId": "16aaf306-d2c1-4e9d-a38c-7491db5206f2"
    },
    {
      "id": "8b335e7f-e657-424f-a9a7-b5ff9ec20dd7",
      "name": "Formal Contexts",
      "categoryId": "16aaf306-d2c1-4e9d-a38c-7491db5206f2"
    },
    {
      "id": "34cb7d87-25d4-4426-8365-afc46e7fcd60",
      "name": "Galois Connections",
      "categoryId": "16aaf306-d2c1-4e9d-a38c-7491db5206f2"
    },
    {
      "id": "fabae72d-8473-4b96-bf90-5a742dc05ab7",
      "name": "Concept Hierarchies",
      "categoryId": "16aaf306-d2c1-4e9d-a38c-7491db5206f2"
    },
    {
      "id": "963e1cf7-2020-4cba-b4df-f634961b2d2c",
      "name": "Data Formalization",
      "categoryId": "16aaf306-d2c1-4e9d-a38c-7491db5206f2"
    },
    {
      "id": "c045278f-53fa-4ecd-895b-83e877437486",
      "name": "Taxonomy Construction",
      "categoryId": "16aaf306-d2c1-4e9d-a38c-7491db5206f2"
    },
    {
      "id": "faa8a433-5522-4639-8ff3-06ca7ea859a9",
      "name": "Knowledge Representation",
      "categoryId": "16aaf306-d2c1-4e9d-a38c-7491db5206f2"
    },
    {
      "id": "331af683-ecc4-43f1-803e-c393534a65c5",
      "name": "Concept Lattices",
      "categoryId": "16aaf306-d2c1-4e9d-a38c-7491db5206f2"
    },
    {
      "id": "afa95a94-b8e3-42d9-9549-f084a801a8c6",
      "name": "Order Theory",
      "categoryId": "16aaf306-d2c1-4e9d-a38c-7491db5206f2"
    },
    {
      "id": "641e65b1-3c81-492f-a53e-8558ff186e80",
      "name": "Conceptual Structures",
      "categoryId": "16aaf306-d2c1-4e9d-a38c-7491db5206f2"
    },
    {
      "id": "9e93c556-feb3-4388-8a7f-0939d92c3bfd",
      "name": "Reinforcement Learning",
      "categoryId": "67b9e9a4-e629-4c13-99d4-8f8276a45b8c"
    },
    {
      "id": "802af3d2-eb0f-4682-8e0a-755b74bccb6c",
      "name": "Inverse Reinforcement Learning",
      "categoryId": "67b9e9a4-e629-4c13-99d4-8f8276a45b8c"
    },
    {
      "id": "2d136b3f-d079-413c-b717-731f16f522c8",
      "name": "Forward Reinforcement Learning",
      "categoryId": "67b9e9a4-e629-4c13-99d4-8f8276a45b8c"
    },
    {
      "id": "171ad0f7-a010-4aae-bc52-114f87543696",
      "name": "Imitation Learning",
      "categoryId": "67b9e9a4-e629-4c13-99d4-8f8276a45b8c"
    },
    {
      "id": "bacf3252-81b5-4ba1-a690-388bc75df644",
      "name": "Machine Learning Paradigms",
      "categoryId": "67b9e9a4-e629-4c13-99d4-8f8276a45b8c"
    },
    {
      "id": "0a138d9c-8215-4c34-ad38-5d50c9545b63",
      "name": "Sequential Decision Making",
      "categoryId": "67b9e9a4-e629-4c13-99d4-8f8276a45b8c"
    },
    {
      "id": "157d1b4c-098d-429b-9956-b1bd7122ebc7",
      "name": "Policy Optimization",
      "categoryId": "67b9e9a4-e629-4c13-99d4-8f8276a45b8c"
    },
    {
      "id": "0f29b288-ffd5-4755-94df-23f0b06eb2fe",
      "name": "Reward Modeling",
      "categoryId": "67b9e9a4-e629-4c13-99d4-8f8276a45b8c"
    },
    {
      "id": "56d4a737-d585-4ec1-9570-c2bda163400f",
      "name": "Markov Decision Processes (MDPs)",
      "categoryId": "67b9e9a4-e629-4c13-99d4-8f8276a45b8c"
    },
    {
      "id": "a4f59ebf-a75a-4ae2-9ed3-00efe6bb887d",
      "name": "Autonomous Agents",
      "categoryId": "67b9e9a4-e629-4c13-99d4-8f8276a45b8c"
    },
    {
      "id": "52552f26-6351-4e6d-82b2-7423ec9551ac",
      "name": "Behavioral Cloning",
      "categoryId": "67b9e9a4-e629-4c13-99d4-8f8276a45b8c"
    },
    {
      "id": "0dc15975-9663-498a-8c14-eed6b5481fa1",
      "name": "Knowledge inference",
      "categoryId": "ec67470b-edfe-42a3-89b8-85670f52d1cf"
    },
    {
      "id": "8c2c6d72-f304-4808-bfd2-01fc6b267d80",
      "name": "rule-based systems",
      "categoryId": "ec67470b-edfe-42a3-89b8-85670f52d1cf"
    },
    {
      "id": "75a6a5de-6256-435d-8c3d-17996eafa79c",
      "name": "logical reasoning",
      "categoryId": "ec67470b-edfe-42a3-89b8-85670f52d1cf"
    },
    {
      "id": "23e934f1-43d2-4374-ae22-12b1b91b2086",
      "name": "expert systems",
      "categoryId": "ec67470b-edfe-42a3-89b8-85670f52d1cf"
    },
    {
      "id": "64f2cab6-ca00-4fb0-93c3-a5bb07709593",
      "name": "inference engine",
      "categoryId": "ec67470b-edfe-42a3-89b8-85670f52d1cf"
    },
    {
      "id": "6dbb6e0e-f212-4062-8113-3645882cd7c8",
      "name": "propositional logic",
      "categoryId": "ec67470b-edfe-42a3-89b8-85670f52d1cf"
    },
    {
      "id": "d2add922-c9e3-4df0-87e9-5385429c0870",
      "name": "predicate logic",
      "categoryId": "ec67470b-edfe-42a3-89b8-85670f52d1cf"
    },
    {
      "id": "778c33ee-c319-4cd5-8535-86f2b8a897ae",
      "name": "rule chaining",
      "categoryId": "ec67470b-edfe-42a3-89b8-85670f52d1cf"
    },
    {
      "id": "97acb04b-710b-4c91-8730-18f356543d91",
      "name": "forward reasoning",
      "categoryId": "ec67470b-edfe-42a3-89b8-85670f52d1cf"
    },
    {
      "id": "65452514-bed4-4f05-aaa7-0dd3faaded44",
      "name": "declarative programming",
      "categoryId": "ec67470b-edfe-42a3-89b8-85670f52d1cf"
    },
    {
      "id": "30c3fda6-e3e8-45b7-927f-edf58eb7620f",
      "name": "Diffusion Processes",
      "categoryId": "82b1c223-ea8a-4d43-af4f-39ad20e7708b"
    },
    {
      "id": "dd6d13c7-496e-4a65-a99d-cdea6c66c954",
      "name": "Probabilistic Models",
      "categoryId": "82b1c223-ea8a-4d43-af4f-39ad20e7708b"
    },
    {
      "id": "2a20d572-1661-423b-9fc5-67343646a9aa",
      "name": "Generative Modeling",
      "categoryId": "82b1c223-ea8a-4d43-af4f-39ad20e7708b"
    },
    {
      "id": "202799fc-33ab-4f06-8efe-f2eb6639586a",
      "name": "Markov Processes",
      "categoryId": "82b1c223-ea8a-4d43-af4f-39ad20e7708b"
    },
    {
      "id": "9db3513a-54e1-424f-8767-c196e2490b12",
      "name": "Stochastic Differential Equations",
      "categoryId": "82b1c223-ea8a-4d43-af4f-39ad20e7708b"
    },
    {
      "id": "dc43530e-295b-433b-a3bb-91a0606c19a0",
      "name": "Noise Diffusion",
      "categoryId": "82b1c223-ea8a-4d43-af4f-39ad20e7708b"
    },
    {
      "id": "9c9ce4ab-7ba5-4cdb-b62b-df65390d08fc",
      "name": "Data Generation",
      "categoryId": "82b1c223-ea8a-4d43-af4f-39ad20e7708b"
    },
    {
      "id": "e0919597-2efd-446d-b977-7fce76ddc7ef",
      "name": "Variational Methods",
      "categoryId": "82b1c223-ea8a-4d43-af4f-39ad20e7708b"
    },
    {
      "id": "34cb6e84-965f-421e-a73b-8692aa8aa04e",
      "name": "Neural Networks",
      "categoryId": "f32b4ce5-e751-440e-800e-0e6245cb1033"
    },
    {
      "id": "669ae29c-4242-4fda-83bd-bd4fa9336152",
      "name": "Deep Learning",
      "categoryId": "f32b4ce5-e751-440e-800e-0e6245cb1033"
    },
    {
      "id": "97e58290-74fb-4f9a-b508-1167aca4abc7",
      "name": "Model Evaluation",
      "categoryId": "f32b4ce5-e751-440e-800e-0e6245cb1033"
    },
    {
      "id": "dd2cde1f-94a3-46ea-89f6-eb62de4d27e3",
      "name": "Computational Graphs",
      "categoryId": "f32b4ce5-e751-440e-800e-0e6245cb1033"
    },
    {
      "id": "32392216-e87d-4fbc-b9ca-c55396b7fd77",
      "name": "Activation Functions",
      "categoryId": "f32b4ce5-e751-440e-800e-0e6245cb1033"
    },
    {
      "id": "7d830319-54a0-43bb-b379-8f595bcec235",
      "name": "Backpropagation",
      "categoryId": "f32b4ce5-e751-440e-800e-0e6245cb1033"
    },
    {
      "id": "c2e271d6-a98b-4910-81da-1cbd17b8c38d",
      "name": "TensorFlow",
      "categoryId": "f32b4ce5-e751-440e-800e-0e6245cb1033"
    },
    {
      "id": "79237587-ee39-41d8-b1aa-124c9896547d",
      "name": "PyTorch",
      "categoryId": "f32b4ce5-e751-440e-800e-0e6245cb1033"
    },
    {
      "id": "19b2dafc-2ebd-49c9-87ac-7b447880a3a8",
      "name": "Foundation Model",
      "categoryId": "37f413f4-2e00-48ec-99e6-8eac4f70df87"
    },
    {
      "id": "0d794903-56d3-4685-bf0d-19da895ba0c9",
      "name": "Large Language Model",
      "categoryId": "37f413f4-2e00-48ec-99e6-8eac4f70df87"
    },
    {
      "id": "86f0e8f9-5c11-49e9-9c78-eac2e63d9829",
      "name": "Pretrained Model",
      "categoryId": "37f413f4-2e00-48ec-99e6-8eac4f70df87"
    },
    {
      "id": "ab25166a-65c2-4f14-ba7a-e98832f6ae2f",
      "name": "Deep Learning",
      "categoryId": "37f413f4-2e00-48ec-99e6-8eac4f70df87"
    },
    {
      "id": "fc2ddb38-b02c-4819-bc8a-750279ba05d0",
      "name": "Natural Language Processing",
      "categoryId": "37f413f4-2e00-48ec-99e6-8eac4f70df87"
    },
    {
      "id": "6ff78a3a-eff7-41dc-8ec6-3a9f1bd4d1c7",
      "name": "Generative AI",
      "categoryId": "37f413f4-2e00-48ec-99e6-8eac4f70df87"
    },
    {
      "id": "7b182862-c531-47b9-a9f1-922c91a8b6d2",
      "name": "Unsupervised Learning",
      "categoryId": "37f413f4-2e00-48ec-99e6-8eac4f70df87"
    },
    {
      "id": "734896e7-04a0-4c79-acd4-18650c5f8349",
      "name": "Transfer Learning",
      "categoryId": "37f413f4-2e00-48ec-99e6-8eac4f70df87"
    },
    {
      "id": "31b3c4df-7510-41f6-9fb6-08e627025826",
      "name": "Multimodal AI",
      "categoryId": "37f413f4-2e00-48ec-99e6-8eac4f70df87"
    },
    {
      "id": "ad57baf7-fd49-49d9-ab7a-688d6d8ec737",
      "name": "Representation Learning",
      "categoryId": "37f413f4-2e00-48ec-99e6-8eac4f70df87"
    },
    {
      "id": "9a3f38d3-9c1c-47db-ace2-c224cbda377e",
      "name": "Foundation Models",
      "categoryId": "8f374a2a-5e60-472f-bb50-83656c4b798f"
    },
    {
      "id": "819c7bd9-23c8-48d9-99a2-789419a9b249",
      "name": "Transformer Architectures",
      "categoryId": "8f374a2a-5e60-472f-bb50-83656c4b798f"
    },
    {
      "id": "b02ea9cc-7d59-4302-993c-3c142a2519fc",
      "name": "Large-Scale Pretrained Models",
      "categoryId": "8f374a2a-5e60-472f-bb50-83656c4b798f"
    },
    {
      "id": "e511168a-e9d4-42c1-99e9-9f3be627f203",
      "name": "Representation Learning",
      "categoryId": "8f374a2a-5e60-472f-bb50-83656c4b798f"
    },
    {
      "id": "af7a843a-553e-4ce3-bfc8-96e28f3210b2",
      "name": "Transfer Learning",
      "categoryId": "8f374a2a-5e60-472f-bb50-83656c4b798f"
    },
    {
      "id": "f047e472-0562-49b9-8cdc-1e450d9b22bc",
      "name": "Self-Supervised Learning",
      "categoryId": "8f374a2a-5e60-472f-bb50-83656c4b798f"
    },
    {
      "id": "761fa5b8-ecfd-4183-8824-fc9059af9139",
      "name": "Multimodal Models",
      "categoryId": "8f374a2a-5e60-472f-bb50-83656c4b798f"
    },
    {
      "id": "7c1bb0ab-4f81-457e-8401-a1ef52169e3a",
      "name": "Zero-Shot Learning",
      "categoryId": "8f374a2a-5e60-472f-bb50-83656c4b798f"
    },
    {
      "id": "535b73c2-79b9-4844-acbf-694efecbf6cd",
      "name": "Artificial Intelligence",
      "categoryId": "6e3eea6d-6338-44f4-8991-3e73a0747f57"
    },
    {
      "id": "3000f57a-6731-4f3a-90ec-d54dadc258ed",
      "name": "Machine Learning",
      "categoryId": "6e3eea6d-6338-44f4-8991-3e73a0747f57"
    },
    {
      "id": "43f0ce96-03c4-430f-ab43-7dbd1593d776",
      "name": "Deep Learning",
      "categoryId": "6e3eea6d-6338-44f4-8991-3e73a0747f57"
    },
    {
      "id": "b37180cf-0dac-4cfa-adc5-07cae90089f6",
      "name": "Natural Language Processing",
      "categoryId": "6e3eea6d-6338-44f4-8991-3e73a0747f57"
    },
    {
      "id": "f1187de2-fb9d-4a51-9ca8-aaf47ec23fee",
      "name": "Transfer Learning",
      "categoryId": "6e3eea6d-6338-44f4-8991-3e73a0747f57"
    },
    {
      "id": "b698638e-f7b9-4f11-bea2-cfad65640f62",
      "name": "Model Pretraining",
      "categoryId": "6e3eea6d-6338-44f4-8991-3e73a0747f57"
    },
    {
      "id": "61214d8d-2be2-4fb6-87ed-1424d6f2cbb0",
      "name": "Large-Scale Models",
      "categoryId": "6e3eea6d-6338-44f4-8991-3e73a0747f57"
    },
    {
      "id": "f819d97f-2728-4407-b4b5-013afbdab638",
      "name": "Model Architecture",
      "categoryId": "6e3eea6d-6338-44f4-8991-3e73a0747f57"
    },
    {
      "id": "59202fd7-41ee-4698-9261-a49308c28a81",
      "name": "AI Infrastructure",
      "categoryId": "6e3eea6d-6338-44f4-8991-3e73a0747f57"
    },
    {
      "id": "150dd296-8814-440f-8ad6-851da266af11",
      "name": "Data Efficiency",
      "categoryId": "6e3eea6d-6338-44f4-8991-3e73a0747f57"
    },
    {
      "id": "eae322d8-d378-434c-9b56-70c0dce631ad",
      "name": "Multimodal AI",
      "categoryId": "6e3eea6d-6338-44f4-8991-3e73a0747f57"
    },
    {
      "id": "52d1323f-6aef-42d8-99e8-10480bd656f4",
      "name": "Sub-category tags for 'Foundational AI Model' include terms such as 'Large Language Model'",
      "categoryId": "e0597348-9c6f-44f3-8e63-0a3d655bcaea"
    },
    {
      "id": "19f77755-8509-4d46-bbb2-c9b86aa11e61",
      "name": "'Pretraining'",
      "categoryId": "e0597348-9c6f-44f3-8e63-0a3d655bcaea"
    },
    {
      "id": "0ef42f7e-29f3-4238-b98d-a73b3831a509",
      "name": "'Transformer Architecture'",
      "categoryId": "e0597348-9c6f-44f3-8e63-0a3d655bcaea"
    },
    {
      "id": "3cd8d5ea-5646-4593-9897-11036775b09f",
      "name": "'Neural Network Foundations'",
      "categoryId": "e0597348-9c6f-44f3-8e63-0a3d655bcaea"
    },
    {
      "id": "4c7c1a3d-e552-45d9-9dfc-9af42238a0c5",
      "name": "'Model Scaling'",
      "categoryId": "e0597348-9c6f-44f3-8e63-0a3d655bcaea"
    },
    {
      "id": "925f2ff0-9a64-442c-bf9d-b509b4e8a848",
      "name": "and 'Natural Language Processing'. These tags help categorize the model within the broader AI landscape focusing on core building blocks and fundamental design principles that underpin advanced AI systems.",
      "categoryId": "e0597348-9c6f-44f3-8e63-0a3d655bcaea"
    },
    {
      "id": "a57b9d45-f17f-4825-8488-b24ee46da68c",
      "name": "Fourier Features",
      "categoryId": "193aa14f-9991-4cf7-9ce5-b852f98b7cbb"
    },
    {
      "id": "1e5b737f-1179-489d-b65f-a85467790774",
      "name": "Feature Mapping",
      "categoryId": "193aa14f-9991-4cf7-9ce5-b852f98b7cbb"
    },
    {
      "id": "33aff227-e107-4670-9768-ff7e7a836027",
      "name": "Random Fourier Features",
      "categoryId": "193aa14f-9991-4cf7-9ce5-b852f98b7cbb"
    },
    {
      "id": "d2cf19e3-25d0-4115-9210-bcfc2d0e60e1",
      "name": "Kernel Approximation",
      "categoryId": "193aa14f-9991-4cf7-9ce5-b852f98b7cbb"
    },
    {
      "id": "9e12627b-5e0f-43ca-b2b7-2c681fd043ad",
      "name": "Positional Encoding",
      "categoryId": "193aa14f-9991-4cf7-9ce5-b852f98b7cbb"
    },
    {
      "id": "67da95d8-8c10-43ae-b640-03b993a2300f",
      "name": "Randomized Feature Maps",
      "categoryId": "193aa14f-9991-4cf7-9ce5-b852f98b7cbb"
    },
    {
      "id": "181bab85-52e9-4fa5-bacc-9dcf2aebd8c0",
      "name": "Kernel Methods",
      "categoryId": "193aa14f-9991-4cf7-9ce5-b852f98b7cbb"
    },
    {
      "id": "b0d4718e-b2b4-4018-8615-371f2508c0bb",
      "name": "High-dimensional Data Representation",
      "categoryId": "193aa14f-9991-4cf7-9ce5-b852f98b7cbb"
    },
    {
      "id": "1c86374e-cb89-4ae5-a356-cff6ca8f6a19",
      "name": "Neural Networks",
      "categoryId": "b7c35577-03d9-4f63-bb37-54771c921f5b"
    },
    {
      "id": "b12c94ac-a226-42a6-b25c-8eaed8e4d889",
      "name": "Feature Engineering",
      "categoryId": "b7c35577-03d9-4f63-bb37-54771c921f5b"
    },
    {
      "id": "a948409d-2da5-4e97-9a3e-39b5cc8eafd1",
      "name": "Kernel Methods",
      "categoryId": "b7c35577-03d9-4f63-bb37-54771c921f5b"
    },
    {
      "id": "481a2440-b685-49b8-ad1f-53981c23b5b9",
      "name": "Positional Encoding",
      "categoryId": "b7c35577-03d9-4f63-bb37-54771c921f5b"
    },
    {
      "id": "9cd20cb0-a94f-4b65-82e9-6f586d10713d",
      "name": "Machine Learning Foundations",
      "categoryId": "b7c35577-03d9-4f63-bb37-54771c921f5b"
    },
    {
      "id": "02d9b98f-c2ac-4f83-ba32-ed6c95ec252c",
      "name": "Deep Learning Techniques",
      "categoryId": "b7c35577-03d9-4f63-bb37-54771c921f5b"
    },
    {
      "id": "192cbe09-1692-4490-bf34-7bed0bc212be",
      "name": "Signal Processing",
      "categoryId": "b7c35577-03d9-4f63-bb37-54771c921f5b"
    },
    {
      "id": "b1da605e-0099-419f-b5b5-73814c94ad0c",
      "name": "High-dimensional Data",
      "categoryId": "b7c35577-03d9-4f63-bb37-54771c921f5b"
    },
    {
      "id": "093d408d-f00e-48d5-b2df-d79b34042a90",
      "name": "Embedding Methods",
      "categoryId": "b7c35577-03d9-4f63-bb37-54771c921f5b"
    },
    {
      "id": "21856d8a-b1d3-40e0-b6fa-307646746b20",
      "name": "Representation Learning",
      "categoryId": "b7c35577-03d9-4f63-bb37-54771c921f5b"
    },
    {
      "id": "5e787697-be28-4691-966d-a0daac18af54",
      "name": "Fourier Neural Operator",
      "categoryId": "a23a0fb2-b968-42dd-9eb7-950e8cb66d93"
    },
    {
      "id": "e66ab9a0-d583-4551-a2e2-180407f6f7b1",
      "name": "FNO",
      "categoryId": "a23a0fb2-b968-42dd-9eb7-950e8cb66d93"
    },
    {
      "id": "b7bc2e7e-772d-4299-981a-2b635150759f",
      "name": "operator learning",
      "categoryId": "a23a0fb2-b968-42dd-9eb7-950e8cb66d93"
    },
    {
      "id": "28fde690-ab44-4791-be25-ef9090923482",
      "name": "neural operator",
      "categoryId": "a23a0fb2-b968-42dd-9eb7-950e8cb66d93"
    },
    {
      "id": "7aed1131-b11d-404f-a258-52706d80f019",
      "name": "spectral methods",
      "categoryId": "a23a0fb2-b968-42dd-9eb7-950e8cb66d93"
    },
    {
      "id": "2df98b65-552e-4fc6-a474-f8fba62be927",
      "name": "function approximation",
      "categoryId": "a23a0fb2-b968-42dd-9eb7-950e8cb66d93"
    },
    {
      "id": "06084247-a5f4-45c1-bbc4-947bb20285c0",
      "name": "deep learning",
      "categoryId": "a23a0fb2-b968-42dd-9eb7-950e8cb66d93"
    },
    {
      "id": "b451881f-a0e3-455a-a891-e79e20ecb838",
      "name": "partial differential equations",
      "categoryId": "a23a0fb2-b968-42dd-9eb7-950e8cb66d93"
    },
    {
      "id": "d6ace6f4-f545-4a0b-8f94-923e86459ea3",
      "name": "PDE solving",
      "categoryId": "a23a0fb2-b968-42dd-9eb7-950e8cb66d93"
    },
    {
      "id": "3c2e8fd0-c8e0-47c8-9cee-fc5ba3f1b0db",
      "name": "Fourier analysis",
      "categoryId": "a23a0fb2-b968-42dd-9eb7-950e8cb66d93"
    },
    {
      "id": "c90d77b9-cae5-4861-b9b8-6abe5f30e3f3",
      "name": "neural networks",
      "categoryId": "a23a0fb2-b968-42dd-9eb7-950e8cb66d93"
    },
    {
      "id": "6a1e9e3a-cd69-429b-9d00-aafe9f49c262",
      "name": "operator learning architectures",
      "categoryId": "a23a0fb2-b968-42dd-9eb7-950e8cb66d93"
    },
    {
      "id": "7e75d7e0-9484-40bc-ad9c-ee374cba823a",
      "name": "Fourier Neural Operators",
      "categoryId": "68ad24ff-10c9-4528-8cf4-90e1fced8c2f"
    },
    {
      "id": "f54992e2-8f53-4889-8b57-891a771d08c1",
      "name": "FNO",
      "categoryId": "68ad24ff-10c9-4528-8cf4-90e1fced8c2f"
    },
    {
      "id": "42fca705-04a3-4e2b-9e5f-42d37b0811e2",
      "name": "Operator Learning",
      "categoryId": "68ad24ff-10c9-4528-8cf4-90e1fced8c2f"
    },
    {
      "id": "4b6f4478-2080-4db3-a85e-1edc037599ae",
      "name": "Infinite-Dimensional Problems",
      "categoryId": "68ad24ff-10c9-4528-8cf4-90e1fced8c2f"
    },
    {
      "id": "87d50110-3218-4c15-9bb6-2d40a002ac25",
      "name": "Deep Learning",
      "categoryId": "68ad24ff-10c9-4528-8cf4-90e1fced8c2f"
    },
    {
      "id": "46b7086d-093c-4816-8ea0-3515bd9e42b3",
      "name": "Functional Analysis",
      "categoryId": "68ad24ff-10c9-4528-8cf4-90e1fced8c2f"
    },
    {
      "id": "7f958407-5b45-4085-9ff1-b6711931e0ff",
      "name": "Spectral Methods",
      "categoryId": "68ad24ff-10c9-4528-8cf4-90e1fced8c2f"
    },
    {
      "id": "0afc6002-0df6-4a5a-a44b-dd50a152c500",
      "name": "Neural Operator Architectures",
      "categoryId": "68ad24ff-10c9-4528-8cf4-90e1fced8c2f"
    },
    {
      "id": "8d210700-fe11-49d7-b24b-4668576d3103",
      "name": "Data-Driven Modelling",
      "categoryId": "68ad24ff-10c9-4528-8cf4-90e1fced8c2f"
    },
    {
      "id": "91765d64-d600-4fb8-b93f-f646a9ba6c5e",
      "name": "PDE Solvers",
      "categoryId": "68ad24ff-10c9-4528-8cf4-90e1fced8c2f"
    },
    {
      "id": "41b5a32c-bac8-4251-a5b5-0488fa7dd952",
      "name": "Fourier Neural Operators Enhancements",
      "categoryId": "1a28632c-3afc-41d1-a337-8229d387d2ef"
    },
    {
      "id": "579f5438-087f-41fb-bcbc-5d565bbe9fc5",
      "name": "Neural Operators",
      "categoryId": "1a28632c-3afc-41d1-a337-8229d387d2ef"
    },
    {
      "id": "5f29070f-07b6-44bc-8411-543214b94ff5",
      "name": "Fourier Transform",
      "categoryId": "1a28632c-3afc-41d1-a337-8229d387d2ef"
    },
    {
      "id": "edcb629c-ff60-4cfa-9429-ef34cfcf0289",
      "name": "High-dimensional PDEs",
      "categoryId": "1a28632c-3afc-41d1-a337-8229d387d2ef"
    },
    {
      "id": "9d888f90-005a-4930-b5e9-603adc850d34",
      "name": "Operator Learning",
      "categoryId": "1a28632c-3afc-41d1-a337-8229d387d2ef"
    },
    {
      "id": "f4b34965-2fbd-47aa-811f-c328cb92e373",
      "name": "Deep Learning",
      "categoryId": "1a28632c-3afc-41d1-a337-8229d387d2ef"
    },
    {
      "id": "e4960def-517d-4e1b-bb18-2789938e7cdd",
      "name": "Function Approximation",
      "categoryId": "1a28632c-3afc-41d1-a337-8229d387d2ef"
    },
    {
      "id": "48badc81-98aa-466c-a2fa-e44f54824aaf",
      "name": "Advanced Neural Architectures",
      "categoryId": "1a28632c-3afc-41d1-a337-8229d387d2ef"
    },
    {
      "id": "c6936b7a-8251-4274-9b52-277e05d7d569",
      "name": "Frequency Domain Methods",
      "categoryId": "1a28632c-3afc-41d1-a337-8229d387d2ef"
    },
    {
      "id": "128301b2-fbbb-421d-b740-8d22d25a8e0d",
      "name": "Efficiency Improvements",
      "categoryId": "1a28632c-3afc-41d1-a337-8229d387d2ef"
    },
    {
      "id": "b85e775d-fe31-4dd8-b5cc-86f4f02a0090",
      "name": "Operator Learning",
      "categoryId": "4af4314e-f98c-49a8-ab66-4db689665013"
    },
    {
      "id": "46d7f8cf-752b-4a76-b482-3666fdcb585d",
      "name": "Fourier Transforms",
      "categoryId": "4af4314e-f98c-49a8-ab66-4db689665013"
    },
    {
      "id": "a694290f-a60f-47cd-bc9d-96115a14b5eb",
      "name": "PDE Solvers",
      "categoryId": "4af4314e-f98c-49a8-ab66-4db689665013"
    },
    {
      "id": "901f9b5f-62a5-4ee0-ab31-2aba37e411c7",
      "name": "Neural Operator Extensions",
      "categoryId": "4af4314e-f98c-49a8-ab66-4db689665013"
    },
    {
      "id": "88857b93-b2b8-4dc8-a39e-ba46fd0494d6",
      "name": "Function Approximation",
      "categoryId": "4af4314e-f98c-49a8-ab66-4db689665013"
    },
    {
      "id": "19b717bc-5709-4e83-a4b1-d6eb58c375a9",
      "name": "Fourier Neural Operators Techniques",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "54d347f9-3baa-4bd2-9466-239fea9b264f",
      "name": "Fourier Neural Operators",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "18cbaa78-319e-4e56-90da-f9468ddc853b",
      "name": "Operator Learning",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "e14f30cd-22b1-4e8b-9a1c-3da9ec6d9850",
      "name": "Spectral Methods",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "4a44e9c4-1be4-4910-9f40-5fc27c67a5b3",
      "name": "Functional Approximation",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "9ae644f9-5614-4cb8-a067-f3a9a6cdb0b2",
      "name": "PDE Solvers",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "47bdb55c-fc19-404a-9685-08a13747271b",
      "name": "Neural Operator Methods",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "c2132859-b961-42f3-b1cb-978b1f0fa697",
      "name": "Fourier Neural Operators Techniques Enhancements",
      "categoryId": "44ee7168-0e06-4906-92da-c4c16c8f3dbb"
    },
    {
      "id": "6f55ea2c-1647-4015-9421-277132b44966",
      "name": "Neural Operators",
      "categoryId": "44ee7168-0e06-4906-92da-c4c16c8f3dbb"
    },
    {
      "id": "15039e52-44f4-4f93-a4fa-a44661573745",
      "name": "Fourier Transform",
      "categoryId": "44ee7168-0e06-4906-92da-c4c16c8f3dbb"
    },
    {
      "id": "1e671810-1318-44bf-b213-49d0117b36a7",
      "name": "Spectral Methods",
      "categoryId": "44ee7168-0e06-4906-92da-c4c16c8f3dbb"
    },
    {
      "id": "25ca99a0-d276-40cc-a4d2-fa60bd35df2f",
      "name": "Deep Learning",
      "categoryId": "44ee7168-0e06-4906-92da-c4c16c8f3dbb"
    },
    {
      "id": "1c08a553-6942-4523-9cf8-62dcb9d5a7a2",
      "name": "Scientific Machine Learning",
      "categoryId": "44ee7168-0e06-4906-92da-c4c16c8f3dbb"
    },
    {
      "id": "da83db62-096c-4cbf-a396-ebc314f12e32",
      "name": "Operator Learning",
      "categoryId": "44ee7168-0e06-4906-92da-c4c16c8f3dbb"
    },
    {
      "id": "47ac5278-dc3d-413e-8ecf-3938c3108d60",
      "name": "Functional Approximation",
      "categoryId": "44ee7168-0e06-4906-92da-c4c16c8f3dbb"
    },
    {
      "id": "1809a6e9-47ce-4ebc-bed6-8056f15411e5",
      "name": "Computational Mathematics",
      "categoryId": "44ee7168-0e06-4906-92da-c4c16c8f3dbb"
    },
    {
      "id": "a6c596a2-791d-4f55-bbef-308c4965b096",
      "name": "High-Dimensional Data",
      "categoryId": "44ee7168-0e06-4906-92da-c4c16c8f3dbb"
    },
    {
      "id": "2a86e61f-d3e3-41c6-8221-e4f790a63b74",
      "name": "Model Acceleration",
      "categoryId": "44ee7168-0e06-4906-92da-c4c16c8f3dbb"
    },
    {
      "id": "1a742647-5d27-470b-a658-5bfed6204f33",
      "name": "Neural Network Optimization",
      "categoryId": "44ee7168-0e06-4906-92da-c4c16c8f3dbb"
    },
    {
      "id": "95931671-2dec-46a1-b339-02a3fb929bb0",
      "name": "Fourier Domain Methods",
      "categoryId": "44ee7168-0e06-4906-92da-c4c16c8f3dbb"
    },
    {
      "id": "099961ae-2aec-4941-a861-3634f74ee1e6",
      "name": "Fourier Neural Operators Techniques Extensions",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "5c322c83-583a-4ace-8729-832d2d47fd7f",
      "name": "Neural Operators",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "2dbd8ade-bae4-491d-a64b-21b46ef28dfb",
      "name": "Fourier Transform",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "45b4a8a5-9904-48d8-8d1f-53fa92552996",
      "name": "Function Approximation",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "881b9265-fc77-48ae-be9d-a0ada8df01f8",
      "name": "Computational Mathematics",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "37cc67e0-c06d-4990-a7c9-2fdaf0821b2f",
      "name": "Integral Kernel Methods",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "e639037d-6879-4a25-bf9e-cd6fb1affae1",
      "name": "Fourier Neural Operators Techniques Extensions",
      "categoryId": "d9632ffa-d344-412c-91fa-612311a084fd"
    },
    {
      "id": "22b15b57-8baa-48d0-a232-eacc3affb434",
      "name": "Spectral Methods",
      "categoryId": "d9632ffa-d344-412c-91fa-612311a084fd"
    },
    {
      "id": "ed6faf2b-5a34-4925-bc02-e6331b91a424",
      "name": "Operator Learning",
      "categoryId": "d9632ffa-d344-412c-91fa-612311a084fd"
    },
    {
      "id": "a32a594a-9d2e-4550-86e9-cc53df7ecbb6",
      "name": "Deep Approximate Operators",
      "categoryId": "d9632ffa-d344-412c-91fa-612311a084fd"
    },
    {
      "id": "4f6234d4-7ca6-4a37-80d8-1985dbeb936f",
      "name": "Function Space Regression",
      "categoryId": "d9632ffa-d344-412c-91fa-612311a084fd"
    },
    {
      "id": "abcd3448-0fc9-4726-8a79-99208e6e4721",
      "name": "Numerical Solutions of PDEs",
      "categoryId": "d9632ffa-d344-412c-91fa-612311a084fd"
    },
    {
      "id": "5891c68f-3d5c-49a6-b885-252f9b2ae8ce",
      "name": "Fourier Transform",
      "categoryId": "d9632ffa-d344-412c-91fa-612311a084fd"
    },
    {
      "id": "3991f542-31c6-4555-8061-577475a90a0f",
      "name": "Spectral Neural Networks",
      "categoryId": "d9632ffa-d344-412c-91fa-612311a084fd"
    },
    {
      "id": "33ea631f-1931-433c-94ea-ad561342f5b2",
      "name": "Operator Approximation",
      "categoryId": "d9632ffa-d344-412c-91fa-612311a084fd"
    },
    {
      "id": "517ea337-afb0-402e-bd56-c3f746f7e2d1",
      "name": "Deep Learning for Scientific Computing",
      "categoryId": "d9632ffa-d344-412c-91fa-612311a084fd"
    },
    {
      "id": "ac1a044c-9ed3-4fb1-bdde-4695f936db19",
      "name": "Fourier Neural Operators",
      "categoryId": "4cdc6590-04bd-4428-b186-d0180bae17a5"
    },
    {
      "id": "5a7e568c-f644-4164-8ab1-1258803dbfa2",
      "name": "Operator Learning",
      "categoryId": "4cdc6590-04bd-4428-b186-d0180bae17a5"
    },
    {
      "id": "98b0b0e0-4eb2-461e-bb5c-1fb307cac71a",
      "name": "Numerical PDE Solvers",
      "categoryId": "4cdc6590-04bd-4428-b186-d0180bae17a5"
    },
    {
      "id": "cab8b8ac-6704-4dba-baf3-fe8cd9527a1f",
      "name": "Deep Learning",
      "categoryId": "4cdc6590-04bd-4428-b186-d0180bae17a5"
    },
    {
      "id": "0fc1f251-10ac-4351-9232-0cccf2e97ca9",
      "name": "Neural Operator Methods",
      "categoryId": "4cdc6590-04bd-4428-b186-d0180bae17a5"
    },
    {
      "id": "52e9a2c5-7d84-48ab-9a9e-b2c10747a103",
      "name": "Neural PDE Solvers",
      "categoryId": "4cdc6590-04bd-4428-b186-d0180bae17a5"
    },
    {
      "id": "9bc556e0-20cb-47df-88dc-6889ea7e3cb3",
      "name": "Computational Mathematics",
      "categoryId": "4cdc6590-04bd-4428-b186-d0180bae17a5"
    },
    {
      "id": "465c0d4d-7e87-453d-85db-9e32a449675c",
      "name": "Neural Operators",
      "categoryId": "20ffb055-e2ec-409b-9c61-fb1e86158272"
    },
    {
      "id": "f296985a-e601-47ec-8b94-83a05fc51462",
      "name": "Fourier Transforms",
      "categoryId": "20ffb055-e2ec-409b-9c61-fb1e86158272"
    },
    {
      "id": "69010cb1-d200-4102-a299-ca92c56eb595",
      "name": "Deep Learning Extensions",
      "categoryId": "20ffb055-e2ec-409b-9c61-fb1e86158272"
    },
    {
      "id": "9ba6128a-5c9c-45cc-8151-5740101a40e9",
      "name": "Model Enhancements",
      "categoryId": "20ffb055-e2ec-409b-9c61-fb1e86158272"
    },
    {
      "id": "04d4029a-00a7-4085-99f0-98a4f25fe950",
      "name": "Numerical Methods",
      "categoryId": "20ffb055-e2ec-409b-9c61-fb1e86158272"
    },
    {
      "id": "514ddf69-2166-4d8b-abe0-22001a2aba34",
      "name": "Fourier Transform",
      "categoryId": "bb9827c8-518a-4dae-ba99-ef114de5a35f"
    },
    {
      "id": "91ac82c2-3a39-473e-8360-c2b26b3a84cf",
      "name": "convolutional neural networks (CNNs)",
      "categoryId": "bb9827c8-518a-4dae-ba99-ef114de5a35f"
    },
    {
      "id": "c33e8979-f51b-40f3-95bf-e56ca0072589",
      "name": "frequency domain analysis",
      "categoryId": "bb9827c8-518a-4dae-ba99-ef114de5a35f"
    },
    {
      "id": "5522b166-8ece-45a0-88ea-c8ec508a8472",
      "name": "spectral methods",
      "categoryId": "bb9827c8-518a-4dae-ba99-ef114de5a35f"
    },
    {
      "id": "6e1b4d3e-4a83-4c8c-8be0-b9014e748f73",
      "name": "signal processing in deep learning",
      "categoryId": "bb9827c8-518a-4dae-ba99-ef114de5a35f"
    },
    {
      "id": "66ab3e55-6278-4f67-a0ae-681edda8d086",
      "name": "Fourier analysis in neural networks",
      "categoryId": "bb9827c8-518a-4dae-ba99-ef114de5a35f"
    },
    {
      "id": "810abc3d-1803-4622-9d26-c4fbb0273637",
      "name": "Clustering Validation",
      "categoryId": "67e320dd-1113-4cb1-b52a-f1b9e1fe06d9"
    },
    {
      "id": "645dd955-146f-4049-a9c5-e9456b097fea",
      "name": "Internal Validation Metrics",
      "categoryId": "67e320dd-1113-4cb1-b52a-f1b9e1fe06d9"
    },
    {
      "id": "5dbe8259-7e81-4b95-b7d0-44646b896d8e",
      "name": "Similarity Measures",
      "categoryId": "67e320dd-1113-4cb1-b52a-f1b9e1fe06d9"
    },
    {
      "id": "a4000619-7e59-4a76-8905-b960beac9b24",
      "name": "Cluster Similarity Indices",
      "categoryId": "67e320dd-1113-4cb1-b52a-f1b9e1fe06d9"
    },
    {
      "id": "bb2f2ed5-5831-4c75-81ac-7807dc9bdf12",
      "name": "Clustering Validation Metrics",
      "categoryId": "67e320dd-1113-4cb1-b52a-f1b9e1fe06d9"
    },
    {
      "id": "12678578-6d75-4a96-ab09-6732e239be71",
      "name": "Performance Evaluation in Unsupervised Learning",
      "categoryId": "67e320dd-1113-4cb1-b52a-f1b9e1fe06d9"
    },
    {
      "id": "272d89e2-8e0c-4d4c-ba37-ae6be70a4c32",
      "name": "Data Mining",
      "categoryId": "4935a6fe-6ca3-4fe0-9dbe-b9813d81ed6e"
    },
    {
      "id": "893df46f-bc5e-4363-9e6c-cfdd44434851",
      "name": "Pattern Mining",
      "categoryId": "4935a6fe-6ca3-4fe0-9dbe-b9813d81ed6e"
    },
    {
      "id": "825edbd0-398f-43ed-8c1e-4bde2d014c22",
      "name": "Association Rule Mining",
      "categoryId": "4935a6fe-6ca3-4fe0-9dbe-b9813d81ed6e"
    },
    {
      "id": "9c249d7f-29c2-464c-8271-5a2a29efab1c",
      "name": "Frequent Pattern Mining",
      "categoryId": "4935a6fe-6ca3-4fe0-9dbe-b9813d81ed6e"
    },
    {
      "id": "564e4d36-9764-4325-8f40-0a51d2a34010",
      "name": "Commercial Data Analysis",
      "categoryId": "4935a6fe-6ca3-4fe0-9dbe-b9813d81ed6e"
    },
    {
      "id": "a8110664-a1b6-43ee-abcd-27ab8c82b2ce",
      "name": "Market Basket Analysis",
      "categoryId": "4935a6fe-6ca3-4fe0-9dbe-b9813d81ed6e"
    },
    {
      "id": "47e236c9-4947-4621-aa95-466184e1386c",
      "name": "Sequential Pattern Mining",
      "categoryId": "4935a6fe-6ca3-4fe0-9dbe-b9813d81ed6e"
    },
    {
      "id": "bdc8be07-28f5-4d97-b2a2-279626c5d5a3",
      "name": "quantization",
      "categoryId": "0f76ba94-08bc-41eb-b63a-5705db90e221"
    },
    {
      "id": "db568aa5-e990-4bbc-b982-51984dce4068",
      "name": "low-precision computation",
      "categoryId": "0f76ba94-08bc-41eb-b63a-5705db90e221"
    },
    {
      "id": "407cc221-565b-479b-9df7-a099b78e044d",
      "name": "model compression",
      "categoryId": "0f76ba94-08bc-41eb-b63a-5705db90e221"
    },
    {
      "id": "1490d191-3ef4-4690-93b7-ac9495dc2a2f",
      "name": "fp16",
      "categoryId": "0f76ba94-08bc-41eb-b63a-5705db90e221"
    },
    {
      "id": "373cb468-533f-4441-af41-cead74d6f451",
      "name": "half-precision floating point",
      "categoryId": "0f76ba94-08bc-41eb-b63a-5705db90e221"
    },
    {
      "id": "46cde395-2bc9-4ff1-b724-df83f5850302",
      "name": "neural network optimization",
      "categoryId": "0f76ba94-08bc-41eb-b63a-5705db90e221"
    },
    {
      "id": "e0862afe-73ed-4637-8395-c0595dfe0024",
      "name": "model deployment",
      "categoryId": "0f76ba94-08bc-41eb-b63a-5705db90e221"
    },
    {
      "id": "44a33139-e677-4a9d-8f61-49d268d6c1cc",
      "name": "inference speed",
      "categoryId": "0f76ba94-08bc-41eb-b63a-5705db90e221"
    },
    {
      "id": "f124f75f-d720-4ae4-a293-1c30dd411faa",
      "name": "memory efficiency",
      "categoryId": "0f76ba94-08bc-41eb-b63a-5705db90e221"
    },
    {
      "id": "22f13abb-ef18-4c60-87b8-0131e4c8b177",
      "name": "FPGA",
      "categoryId": "51215db2-fd1d-40fe-b551-e2e05fa03457"
    },
    {
      "id": "b6b260e0-7538-4952-8f00-1a14aad7a969",
      "name": "Field Programmable Gate Arrays",
      "categoryId": "51215db2-fd1d-40fe-b551-e2e05fa03457"
    },
    {
      "id": "813f7299-cffe-47a1-a347-e0bfb106e104",
      "name": "Hardware Acceleration",
      "categoryId": "51215db2-fd1d-40fe-b551-e2e05fa03457"
    },
    {
      "id": "28143cfe-ffac-4354-8e39-92e7356a3bd8",
      "name": "Reconfigurable Computing",
      "categoryId": "51215db2-fd1d-40fe-b551-e2e05fa03457"
    },
    {
      "id": "d3cefc96-7631-4817-b161-d5f87dd6b13a",
      "name": "Custom Hardware for AI",
      "categoryId": "51215db2-fd1d-40fe-b551-e2e05fa03457"
    },
    {
      "id": "081c2234-02e5-41c9-94da-ad7f1ee81768",
      "name": "Edge Computing Devices",
      "categoryId": "51215db2-fd1d-40fe-b551-e2e05fa03457"
    },
    {
      "id": "ac3182e9-0088-4db4-8644-cb2f5a5d9e89",
      "name": "Low-Latency Computation",
      "categoryId": "51215db2-fd1d-40fe-b551-e2e05fa03457"
    },
    {
      "id": "cbbfa679-0c75-4837-9a52-710ccaaadbf9",
      "name": "Embedded AI Systems",
      "categoryId": "51215db2-fd1d-40fe-b551-e2e05fa03457"
    },
    {
      "id": "7ca16575-5f61-4d97-985e-d82ababe42d6",
      "name": "Accelerator Architectures",
      "categoryId": "51215db2-fd1d-40fe-b551-e2e05fa03457"
    },
    {
      "id": "2a2dea26-a5b8-4882-a63c-b018a3d70869",
      "name": "Hardware Description Languages (HDL)",
      "categoryId": "51215db2-fd1d-40fe-b551-e2e05fa03457"
    },
    {
      "id": "18a8e2e3-9203-410c-b7f8-b3d3abce6225",
      "name": "Fractal Network Models",
      "categoryId": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7"
    },
    {
      "id": "ab4bf596-b672-4ee9-a32b-bc430457c82e",
      "name": "Hierarchical Networks",
      "categoryId": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7"
    },
    {
      "id": "98aa0882-4f64-412a-adb6-1cb90c53785c",
      "name": "Complex Systems",
      "categoryId": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7"
    },
    {
      "id": "b74131c3-d351-447e-8312-e783559dbeb6",
      "name": "Self-similarity",
      "categoryId": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7"
    },
    {
      "id": "bea2db31-29eb-40e3-a4d1-2365f911ee25",
      "name": "Multiscale Modeling",
      "categoryId": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7"
    },
    {
      "id": "f7b38d6a-5e32-44d7-bc0e-e3c0943f1ee6",
      "name": "Nonlinear Dynamics",
      "categoryId": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7"
    },
    {
      "id": "c150cd50-5ea8-4e5a-91f5-bde594dc3409",
      "name": "Network Topology",
      "categoryId": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7"
    },
    {
      "id": "75985cef-b1fa-4615-bf71-213e651f8bd6",
      "name": "Self-organizing Systems",
      "categoryId": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7"
    },
    {
      "id": "e6d685c6-edd4-4ac1-aea3-aa1d87afd914",
      "name": "Scale-invariance",
      "categoryId": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7"
    },
    {
      "id": "6aa6e1eb-8bd9-4553-b23a-48ca039793fe",
      "name": "Fractal Networks",
      "categoryId": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7"
    },
    {
      "id": "fbe332ce-4916-49db-aada-ba8bc450644a",
      "name": "Hierarchical Neural Networks",
      "categoryId": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7"
    },
    {
      "id": "b32cb1ba-1edf-4d59-aaa2-5a4dc669c819",
      "name": "Self-similar Structures",
      "categoryId": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7"
    },
    {
      "id": "cc6a158e-550b-40c2-9603-c740b0a6035f",
      "name": "Recursive Architectures",
      "categoryId": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7"
    },
    {
      "id": "3f351a61-416b-4d03-8b87-d5d044a81719",
      "name": "Multi-scale Processing",
      "categoryId": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7"
    },
    {
      "id": "485bdb94-d384-45a0-9fa0-0663469db644",
      "name": "Deep Neural Networks",
      "categoryId": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7"
    },
    {
      "id": "ff66d00c-ff08-48cb-a053-01edbb5b56ab",
      "name": "Hierarchical Learning",
      "categoryId": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7"
    },
    {
      "id": "8396e0f8-91cd-4346-97a8-25e84f84f2db",
      "name": "Self-organizing Networks",
      "categoryId": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7"
    },
    {
      "id": "370a83cb-d0ad-424a-8b85-5eee1a647925",
      "name": "Multilevel Methodologies",
      "categoryId": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7"
    },
    {
      "id": "64beabe5-03fb-4b2e-bec2-c2385ffeb67e",
      "name": "Fractional Calculus",
      "categoryId": "5445f1f8-954a-48c1-b83f-5ab771ffdefa"
    },
    {
      "id": "041a6eb0-21af-49c0-9cde-31a9ae4a6a7d",
      "name": "Non-integer Order Derivatives",
      "categoryId": "5445f1f8-954a-48c1-b83f-5ab771ffdefa"
    },
    {
      "id": "5edd84fd-a4dd-49dc-802e-42b73a958d13",
      "name": "Generalized Differentiation",
      "categoryId": "5445f1f8-954a-48c1-b83f-5ab771ffdefa"
    },
    {
      "id": "13e1fdb6-eaf6-49a1-af47-27db16c0b8c8",
      "name": "Nonlocal Operators",
      "categoryId": "5445f1f8-954a-48c1-b83f-5ab771ffdefa"
    },
    {
      "id": "1e40a541-6dcf-4835-84d2-572940326e3a",
      "name": "Fractional Integrals",
      "categoryId": "5445f1f8-954a-48c1-b83f-5ab771ffdefa"
    },
    {
      "id": "3ca5d322-cd95-45df-aa0a-b009b1fa228a",
      "name": "Advanced Calculus",
      "categoryId": "5445f1f8-954a-48c1-b83f-5ab771ffdefa"
    },
    {
      "id": "ea9550f3-a8be-4f0d-a836-a41b6189f96f",
      "name": "Mathematical Analysis",
      "categoryId": "5445f1f8-954a-48c1-b83f-5ab771ffdefa"
    },
    {
      "id": "a900abfc-5d97-46c3-8a61-ad7ce22989f4",
      "name": "Diffusion Processes",
      "categoryId": "5445f1f8-954a-48c1-b83f-5ab771ffdefa"
    },
    {
      "id": "6e20959c-6e57-41f1-8c25-666a57eccb94",
      "name": "Memory Effects",
      "categoryId": "5445f1f8-954a-48c1-b83f-5ab771ffdefa"
    },
    {
      "id": "5a5340aa-cfeb-4d76-9a9b-4457ff474ca5",
      "name": "Audio Preprocessing",
      "categoryId": "c772f870-7b52-4777-b60a-c3dc0d394d53"
    },
    {
      "id": "ee9f1a36-f247-4ad7-9c53-68723f4e933b",
      "name": "Spectrogram Analysis",
      "categoryId": "c772f870-7b52-4777-b60a-c3dc0d394d53"
    },
    {
      "id": "d76fe95a-c437-4d6d-a4e8-a0dc02d77684",
      "name": "Signal Processing",
      "categoryId": "c772f870-7b52-4777-b60a-c3dc0d394d53"
    },
    {
      "id": "1a34c41a-99cd-43de-bb23-0cdc983e78da",
      "name": "Time-Series Data",
      "categoryId": "c772f870-7b52-4777-b60a-c3dc0d394d53"
    },
    {
      "id": "67a6f150-c44b-4b31-bccd-3b53506cffc2",
      "name": "Feature Extraction",
      "categoryId": "c772f870-7b52-4777-b60a-c3dc0d394d53"
    },
    {
      "id": "2d4a1aeb-1b23-4877-8bbb-cb3675707799",
      "name": "Data Augmentation",
      "categoryId": "c772f870-7b52-4777-b60a-c3dc0d394d53"
    },
    {
      "id": "226b9190-a94f-4784-a1b3-8a37fae9eebd",
      "name": "Knowledge Representation",
      "categoryId": "ee2f3a89-50db-4d87-a0ce-6745e7f25d99"
    },
    {
      "id": "6e7011e3-26b1-42fd-ab26-6602ee89e1bf",
      "name": "Evaluation Metrics",
      "categoryId": "a2f160cb-c882-4fc0-8e76-7a20a28f347c"
    },
    {
      "id": "ec7b0855-c2f7-4933-ab4d-6bcae9cebace",
      "name": "Image Quality Assessment",
      "categoryId": "a2f160cb-c882-4fc0-8e76-7a20a28f347c"
    },
    {
      "id": "85b7442a-98e0-444e-a9d4-480cc7fe9aac",
      "name": "GANs",
      "categoryId": "a2f160cb-c882-4fc0-8e76-7a20a28f347c"
    },
    {
      "id": "25b19541-915f-4b78-b384-663941a50de4",
      "name": "Statistical Distances",
      "categoryId": "a2f160cb-c882-4fc0-8e76-7a20a28f347c"
    },
    {
      "id": "febca8e4-e0e5-422e-a4ad-0aaf79b288e4",
      "name": "Model Evaluation",
      "categoryId": "a2f160cb-c882-4fc0-8e76-7a20a28f347c"
    },
    {
      "id": "abe8f879-91ad-4677-b6db-9a7dad85c00b",
      "name": "Machine Learning",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "167a31e8-7370-4fd5-9eb5-0454d5f66d98",
      "name": "Data Analysis",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "04c7b842-59c0-4a0f-87a1-3d502dd5bb5d",
      "name": "Pattern Recognition",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "0fd40162-f566-43e7-bd99-9f71772a864a",
      "name": "Algorithmic Techniques",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "69dc0e7e-560c-4419-bd49-2669f4351534",
      "name": "Data Mining",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "f308d66f-0f63-423d-b9e7-a04f51d43c05",
      "name": "Supervised Learning",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "6ace9e41-867f-4bf0-8913-291ff79e4751",
      "name": "Unsupervised Learning",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "1587bc94-7401-41d4-8538-c50f950cbd30",
      "name": "Data-driven Models",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "bab5dec4-8e9e-4590-9cde-fb72736b3e8a",
      "name": "Statistical Methods",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "0625ea87-701b-47a6-a839-7164e95c19fe",
      "name": "Clustering Algorithms",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "13e62cee-361b-4d45-8ce2-d40e3a13601f",
      "name": "Classification Techniques",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "1a008793-4731-4084-9348-32e63d686fd9",
      "name": "Numerical Encoding",
      "categoryId": "3fe5ddd5-daa7-493d-9ff3-95fbe4bfe43b"
    },
    {
      "id": "d8df8aed-1d00-40d9-bdd3-5709d986acef",
      "name": "Categorical Data",
      "categoryId": "3fe5ddd5-daa7-493d-9ff3-95fbe4bfe43b"
    },
    {
      "id": "7f4874d8-05c6-4812-a035-47761728e9f6",
      "name": "Feature Engineering",
      "categoryId": "3fe5ddd5-daa7-493d-9ff3-95fbe4bfe43b"
    },
    {
      "id": "e4695129-6574-4265-82fe-af3209ee8f2d",
      "name": "Data Preprocessing",
      "categoryId": "3fe5ddd5-daa7-493d-9ff3-95fbe4bfe43b"
    },
    {
      "id": "5b42ba77-3413-4438-8994-c6531c8670ae",
      "name": "Data Transformation",
      "categoryId": "3fe5ddd5-daa7-493d-9ff3-95fbe4bfe43b"
    },
    {
      "id": "c93d8d84-9014-44e8-aa17-fdeff745a0a5",
      "name": "Encoding Techniques",
      "categoryId": "3fe5ddd5-daa7-493d-9ff3-95fbe4bfe43b"
    },
    {
      "id": "a46251c2-cc81-4d72-814a-71d603c3d010",
      "name": "NLP",
      "categoryId": "04371312-beca-4cb2-8360-ec20748cdaae"
    },
    {
      "id": "4e7cbfd2-2b5f-42a0-880d-646bdc17ecd3",
      "name": "Text Generation",
      "categoryId": "04371312-beca-4cb2-8360-ec20748cdaae"
    },
    {
      "id": "51fff397-b821-4ed0-b629-7668824d3369",
      "name": "Language Modeling",
      "categoryId": "04371312-beca-4cb2-8360-ec20748cdaae"
    },
    {
      "id": "23a55128-9bbc-4f0f-91b8-c3f2324f3b7a",
      "name": "Prompt Engineering",
      "categoryId": "04371312-beca-4cb2-8360-ec20748cdaae"
    },
    {
      "id": "fc43f6b0-7583-4ea7-84e3-ed18e0ec7820",
      "name": "AI Text Tools",
      "categoryId": "04371312-beca-4cb2-8360-ec20748cdaae"
    },
    {
      "id": "b03acda3-9fbb-4872-96da-255e6f93b1a0",
      "name": "Language Penalties",
      "categoryId": "04371312-beca-4cb2-8360-ec20748cdaae"
    },
    {
      "id": "3a6f3425-a127-454e-9e73-6eb08b775df9",
      "name": "Natural Language Processing",
      "categoryId": "dc763446-344a-45ed-8361-8982b166ce2a"
    },
    {
      "id": "38d5065b-6022-4435-bce4-80b7c70346bb",
      "name": "Text Mining",
      "categoryId": "dc763446-344a-45ed-8361-8982b166ce2a"
    },
    {
      "id": "cbf5da38-f5c8-4ac3-b98a-c1a67094bba7",
      "name": "Feature Selection",
      "categoryId": "dc763446-344a-45ed-8361-8982b166ce2a"
    },
    {
      "id": "c65bbf65-e7d4-4ea9-b908-c02e8401faa0",
      "name": "Data Preprocessing",
      "categoryId": "dc763446-344a-45ed-8361-8982b166ce2a"
    },
    {
      "id": "fc558910-c3bd-4f43-8326-3106e4acc636",
      "name": "Dimensionality Reduction",
      "categoryId": "dc763446-344a-45ed-8361-8982b166ce2a"
    },
    {
      "id": "81b9f178-c11a-4ffa-9a26-3a58d4bd12f8",
      "name": "Signal Processing",
      "categoryId": "dc763446-344a-45ed-8361-8982b166ce2a"
    },
    {
      "id": "3de5616a-3f11-4dd4-871c-6b0cfb866cb0",
      "name": "Frequency-based algorithms fall under the sub-category of statistical and pattern recognition methods within machine learning. They are closely related to signal processing",
      "categoryId": "15163f57-df7e-45f9-b10f-4306045ff1c9"
    },
    {
      "id": "6ab27f8d-affe-452e-bb38-60720b036731",
      "name": "time-series analysis",
      "categoryId": "15163f57-df7e-45f9-b10f-4306045ff1c9"
    },
    {
      "id": "4b896611-bf6d-4abb-aa10-dc283595681a",
      "name": "and probabilistic modeling. These algorithms leverage frequency components or distributions to identify patterns",
      "categoryId": "15163f57-df7e-45f9-b10f-4306045ff1c9"
    },
    {
      "id": "88e6218f-9b0b-41e8-a5db-887cd0d02fb4",
      "name": "anomalies",
      "categoryId": "15163f57-df7e-45f9-b10f-4306045ff1c9"
    },
    {
      "id": "5d064681-7ebc-4d74-a50a-5f477090244c",
      "name": "or features in data sets",
      "categoryId": "15163f57-df7e-45f9-b10f-4306045ff1c9"
    },
    {
      "id": "8bad2a9b-2f09-40fb-b0cf-24feb5fe0934",
      "name": "often utilizing techniques such as Fourier transforms",
      "categoryId": "15163f57-df7e-45f9-b10f-4306045ff1c9"
    },
    {
      "id": "7893e239-6271-4437-a190-7b2230ad0ddc",
      "name": "spectral analysis",
      "categoryId": "15163f57-df7e-45f9-b10f-4306045ff1c9"
    },
    {
      "id": "032d2682-9c57-4b53-a462-0c8e2163e555",
      "name": "and spectral density estimation.",
      "categoryId": "15163f57-df7e-45f9-b10f-4306045ff1c9"
    },
    {
      "id": "73ae3aae-80c4-46fc-9086-879ea2547b53",
      "name": "Sampling Techniques",
      "categoryId": "a16f1228-794f-400e-b347-5b108094d53f"
    },
    {
      "id": "17e8d5b9-ae42-4779-940d-b9704ffcb053",
      "name": "Frequency-Based Sampling",
      "categoryId": "a16f1228-794f-400e-b347-5b108094d53f"
    },
    {
      "id": "89babcf7-de7d-4c7d-9783-a14625d6ac6b",
      "name": "Data Sampling Methods",
      "categoryId": "a16f1228-794f-400e-b347-5b108094d53f"
    },
    {
      "id": "5d053cb1-0742-42cf-8b97-eb6e6c9e349a",
      "name": "Data Subsetting",
      "categoryId": "a16f1228-794f-400e-b347-5b108094d53f"
    },
    {
      "id": "de981ef5-702b-4ee8-b7e0-d5d10329db6c",
      "name": "Data Frequency Analysis",
      "categoryId": "a16f1228-794f-400e-b347-5b108094d53f"
    },
    {
      "id": "565fb2a8-6836-4516-87df-2d77254ad0c5",
      "name": "Statistical Sampling Techniques",
      "categoryId": "a16f1228-794f-400e-b347-5b108094d53f"
    },
    {
      "id": "50581abd-371c-49c2-a0ff-ecc466e7bb8b",
      "name": "Data Quality",
      "categoryId": "a16f1228-794f-400e-b347-5b108094d53f"
    },
    {
      "id": "bdfab8ce-c3e2-4f47-bbbc-324407429152",
      "name": "Sampling Strategies",
      "categoryId": "a16f1228-794f-400e-b347-5b108094d53f"
    },
    {
      "id": "4f865ce1-94ba-481f-a230-82824f7f6cf9",
      "name": "Semi-supervised Learning",
      "categoryId": "618807d6-9f71-412e-a016-f6f4377fcc34"
    },
    {
      "id": "30e74c29-92ee-4908-b7d3-2b34b6ba7e34",
      "name": "Self-training",
      "categoryId": "618807d6-9f71-412e-a016-f6f4377fcc34"
    },
    {
      "id": "5d332b3c-a432-4846-8fd3-037897a07a4b",
      "name": "Confidence Calibration",
      "categoryId": "618807d6-9f71-412e-a016-f6f4377fcc34"
    },
    {
      "id": "6bd917bd-2e0c-4c37-a591-d38fb2303309",
      "name": "Pseudo-labeling",
      "categoryId": "618807d6-9f71-412e-a016-f6f4377fcc34"
    },
    {
      "id": "a7ff5a32-0892-4147-b25e-b74e3ac08bcd",
      "name": "Weak Labels",
      "categoryId": "618807d6-9f71-412e-a016-f6f4377fcc34"
    },
    {
      "id": "f11093b5-fe24-4ff6-864e-9b60da7044e9",
      "name": "Supervised Learning",
      "categoryId": "b4ffc370-1d98-4c88-a8a7-f8ab7121501c"
    },
    {
      "id": "df6b7c8e-e5a4-4523-a5b3-f0305508b21d",
      "name": "Data Quality",
      "categoryId": "b4ffc370-1d98-4c88-a8a7-f8ab7121501c"
    },
    {
      "id": "2d7713fd-a2f5-427a-8e89-b394f74f8333",
      "name": "Data Preprocessing",
      "categoryId": "b4ffc370-1d98-4c88-a8a7-f8ab7121501c"
    },
    {
      "id": "62aa6a6c-5957-4013-bdfd-5757da990c41",
      "name": "Noise Robustness",
      "categoryId": "b4ffc370-1d98-4c88-a8a7-f8ab7121501c"
    },
    {
      "id": "02102568-f76f-4dd1-a826-511c25f6968f",
      "name": "Noise Handling",
      "categoryId": "b4ffc370-1d98-4c88-a8a7-f8ab7121501c"
    },
    {
      "id": "e5d05512-c226-4b5e-8724-69a39b8f9da0",
      "name": "Data Cleansing",
      "categoryId": "b4ffc370-1d98-4c88-a8a7-f8ab7121501c"
    },
    {
      "id": "9632be2a-0517-4196-9d4a-15d2c19e517e",
      "name": "Machine Learning Challenges",
      "categoryId": "b4ffc370-1d98-4c88-a8a7-f8ab7121501c"
    },
    {
      "id": "ebebd18e-fbdd-4885-92ce-50c9b70aac58",
      "name": "Classification",
      "categoryId": "b4ffc370-1d98-4c88-a8a7-f8ab7121501c"
    },
    {
      "id": "432dab8f-f3bc-44c7-8939-4cf047905d7d",
      "name": "Regression",
      "categoryId": "b4ffc370-1d98-4c88-a8a7-f8ab7121501c"
    },
    {
      "id": "de17c685-ed9c-4d61-9f1b-5dbe32a55085",
      "name": "Data Labeling",
      "categoryId": "b4ffc370-1d98-4c88-a8a7-f8ab7121501c"
    },
    {
      "id": "56a024f0-aad2-4d2d-b2bd-437033676813",
      "name": "Semi-supervised Learning",
      "categoryId": "05a932c8-c094-4cc4-a95e-c454d56ad8ca"
    },
    {
      "id": "d0bf6f4d-bf15-4176-be21-ff4f3c5d629f",
      "name": "Graph-based Algorithms",
      "categoryId": "05a932c8-c094-4cc4-a95e-c454d56ad8ca"
    },
    {
      "id": "c4ffb0d8-7c0b-4c24-b757-64a70354adb3",
      "name": "Machine Learning",
      "categoryId": "05a932c8-c094-4cc4-a95e-c454d56ad8ca"
    },
    {
      "id": "d26ca7b6-fe4a-40be-8e47-6133bf46d441",
      "name": "Data Labeling",
      "categoryId": "05a932c8-c094-4cc4-a95e-c454d56ad8ca"
    },
    {
      "id": "dbf6c281-4473-4fb9-9908-3c238faf4158",
      "name": "Unsupervised Learning",
      "categoryId": "05a932c8-c094-4cc4-a95e-c454d56ad8ca"
    },
    {
      "id": "dcee856f-cfb9-4419-8178-7bcd73c5c251",
      "name": "Graph Theory",
      "categoryId": "05a932c8-c094-4cc4-a95e-c454d56ad8ca"
    },
    {
      "id": "d0f69dce-f13f-4cb4-afc2-6ece093508e3",
      "name": "Propagation Algorithms",
      "categoryId": "05a932c8-c094-4cc4-a95e-c454d56ad8ca"
    },
    {
      "id": "2c42180f-425a-424d-9959-fce8b1877455",
      "name": "Semi-supervised learning",
      "categoryId": "3474fe82-93a5-4ccd-96a8-7cf1326920f7"
    },
    {
      "id": "a5cedb9d-efc4-4783-aeaf-2b035094d7ef",
      "name": "graph-based algorithms",
      "categoryId": "3474fe82-93a5-4ccd-96a8-7cf1326920f7"
    },
    {
      "id": "3469c37d-2ee0-405a-818c-63bc4c22b087",
      "name": "propagation methods",
      "categoryId": "3474fe82-93a5-4ccd-96a8-7cf1326920f7"
    },
    {
      "id": "bb28ba08-a605-4cd1-bedf-df54a6f9c896",
      "name": "machine learning",
      "categoryId": "3474fe82-93a5-4ccd-96a8-7cf1326920f7"
    },
    {
      "id": "5745536a-6ef1-4d53-81a7-5f1c2926914e",
      "name": "data labeling",
      "categoryId": "3474fe82-93a5-4ccd-96a8-7cf1326920f7"
    },
    {
      "id": "13b0a9a2-98c1-4514-8e8e-8b1fcb971679",
      "name": "semi-supervised classifiers",
      "categoryId": "3474fe82-93a5-4ccd-96a8-7cf1326920f7"
    },
    {
      "id": "40e2f914-6980-4a0b-bdb7-57e76d72e792",
      "name": "label diffusion",
      "categoryId": "3474fe82-93a5-4ccd-96a8-7cf1326920f7"
    },
    {
      "id": "16a97fc0-da88-4082-a6e9-a82088b7b426",
      "name": "similarity graphs",
      "categoryId": "3474fe82-93a5-4ccd-96a8-7cf1326920f7"
    },
    {
      "id": "c197736d-ccc3-4697-9fda-58cf6fc024e9",
      "name": "clustering",
      "categoryId": "3474fe82-93a5-4ccd-96a8-7cf1326920f7"
    },
    {
      "id": "f3bf9a46-ddcf-49ef-a7b6-81e277d66658",
      "name": "community detection",
      "categoryId": "3474fe82-93a5-4ccd-96a8-7cf1326920f7"
    },
    {
      "id": "80463c9a-19f1-4769-a383-064780be7c52",
      "name": "Supervised Learning",
      "categoryId": "369340b8-283b-4b8a-8ad5-723e48cf9fa1"
    },
    {
      "id": "28b88087-a55a-407a-84e9-8aa05bdd1621",
      "name": "Neural Networks",
      "categoryId": "369340b8-283b-4b8a-8ad5-723e48cf9fa1"
    },
    {
      "id": "dcc951e0-9fb6-4d29-9340-de677b996e28",
      "name": "Classification",
      "categoryId": "369340b8-283b-4b8a-8ad5-723e48cf9fa1"
    },
    {
      "id": "a5e8b6d2-b3c7-4ea1-b2f9-37562aa60413",
      "name": "Loss Functions",
      "categoryId": "369340b8-283b-4b8a-8ad5-723e48cf9fa1"
    },
    {
      "id": "b3559292-a277-482d-bff3-40089421cd76",
      "name": "Model Regularization",
      "categoryId": "369340b8-283b-4b8a-8ad5-723e48cf9fa1"
    },
    {
      "id": "cb334064-b53b-45f2-b498-b16a842fe53b",
      "name": "Machine Learning",
      "categoryId": "d87737eb-4f8f-4978-a432-d782df021d96"
    },
    {
      "id": "2608333a-6325-490c-9d8b-cf1cb97bc78d",
      "name": "Neural Networks",
      "categoryId": "d87737eb-4f8f-4978-a432-d782df021d96"
    },
    {
      "id": "be80a38f-aa8c-4cc2-8975-d14f78c2a286",
      "name": "Deep Learning",
      "categoryId": "d87737eb-4f8f-4978-a432-d782df021d96"
    },
    {
      "id": "6f19e371-2d8c-4130-b53f-6dfc4f087046",
      "name": "Supervised Learning",
      "categoryId": "d87737eb-4f8f-4978-a432-d782df021d96"
    },
    {
      "id": "a89e8372-9165-46b7-bff2-7919b95f29f6",
      "name": "Loss Functions",
      "categoryId": "d87737eb-4f8f-4978-a432-d782df021d96"
    },
    {
      "id": "84c25096-308a-4a55-b581-fe01199dc285",
      "name": "Regularization Techniques",
      "categoryId": "d87737eb-4f8f-4978-a432-d782df021d96"
    },
    {
      "id": "504638c9-89f6-4805-b750-8b7704e43caa",
      "name": "Model Calibration",
      "categoryId": "d87737eb-4f8f-4978-a432-d782df021d96"
    },
    {
      "id": "d16a4a1a-c673-412e-a92c-86599e1f0f45",
      "name": "Probabilistic Models",
      "categoryId": "d87737eb-4f8f-4978-a432-d782df021d96"
    },
    {
      "id": "e2d8a1b0-95db-4ac1-a59f-ddbd491cf1fa",
      "name": "Ladder Nets fall under the sub-category of neural network architectures",
      "categoryId": "5333e89e-2492-4d6f-b6b1-e72dc32f5208"
    },
    {
      "id": "3fdfdc89-8d76-4fd7-8b50-c9367c0be246",
      "name": "specifically within deep learning models designed for image segmentation and hierarchical feature extraction. Relevant sub-category tags include 'neural networks'",
      "categoryId": "5333e89e-2492-4d6f-b6b1-e72dc32f5208"
    },
    {
      "id": "74269981-714b-4a07-babd-600df5fa1b0e",
      "name": "'deep learning'",
      "categoryId": "5333e89e-2492-4d6f-b6b1-e72dc32f5208"
    },
    {
      "id": "36c24874-154d-48a5-acc5-4e9cd5d8a45a",
      "name": "'hierarchical networks'",
      "categoryId": "5333e89e-2492-4d6f-b6b1-e72dc32f5208"
    },
    {
      "id": "0008b7bc-c3ed-4d59-bd5b-c4be1df8a6aa",
      "name": "and 'multi-scale processing'.",
      "categoryId": "5333e89e-2492-4d6f-b6b1-e72dc32f5208"
    },
    {
      "id": "79f8e5e3-a18a-4447-b1be-dd202ebab1a1",
      "name": "Ladder Nets Enhancements",
      "categoryId": "3cf62c13-b26d-412c-9323-d849e20110c1"
    },
    {
      "id": "22fdb3c0-0249-4474-aaec-46bce60c7396",
      "name": "Deep Learning",
      "categoryId": "3cf62c13-b26d-412c-9323-d849e20110c1"
    },
    {
      "id": "9aa0a9d3-26e5-4dcf-be3e-a0d163c91951",
      "name": "Neural Network Architectures",
      "categoryId": "3cf62c13-b26d-412c-9323-d849e20110c1"
    },
    {
      "id": "03e5590e-10fc-4cce-8619-47a4d29cd2cd",
      "name": "Skip Connections",
      "categoryId": "3cf62c13-b26d-412c-9323-d849e20110c1"
    },
    {
      "id": "3bea07f7-bf0f-483f-b373-6b24006c8356",
      "name": "Network Regularization",
      "categoryId": "3cf62c13-b26d-412c-9323-d849e20110c1"
    },
    {
      "id": "15c03a73-cc50-42bd-8ae0-ec03e7dfd7f9",
      "name": "Enhanced Feature Extraction",
      "categoryId": "3cf62c13-b26d-412c-9323-d849e20110c1"
    },
    {
      "id": "e8c34369-5fc6-40bf-91ce-c9f95df679fb",
      "name": "Multi-layer Learning",
      "categoryId": "3cf62c13-b26d-412c-9323-d849e20110c1"
    },
    {
      "id": "e0ef8f21-f430-4453-a8dc-074701b802ab",
      "name": "Neural Network Optimization",
      "categoryId": "3cf62c13-b26d-412c-9323-d849e20110c1"
    },
    {
      "id": "1665e4bc-20c0-4a33-a148-fa6810769a32",
      "name": "Hierarchical Learning Methods",
      "categoryId": "3cf62c13-b26d-412c-9323-d849e20110c1"
    },
    {
      "id": "7fbbe364-9a9d-4552-8589-c9e056cf1276",
      "name": "Ladder Nets Enhancements Techniques",
      "categoryId": "8036fb15-70a5-4cbd-b917-a0846835fd10"
    },
    {
      "id": "3779e4af-5501-47f0-baca-056337b140c8",
      "name": "Deep Learning",
      "categoryId": "8036fb15-70a5-4cbd-b917-a0846835fd10"
    },
    {
      "id": "72a3cd34-2347-4ff9-a8f5-dc947ef2d06a",
      "name": "Neural Network Optimization",
      "categoryId": "8036fb15-70a5-4cbd-b917-a0846835fd10"
    },
    {
      "id": "42e44246-e32f-4921-a81b-0a64e437c199",
      "name": "Convolutional Networks",
      "categoryId": "8036fb15-70a5-4cbd-b917-a0846835fd10"
    },
    {
      "id": "0757959c-31fe-445f-8d9a-918ff8737781",
      "name": "Feature Extraction",
      "categoryId": "8036fb15-70a5-4cbd-b917-a0846835fd10"
    },
    {
      "id": "7c467c66-88f2-4b19-aa7b-3e8ce66ecc23",
      "name": "Model Scaling",
      "categoryId": "8036fb15-70a5-4cbd-b917-a0846835fd10"
    },
    {
      "id": "4a7567d8-8a3f-4223-9da7-91700cdbeca5",
      "name": "Regularization Methods",
      "categoryId": "8036fb15-70a5-4cbd-b917-a0846835fd10"
    },
    {
      "id": "8b801bb4-bd0c-4886-af6e-ae4df734297d",
      "name": "Training Acceleration",
      "categoryId": "8036fb15-70a5-4cbd-b917-a0846835fd10"
    },
    {
      "id": "1bf2a138-5889-4d12-b72a-f879530c988a",
      "name": "Hyperparameter Tuning",
      "categoryId": "8036fb15-70a5-4cbd-b917-a0846835fd10"
    },
    {
      "id": "bfd92cde-4097-4ce2-b3ef-1e9e144196a2",
      "name": "Network Architecture Improvements",
      "categoryId": "8036fb15-70a5-4cbd-b917-a0846835fd10"
    },
    {
      "id": "5d02b05a-b7ba-452e-9689-00e570bc0237",
      "name": "Ladder Nets Extensions",
      "categoryId": "b5fd6ba2-5581-4576-b2d8-ca4382e4019b"
    },
    {
      "id": "5a3e141b-8073-45d5-9499-275d925edfe3",
      "name": "Neural Network Architectures",
      "categoryId": "b5fd6ba2-5581-4576-b2d8-ca4382e4019b"
    },
    {
      "id": "62f4ad81-d18e-4b42-aeb5-85030b093c11",
      "name": "Deep Learning Modules",
      "categoryId": "b5fd6ba2-5581-4576-b2d8-ca4382e4019b"
    },
    {
      "id": "d870c326-398f-4c10-8f38-04fbaa9a3b0f",
      "name": "Hierarchical Neural Networks",
      "categoryId": "b5fd6ba2-5581-4576-b2d8-ca4382e4019b"
    },
    {
      "id": "fb808508-1478-4f27-a8f5-db877e8adb8d",
      "name": "Multi-Layer Neural Networks",
      "categoryId": "b5fd6ba2-5581-4576-b2d8-ca4382e4019b"
    },
    {
      "id": "2edb8faa-7ea8-42e2-9433-4ba0e699c0b8",
      "name": "Incremental Learning in Neural Networks",
      "categoryId": "b5fd6ba2-5581-4576-b2d8-ca4382e4019b"
    },
    {
      "id": "e0a3206e-30d1-42d0-b4ac-7aeb1bd49181",
      "name": "Multi-Scale Neural Architectures",
      "categoryId": "b5fd6ba2-5581-4576-b2d8-ca4382e4019b"
    },
    {
      "id": "2b32cddb-0241-48c5-9c9b-ffd7d2186577",
      "name": "Network Expansion Techniques",
      "categoryId": "b5fd6ba2-5581-4576-b2d8-ca4382e4019b"
    },
    {
      "id": "178783ad-05a7-4689-8975-87e9d56d2ee6",
      "name": "Modular Neural Networks",
      "categoryId": "b5fd6ba2-5581-4576-b2d8-ca4382e4019b"
    },
    {
      "id": "0f6e8f43-7cec-4c96-89c6-eabccb83b674",
      "name": "Hierarchical Learning Systems",
      "categoryId": "b5fd6ba2-5581-4576-b2d8-ca4382e4019b"
    },
    {
      "id": "ad8bc4e4-e477-4ad6-973d-42104f0bf5d2",
      "name": "Ladder Nets Extensions Techniques",
      "categoryId": "b017525a-0826-4881-9223-ee79ca9969a1"
    },
    {
      "id": "181c70e1-b18e-4698-8ea7-15c40fbefbb6",
      "name": "Neural Network Architectures",
      "categoryId": "b017525a-0826-4881-9223-ee79ca9969a1"
    },
    {
      "id": "33f069bc-38cb-4db5-8f89-0c92a53ee9d4",
      "name": "Network Expansion Methods",
      "categoryId": "b017525a-0826-4881-9223-ee79ca9969a1"
    },
    {
      "id": "68a3517a-fcbe-44a5-9f8a-09b92ad6fa9d",
      "name": "Deep Learning Model Enhancements",
      "categoryId": "b017525a-0826-4881-9223-ee79ca9969a1"
    },
    {
      "id": "81185b0b-1132-4091-a77f-e509bc5d7aa1",
      "name": "Progressive Network Growth",
      "categoryId": "b017525a-0826-4881-9223-ee79ca9969a1"
    },
    {
      "id": "bbfb0afd-1f7c-44f2-ac94-96beff39dc2f",
      "name": "Hierarchical Network Design",
      "categoryId": "b017525a-0826-4881-9223-ee79ca9969a1"
    },
    {
      "id": "d8dac3d1-8f16-4781-add7-880367f815c5",
      "name": "Batch Processing",
      "categoryId": "1540d631-e09d-4ed0-bbc4-631a933f8ac4"
    },
    {
      "id": "24594b85-f927-4d02-b043-f5024eebd8c8",
      "name": "Real-time Streaming",
      "categoryId": "1540d631-e09d-4ed0-bbc4-631a933f8ac4"
    },
    {
      "id": "3798a8eb-4fcf-4411-ab9d-e1528912bf55",
      "name": "Data Pipeline",
      "categoryId": "1540d631-e09d-4ed0-bbc4-631a933f8ac4"
    },
    {
      "id": "7fad01b9-15da-4bc7-adbe-52ccefbe49dc",
      "name": "Data Storage",
      "categoryId": "1540d631-e09d-4ed0-bbc4-631a933f8ac4"
    },
    {
      "id": "a7360818-a468-417f-a86e-e02e7ab68d04",
      "name": "Fault Tolerance",
      "categoryId": "1540d631-e09d-4ed0-bbc4-631a933f8ac4"
    },
    {
      "id": "729d9578-0ddd-4c25-85c1-355e9810dabc",
      "name": "Data Scalability",
      "categoryId": "1540d631-e09d-4ed0-bbc4-631a933f8ac4"
    },
    {
      "id": "4d2c5193-23a8-4b7e-823b-3b9f7e7ba0bb",
      "name": "Language Generation Evaluation",
      "categoryId": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7"
    },
    {
      "id": "5c7c1cb2-5bf0-42b6-9e6c-c26905b38320",
      "name": "Natural Language Processing",
      "categoryId": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7"
    },
    {
      "id": "8ba014e0-d5b3-412a-adae-ae8050235e67",
      "name": "Text Generation Metrics",
      "categoryId": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7"
    },
    {
      "id": "84a40f1c-841b-45d2-84ad-1eafba837db2",
      "name": "Model Assessment",
      "categoryId": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7"
    },
    {
      "id": "f8b473cd-7718-4133-8cc3-106c6ca5f547",
      "name": "Language Model Evaluation",
      "categoryId": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7"
    },
    {
      "id": "87c97821-1783-44ef-aae6-81a3e08cb3a9",
      "name": "Coherence Measurement",
      "categoryId": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7"
    },
    {
      "id": "d986e5ee-b132-428a-bd08-f13b7ea70aa9",
      "name": "Fluency Testing",
      "categoryId": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7"
    },
    {
      "id": "a48976a3-6831-46de-a54a-cc1fa55f4c6a",
      "name": "Content Quality Analysis",
      "categoryId": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7"
    },
    {
      "id": "8314fc65-fcb0-42b4-8ef1-c8642ceb9fb6",
      "name": "Model Robustness",
      "categoryId": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7"
    },
    {
      "id": "ffede9e0-2f04-49c0-bdfc-6dcdf0cc7e2b",
      "name": "Human-AI Comparison",
      "categoryId": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7"
    },
    {
      "id": "3943c2f3-7222-4754-bbf6-c64ed8b6dbef",
      "name": "Natural Language Processing (NLP)",
      "categoryId": "dd7ed944-5362-4778-9b2c-00a657481e3f"
    },
    {
      "id": "e0e6df6c-f26d-431e-b8bc-8844ef24e1b8",
      "name": "Robotics",
      "categoryId": "dd7ed944-5362-4778-9b2c-00a657481e3f"
    },
    {
      "id": "3f29eff2-8294-4079-b1ea-6c902324af6b",
      "name": "Text Generation",
      "categoryId": "dd7ed944-5362-4778-9b2c-00a657481e3f"
    },
    {
      "id": "0de50da1-f11c-4cc8-817a-0fafc9b6033d",
      "name": "Human-Robot Interaction",
      "categoryId": "dd7ed944-5362-4778-9b2c-00a657481e3f"
    },
    {
      "id": "1b6681ff-28cc-45cb-98d3-3a8ab774aacd",
      "name": "Dialogue Systems",
      "categoryId": "dd7ed944-5362-4778-9b2c-00a657481e3f"
    },
    {
      "id": "befd0722-5119-4590-bc3e-0f8dd21b26c4",
      "name": "Autonomous Agents",
      "categoryId": "dd7ed944-5362-4778-9b2c-00a657481e3f"
    },
    {
      "id": "265a1629-4564-49b3-b11c-dc7fa7e66328",
      "name": "Semantic Understanding",
      "categoryId": "dd7ed944-5362-4778-9b2c-00a657481e3f"
    },
    {
      "id": "960fcbfe-ed0f-405f-85c6-97e2d3492791",
      "name": "Context-aware Language Models",
      "categoryId": "dd7ed944-5362-4778-9b2c-00a657481e3f"
    },
    {
      "id": "faf15def-22ed-4cf6-ba64-0b35c23561a9",
      "name": "Robot Communication",
      "categoryId": "dd7ed944-5362-4778-9b2c-00a657481e3f"
    },
    {
      "id": "95352cb8-b213-4d62-b0b6-78bbc13e0e52",
      "name": "Conversational AI",
      "categoryId": "dd7ed944-5362-4778-9b2c-00a657481e3f"
    },
    {
      "id": "d3aff5c2-023f-43d5-b502-675fc8b7ce08",
      "name": "Language Model Adaptation",
      "categoryId": "29861353-f354-406d-b64b-c1255eb0bc79"
    },
    {
      "id": "e1c09896-2001-4eca-9ec1-555b52b4a325",
      "name": "Model Fine-tuning",
      "categoryId": "29861353-f354-406d-b64b-c1255eb0bc79"
    },
    {
      "id": "740b9937-ad92-425d-9c8a-aa7cd2575b23",
      "name": "Transfer Learning",
      "categoryId": "29861353-f354-406d-b64b-c1255eb0bc79"
    },
    {
      "id": "5712787f-2694-4448-a85e-233ed1f0abc2",
      "name": "Domain Adaptation",
      "categoryId": "29861353-f354-406d-b64b-c1255eb0bc79"
    },
    {
      "id": "4ceb35be-d5f6-42de-b671-c41f2afc2724",
      "name": "Few-Shot Learning",
      "categoryId": "29861353-f354-406d-b64b-c1255eb0bc79"
    },
    {
      "id": "c04a9613-b4ca-42be-872e-09a32c31bd68",
      "name": "Zero-Shot Learning",
      "categoryId": "29861353-f354-406d-b64b-c1255eb0bc79"
    },
    {
      "id": "0835d104-3fca-4502-b7f1-21d63b5d77f7",
      "name": "Continual Learning",
      "categoryId": "29861353-f354-406d-b64b-c1255eb0bc79"
    },
    {
      "id": "c2d2c529-bd79-408e-abf7-ee09c99b1402",
      "name": "Model Generalization",
      "categoryId": "29861353-f354-406d-b64b-c1255eb0bc79"
    },
    {
      "id": "70b5a382-9235-4a8d-ba9d-8115d1e314d9",
      "name": "NLP Model Tuning",
      "categoryId": "29861353-f354-406d-b64b-c1255eb0bc79"
    },
    {
      "id": "cd2b49dd-9983-48ec-8b1a-6aff362fb8c9",
      "name": "Pre-trained Language Models",
      "categoryId": "29861353-f354-406d-b64b-c1255eb0bc79"
    },
    {
      "id": "1b3be4f8-3a21-4049-88e8-cd50460b6b87",
      "name": "Language model evaluation involves sub-category tags such as perplexity",
      "categoryId": "c7c67f26-e995-4ed5-92a0-6ed12ae458bd"
    },
    {
      "id": "5d74e2cb-1122-4c76-b281-57c79689d730",
      "name": "BLEU score",
      "categoryId": "c7c67f26-e995-4ed5-92a0-6ed12ae458bd"
    },
    {
      "id": "160595f2-31c3-4dd8-bbcf-5f07a23d3c70",
      "name": "ROUGE",
      "categoryId": "c7c67f26-e995-4ed5-92a0-6ed12ae458bd"
    },
    {
      "id": "d968b26a-132a-4966-937d-331ef39f87b8",
      "name": "accuracy",
      "categoryId": "c7c67f26-e995-4ed5-92a0-6ed12ae458bd"
    },
    {
      "id": "74dd99aa-a670-4f52-994f-e931ed1cfc1f",
      "name": "F1 score",
      "categoryId": "c7c67f26-e995-4ed5-92a0-6ed12ae458bd"
    },
    {
      "id": "32eecac1-6a9c-4856-b23e-2282d342bd69",
      "name": "validation loss",
      "categoryId": "c7c67f26-e995-4ed5-92a0-6ed12ae458bd"
    },
    {
      "id": "235de4fb-0d2a-4dab-adbd-97e5a63a84a4",
      "name": "and cross-entropy loss. These tags help categorize the specific metrics and criteria used to assess different aspects of language model performance",
      "categoryId": "c7c67f26-e995-4ed5-92a0-6ed12ae458bd"
    },
    {
      "id": "a5948fa0-86e1-4a6a-aadf-cd2d963491f1",
      "name": "including fluency",
      "categoryId": "c7c67f26-e995-4ed5-92a0-6ed12ae458bd"
    },
    {
      "id": "702fe3c7-b41d-44a7-b865-37ff1a81513d",
      "name": "coherence",
      "categoryId": "c7c67f26-e995-4ed5-92a0-6ed12ae458bd"
    },
    {
      "id": "bcd24414-956a-4015-8e1a-aefa1d64327c",
      "name": "relevance",
      "categoryId": "c7c67f26-e995-4ed5-92a0-6ed12ae458bd"
    },
    {
      "id": "8ddff22e-3513-48f8-bcad-187de0c09022",
      "name": "and correctness.",
      "categoryId": "c7c67f26-e995-4ed5-92a0-6ed12ae458bd"
    },
    {
      "id": "55b38c55-92e3-4f30-9aee-98068b5823d6",
      "name": "Natural Language Processing",
      "categoryId": "c25cc053-793f-446d-904f-fc6f51f14422"
    },
    {
      "id": "87717397-79e8-40aa-bc4f-e9f58cfc5d21",
      "name": "Machine Learning",
      "categoryId": "c25cc053-793f-446d-904f-fc6f51f14422"
    },
    {
      "id": "7ce0abc8-19a1-4ed3-8ad2-81d8df8d47e3",
      "name": "Deep Learning",
      "categoryId": "c25cc053-793f-446d-904f-fc6f51f14422"
    },
    {
      "id": "2744cbc4-4cba-487a-8f9a-376ed3da10b4",
      "name": "Model Adaptation",
      "categoryId": "c25cc053-793f-446d-904f-fc6f51f14422"
    },
    {
      "id": "4a13b670-1d49-44d3-90b6-5671c301cc6a",
      "name": "Transfer Learning",
      "categoryId": "c25cc053-793f-446d-904f-fc6f51f14422"
    },
    {
      "id": "b50a1596-7cc0-44fe-b885-d4d21c7993fd",
      "name": "Neural Networks",
      "categoryId": "c25cc053-793f-446d-904f-fc6f51f14422"
    },
    {
      "id": "f4fc5cb1-5b00-4bd0-878a-1354f9fced95",
      "name": "Conversational AI",
      "categoryId": "c25cc053-793f-446d-904f-fc6f51f14422"
    },
    {
      "id": "44788346-3c7d-4e03-8ed3-4c9a607e6f3d",
      "name": "Text Generation",
      "categoryId": "c25cc053-793f-446d-904f-fc6f51f14422"
    },
    {
      "id": "d1292fde-7373-490e-a95c-2773594a60d2",
      "name": "Contextual Embeddings",
      "categoryId": "c25cc053-793f-446d-904f-fc6f51f14422"
    },
    {
      "id": "38d3c48d-5ba3-4ce9-8065-63336444ea85",
      "name": "Natural Language Processing (NLP)",
      "categoryId": "83f17289-a385-485d-a871-d0b2aa12f325"
    },
    {
      "id": "aa5406f7-4617-4b05-8593-f7a4173067c6",
      "name": "Machine Learning",
      "categoryId": "83f17289-a385-485d-a871-d0b2aa12f325"
    },
    {
      "id": "9a273478-2f60-4fe8-87ec-9722b4174163",
      "name": "Deep Learning",
      "categoryId": "83f17289-a385-485d-a871-d0b2aa12f325"
    },
    {
      "id": "8e8ac3af-2740-438c-a06c-2fe94953a465",
      "name": "Transfer Learning",
      "categoryId": "83f17289-a385-485d-a871-d0b2aa12f325"
    },
    {
      "id": "451982ed-f707-4a2c-bc07-bfc4e59fc0b4",
      "name": "Fine-tuning",
      "categoryId": "83f17289-a385-485d-a871-d0b2aa12f325"
    },
    {
      "id": "fd4a717f-0d0c-465a-a3cb-79ec6e4661be",
      "name": "Unsupervised Learning",
      "categoryId": "83f17289-a385-485d-a871-d0b2aa12f325"
    },
    {
      "id": "d3625ae6-fbbd-492f-9237-2dd7feb6bd96",
      "name": "Semi-supervised Learning",
      "categoryId": "83f17289-a385-485d-a871-d0b2aa12f325"
    },
    {
      "id": "729f1863-a474-4567-b29b-64a8e98188d9",
      "name": "Transformer Architecture",
      "categoryId": "83f17289-a385-485d-a871-d0b2aa12f325"
    },
    {
      "id": "54e429d9-a0aa-4c9f-b496-4821ed9caa91",
      "name": "Self-attention Mechanism",
      "categoryId": "83f17289-a385-485d-a871-d0b2aa12f325"
    },
    {
      "id": "c7813086-f603-46c3-8a7c-456422925112",
      "name": "Large-scale Language Models",
      "categoryId": "83f17289-a385-485d-a871-d0b2aa12f325"
    },
    {
      "id": "284367fb-ee2a-4f44-9d76-314f9e370b86",
      "name": "Contextual Embeddings",
      "categoryId": "83f17289-a385-485d-a871-d0b2aa12f325"
    },
    {
      "id": "9269897c-80af-4b70-a0f4-b1a6d872cb8f",
      "name": "Language Modeling",
      "categoryId": "68a34110-1aef-4dee-a219-19cac6ec7ed0"
    },
    {
      "id": "29f2f6fa-d2ae-43b6-a362-0562f41ee368",
      "name": "Natural Language Processing (NLP)",
      "categoryId": "68a34110-1aef-4dee-a219-19cac6ec7ed0"
    },
    {
      "id": "54358df3-f222-4f3e-9a75-dba846914119",
      "name": "Text Generation",
      "categoryId": "68a34110-1aef-4dee-a219-19cac6ec7ed0"
    },
    {
      "id": "1e1c0a0b-32ff-42f1-8a40-5790eae7c6e0",
      "name": "Sequence Modeling",
      "categoryId": "68a34110-1aef-4dee-a219-19cac6ec7ed0"
    },
    {
      "id": "0e4cf086-293d-4bdc-963a-2333cfa23811",
      "name": "Probabilistic Models",
      "categoryId": "68a34110-1aef-4dee-a219-19cac6ec7ed0"
    },
    {
      "id": "6c5eacab-85bc-4f15-81e0-00ceba6e2156",
      "name": "Neural Language Models",
      "categoryId": "68a34110-1aef-4dee-a219-19cac6ec7ed0"
    },
    {
      "id": "ea24e375-c2b8-4c74-810a-014c7b807d2b",
      "name": "Recurrent Neural Networks (RNNs)",
      "categoryId": "68a34110-1aef-4dee-a219-19cac6ec7ed0"
    },
    {
      "id": "62dfaf8b-f1d6-4e1c-a9f7-487f9cc53474",
      "name": "Long Short-Term Memory (LSTM)",
      "categoryId": "68a34110-1aef-4dee-a219-19cac6ec7ed0"
    },
    {
      "id": "c83dd678-cbf8-4fd7-ac2f-c337c95f0c6d",
      "name": "Transformer Models",
      "categoryId": "68a34110-1aef-4dee-a219-19cac6ec7ed0"
    },
    {
      "id": "48fdb0b2-ce71-4c4c-a7a6-13623ecbaadf",
      "name": "Contextual Language Models",
      "categoryId": "68a34110-1aef-4dee-a219-19cac6ec7ed0"
    },
    {
      "id": "78fda110-d26b-4f95-9fe9-69af5e5ba240",
      "name": "Autoregressive Models",
      "categoryId": "68a34110-1aef-4dee-a219-19cac6ec7ed0"
    },
    {
      "id": "9817c6de-7c55-4178-8cba-1ff72fe5f8d4",
      "name": "Masked Language Models",
      "categoryId": "68a34110-1aef-4dee-a219-19cac6ec7ed0"
    },
    {
      "id": "ce4d42b1-22cb-425f-aee1-cf49f839929f",
      "name": "Language Models",
      "categoryId": "1b39fd05-f939-483a-97b7-76ac4fac7094"
    },
    {
      "id": "2b222c12-9bb7-4aee-8a0e-d9a94fe7ef67",
      "name": "NLP Models",
      "categoryId": "1b39fd05-f939-483a-97b7-76ac4fac7094"
    },
    {
      "id": "9cc5a5c6-535d-43dc-91d8-68b6de77e325",
      "name": "Probabilistic Language Models",
      "categoryId": "1b39fd05-f939-483a-97b7-76ac4fac7094"
    },
    {
      "id": "e65eb1a6-80bf-4042-9a56-dd76c80ea31d",
      "name": "Neural Language Models",
      "categoryId": "1b39fd05-f939-483a-97b7-76ac4fac7094"
    },
    {
      "id": "f6a1ca23-a974-4801-9442-67b956f13f62",
      "name": "Generative Models",
      "categoryId": "1b39fd05-f939-483a-97b7-76ac4fac7094"
    },
    {
      "id": "85373010-a744-4b2f-83a2-9b10a7257f47",
      "name": "Contextual Language Models",
      "categoryId": "1b39fd05-f939-483a-97b7-76ac4fac7094"
    },
    {
      "id": "64921dbf-55c3-4b54-9fd6-94dc3061747b",
      "name": "Transformer Models",
      "categoryId": "1b39fd05-f939-483a-97b7-76ac4fac7094"
    },
    {
      "id": "f696ba94-2463-4db1-b43a-2ac60844e907",
      "name": "Sequence Prediction",
      "categoryId": "1b39fd05-f939-483a-97b7-76ac4fac7094"
    },
    {
      "id": "624274a8-3316-446e-814a-b4dfdb83b926",
      "name": "Text Generation",
      "categoryId": "1b39fd05-f939-483a-97b7-76ac4fac7094"
    },
    {
      "id": "14295711-3367-4466-a27a-7c5e07e3f232",
      "name": "Machine Translation",
      "categoryId": "1b39fd05-f939-483a-97b7-76ac4fac7094"
    },
    {
      "id": "e8970752-77d2-4086-b835-f1541bf3a3cd",
      "name": "Speech Recognition",
      "categoryId": "1b39fd05-f939-483a-97b7-76ac4fac7094"
    },
    {
      "id": "72677967-aa1e-4177-a7c4-95f95913125b",
      "name": "Chatbots",
      "categoryId": "1b39fd05-f939-483a-97b7-76ac4fac7094"
    },
    {
      "id": "cd68ecaf-3351-4db4-9fc7-cc26d869967c",
      "name": "Voice Assistants",
      "categoryId": "1b39fd05-f939-483a-97b7-76ac4fac7094"
    },
    {
      "id": "0e60dd62-7aef-4ae5-8008-bf10bc215e2f",
      "name": "Deep Learning",
      "categoryId": "1b39fd05-f939-483a-97b7-76ac4fac7094"
    },
    {
      "id": "091f8001-d8a9-4048-a1ff-0f88cfd54b67",
      "name": "Natural Language Processing",
      "categoryId": "1b39fd05-f939-483a-97b7-76ac4fac7094"
    },
    {
      "id": "a1e2e98c-6f3f-421c-b271-63dd0524c1a1",
      "name": "Language Models",
      "categoryId": "7ce04689-9d02-4038-9353-68d11c54b9fd"
    },
    {
      "id": "7c8ea90d-47a6-4c81-8a03-d24cd54fc98e",
      "name": "Transformer Models",
      "categoryId": "7ce04689-9d02-4038-9353-68d11c54b9fd"
    },
    {
      "id": "99382cf2-d423-4567-84fe-2140376d0da6",
      "name": "NLP Models",
      "categoryId": "7ce04689-9d02-4038-9353-68d11c54b9fd"
    },
    {
      "id": "adb149f4-a664-48fb-8080-083487cf54d7",
      "name": "Deep Learning",
      "categoryId": "7ce04689-9d02-4038-9353-68d11c54b9fd"
    },
    {
      "id": "2f956404-7972-4735-b999-e3882098ee69",
      "name": "Contextual Embeddings",
      "categoryId": "7ce04689-9d02-4038-9353-68d11c54b9fd"
    },
    {
      "id": "1664c83d-9068-474d-b526-41ec1e068c68",
      "name": "Generative Models",
      "categoryId": "7ce04689-9d02-4038-9353-68d11c54b9fd"
    },
    {
      "id": "2de3ac0e-e833-4e24-bb73-7213fd767236",
      "name": "Bidirectional Models",
      "categoryId": "7ce04689-9d02-4038-9353-68d11c54b9fd"
    },
    {
      "id": "6fc375d5-66bc-4db3-85f9-9309695616d0",
      "name": "Self-Attention",
      "categoryId": "7ce04689-9d02-4038-9353-68d11c54b9fd"
    },
    {
      "id": "abd9a3ab-bb10-40e2-be06-a5fead2225a7",
      "name": "Pre-trained Models",
      "categoryId": "7ce04689-9d02-4038-9353-68d11c54b9fd"
    },
    {
      "id": "1e3d39a1-5a2c-4c35-85a3-de56114c4889",
      "name": "Fine-tuning",
      "categoryId": "7ce04689-9d02-4038-9353-68d11c54b9fd"
    },
    {
      "id": "fdc72108-767e-41cf-9679-ef615fb25368",
      "name": "Probability Distributions",
      "categoryId": "d40eb624-31ec-434b-9e62-1aff69486ca6"
    },
    {
      "id": "7b821f7e-6bff-4e0e-9ef0-5ee043adfc58",
      "name": "Continuous Distributions",
      "categoryId": "d40eb624-31ec-434b-9e62-1aff69486ca6"
    },
    {
      "id": "b20ca6a9-8f66-4c1f-b213-f692e97027ef",
      "name": "Symmetric Distributions",
      "categoryId": "d40eb624-31ec-434b-9e62-1aff69486ca6"
    },
    {
      "id": "6400d38b-cc6b-4ab0-94c8-ef756d2dac09",
      "name": "Central Limit Theorem",
      "categoryId": "d40eb624-31ec-434b-9e62-1aff69486ca6"
    },
    {
      "id": "afc19ceb-498d-4ad2-9566-2126c63eb37f",
      "name": "Statistical Modeling",
      "categoryId": "d40eb624-31ec-434b-9e62-1aff69486ca6"
    },
    {
      "id": "50f2b226-359f-44cd-9fe2-6bc66e3c2cbc",
      "name": "Bayesian Inference",
      "categoryId": "d40eb624-31ec-434b-9e62-1aff69486ca6"
    },
    {
      "id": "a6f31dc3-5846-41e3-a467-28068d18a7b8",
      "name": "Signal Processing",
      "categoryId": "d40eb624-31ec-434b-9e62-1aff69486ca6"
    },
    {
      "id": "f4c5f149-7ee4-4628-a671-79d17b89e924",
      "name": "Noise Modeling",
      "categoryId": "d40eb624-31ec-434b-9e62-1aff69486ca6"
    },
    {
      "id": "cae56b97-edf9-4733-b330-1c68064259fa",
      "name": "Laplacian Regularization",
      "categoryId": "e5f197c3-e00a-4c39-8e04-cb47c529ef8b"
    },
    {
      "id": "47f52594-9878-4e81-aedd-eb9981b81370",
      "name": "Manifold Learning",
      "categoryId": "e5f197c3-e00a-4c39-8e04-cb47c529ef8b"
    },
    {
      "id": "01c81f1a-ed03-4cf6-af2b-6b2dcd066aa8",
      "name": "Graph-based Regularization",
      "categoryId": "e5f197c3-e00a-4c39-8e04-cb47c529ef8b"
    },
    {
      "id": "4b9acf9f-9517-477c-ab12-202a3435ad78",
      "name": "Semi-supervised Learning",
      "categoryId": "e5f197c3-e00a-4c39-8e04-cb47c529ef8b"
    },
    {
      "id": "70a8188b-7bd3-4786-8b07-924711a0bcc6",
      "name": "Smoothness Constraints",
      "categoryId": "e5f197c3-e00a-4c39-8e04-cb47c529ef8b"
    },
    {
      "id": "c71f8903-e046-4133-86e3-41ebeed36982",
      "name": "Geometric Regularization",
      "categoryId": "e5f197c3-e00a-4c39-8e04-cb47c529ef8b"
    },
    {
      "id": "0efc4073-0197-4798-972a-9712efe39fe7",
      "name": "Spectral Graph Theory",
      "categoryId": "e5f197c3-e00a-4c39-8e04-cb47c529ef8b"
    },
    {
      "id": "df86cd67-188a-4769-80f1-b05c50eef10c",
      "name": "Natural Language Processing",
      "categoryId": "8ba0c392-1499-48d0-9d26-b9db4d846921"
    },
    {
      "id": "6d859d5b-81de-4463-b731-b52192a82dbb",
      "name": "Computer Vision",
      "categoryId": "8ba0c392-1499-48d0-9d26-b9db4d846921"
    },
    {
      "id": "7496f13d-9c88-47bb-8eed-26b8c233130e",
      "name": "Multimodal Models",
      "categoryId": "8ba0c392-1499-48d0-9d26-b9db4d846921"
    },
    {
      "id": "ff5f1bc3-d526-4f7f-9bdf-642fbb17b57f",
      "name": "Deep Learning",
      "categoryId": "8ba0c392-1499-48d0-9d26-b9db4d846921"
    },
    {
      "id": "9632d11b-25a3-4a55-8c26-4eaee8521b98",
      "name": "Transfer Learning",
      "categoryId": "8ba0c392-1499-48d0-9d26-b9db4d846921"
    },
    {
      "id": "81478beb-a449-4a5d-9f46-6291783d019a",
      "name": "Model Scaling",
      "categoryId": "8ba0c392-1499-48d0-9d26-b9db4d846921"
    },
    {
      "id": "0e58bd5f-4d52-4848-8cdc-8ccae5b6c203",
      "name": "Pretraining",
      "categoryId": "8ba0c392-1499-48d0-9d26-b9db4d846921"
    },
    {
      "id": "3a316f1b-f93c-43bc-b533-2130f87feba1",
      "name": "Fine-tuning",
      "categoryId": "8ba0c392-1499-48d0-9d26-b9db4d846921"
    },
    {
      "id": "135ad075-3367-45bd-8f0c-d50d84199693",
      "name": "Transformer Architectures",
      "categoryId": "8ba0c392-1499-48d0-9d26-b9db4d846921"
    },
    {
      "id": "5fab44c7-16c8-4567-8c44-fe09b1ee93a5",
      "name": "Large-Scale Data",
      "categoryId": "8ba0c392-1499-48d0-9d26-b9db4d846921"
    },
    {
      "id": "f828c06c-80b2-47d5-a1ce-da0d7cb23690",
      "name": "Model Compression",
      "categoryId": "8ba0c392-1499-48d0-9d26-b9db4d846921"
    },
    {
      "id": "4097aa23-60f0-465e-8a09-836e7711031b",
      "name": "Large Language Models (LLMs)",
      "categoryId": "3ee61d83-32ba-4e14-a555-571c40195b78"
    },
    {
      "id": "5d6f99c6-7f70-4613-85ff-2698a82673b5",
      "name": "Natural Language Processing (NLP)",
      "categoryId": "3ee61d83-32ba-4e14-a555-571c40195b78"
    },
    {
      "id": "f838c6e0-7293-4d2f-a02b-f0625fef22f5",
      "name": "Transformer Models",
      "categoryId": "3ee61d83-32ba-4e14-a555-571c40195b78"
    },
    {
      "id": "bf01810b-7c16-48c9-b1e2-8aebf4b0890e",
      "name": "Deep Learning",
      "categoryId": "3ee61d83-32ba-4e14-a555-571c40195b78"
    },
    {
      "id": "438fca87-c5f9-4156-b7ad-2b7374756cb4",
      "name": "Artificial Intelligence",
      "categoryId": "3ee61d83-32ba-4e14-a555-571c40195b78"
    },
    {
      "id": "0e22bc22-2e66-41ca-9b71-03c8d5982f98",
      "name": "Text Generation",
      "categoryId": "3ee61d83-32ba-4e14-a555-571c40195b78"
    },
    {
      "id": "36a72913-257f-4ad4-b1bc-49c3cc578287",
      "name": "Contextual Embedding",
      "categoryId": "3ee61d83-32ba-4e14-a555-571c40195b78"
    },
    {
      "id": "9e889e7c-a869-4246-aaf0-3f96aab36c4a",
      "name": "Embedding Models",
      "categoryId": "3ee61d83-32ba-4e14-a555-571c40195b78"
    },
    {
      "id": "34071fe7-a1bf-4894-bf74-5ea116207ead",
      "name": "Sequence Modeling",
      "categoryId": "3ee61d83-32ba-4e14-a555-571c40195b78"
    },
    {
      "id": "4631cc83-e2a2-4c79-a626-124933d39224",
      "name": "Neural Networks",
      "categoryId": "3ee61d83-32ba-4e14-a555-571c40195b78"
    },
    {
      "id": "10b697ef-3f8e-4f84-8421-4f79831482b2",
      "name": "Language Models",
      "categoryId": "081dd52e-9610-43a8-9200-f32b30349251"
    },
    {
      "id": "27b3fc49-0b7e-4bd7-a64f-0d7641851ea4",
      "name": "Transformer Architectures",
      "categoryId": "081dd52e-9610-43a8-9200-f32b30349251"
    },
    {
      "id": "08d96cb9-6cca-4f79-be1c-88ed7eb25dba",
      "name": "Model Scaling",
      "categoryId": "081dd52e-9610-43a8-9200-f32b30349251"
    },
    {
      "id": "1ce8297d-5347-4d66-af1b-d6ec52a302c4",
      "name": "Natural Language Processing",
      "categoryId": "081dd52e-9610-43a8-9200-f32b30349251"
    },
    {
      "id": "e91e0d3d-391a-4423-a27f-28e914c9a65b",
      "name": "Computer Vision",
      "categoryId": "081dd52e-9610-43a8-9200-f32b30349251"
    },
    {
      "id": "3c3bb2aa-1c26-46f0-8cb6-ee5d23463a7c",
      "name": "Model Training Techniques",
      "categoryId": "081dd52e-9610-43a8-9200-f32b30349251"
    },
    {
      "id": "b5ec2fa5-6e85-4eaf-b53e-b54052401177",
      "name": "Supervised Learning",
      "categoryId": "b70b98c0-09e1-4cb5-b0f2-a3b03b850e7e"
    },
    {
      "id": "98c1b6f6-b38b-4928-bed3-2c1b50e81c45",
      "name": "Regression",
      "categoryId": "b70b98c0-09e1-4cb5-b0f2-a3b03b850e7e"
    },
    {
      "id": "dc7817a5-f2b5-4b35-97ae-4a946cd47a4c",
      "name": "Regularization Techniques",
      "categoryId": "b70b98c0-09e1-4cb5-b0f2-a3b03b850e7e"
    },
    {
      "id": "5b7b2228-0583-4d94-b95d-f86170e7442b",
      "name": "Linear Models",
      "categoryId": "b70b98c0-09e1-4cb5-b0f2-a3b03b850e7e"
    },
    {
      "id": "bb69979a-d26f-4c47-8d62-a627338a4f10",
      "name": "Feature Selection",
      "categoryId": "b70b98c0-09e1-4cb5-b0f2-a3b03b850e7e"
    },
    {
      "id": "db6991de-f9c7-4a6c-a1eb-f1d2001371e6",
      "name": "Penalization Methods",
      "categoryId": "b70b98c0-09e1-4cb5-b0f2-a3b03b850e7e"
    },
    {
      "id": "354a2992-6f0f-4575-9395-aa94d4c0e1ca",
      "name": "Sparse Models",
      "categoryId": "b70b98c0-09e1-4cb5-b0f2-a3b03b850e7e"
    },
    {
      "id": "0c9eb019-b17b-4a88-92ba-d15a9907964c",
      "name": "Shrinkage Methods",
      "categoryId": "b70b98c0-09e1-4cb5-b0f2-a3b03b850e7e"
    },
    {
      "id": "026abae5-2d75-4c9b-8413-06903161d8e0",
      "name": "Supervised Learning",
      "categoryId": "738a6bae-54b8-4fff-98c8-b9f6bf96477f"
    },
    {
      "id": "ea6404f7-079a-4ee7-a456-3d6da333d10a",
      "name": "Regression Analysis",
      "categoryId": "738a6bae-54b8-4fff-98c8-b9f6bf96477f"
    },
    {
      "id": "1a1b899e-cfcc-4394-8449-b135873336f0",
      "name": "Regularization Techniques",
      "categoryId": "738a6bae-54b8-4fff-98c8-b9f6bf96477f"
    },
    {
      "id": "4ad89322-443d-49f4-9c9c-4b181dc93147",
      "name": "Linear Models",
      "categoryId": "738a6bae-54b8-4fff-98c8-b9f6bf96477f"
    },
    {
      "id": "1d3c458a-7ab1-4440-8429-900e4013bc14",
      "name": "Penalized Regression",
      "categoryId": "738a6bae-54b8-4fff-98c8-b9f6bf96477f"
    },
    {
      "id": "578760c2-9063-4a81-9f66-4774b653ec6e",
      "name": "Feature Selection",
      "categoryId": "738a6bae-54b8-4fff-98c8-b9f6bf96477f"
    },
    {
      "id": "e37c1f0a-fc1b-4607-b749-2e3f71ef2533",
      "name": "Machine Learning Models",
      "categoryId": "738a6bae-54b8-4fff-98c8-b9f6bf96477f"
    },
    {
      "id": "dd91eac9-aad4-4d88-9af2-74e6c975eec1",
      "name": "Predictive Modeling",
      "categoryId": "738a6bae-54b8-4fff-98c8-b9f6bf96477f"
    },
    {
      "id": "673afa9a-d1b0-4560-84d6-b825e61c0276",
      "name": "Supervised Learning",
      "categoryId": "293d145e-3b41-4bd3-bdf8-d8aae6a49633"
    },
    {
      "id": "2043f240-a15e-4f9f-b3cd-3c801c4118f9",
      "name": "Regression",
      "categoryId": "293d145e-3b41-4bd3-bdf8-d8aae6a49633"
    },
    {
      "id": "19431ae8-f9e4-42b0-be3d-dafe61608648",
      "name": "Regularization",
      "categoryId": "293d145e-3b41-4bd3-bdf8-d8aae6a49633"
    },
    {
      "id": "129f6042-1c00-4829-8361-0dc39be0a170",
      "name": "Linear Models",
      "categoryId": "293d145e-3b41-4bd3-bdf8-d8aae6a49633"
    },
    {
      "id": "5ba4e7e1-6ece-4f13-b5d3-040b3f397af4",
      "name": "Penalized Regression",
      "categoryId": "293d145e-3b41-4bd3-bdf8-d8aae6a49633"
    },
    {
      "id": "498d971a-4368-4133-8e04-0c59fb5d1ffe",
      "name": "Lasso Regression",
      "categoryId": "293d145e-3b41-4bd3-bdf8-d8aae6a49633"
    },
    {
      "id": "2bcecdec-c877-4fb9-969a-e9f31eb1b5fa",
      "name": "Ridge Regression",
      "categoryId": "293d145e-3b41-4bd3-bdf8-d8aae6a49633"
    },
    {
      "id": "b89b3652-cb86-4b2f-a488-db9bd5d7f4ec",
      "name": "Parameter Shrinkage",
      "categoryId": "293d145e-3b41-4bd3-bdf8-d8aae6a49633"
    },
    {
      "id": "1d467281-2399-454d-bc7e-7fb24534d384",
      "name": "High-dimensional Data",
      "categoryId": "293d145e-3b41-4bd3-bdf8-d8aae6a49633"
    },
    {
      "id": "2ee531a1-e8b5-4b01-ac03-c764a41ecf47",
      "name": "Feature Selection",
      "categoryId": "293d145e-3b41-4bd3-bdf8-d8aae6a49633"
    },
    {
      "id": "09279ba5-438c-4ff9-999b-13f216f991cf",
      "name": "Machine Learning Techniques",
      "categoryId": "293d145e-3b41-4bd3-bdf8-d8aae6a49633"
    },
    {
      "id": "f79890f1-32be-45c4-a683-af746b58cc1d",
      "name": "Supervised Learning",
      "categoryId": "623343fe-a47b-418b-9c99-4f89338c2e57"
    },
    {
      "id": "7d03e886-fb78-4c21-ad0d-bf23972c1d93",
      "name": "Regression Techniques",
      "categoryId": "623343fe-a47b-418b-9c99-4f89338c2e57"
    },
    {
      "id": "6387cdfc-f94f-4cc2-af20-e0cb89e5a1c9",
      "name": "Regularization Methods",
      "categoryId": "623343fe-a47b-418b-9c99-4f89338c2e57"
    },
    {
      "id": "0129eea1-6556-4db1-baa9-be3480a05574",
      "name": "Linear Models",
      "categoryId": "623343fe-a47b-418b-9c99-4f89338c2e57"
    },
    {
      "id": "7d4c4a17-e5fa-487e-98a5-6d3526faa1e2",
      "name": "Parametric Models",
      "categoryId": "623343fe-a47b-418b-9c99-4f89338c2e57"
    },
    {
      "id": "848b1da7-2d33-40a4-a9e3-3700a128e201",
      "name": "Penalized Regression",
      "categoryId": "623343fe-a47b-418b-9c99-4f89338c2e57"
    },
    {
      "id": "bfb00585-6f02-4ec8-b143-c5a925da63de",
      "name": "Lasso",
      "categoryId": "623343fe-a47b-418b-9c99-4f89338c2e57"
    },
    {
      "id": "6b4d5de6-7f2a-410a-af9e-c15103df8cb8",
      "name": "Ridge Regression",
      "categoryId": "623343fe-a47b-418b-9c99-4f89338c2e57"
    },
    {
      "id": "a777227d-68d4-4b97-8bf6-3828756c1e99",
      "name": "Latency Optimization",
      "categoryId": "be926310-7863-4039-80de-38cdc305d7a7"
    },
    {
      "id": "db03d65b-3f49-4728-9224-9d294af0c004",
      "name": "Performance Tuning",
      "categoryId": "be926310-7863-4039-80de-38cdc305d7a7"
    },
    {
      "id": "e6e54b78-4a64-45c7-9901-5ff99d2fb15c",
      "name": "System Optimization",
      "categoryId": "be926310-7863-4039-80de-38cdc305d7a7"
    },
    {
      "id": "5e8d78f3-e53a-4ede-a8ad-36592f7a5097",
      "name": "Real-time Processing",
      "categoryId": "be926310-7863-4039-80de-38cdc305d7a7"
    },
    {
      "id": "69a8daf4-d5d7-4837-96d8-480aeabc086a",
      "name": "Response Time Reduction",
      "categoryId": "be926310-7863-4039-80de-38cdc305d7a7"
    },
    {
      "id": "4b4ae1da-f813-4be5-9260-282e1871e16c",
      "name": "Computational Efficiency",
      "categoryId": "be926310-7863-4039-80de-38cdc305d7a7"
    },
    {
      "id": "a1335708-6610-48ae-92b0-feca945b6df5",
      "name": "Network Latency",
      "categoryId": "be926310-7863-4039-80de-38cdc305d7a7"
    },
    {
      "id": "5fdd1e76-c851-4922-8f1c-439a73fce913",
      "name": "Data Transfer Optimization",
      "categoryId": "be926310-7863-4039-80de-38cdc305d7a7"
    },
    {
      "id": "68dcf394-d61e-46ca-8608-6d826068de76",
      "name": "Hardware Acceleration",
      "categoryId": "be926310-7863-4039-80de-38cdc305d7a7"
    },
    {
      "id": "465860a6-f2e3-4129-ba8d-3a7a4c84947d",
      "name": "Software Optimization",
      "categoryId": "be926310-7863-4039-80de-38cdc305d7a7"
    },
    {
      "id": "c4665ca8-c990-494c-bd1e-65e73f6fd37a",
      "name": "real-time learning",
      "categoryId": "13d6cfbf-6802-4c47-ad77-d9e42552b977"
    },
    {
      "id": "fd7e3aa0-02db-4efa-a33a-250365f89bcc",
      "name": "adaptive training",
      "categoryId": "13d6cfbf-6802-4c47-ad77-d9e42552b977"
    },
    {
      "id": "44e767ff-9e9d-42a7-b950-e45af8e4d58f",
      "name": "performance optimization",
      "categoryId": "13d6cfbf-6802-4c47-ad77-d9e42552b977"
    },
    {
      "id": "c7b32ceb-2614-46ff-8fad-ffa32d1fb217",
      "name": "model latency",
      "categoryId": "13d6cfbf-6802-4c47-ad77-d9e42552b977"
    },
    {
      "id": "22dbcda5-9904-4ba8-8816-7a25a1d76c5d",
      "name": "training efficiency",
      "categoryId": "13d6cfbf-6802-4c47-ad77-d9e42552b977"
    },
    {
      "id": "c2030b59-7411-4598-927c-b507aa3bbff1",
      "name": "resource-aware ML",
      "categoryId": "13d6cfbf-6802-4c47-ad77-d9e42552b977"
    },
    {
      "id": "d34dd36b-7fe3-47fc-87d2-ccaeaab96a75",
      "name": "scalable machine learning",
      "categoryId": "13d6cfbf-6802-4c47-ad77-d9e42552b977"
    },
    {
      "id": "1984b619-0d01-4278-a9d4-6f912cb3541d",
      "name": "edge computing AI",
      "categoryId": "13d6cfbf-6802-4c47-ad77-d9e42552b977"
    },
    {
      "id": "104a54e4-9947-49b2-9d1b-a17c56168868",
      "name": "time-sensitive computing",
      "categoryId": "13d6cfbf-6802-4c47-ad77-d9e42552b977"
    },
    {
      "id": "ba2398df-38aa-435d-beb1-85551c9a10fd",
      "name": "Dimensionality Reduction",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "ca240c55-bc42-4383-945e-86fabb9ef8ed",
      "name": "Neural Network Compression",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "4337f19e-e95a-4f76-9890-32101d01df2f",
      "name": "Feature Extraction",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "ed832016-911a-46ff-9a89-fb2394e1cb23",
      "name": "Deep Learning Optimization",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "c9e8fee6-39f6-4548-80a6-c0810d6b602f",
      "name": "Model Pruning",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "2b793608-43d7-4ad0-b43c-cc825dd4a4d6",
      "name": "Generative Models",
      "categoryId": "3e8a0f67-698b-4ccf-9438-e31ac1cd3ab5"
    },
    {
      "id": "8c905b18-e2ac-447a-a49c-c72fbfb4d9aa",
      "name": "Diffusion Models",
      "categoryId": "3e8a0f67-698b-4ccf-9438-e31ac1cd3ab5"
    },
    {
      "id": "ddd7c3de-7b06-4e04-b13e-5fb18eeeffce",
      "name": "Latent Space",
      "categoryId": "3e8a0f67-698b-4ccf-9438-e31ac1cd3ab5"
    },
    {
      "id": "42712bcc-47bf-4947-b9da-38b5550afd57",
      "name": "Deep Learning",
      "categoryId": "3e8a0f67-698b-4ccf-9438-e31ac1cd3ab5"
    },
    {
      "id": "d8a64297-0160-4973-b085-91ae3d7ada31",
      "name": "Computer Vision",
      "categoryId": "3e8a0f67-698b-4ccf-9438-e31ac1cd3ab5"
    },
    {
      "id": "cfaeff11-77b9-4f37-b3e9-01060bf0eac2",
      "name": "Image Synthesis",
      "categoryId": "3e8a0f67-698b-4ccf-9438-e31ac1cd3ab5"
    },
    {
      "id": "41f23cca-fb80-4155-aa39-b614255c951c",
      "name": "Generative AI",
      "categoryId": "3e8a0f67-698b-4ccf-9438-e31ac1cd3ab5"
    },
    {
      "id": "fae435c7-11e1-4d33-83b5-5cb99f7f3f08",
      "name": "Neural Networks",
      "categoryId": "3e8a0f67-698b-4ccf-9438-e31ac1cd3ab5"
    },
    {
      "id": "1e5cc1cd-24ec-46fa-9658-6cdb344c8873",
      "name": "Variational Autoencoders",
      "categoryId": "3e8a0f67-698b-4ccf-9438-e31ac1cd3ab5"
    },
    {
      "id": "65f76f4c-08af-4587-87b8-678593e46051",
      "name": "Probabilistic Modeling",
      "categoryId": "3e8a0f67-698b-4ccf-9438-e31ac1cd3ab5"
    },
    {
      "id": "4cad352f-52a1-4ac3-96b3-d1a2aa1b4c06",
      "name": "Deep Generative Models",
      "categoryId": "3211afce-2d2a-4bd7-8220-ed642e49b2b5"
    },
    {
      "id": "12723ca4-58ef-4ad9-8a60-ad3df2732233",
      "name": "Probabilistic Models",
      "categoryId": "3211afce-2d2a-4bd7-8220-ed642e49b2b5"
    },
    {
      "id": "6208d6c7-20da-4a9f-814c-b2c27e49a3ce",
      "name": "Diffusion Processes",
      "categoryId": "3211afce-2d2a-4bd7-8220-ed642e49b2b5"
    },
    {
      "id": "2918d598-59e1-4040-9847-8677d8cfe1e8",
      "name": "Computer Vision",
      "categoryId": "3211afce-2d2a-4bd7-8220-ed642e49b2b5"
    },
    {
      "id": "1567b1da-9eda-44ec-9d6c-2323062140d1",
      "name": "Image Synthesis",
      "categoryId": "3211afce-2d2a-4bd7-8220-ed642e49b2b5"
    },
    {
      "id": "2ce56870-336b-47b0-aaa5-8a368dcdf724",
      "name": "Latent Space Modeling",
      "categoryId": "3211afce-2d2a-4bd7-8220-ed642e49b2b5"
    },
    {
      "id": "6f1a7223-6b53-4c13-b223-865b1cd4aa64",
      "name": "Neural Networks",
      "categoryId": "3211afce-2d2a-4bd7-8220-ed642e49b2b5"
    },
    {
      "id": "81d49c76-aeb3-41f6-89eb-a4cfb679a9a8",
      "name": "Unsupervised Learning",
      "categoryId": "3211afce-2d2a-4bd7-8220-ed642e49b2b5"
    },
    {
      "id": "5226325b-b454-4a92-bbe7-900acd0c13a2",
      "name": "Topic Modeling",
      "categoryId": "6bd59b84-978b-4ae6-a812-c596d49a29aa"
    },
    {
      "id": "310cee59-2880-40f7-80cf-58069ef14df6",
      "name": "Bayesian Inference",
      "categoryId": "6bd59b84-978b-4ae6-a812-c596d49a29aa"
    },
    {
      "id": "69c8b09a-bf06-497f-bbd4-f09f7864d8a2",
      "name": "Unsupervised Learning",
      "categoryId": "6bd59b84-978b-4ae6-a812-c596d49a29aa"
    },
    {
      "id": "492450b9-9f79-4cf8-9773-f7b803136f33",
      "name": "Probabilistic Models",
      "categoryId": "6bd59b84-978b-4ae6-a812-c596d49a29aa"
    },
    {
      "id": "91cd6c7d-fbdf-45f4-bee3-48ca089d9f2e",
      "name": "Document Clustering",
      "categoryId": "6bd59b84-978b-4ae6-a812-c596d49a29aa"
    },
    {
      "id": "544b2b90-fc4f-44f8-99c3-1743e63b23ef",
      "name": "Text Mining",
      "categoryId": "6bd59b84-978b-4ae6-a812-c596d49a29aa"
    },
    {
      "id": "33bad4fa-0796-4ada-b7a0-ed425f4c3292",
      "name": "Natural Language Processing (NLP)",
      "categoryId": "6bd59b84-978b-4ae6-a812-c596d49a29aa"
    },
    {
      "id": "de90910c-4d88-48a4-960f-9c923f0e0362",
      "name": "Dimensionality Reduction",
      "categoryId": "6bd59b84-978b-4ae6-a812-c596d49a29aa"
    },
    {
      "id": "fa79fb6d-f3bc-4178-994b-527e8a66fc59",
      "name": "Natural Language Processing",
      "categoryId": "07424377-51ad-489f-a046-e4e860551930"
    },
    {
      "id": "8e5ac8a4-7c5d-4ea3-ae47-ee6eefe7707f",
      "name": "Topic Modeling",
      "categoryId": "07424377-51ad-489f-a046-e4e860551930"
    },
    {
      "id": "c1b2dcaf-c9fa-44d2-8b95-8765f4e5086b",
      "name": "Probabilistic Models",
      "categoryId": "07424377-51ad-489f-a046-e4e860551930"
    },
    {
      "id": "9fd88dbe-4661-44d8-a74e-73db50851a11",
      "name": "Unsupervised Learning",
      "categoryId": "07424377-51ad-489f-a046-e4e860551930"
    },
    {
      "id": "733311a9-68c5-4464-b21e-f7924abb5a66",
      "name": "Bayesian Methods",
      "categoryId": "07424377-51ad-489f-a046-e4e860551930"
    },
    {
      "id": "ea3bc011-e364-4962-ab73-f4cba2ceb265",
      "name": "Text Mining",
      "categoryId": "07424377-51ad-489f-a046-e4e860551930"
    },
    {
      "id": "ad903595-cf80-466a-a25e-00e59d08049e",
      "name": "Dimensionality Reduction",
      "categoryId": "07424377-51ad-489f-a046-e4e860551930"
    },
    {
      "id": "5b6cbe7d-a0d3-472b-96b9-38b7f11e32d1",
      "name": "Machine Learning Algorithms",
      "categoryId": "07424377-51ad-489f-a046-e4e860551930"
    },
    {
      "id": "6a24c4ad-7590-4c42-9b41-a58dcc8865f2",
      "name": "Data Preprocessing",
      "categoryId": "07424377-51ad-489f-a046-e4e860551930"
    },
    {
      "id": "ea1ce754-7684-49b6-bfb7-090513d047e8",
      "name": "Statistical Modeling",
      "categoryId": "07424377-51ad-489f-a046-e4e860551930"
    },
    {
      "id": "1d8aa901-ad0b-4071-a933-35effa5ff2ee",
      "name": "Machine Learning",
      "categoryId": "2ed7b5c6-e7ef-4b58-aafa-176349399b9b"
    },
    {
      "id": "37050455-9e27-4aab-9a83-005969b3338c",
      "name": "Deep Learning",
      "categoryId": "2ed7b5c6-e7ef-4b58-aafa-176349399b9b"
    },
    {
      "id": "5519d86e-d38f-41f7-957a-ad02a1d12307",
      "name": "Representation Learning",
      "categoryId": "2ed7b5c6-e7ef-4b58-aafa-176349399b9b"
    },
    {
      "id": "08a8f894-d63e-483b-9d5a-7778f95f6284",
      "name": "Information Theory",
      "categoryId": "2ed7b5c6-e7ef-4b58-aafa-176349399b9b"
    },
    {
      "id": "599107e9-3e09-466f-a3d4-ce8c38965f5d",
      "name": "Compression",
      "categoryId": "2ed7b5c6-e7ef-4b58-aafa-176349399b9b"
    },
    {
      "id": "56779133-9b64-4146-9e32-74e84acf84f7",
      "name": "Neural Networks",
      "categoryId": "2ed7b5c6-e7ef-4b58-aafa-176349399b9b"
    },
    {
      "id": "152a5702-dd90-4354-ad82-cbae6adea2e2",
      "name": "Variational Methods",
      "categoryId": "2ed7b5c6-e7ef-4b58-aafa-176349399b9b"
    },
    {
      "id": "02effe67-d23c-486e-83a1-76a10a799c27",
      "name": "Bayesian Inference",
      "categoryId": "2ed7b5c6-e7ef-4b58-aafa-176349399b9b"
    },
    {
      "id": "14e761d8-bcae-472c-824a-08563e89e661",
      "name": "Probabilistic Models",
      "categoryId": "2ed7b5c6-e7ef-4b58-aafa-176349399b9b"
    },
    {
      "id": "756690f1-caa9-4e99-9288-1079758e22a8",
      "name": "Data Compression",
      "categoryId": "2ed7b5c6-e7ef-4b58-aafa-176349399b9b"
    },
    {
      "id": "8bd0f4cc-0f18-4982-9c0a-6dd03403b46e",
      "name": "Dimensionality Reduction",
      "categoryId": "2ed7b5c6-e7ef-4b58-aafa-176349399b9b"
    },
    {
      "id": "5da7a85d-2787-4ab8-b6f0-5e4887aaf317",
      "name": "Natural Language Processing",
      "categoryId": "14867a94-bcae-4075-8ee4-7154def1ed01"
    },
    {
      "id": "30852a50-c99a-4a09-a6cb-f8d086665cf0",
      "name": "Text Mining",
      "categoryId": "14867a94-bcae-4075-8ee4-7154def1ed01"
    },
    {
      "id": "673ea721-093b-44ff-a9b8-c4859fc2aaa5",
      "name": "Dimensionality Reduction",
      "categoryId": "14867a94-bcae-4075-8ee4-7154def1ed01"
    },
    {
      "id": "397d5ac1-4ba6-43bd-8037-9a39c697ebe7",
      "name": "Semantic Analysis",
      "categoryId": "14867a94-bcae-4075-8ee4-7154def1ed01"
    },
    {
      "id": "620b8ff1-7e6b-4e74-83c3-e03a2f432cbb",
      "name": "Unsupervised Learning",
      "categoryId": "14867a94-bcae-4075-8ee4-7154def1ed01"
    },
    {
      "id": "175d8644-c31f-452f-a340-24a96223b428",
      "name": "Topic Modeling",
      "categoryId": "14867a94-bcae-4075-8ee4-7154def1ed01"
    },
    {
      "id": "5f6a999b-6d7c-4acb-9102-14cb4bd2c9db",
      "name": "Latent Semantic Analysis",
      "categoryId": "e439aa10-143d-4c8d-bc4f-0f87e833d241"
    },
    {
      "id": "a4ba1ccd-97f4-4576-b521-3ccc3475bf62",
      "name": "Dimensionality Reduction",
      "categoryId": "e439aa10-143d-4c8d-bc4f-0f87e833d241"
    },
    {
      "id": "5980d75f-4a66-4197-8b5c-0a623a4329d4",
      "name": "Semantic Search",
      "categoryId": "e439aa10-143d-4c8d-bc4f-0f87e833d241"
    },
    {
      "id": "97073224-fa20-4e88-a6fe-c3b4941068cc",
      "name": "Unsupervised Learning",
      "categoryId": "e439aa10-143d-4c8d-bc4f-0f87e833d241"
    },
    {
      "id": "53e907cc-dbac-4806-9b71-b96471288699",
      "name": "Text Similarity",
      "categoryId": "e439aa10-143d-4c8d-bc4f-0f87e833d241"
    },
    {
      "id": "2d01f7df-9b23-496f-a0f8-bc9edcfb22df",
      "name": "Text Processing",
      "categoryId": "b1839f82-076b-4d1e-a2a0-824fe015be59"
    },
    {
      "id": "2be5315b-d861-4b71-b20e-76ba9f398bb1",
      "name": "Information Retrieval",
      "categoryId": "b1839f82-076b-4d1e-a2a0-824fe015be59"
    },
    {
      "id": "7377c36e-2d46-4384-8b51-211991f62f62",
      "name": "Natural Language Processing (NLP)",
      "categoryId": "b1839f82-076b-4d1e-a2a0-824fe015be59"
    },
    {
      "id": "31763187-8798-458e-b4f2-43efffffbf1e",
      "name": "Dimensionality Reduction",
      "categoryId": "b1839f82-076b-4d1e-a2a0-824fe015be59"
    },
    {
      "id": "02d2613b-308b-41d2-8bc0-dea379f62922",
      "name": "Semantic Analysis",
      "categoryId": "b1839f82-076b-4d1e-a2a0-824fe015be59"
    },
    {
      "id": "ea45528a-38ca-49f9-9558-9b8161eb899f",
      "name": "Unsupervised Learning",
      "categoryId": "b1839f82-076b-4d1e-a2a0-824fe015be59"
    },
    {
      "id": "b1fc3410-f2a3-4cf2-ad6d-b8e9e3090198",
      "name": "Latent Variable Models",
      "categoryId": "b1839f82-076b-4d1e-a2a0-824fe015be59"
    },
    {
      "id": "34bb40bd-83c9-44fa-8ece-9e358bb241f3",
      "name": "Data Mining",
      "categoryId": "b1839f82-076b-4d1e-a2a0-824fe015be59"
    },
    {
      "id": "6fb4e403-d906-4292-ac41-4d907d381ce4",
      "name": "Natural Language Processing",
      "categoryId": "6fdaf690-f56b-4be7-9530-8c1a06b84b99"
    },
    {
      "id": "9d2b7f5f-e2eb-4b03-941a-36c6c273bec9",
      "name": "Semantic Similarity",
      "categoryId": "6fdaf690-f56b-4be7-9530-8c1a06b84b99"
    },
    {
      "id": "ddcdf5a2-f1d3-4336-bbe1-a6d715dcfc96",
      "name": "Representation Learning",
      "categoryId": "6fdaf690-f56b-4be7-9530-8c1a06b84b99"
    },
    {
      "id": "a308a31c-f925-4dc2-9a90-36bc7cb40724",
      "name": "Embeddings",
      "categoryId": "6fdaf690-f56b-4be7-9530-8c1a06b84b99"
    },
    {
      "id": "059f0206-ac04-4547-b5ee-5d73bb5b9e02",
      "name": "Deep Learning",
      "categoryId": "6fdaf690-f56b-4be7-9530-8c1a06b84b99"
    },
    {
      "id": "8171eb4b-1097-42cb-8fc1-c7c7203b849d",
      "name": "Text Analytics",
      "categoryId": "6fdaf690-f56b-4be7-9530-8c1a06b84b99"
    },
    {
      "id": "40d97c83-d07b-42af-9e4e-053a5ff80214",
      "name": "Generative Models",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "6d293309-2195-4276-bf97-d590f2c292b0",
      "name": "Embedding Spaces",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "f97f7c36-2b0d-4421-84e6-d7f1edab33c7",
      "name": "Variational Autoencoders (VAEs)",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "92f3d039-c7b8-4044-ad3b-6bc29f9488db",
      "name": "Generative Adversarial Networks (GANs)",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "8a46cf6a-1442-41bb-855f-eb6e19cda79e",
      "name": "Manifold Learning",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "ba8bd8ee-5dac-4843-9c87-fd7f89ed3c75",
      "name": "Representation Learning",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "0c624556-cc0d-4be5-a2aa-67781444b8be",
      "name": "Manifold Traversal",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "c92b47b7-d911-46a9-ba16-bb29e2671691",
      "name": "Embedding Space Visualization",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "17f34c8a-731e-41fa-aeaa-8d8a8601a68c",
      "name": "Latent Space",
      "categoryId": "f626050b-7b3e-4633-bd6b-c4e7583cd021"
    },
    {
      "id": "db59544c-b20d-4fbd-9152-48c31945792e",
      "name": "Representation Learning",
      "categoryId": "f626050b-7b3e-4633-bd6b-c4e7583cd021"
    },
    {
      "id": "3b88edbb-5799-45cf-8408-7622f151fd12",
      "name": "Manifold Learning",
      "categoryId": "f626050b-7b3e-4633-bd6b-c4e7583cd021"
    },
    {
      "id": "99b1d70f-0b14-4703-9a4a-6f88c6817e04",
      "name": "Variational Autoencoders (VAEs)",
      "categoryId": "f626050b-7b3e-4633-bd6b-c4e7583cd021"
    },
    {
      "id": "a138768b-e773-4038-acef-71e2a68f34f5",
      "name": "Generative Adversarial Networks (GANs)",
      "categoryId": "f626050b-7b3e-4633-bd6b-c4e7583cd021"
    },
    {
      "id": "eb29f43b-a8b3-45f7-b4f9-01d0b72ff298",
      "name": "Embedding Spaces",
      "categoryId": "f626050b-7b3e-4633-bd6b-c4e7583cd021"
    },
    {
      "id": "c725d351-7e5c-44ee-8e6b-5fee31e20a90",
      "name": "Latent Space Exploration Extensions",
      "categoryId": "42ca4030-93f8-49f7-9508-9dc5f2cc3cb5"
    },
    {
      "id": "573badb4-945d-4b10-ab89-d336785807ba",
      "name": "Generative Models",
      "categoryId": "42ca4030-93f8-49f7-9508-9dc5f2cc3cb5"
    },
    {
      "id": "f4dbdef4-71bd-493e-a71b-57554e95195e",
      "name": "Variational Autoencoders (VAEs)",
      "categoryId": "42ca4030-93f8-49f7-9508-9dc5f2cc3cb5"
    },
    {
      "id": "d77c2899-6cdc-40d0-ae91-53dddded2740",
      "name": "Generative Adversarial Networks (GANs)",
      "categoryId": "42ca4030-93f8-49f7-9508-9dc5f2cc3cb5"
    },
    {
      "id": "88098ed8-ec7f-4587-9786-3c81af9be6e3",
      "name": "Manifold Learning",
      "categoryId": "42ca4030-93f8-49f7-9508-9dc5f2cc3cb5"
    },
    {
      "id": "43dbaeb6-debf-4ec1-883c-871b75a86075",
      "name": "Dimensionality Reduction",
      "categoryId": "42ca4030-93f8-49f7-9508-9dc5f2cc3cb5"
    },
    {
      "id": "e9cbb760-6fc6-49e4-8897-7c729b36523d",
      "name": "Latent Space Interpolation",
      "categoryId": "42ca4030-93f8-49f7-9508-9dc5f2cc3cb5"
    },
    {
      "id": "be60f579-3859-4ac9-8019-ff7435f7e431",
      "name": "Representation Learning",
      "categoryId": "42ca4030-93f8-49f7-9508-9dc5f2cc3cb5"
    },
    {
      "id": "e3add5ee-8d6e-458f-b5d4-0f425d393cfc",
      "name": "Embedding Spaces",
      "categoryId": "42ca4030-93f8-49f7-9508-9dc5f2cc3cb5"
    },
    {
      "id": "6ae5dbe0-6b98-40eb-be72-5e3bd096f478",
      "name": "Model Fine-tuning",
      "categoryId": "42ca4030-93f8-49f7-9508-9dc5f2cc3cb5"
    },
    {
      "id": "b053fe74-00e1-40ae-9f38-6864e322f36f",
      "name": "Latent Space Exploration Extensions is a specialized area within generative modeling",
      "categoryId": "4b3b6d86-b112-4598-91bb-97ba6c587215"
    },
    {
      "id": "c84cff55-4045-4e89-a09f-ae08240044a6",
      "name": "focusing on enhancing the capabilities of models like Variational Autoencoders (VAEs)",
      "categoryId": "4b3b6d86-b112-4598-91bb-97ba6c587215"
    },
    {
      "id": "b0b23a18-2c46-43c8-b342-3e955e092049",
      "name": "Generative Adversarial Networks (GANs)",
      "categoryId": "4b3b6d86-b112-4598-91bb-97ba6c587215"
    },
    {
      "id": "a9f0d2fe-f188-4c8b-bc39-8ef6a5464c89",
      "name": "and other deep generative architectures. Sub-category tags include Latent Space Manipulation",
      "categoryId": "4b3b6d86-b112-4598-91bb-97ba6c587215"
    },
    {
      "id": "b65c1197-b5f7-484f-88c4-b0e16f1faf76",
      "name": "Interpolation",
      "categoryId": "4b3b6d86-b112-4598-91bb-97ba6c587215"
    },
    {
      "id": "f6c9e8bd-c74b-46be-bc2f-6613f1a750fb",
      "name": "Semantic Editing",
      "categoryId": "4b3b6d86-b112-4598-91bb-97ba6c587215"
    },
    {
      "id": "7f8f751a-7600-445e-9ac9-cff63801ecb6",
      "name": "Dimensionality Reduction",
      "categoryId": "4b3b6d86-b112-4598-91bb-97ba6c587215"
    },
    {
      "id": "74665b88-a6cb-4ea7-8e32-fcea06932d6c",
      "name": "and Representation Learning. These tags help categorize the methods that extend basic latent space exploration to include more nuanced control",
      "categoryId": "4b3b6d86-b112-4598-91bb-97ba6c587215"
    },
    {
      "id": "b249a22c-dfda-4f02-8e81-8efd2e80e5c1",
      "name": "disentanglement",
      "categoryId": "4b3b6d86-b112-4598-91bb-97ba6c587215"
    },
    {
      "id": "43c2e9bd-ef49-4b41-9ad1-4a497c51c2f1",
      "name": "and meaningful transformations of the generated data.",
      "categoryId": "4b3b6d86-b112-4598-91bb-97ba6c587215"
    },
    {
      "id": "82a7890a-840b-40fe-a721-f766756a5ac6",
      "name": "Latent Space Exploration Extensions Techniques",
      "categoryId": "132a1d10-78d6-47e0-aaed-db18d4661196"
    },
    {
      "id": "b8de55d6-d962-4c9f-aba1-f52e6c931c93",
      "name": "Deep Generative Models",
      "categoryId": "132a1d10-78d6-47e0-aaed-db18d4661196"
    },
    {
      "id": "7c131a44-2490-4727-a1b2-1f5c83320ac5",
      "name": "Variational Autoencoders (VAEs)",
      "categoryId": "132a1d10-78d6-47e0-aaed-db18d4661196"
    },
    {
      "id": "4c72c862-7103-4c43-9b55-3007bd3f76dc",
      "name": "Generative Adversarial Networks (GANs)",
      "categoryId": "132a1d10-78d6-47e0-aaed-db18d4661196"
    },
    {
      "id": "4876aaab-b503-42ae-b4d6-dd0dcffe7b14",
      "name": "Manifold Traversal",
      "categoryId": "132a1d10-78d6-47e0-aaed-db18d4661196"
    },
    {
      "id": "8162017c-c926-4407-8209-65664723febf",
      "name": "Latent Space Arithmetic",
      "categoryId": "132a1d10-78d6-47e0-aaed-db18d4661196"
    },
    {
      "id": "073bb664-6466-485e-b8ef-e5c061f60fa7",
      "name": "Dimensionality Reduction",
      "categoryId": "132a1d10-78d6-47e0-aaed-db18d4661196"
    },
    {
      "id": "1c1e4c7a-7b2a-4e27-97ea-4e598ca9757d",
      "name": "Representation Learning",
      "categoryId": "132a1d10-78d6-47e0-aaed-db18d4661196"
    },
    {
      "id": "cdfe76cc-a632-427b-be5d-cf808fbac4e2",
      "name": "Embedding Spaces",
      "categoryId": "132a1d10-78d6-47e0-aaed-db18d4661196"
    },
    {
      "id": "37056d27-6a0e-4ee4-bc06-0ab7a519a4cb",
      "name": "Data Synthesis",
      "categoryId": "132a1d10-78d6-47e0-aaed-db18d4661196"
    },
    {
      "id": "df088d0a-0ad6-4a03-a3b7-c675dcf2a461",
      "name": "Novelty Detection",
      "categoryId": "132a1d10-78d6-47e0-aaed-db18d4661196"
    },
    {
      "id": "68facd19-3d17-43ac-95ba-3bcda5258f14",
      "name": "Latent Space Exploration Extensions Techniques Enhancements Sub-category Tags include Variational Autoencoders (VAEs)",
      "categoryId": "fdb982a0-2ecb-4ab2-995e-ff18122d816d"
    },
    {
      "id": "51603cef-f0f7-47c6-bfd4-7b95598f9219",
      "name": "Generative Adversarial Networks (GANs)",
      "categoryId": "fdb982a0-2ecb-4ab2-995e-ff18122d816d"
    },
    {
      "id": "47a8b536-2bf2-4b29-8fdc-39945e43e841",
      "name": "Manifold Learning",
      "categoryId": "fdb982a0-2ecb-4ab2-995e-ff18122d816d"
    },
    {
      "id": "b4f20394-be40-4d48-9fac-c94d1979be27",
      "name": "Dimensionality Reduction",
      "categoryId": "fdb982a0-2ecb-4ab2-995e-ff18122d816d"
    },
    {
      "id": "96b0bea4-3171-47bc-be29-f0724e8921ae",
      "name": "Interpolation Methods",
      "categoryId": "fdb982a0-2ecb-4ab2-995e-ff18122d816d"
    },
    {
      "id": "4b333df4-27e6-4fdb-b831-7a1d7c396c81",
      "name": "Disentangled Representations",
      "categoryId": "fdb982a0-2ecb-4ab2-995e-ff18122d816d"
    },
    {
      "id": "f3c528c2-7c78-470c-bf4e-96aacfadfbe8",
      "name": "and Latent Space Manipulation. These tags help categorize advanced methods used to analyze and manipulate the latent representations in generative models",
      "categoryId": "fdb982a0-2ecb-4ab2-995e-ff18122d816d"
    },
    {
      "id": "62d429cb-a2ce-4116-a1e6-ed68a6732ae9",
      "name": "facilitating better understanding and controlled generation of data.",
      "categoryId": "fdb982a0-2ecb-4ab2-995e-ff18122d816d"
    },
    {
      "id": "0ee7c5e1-6b55-4712-9664-3f25c02ca6a9",
      "name": "Latent Space Exploration Techniques",
      "categoryId": "14b2607b-fd5f-4c2d-be29-eaf24b185168"
    },
    {
      "id": "17523c97-d182-4581-80e1-b889bbd1d4d1",
      "name": "Manifold Learning",
      "categoryId": "14b2607b-fd5f-4c2d-be29-eaf24b185168"
    },
    {
      "id": "cb2df7e1-5ad7-4115-938b-7df7c6da91e3",
      "name": "Dimensionality Reduction",
      "categoryId": "14b2607b-fd5f-4c2d-be29-eaf24b185168"
    },
    {
      "id": "239f5146-04cf-4207-b096-85bb1bf6bfc7",
      "name": "Representation Learning",
      "categoryId": "14b2607b-fd5f-4c2d-be29-eaf24b185168"
    },
    {
      "id": "bd38f0c5-5194-40e4-a691-240395bba823",
      "name": "Latent Variable Models",
      "categoryId": "14b2607b-fd5f-4c2d-be29-eaf24b185168"
    },
    {
      "id": "83ead385-a24f-4a4c-8db7-ceef453c6aa2",
      "name": "Variational Autoencoders",
      "categoryId": "14b2607b-fd5f-4c2d-be29-eaf24b185168"
    },
    {
      "id": "a9ef9724-3761-4e41-9e21-0a847bf7ca02",
      "name": "Generative Adversarial Networks",
      "categoryId": "14b2607b-fd5f-4c2d-be29-eaf24b185168"
    },
    {
      "id": "f44692c9-41b3-43d3-86c6-191586c2a57b",
      "name": "Interpolation",
      "categoryId": "14b2607b-fd5f-4c2d-be29-eaf24b185168"
    },
    {
      "id": "7abe19a8-ad1c-42d6-8b6a-7e294bacc656",
      "name": "Latent Space Arithmetic",
      "categoryId": "14b2607b-fd5f-4c2d-be29-eaf24b185168"
    },
    {
      "id": "fc76255c-a8b7-4790-b16a-2bb734f18137",
      "name": "Embedding Spaces",
      "categoryId": "14b2607b-fd5f-4c2d-be29-eaf24b185168"
    },
    {
      "id": "431d1080-b667-4dc0-b2e0-92ee54443c8e",
      "name": "Latent Space Manipulation is primarily associated with Generative Models",
      "categoryId": "0b980795-0e8c-4a88-9558-3dc165b50901"
    },
    {
      "id": "4bdb2b95-45dc-4144-b171-76d78efdf444",
      "name": "particularly Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs). Key sub-category tags include Latent Representation",
      "categoryId": "0b980795-0e8c-4a88-9558-3dc165b50901"
    },
    {
      "id": "5ac0ac31-8902-4b9f-a0f7-de3b9b8fbd6e",
      "name": "Feature Interpolation",
      "categoryId": "0b980795-0e8c-4a88-9558-3dc165b50901"
    },
    {
      "id": "3ee2cf19-ff30-4042-b43e-c140a3cca21c",
      "name": "Style Transfer",
      "categoryId": "0b980795-0e8c-4a88-9558-3dc165b50901"
    },
    {
      "id": "54db5441-2f4a-4b9f-a6bd-eb018b451c84",
      "name": "Dimensionality Reduction",
      "categoryId": "0b980795-0e8c-4a88-9558-3dc165b50901"
    },
    {
      "id": "bc3799b0-c315-4b40-8187-403b281331a2",
      "name": "and Embedding Space Exploration. These tags help categorize techniques focused on navigating and modifying the learned latent representations of data.",
      "categoryId": "0b980795-0e8c-4a88-9558-3dc165b50901"
    },
    {
      "id": "77510841-aa35-4c90-9b60-5afebd3dd279",
      "name": "Sub-category tags for Latent Space Manipulation Methods include 'Representation Learning",
      "categoryId": "220f5104-cf02-4b0b-a4b6-d9a319f1a437"
    },
    {
      "id": "80bf16c3-cc31-4c0b-9086-575d76c82f76",
      "name": "' 'Generative Models",
      "categoryId": "220f5104-cf02-4b0b-a4b6-d9a319f1a437"
    },
    {
      "id": "c0af7c36-e082-4b50-895e-53aef9984a7d",
      "name": "' 'GANs",
      "categoryId": "220f5104-cf02-4b0b-a4b6-d9a319f1a437"
    },
    {
      "id": "7b9c11f0-06c9-441b-b40a-8a6681604964",
      "name": "' 'Autoencoders",
      "categoryId": "220f5104-cf02-4b0b-a4b6-d9a319f1a437"
    },
    {
      "id": "f5811827-7762-4d6c-90e4-91c6c0a1278b",
      "name": "' 'Variational Autoencoders (VAEs)",
      "categoryId": "220f5104-cf02-4b0b-a4b6-d9a319f1a437"
    },
    {
      "id": "a1e8db92-845f-4405-81cb-ec59cf5bebcd",
      "name": "' 'Deep Learning",
      "categoryId": "220f5104-cf02-4b0b-a4b6-d9a319f1a437"
    },
    {
      "id": "6fa303dd-6709-471a-90d6-2c8f0533e91a",
      "name": "' 'Data Embeddings",
      "categoryId": "220f5104-cf02-4b0b-a4b6-d9a319f1a437"
    },
    {
      "id": "93e3e227-02bd-44d8-bb4f-f831f6d1fcbe",
      "name": "' and 'Dimensionality Reduction.' These tags categorize specific techniques and models associated with manipulating and understanding latent spaces within AI/ML workflows.",
      "categoryId": "220f5104-cf02-4b0b-a4b6-d9a319f1a437"
    },
    {
      "id": "ad4a3356-26ad-44b1-a9f5-3429db65fe90",
      "name": "Latent Space Manipulation Techniques",
      "categoryId": "aa173205-a10d-488d-b501-8f87aa6d6681"
    },
    {
      "id": "f7674b89-6971-41f3-91f9-6f4de2d3487e",
      "name": "Generative Models",
      "categoryId": "aa173205-a10d-488d-b501-8f87aa6d6681"
    },
    {
      "id": "552921e9-850a-49e3-8448-e50d1967518d",
      "name": "Variational Autoencoders (VAEs)",
      "categoryId": "aa173205-a10d-488d-b501-8f87aa6d6681"
    },
    {
      "id": "d149b123-59da-42ee-801f-a73e386b7b9a",
      "name": "Generative Adversarial Networks (GANs)",
      "categoryId": "aa173205-a10d-488d-b501-8f87aa6d6681"
    },
    {
      "id": "513dd76c-8e7a-485c-a1b9-5ea02d7e9c3c",
      "name": "Disentangled Representations",
      "categoryId": "aa173205-a10d-488d-b501-8f87aa6d6681"
    },
    {
      "id": "9d830fb0-d346-452b-9a23-efac656cd8cd",
      "name": "Embedding Spaces",
      "categoryId": "aa173205-a10d-488d-b501-8f87aa6d6681"
    },
    {
      "id": "49a9f46d-3172-4cd8-8e1a-7d7ea563ec5b",
      "name": "Feature Interpolation",
      "categoryId": "aa173205-a10d-488d-b501-8f87aa6d6681"
    },
    {
      "id": "bd42eda2-130c-47f6-afbc-25c16f6e049d",
      "name": "Attribute Editing",
      "categoryId": "aa173205-a10d-488d-b501-8f87aa6d6681"
    },
    {
      "id": "360156bf-4074-484e-bda4-2e32da0d19a9",
      "name": "Dimensionality Reduction",
      "categoryId": "aa173205-a10d-488d-b501-8f87aa6d6681"
    },
    {
      "id": "e97c9bc1-67a9-4e6f-923d-ab079b4d81ed",
      "name": "Representation Learning",
      "categoryId": "aa173205-a10d-488d-b501-8f87aa6d6681"
    },
    {
      "id": "e0db6e19-1b4b-451c-9db7-c4d99dca8ee8",
      "name": "Latent Space Models",
      "categoryId": "c8a1736a-8549-4e98-ab91-480924788bd1"
    },
    {
      "id": "05b58676-4089-49a7-a95b-6d242c579c1a",
      "name": "Representation Learning",
      "categoryId": "c8a1736a-8549-4e98-ab91-480924788bd1"
    },
    {
      "id": "537ef966-9a2a-41f1-a78f-666ed492bf9f",
      "name": "Generative Models",
      "categoryId": "c8a1736a-8549-4e98-ab91-480924788bd1"
    },
    {
      "id": "a4b2b571-ba2a-4e04-8611-c5753f3ea6c1",
      "name": "Variational Autoencoders",
      "categoryId": "c8a1736a-8549-4e98-ab91-480924788bd1"
    },
    {
      "id": "b0396b1e-37df-4192-ab32-9b319316f6da",
      "name": "Generative Adversarial Networks",
      "categoryId": "c8a1736a-8549-4e98-ab91-480924788bd1"
    },
    {
      "id": "63418a55-1c83-492c-b924-6a5ee43832f6",
      "name": "Deep Learning",
      "categoryId": "c8a1736a-8549-4e98-ab91-480924788bd1"
    },
    {
      "id": "1b2ab2c7-f191-412f-ba9a-7b284a97fc86",
      "name": "Dimensionality Reduction",
      "categoryId": "c8a1736a-8549-4e98-ab91-480924788bd1"
    },
    {
      "id": "63721b08-e317-4106-908b-b5835f796193",
      "name": "Embedding Spaces",
      "categoryId": "c8a1736a-8549-4e98-ab91-480924788bd1"
    },
    {
      "id": "caa37c41-5294-4097-83ae-f0aca2a5392a",
      "name": "Probabilistic Modeling",
      "categoryId": "c8a1736a-8549-4e98-ab91-480924788bd1"
    },
    {
      "id": "9f80f28a-852c-463b-8ffb-de5f6dce3eec",
      "name": "Manifold Learning",
      "categoryId": "c8a1736a-8549-4e98-ab91-480924788bd1"
    },
    {
      "id": "63cb321b-0890-4fd1-baa5-3055da06f777",
      "name": "Dimensionality Reduction",
      "categoryId": "90759216-9938-4255-ae89-97f048035020"
    },
    {
      "id": "9900f54c-f703-45d4-b8b7-9fa7b18a81f1",
      "name": "Variational Autoencoders",
      "categoryId": "90759216-9938-4255-ae89-97f048035020"
    },
    {
      "id": "83f984cb-660a-42dd-9793-941d61bb79f9",
      "name": "Generative Models",
      "categoryId": "90759216-9938-4255-ae89-97f048035020"
    },
    {
      "id": "e3cca1f5-fa98-4a36-b5a0-03b79bdc1a4d",
      "name": "Embedding Spaces",
      "categoryId": "90759216-9938-4255-ae89-97f048035020"
    },
    {
      "id": "524918ed-cf3d-415c-baee-4af078d007b0",
      "name": "Manifold Learning",
      "categoryId": "90759216-9938-4255-ae89-97f048035020"
    },
    {
      "id": "d5756767-7d4e-4833-bcff-37f817c3f75a",
      "name": "Representation Learning",
      "categoryId": "90759216-9938-4255-ae89-97f048035020"
    },
    {
      "id": "91a53752-83b0-421c-a88b-62ff74accd62",
      "name": "Deep Learning",
      "categoryId": "90759216-9938-4255-ae89-97f048035020"
    },
    {
      "id": "3c499d14-8b60-499b-9499-18c18b9b9998",
      "name": "Neural Networks",
      "categoryId": "90759216-9938-4255-ae89-97f048035020"
    },
    {
      "id": "c7d2c9bc-912e-4dfc-a20c-d547ad306071",
      "name": "Latent Variables",
      "categoryId": "90759216-9938-4255-ae89-97f048035020"
    },
    {
      "id": "fd52dd71-70ef-4e38-bbd1-b63e38f28d52",
      "name": "Feature Extraction",
      "categoryId": "90759216-9938-4255-ae89-97f048035020"
    },
    {
      "id": "6a29373c-bd69-4a20-9d0f-e6eda7bb86c4",
      "name": "Latent Space Network Models",
      "categoryId": "6361e606-eaca-45f3-a223-7115c8e9e752"
    },
    {
      "id": "d2249c66-71d7-4cbd-b928-d7dd00e1288c",
      "name": "Graph Neural Networks",
      "categoryId": "6361e606-eaca-45f3-a223-7115c8e9e752"
    },
    {
      "id": "ec2cb002-59d7-42a7-b49a-d955f92a9d7b",
      "name": "Variational Autoencoders",
      "categoryId": "6361e606-eaca-45f3-a223-7115c8e9e752"
    },
    {
      "id": "e1075808-56e3-434d-a20d-16a4f10eb466",
      "name": "Representation Learning",
      "categoryId": "6361e606-eaca-45f3-a223-7115c8e9e752"
    },
    {
      "id": "8cb1207a-6e7e-4e71-9e26-40bed790a014",
      "name": "Deep Graph Models",
      "categoryId": "6361e606-eaca-45f3-a223-7115c8e9e752"
    },
    {
      "id": "f70099bd-3eba-46dc-971a-0cd2b41749a9",
      "name": "Embedding Techniques",
      "categoryId": "6361e606-eaca-45f3-a223-7115c8e9e752"
    },
    {
      "id": "29b9ef70-903a-48e8-8f27-00d7788f9215",
      "name": "Probabilistic Graph Models",
      "categoryId": "6361e606-eaca-45f3-a223-7115c8e9e752"
    },
    {
      "id": "2a9625c8-1639-4344-89c7-216c687e27db",
      "name": "Generative Models",
      "categoryId": "6361e606-eaca-45f3-a223-7115c8e9e752"
    },
    {
      "id": "60852749-8e72-425d-bc7d-1764a6ee17d5",
      "name": "Unsupervised Learning",
      "categoryId": "6361e606-eaca-45f3-a223-7115c8e9e752"
    },
    {
      "id": "237cbf64-5f8e-494b-bc2c-5d5050075014",
      "name": "Dimensionality Reduction",
      "categoryId": "6361e606-eaca-45f3-a223-7115c8e9e752"
    },
    {
      "id": "cddebbe6-2b71-42f4-9e73-c2196bdeadf3",
      "name": "Reinforcement Learning",
      "categoryId": "c340d5b2-b41f-47f7-a9d5-31290268f9e6"
    },
    {
      "id": "a377bac3-7468-437f-9419-1c33b041a092",
      "name": "Natural Language Processing (NLP)",
      "categoryId": "c340d5b2-b41f-47f7-a9d5-31290268f9e6"
    },
    {
      "id": "9879733e-0909-46ae-81b2-ca9683181094",
      "name": "Sequence Modeling",
      "categoryId": "c340d5b2-b41f-47f7-a9d5-31290268f9e6"
    },
    {
      "id": "afd0cacf-19e4-43b7-b7e3-dc49d679671e",
      "name": "Deep Learning",
      "categoryId": "c340d5b2-b41f-47f7-a9d5-31290268f9e6"
    },
    {
      "id": "68bc8d4b-02c5-4082-95c9-73e15393d691",
      "name": "Policy Optimization",
      "categoryId": "c340d5b2-b41f-47f7-a9d5-31290268f9e6"
    },
    {
      "id": "775d4119-8d9d-4756-a576-77a42f914747",
      "name": "Text Generation",
      "categoryId": "c340d5b2-b41f-47f7-a9d5-31290268f9e6"
    },
    {
      "id": "764aed64-4626-4557-a62e-6c7102490d7b",
      "name": "Probabilistic Modeling",
      "categoryId": "c340d5b2-b41f-47f7-a9d5-31290268f9e6"
    },
    {
      "id": "19483483-feca-43ca-899e-0d5e13435057",
      "name": "Reinforcement Learning",
      "categoryId": "f6e32c03-e555-47c2-9c98-da6ea9354710"
    },
    {
      "id": "f5749793-07c9-44e8-8d4d-324d0f01d233",
      "name": "Policy Optimization",
      "categoryId": "f6e32c03-e555-47c2-9c98-da6ea9354710"
    },
    {
      "id": "c74c6aee-343a-411e-accf-fceff413db0b",
      "name": "Deep Reinforcement Learning",
      "categoryId": "f6e32c03-e555-47c2-9c98-da6ea9354710"
    },
    {
      "id": "ab540c4a-45c4-4937-ae19-ca1cd013db05",
      "name": "Actor-Critic Methods",
      "categoryId": "f6e32c03-e555-47c2-9c98-da6ea9354710"
    },
    {
      "id": "b9b62bb4-d7f7-4e57-9a0b-5524fdcb778e",
      "name": "Stochastic Gradient Methods",
      "categoryId": "f6e32c03-e555-47c2-9c98-da6ea9354710"
    },
    {
      "id": "06221ae0-db1e-4d9b-9d5c-54c27bccebfe",
      "name": "Policy Search Algorithms",
      "categoryId": "f6e32c03-e555-47c2-9c98-da6ea9354710"
    },
    {
      "id": "e693e887-4c64-4fca-8463-1da66d9a1538",
      "name": "Sequential Decision-Making",
      "categoryId": "f6e32c03-e555-47c2-9c98-da6ea9354710"
    },
    {
      "id": "d9b9c5c5-ee82-4bc4-9e58-3d098219a820",
      "name": "Continuous Action Spaces",
      "categoryId": "f6e32c03-e555-47c2-9c98-da6ea9354710"
    },
    {
      "id": "9c862cab-1402-4216-a64a-f25b5d184f01",
      "name": "Stochastic Policies",
      "categoryId": "f6e32c03-e555-47c2-9c98-da6ea9354710"
    },
    {
      "id": "34fca6e3-fa0e-4933-aea1-d8d7bb0277ab",
      "name": "Model-Free Methods",
      "categoryId": "f6e32c03-e555-47c2-9c98-da6ea9354710"
    },
    {
      "id": "39702f80-32d0-4a7e-b8f3-4af08b324afa",
      "name": "Policy Gradient",
      "categoryId": "f88d4ab8-8049-4580-a679-1194e7da77ab"
    },
    {
      "id": "855bd9d4-bb4f-4340-a720-6a8e3e681a2a",
      "name": "Reinforce Algorithm",
      "categoryId": "f88d4ab8-8049-4580-a679-1194e7da77ab"
    },
    {
      "id": "d67c44b4-945a-4160-a905-aa86c3abada6",
      "name": "Actor-Critic Methods",
      "categoryId": "f88d4ab8-8049-4580-a679-1194e7da77ab"
    },
    {
      "id": "21200647-f10d-4890-9caf-aa9cabe7101b",
      "name": "Stochastic Policy Gradient",
      "categoryId": "f88d4ab8-8049-4580-a679-1194e7da77ab"
    },
    {
      "id": "119a285d-53f1-4893-90a8-8b43e4229d6f",
      "name": "Variance Reduction Techniques",
      "categoryId": "f88d4ab8-8049-4580-a679-1194e7da77ab"
    },
    {
      "id": "01945edb-bab4-42c5-89df-33e431fc3636",
      "name": "Deep Policy Gradient",
      "categoryId": "f88d4ab8-8049-4580-a679-1194e7da77ab"
    },
    {
      "id": "4bb622f4-ff9d-4795-9018-764da9c469ca",
      "name": "Policy Optimization",
      "categoryId": "99457e6b-e884-42ed-ba3d-a7395d94a4c2"
    },
    {
      "id": "7656e394-c1c4-4ff2-b57b-312375a0d072",
      "name": "Model-Free Methods",
      "categoryId": "99457e6b-e884-42ed-ba3d-a7395d94a4c2"
    },
    {
      "id": "b3c56d61-d88d-47ff-9b44-5bfe94a0bdb2",
      "name": "Stochastic Policy Gradient",
      "categoryId": "99457e6b-e884-42ed-ba3d-a7395d94a4c2"
    },
    {
      "id": "e5fe715d-206e-4195-a96d-f1b69f335931",
      "name": "Actor-Critic Methods",
      "categoryId": "99457e6b-e884-42ed-ba3d-a7395d94a4c2"
    },
    {
      "id": "119b7a2d-a783-4ae0-b3e3-15958dd4a136",
      "name": "Deep Reinforcement Learning",
      "categoryId": "99457e6b-e884-42ed-ba3d-a7395d94a4c2"
    },
    {
      "id": "9053a7bf-8027-4397-9ce3-06e7c05b9ca3",
      "name": "Continuous Action Spaces",
      "categoryId": "99457e6b-e884-42ed-ba3d-a7395d94a4c2"
    },
    {
      "id": "e39f3663-7eac-4636-b3dd-84e898a8e4b7",
      "name": "Reinforcement Learning",
      "categoryId": "02ce6114-e7b2-4852-95d4-20b9efa8c190"
    },
    {
      "id": "5fd6fd94-172f-4306-880c-b62af8668a17",
      "name": "Dynamic Programming",
      "categoryId": "02ce6114-e7b2-4852-95d4-20b9efa8c190"
    },
    {
      "id": "e79a1e9b-9275-4794-bf63-75dc2f9739c2",
      "name": "Markov Decision Processes",
      "categoryId": "02ce6114-e7b2-4852-95d4-20b9efa8c190"
    },
    {
      "id": "18d7c531-b134-414a-9707-d6508b942879",
      "name": "Policy Optimization",
      "categoryId": "02ce6114-e7b2-4852-95d4-20b9efa8c190"
    },
    {
      "id": "b40b770b-865b-4642-8317-43bd8a8f81e0",
      "name": "Model-Based RL",
      "categoryId": "02ce6114-e7b2-4852-95d4-20b9efa8c190"
    },
    {
      "id": "7619cdda-7b34-4353-9bb2-77f4109cdf95",
      "name": "Policy Evaluation",
      "categoryId": "02ce6114-e7b2-4852-95d4-20b9efa8c190"
    },
    {
      "id": "26ea70a2-d289-4202-940b-b0a38736d11a",
      "name": "Policy Improvement",
      "categoryId": "02ce6114-e7b2-4852-95d4-20b9efa8c190"
    },
    {
      "id": "204e6ac3-5477-47b1-b557-ba663207c7db",
      "name": "Value Iteration",
      "categoryId": "02ce6114-e7b2-4852-95d4-20b9efa8c190"
    },
    {
      "id": "d05a4f0d-77c5-4349-8928-7da326664107",
      "name": "Bellman Equations",
      "categoryId": "02ce6114-e7b2-4852-95d4-20b9efa8c190"
    },
    {
      "id": "55327e82-da79-42f3-a9bc-bcfef13f739c",
      "name": "Stochastic Policies",
      "categoryId": "99457e6b-e884-42ed-ba3d-a7395d94a4c2"
    },
    {
      "id": "9f6ad194-c982-423d-96b3-470e3d077342",
      "name": "Policy Gradient Methods",
      "categoryId": "99457e6b-e884-42ed-ba3d-a7395d94a4c2"
    },
    {
      "id": "0c7cc971-0004-45cb-9230-d6e52e9d558c",
      "name": "Continuous Control",
      "categoryId": "99457e6b-e884-42ed-ba3d-a7395d94a4c2"
    },
    {
      "id": "2f7a582c-9b70-4232-8a14-670e1dc1c4d1",
      "name": "Policy Networks Architecture",
      "categoryId": "99457e6b-e884-42ed-ba3d-a7395d94a4c2"
    },
    {
      "id": "9528b57d-2e47-4236-a08f-fccf91a8b2b0",
      "name": "Neural Policy Parameterization",
      "categoryId": "99457e6b-e884-42ed-ba3d-a7395d94a4c2"
    },
    {
      "id": "3a5ab249-3a48-44c6-933d-693d2ebe3809",
      "name": "Policy Regularization",
      "categoryId": "99457e6b-e884-42ed-ba3d-a7395d94a4c2"
    },
    {
      "id": "492f9272-ac86-4f6b-9aa6-5cb71432fef3",
      "name": "Policy Networks fall under the broader categories of Reinforcement Learning and Neural Network architectures. They are specifically associated with policy-based methods",
      "categoryId": "99457e6b-e884-42ed-ba3d-a7395d94a4c2"
    },
    {
      "id": "72449936-6c97-49a4-b697-753eb4e20d67",
      "name": "which directly parameterize the policy function for decision-making tasks. Relevant sub-category tags include Deep Reinforcement Learning",
      "categoryId": "99457e6b-e884-42ed-ba3d-a7395d94a4c2"
    },
    {
      "id": "1329dd2d-1cb7-4cd5-8ffc-142e818de909",
      "name": "Function Approximation",
      "categoryId": "99457e6b-e884-42ed-ba3d-a7395d94a4c2"
    },
    {
      "id": "6f6b7278-c878-48d3-a56c-b320659934d0",
      "name": "and Stochastic Policies. These tags help categorize policy networks within the context of adaptive decision-making systems and continuous policy optimization techniques.",
      "categoryId": "99457e6b-e884-42ed-ba3d-a7395d94a4c2"
    },
    {
      "id": "f6b2caa5-b3d0-47ae-862c-b27d5a8a8436",
      "name": "Reinforcement Learning",
      "categoryId": "11a5291c-c524-452b-b523-37508ff2092a"
    },
    {
      "id": "dd017202-5563-4718-b862-06d9b2112238",
      "name": "Policy Optimization",
      "categoryId": "11a5291c-c524-452b-b523-37508ff2092a"
    },
    {
      "id": "1c930b08-b76e-4b6b-aac8-65b737d6b81c",
      "name": "Policy Networks",
      "categoryId": "11a5291c-c524-452b-b523-37508ff2092a"
    },
    {
      "id": "15912023-4ee2-406c-bdbd-d0e5dad62a0c",
      "name": "Deep Policy Networks",
      "categoryId": "11a5291c-c524-452b-b523-37508ff2092a"
    },
    {
      "id": "3870a24b-cd23-46aa-95c2-3b83d2e6e036",
      "name": "Actuator Policies",
      "categoryId": "11a5291c-c524-452b-b523-37508ff2092a"
    },
    {
      "id": "20c0fbc5-0540-4231-a944-720ac9f2b56b",
      "name": "Stochastic Policies",
      "categoryId": "11a5291c-c524-452b-b523-37508ff2092a"
    },
    {
      "id": "93e10ad7-ade6-47aa-941c-9091b735ab24",
      "name": "Deterministic Policies",
      "categoryId": "11a5291c-c524-452b-b523-37508ff2092a"
    },
    {
      "id": "96cc67ea-451a-418e-a3bf-408038232eba",
      "name": "Actor-Critic Methods",
      "categoryId": "11a5291c-c524-452b-b523-37508ff2092a"
    },
    {
      "id": "6aced27f-6fd8-4bb0-88b9-df76f1204b76",
      "name": "Policy Gradient Methods",
      "categoryId": "11a5291c-c524-452b-b523-37508ff2092a"
    },
    {
      "id": "92c8123c-e278-423f-b13d-05cf5ca2ef06",
      "name": "Value-Based Methods",
      "categoryId": "11a5291c-c524-452b-b523-37508ff2092a"
    },
    {
      "id": "182ea949-c24f-4cb2-a55b-4e865742181a",
      "name": "Model-Free Policy Methods",
      "categoryId": "11a5291c-c524-452b-b523-37508ff2092a"
    },
    {
      "id": "14ed6c20-6a91-4fa4-8538-7a28cbcccc8b",
      "name": "Optimization Techniques",
      "categoryId": "6b97ea5d-cfff-4435-a8fd-4940a2594e0a"
    },
    {
      "id": "f9feb119-aa45-4eff-940f-a2584e4956c6",
      "name": "Stochastic Gradient Dynamics",
      "categoryId": "6b97ea5d-cfff-4435-a8fd-4940a2594e0a"
    },
    {
      "id": "6ad1cabf-32ee-4429-a413-149445c50e94",
      "name": "Convergence Acceleration",
      "categoryId": "6b97ea5d-cfff-4435-a8fd-4940a2594e0a"
    },
    {
      "id": "a06712d7-c58e-4981-a309-2588221bc42c",
      "name": "Variance Reduction",
      "categoryId": "6b97ea5d-cfff-4435-a8fd-4940a2594e0a"
    },
    {
      "id": "a05ae7e2-6950-4574-8795-911cccb85c26",
      "name": "Training Stabilization",
      "categoryId": "6b97ea5d-cfff-4435-a8fd-4940a2594e0a"
    },
    {
      "id": "90798469-58d6-4134-8939-a94fdd26038f",
      "name": "Optimization",
      "categoryId": "4e4487a8-5959-4646-802e-980132212f3f"
    },
    {
      "id": "fd3e405d-be50-466f-add4-1ea157f0b7e9",
      "name": "Variance Reduction",
      "categoryId": "4e4487a8-5959-4646-802e-980132212f3f"
    },
    {
      "id": "07f76d6a-872e-4b5d-bd5e-59e25024cf13",
      "name": "Stochastic Gradient Descent",
      "categoryId": "4e4487a8-5959-4646-802e-980132212f3f"
    },
    {
      "id": "9dc3beea-bc58-48e8-9433-b19ed107a24d",
      "name": "Model Averaging",
      "categoryId": "4e4487a8-5959-4646-802e-980132212f3f"
    },
    {
      "id": "1cedfeaf-cf0a-4b54-b7f7-6ba64ca39c9c",
      "name": "Convergence Techniques",
      "categoryId": "4e4487a8-5959-4646-802e-980132212f3f"
    },
    {
      "id": "c4fdd880-d24c-4540-a76a-02c09cece631",
      "name": "Learning Rate Schedules",
      "categoryId": "4e4487a8-5959-4646-802e-980132212f3f"
    },
    {
      "id": "64ec915b-47bd-4e8f-a889-270f3e098676",
      "name": "Ensemble Methods",
      "categoryId": "4e4487a8-5959-4646-802e-980132212f3f"
    },
    {
      "id": "bfc39cb8-72ba-4b8d-a5ad-a4cc96af4f06",
      "name": "Regularization Strategies",
      "categoryId": "4e4487a8-5959-4646-802e-980132212f3f"
    },
    {
      "id": "33a5e797-655e-45ac-b94c-2848484938f1",
      "name": "Optimization Techniques",
      "categoryId": "8758d7ed-9b34-4580-a3e9-6baabc5d4782"
    },
    {
      "id": "53f48c79-d6ce-4060-b133-f651fa9700a9",
      "name": "Variance Reduction",
      "categoryId": "8758d7ed-9b34-4580-a3e9-6baabc5d4782"
    },
    {
      "id": "8bbc4293-3532-42de-967e-8cb0e58b35a3",
      "name": "Stochastic Approximation",
      "categoryId": "8758d7ed-9b34-4580-a3e9-6baabc5d4782"
    },
    {
      "id": "d2836f48-1dad-4e82-bb86-1026dc38d1fd",
      "name": "Model Averaging",
      "categoryId": "8758d7ed-9b34-4580-a3e9-6baabc5d4782"
    },
    {
      "id": "e7d09658-ed44-4072-82ed-0d1b594f91df",
      "name": "Neural Network Training Strategies",
      "categoryId": "8758d7ed-9b34-4580-a3e9-6baabc5d4782"
    },
    {
      "id": "55ecad47-8076-4765-b9fd-5b45cb606a6f",
      "name": "Convergence Acceleration",
      "categoryId": "8758d7ed-9b34-4580-a3e9-6baabc5d4782"
    },
    {
      "id": "3925d81f-ce44-44ab-add9-49c838cea2f1",
      "name": "Optimization Algorithms",
      "categoryId": "36a05ba2-b50b-49c6-a989-56e398faf855"
    },
    {
      "id": "a4ee90f8-f040-4123-abcc-e90015332e50",
      "name": "Stochastic Approximation",
      "categoryId": "36a05ba2-b50b-49c6-a989-56e398faf855"
    },
    {
      "id": "b467994e-14b5-4bb2-815b-0e36c6e803f3",
      "name": "Variance Reduction",
      "categoryId": "36a05ba2-b50b-49c6-a989-56e398faf855"
    },
    {
      "id": "ee022723-90c9-43b2-af96-7ad719276cb5",
      "name": "Adaptive Learning",
      "categoryId": "36a05ba2-b50b-49c6-a989-56e398faf855"
    },
    {
      "id": "c7683149-bfd1-44ea-bf0c-2fcec031d89d",
      "name": "Convergence Acceleration",
      "categoryId": "36a05ba2-b50b-49c6-a989-56e398faf855"
    },
    {
      "id": "c62bacc4-c234-4d2d-8db2-b219e6ee0c5f",
      "name": "Prediction Averaging",
      "categoryId": "36a05ba2-b50b-49c6-a989-56e398faf855"
    },
    {
      "id": "fc9661e6-8f85-41a1-96f1-56a4091524b1",
      "name": "Online Learning Techniques",
      "categoryId": "36a05ba2-b50b-49c6-a989-56e398faf855"
    },
    {
      "id": "a0af42cb-ecd6-4604-86f0-5d56d3015f1a",
      "name": "Variance Reduction Methods in SGD",
      "categoryId": "36a05ba2-b50b-49c6-a989-56e398faf855"
    },
    {
      "id": "5c1f3bed-2645-4dc9-82a1-323f06f70ec4",
      "name": "Optimization Techniques",
      "categoryId": "fedc536b-aff8-46b7-97b4-1a665d485f50"
    },
    {
      "id": "169f006c-2b5d-4464-b1e5-3e168374b7ec",
      "name": "Variance Reduction",
      "categoryId": "fedc536b-aff8-46b7-97b4-1a665d485f50"
    },
    {
      "id": "65464f29-539e-44db-a577-6f001f2896ae",
      "name": "Averaging Methods",
      "categoryId": "fedc536b-aff8-46b7-97b4-1a665d485f50"
    },
    {
      "id": "4580d336-7fbb-4a11-8fff-a42eb894d872",
      "name": "Stochastic Gradient Methods",
      "categoryId": "fedc536b-aff8-46b7-97b4-1a665d485f50"
    },
    {
      "id": "f5011d3c-85c0-4697-ac0f-83c4bb9c9958",
      "name": "Convergence Acceleration",
      "categoryId": "fedc536b-aff8-46b7-97b4-1a665d485f50"
    },
    {
      "id": "5abc81b8-9d7b-43a0-ba14-7ce1f99dd17a",
      "name": "Variance-Reduced Gradient",
      "categoryId": "fedc536b-aff8-46b7-97b4-1a665d485f50"
    },
    {
      "id": "f97f9592-83b9-449b-9a55-9d8454f77f90",
      "name": "Optimization Extensions",
      "categoryId": "fedc536b-aff8-46b7-97b4-1a665d485f50"
    },
    {
      "id": "34dee0f7-f01c-4891-b44d-01520762c922",
      "name": "Model Stability",
      "categoryId": "fedc536b-aff8-46b7-97b4-1a665d485f50"
    },
    {
      "id": "3d55233e-e314-4368-b35a-cdd87cec5bd1",
      "name": "Iterative Averaging",
      "categoryId": "fedc536b-aff8-46b7-97b4-1a665d485f50"
    },
    {
      "id": "e9c29299-a5ac-4844-963f-645e79339351",
      "name": "Statistical Estimation",
      "categoryId": "fedc536b-aff8-46b7-97b4-1a665d485f50"
    },
    {
      "id": "4ff56b3a-2762-45f7-aab9-967ea3ea2870",
      "name": "Training Stability",
      "categoryId": "fedc536b-aff8-46b7-97b4-1a665d485f50"
    },
    {
      "id": "f76f9fa9-944e-4293-9af1-88d649a7e0f9",
      "name": "Polyak Averaging Extensions Techniques Extensions Enhancements",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "74f47f09-1750-4cc1-9e68-df2fe65352b4",
      "name": "Variance Reduction",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "042ce2f7-9a3d-4b64-adca-e4fe2a8e1f6e",
      "name": "Optimization Algorithms",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "b8981166-59d8-4107-b816-100d4347f703",
      "name": "Convergence Acceleration",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "1799266f-eb1d-4032-b51b-905892713105",
      "name": "Model Averaging",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "db47f73b-7d04-479c-aceb-d3d544c2147b",
      "name": "Stochastic Optimization",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "4f980b11-0cde-4ebc-84d3-bee36a06210f",
      "name": "Learning Rate Schedules",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "93e9232e-2805-4661-b8d3-b1e4c2b1ac13",
      "name": "Adaptive Averaging",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "1ad83791-d4d3-40a8-bf14-b04c4542fbe8",
      "name": "Momentum Methods",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "34351bd0-d725-438d-be5c-4fa21b05ec74",
      "name": "Optimization Stability",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "d642616e-70c3-45a2-8714-146bd57e3b29",
      "name": "Polyak Averaging Extensions Techniques Extensions Enhancements Techniques can be categorized under optimization methods in machine learning",
      "categoryId": "40fe59b1-0726-4e49-b792-04394279af82"
    },
    {
      "id": "8ed49d6e-0f7d-4023-9da3-ce73e85b7ac7",
      "name": "stochastic approximation algorithms",
      "categoryId": "40fe59b1-0726-4e49-b792-04394279af82"
    },
    {
      "id": "c3d8dc56-3cb0-42d7-a225-c6a17b3eedce",
      "name": "variance reduction techniques",
      "categoryId": "40fe59b1-0726-4e49-b792-04394279af82"
    },
    {
      "id": "af6046fa-4bf2-4e9c-b550-1ddbcd8227ba",
      "name": "and iterative parameter averaging methods. Sub-category tags include stochastic optimization",
      "categoryId": "40fe59b1-0726-4e49-b792-04394279af82"
    },
    {
      "id": "fe816bc3-ad54-46fc-a352-358076c9e86c",
      "name": "variance reduction",
      "categoryId": "40fe59b1-0726-4e49-b792-04394279af82"
    },
    {
      "id": "8c2ccb9c-b046-47a6-bae6-3661ba47a6e1",
      "name": "parameter smoothing",
      "categoryId": "40fe59b1-0726-4e49-b792-04394279af82"
    },
    {
      "id": "28fa835a-e199-461a-bf57-6d9a2655bf8e",
      "name": "convergence enhancement",
      "categoryId": "40fe59b1-0726-4e49-b792-04394279af82"
    },
    {
      "id": "c58465f9-4c72-4ba1-89e1-faf9fd6e9c68",
      "name": "ensemble learning",
      "categoryId": "40fe59b1-0726-4e49-b792-04394279af82"
    },
    {
      "id": "7209a5c6-1f10-4130-a30a-8a8414b2dec0",
      "name": "adaptive averaging",
      "categoryId": "40fe59b1-0726-4e49-b792-04394279af82"
    },
    {
      "id": "602cb98e-0376-4780-8b9c-4231af35ebd4",
      "name": "and incremental learning. These tags aid in organizing related methods that improve the stability and convergence speed of training algorithms",
      "categoryId": "40fe59b1-0726-4e49-b792-04394279af82"
    },
    {
      "id": "44129250-ad61-4ff0-8d7a-3eadf8af393f",
      "name": "especially in deep learning and reinforcement learning contexts.",
      "categoryId": "40fe59b1-0726-4e49-b792-04394279af82"
    },
    {
      "id": "755f6a38-f441-4634-b1a3-194d0ad19aa4",
      "name": "Optimization Techniques",
      "categoryId": "193c441c-0d53-488d-b730-5029bdfdd470"
    },
    {
      "id": "c970c2b5-e675-441f-89e8-ca82eab9ead6",
      "name": "Variance Reduction",
      "categoryId": "193c441c-0d53-488d-b730-5029bdfdd470"
    },
    {
      "id": "4b73b8a0-459f-4232-be57-697d5a222e3a",
      "name": "Stochastic Gradient Methods",
      "categoryId": "193c441c-0d53-488d-b730-5029bdfdd470"
    },
    {
      "id": "0003674e-c03d-422c-a3ad-1a21728f2bbe",
      "name": "Convergence Acceleration",
      "categoryId": "193c441c-0d53-488d-b730-5029bdfdd470"
    },
    {
      "id": "1c3c75eb-fb17-4178-ad29-d38ae6ec24a7",
      "name": "Model Stabilization",
      "categoryId": "193c441c-0d53-488d-b730-5029bdfdd470"
    },
    {
      "id": "0d081765-8298-4470-a833-087df98ef1c0",
      "name": "Numerical Methods",
      "categoryId": "193c441c-0d53-488d-b730-5029bdfdd470"
    },
    {
      "id": "4aedd598-609a-4e04-885b-6267533f665c",
      "name": "Gradient Averaging",
      "categoryId": "193c441c-0d53-488d-b730-5029bdfdd470"
    },
    {
      "id": "0cdc2bde-ca47-407b-84c1-ee28eacf6b39",
      "name": "Polyak Averaging Techniques Extensions",
      "categoryId": "eb60f725-cd3b-42fb-8264-a708ee582c93"
    },
    {
      "id": "74963b27-f8fd-4ea0-bdfa-e6bfc40d5ded",
      "name": "Variance Reduction",
      "categoryId": "eb60f725-cd3b-42fb-8264-a708ee582c93"
    },
    {
      "id": "f63dea55-800c-4165-8198-6eb287ddb413",
      "name": "Convergence Acceleration",
      "categoryId": "eb60f725-cd3b-42fb-8264-a708ee582c93"
    },
    {
      "id": "e16da5cb-24f0-4b10-9e1d-b672af0395ac",
      "name": "Stochastic Optimization",
      "categoryId": "eb60f725-cd3b-42fb-8264-a708ee582c93"
    },
    {
      "id": "466d79d1-dfd0-4757-a1b8-539398e8d540",
      "name": "Adaptive Averaging",
      "categoryId": "eb60f725-cd3b-42fb-8264-a708ee582c93"
    },
    {
      "id": "b83b333a-4d7b-4647-8698-d0153f1c47e0",
      "name": "Momentum Methods",
      "categoryId": "eb60f725-cd3b-42fb-8264-a708ee582c93"
    },
    {
      "id": "91ee2aaa-b10c-46a0-b65f-d2220d7673bf",
      "name": "Variance Reduced Gradient Methods",
      "categoryId": "eb60f725-cd3b-42fb-8264-a708ee582c93"
    },
    {
      "id": "56ad7cff-fecd-484f-bdc0-2755eab6c7c6",
      "name": "Iterative Methods",
      "categoryId": "eb60f725-cd3b-42fb-8264-a708ee582c93"
    },
    {
      "id": "c399233d-e478-40dd-95c2-0ee69fb80799",
      "name": "Optimization Enhancements",
      "categoryId": "eb60f725-cd3b-42fb-8264-a708ee582c93"
    },
    {
      "id": "fc348056-a459-42a0-acca-de64d7f7050e",
      "name": "Optimization Techniques",
      "categoryId": "1516c0ec-8acc-4d4d-b3ab-bd75ba42392a"
    },
    {
      "id": "4fd42899-fe0e-470b-8649-289caafb4782",
      "name": "Stochastic Optimization",
      "categoryId": "1516c0ec-8acc-4d4d-b3ab-bd75ba42392a"
    },
    {
      "id": "82741cee-174c-43e9-86cf-19d18d0a39ea",
      "name": "Variance Reduction",
      "categoryId": "1516c0ec-8acc-4d4d-b3ab-bd75ba42392a"
    },
    {
      "id": "d2024473-7480-44d5-8a00-117f2ca3e80f",
      "name": "Adaptive Methods",
      "categoryId": "1516c0ec-8acc-4d4d-b3ab-bd75ba42392a"
    },
    {
      "id": "78ab53aa-d4bf-41d6-9e20-ce79dc29e328",
      "name": "Gradient Averaging",
      "categoryId": "1516c0ec-8acc-4d4d-b3ab-bd75ba42392a"
    },
    {
      "id": "274cbc0c-1a13-4cac-9160-cdd626df7241",
      "name": "Variance Reduction Techniques",
      "categoryId": "1516c0ec-8acc-4d4d-b3ab-bd75ba42392a"
    },
    {
      "id": "44330b53-d6f3-47dc-883f-c2786c7454c9",
      "name": "Learning Rate Schedules",
      "categoryId": "1516c0ec-8acc-4d4d-b3ab-bd75ba42392a"
    },
    {
      "id": "7034221d-d64e-4954-b372-42e86df49ceb",
      "name": "Model Stabilization",
      "categoryId": "1516c0ec-8acc-4d4d-b3ab-bd75ba42392a"
    },
    {
      "id": "69db4b43-013a-468f-9af2-16c15d20902a",
      "name": "Convergence Acceleration",
      "categoryId": "1516c0ec-8acc-4d4d-b3ab-bd75ba42392a"
    },
    {
      "id": "b43f240a-e8a4-4f49-b930-a8085b464f9e",
      "name": "Distributed Optimization",
      "categoryId": "1516c0ec-8acc-4d4d-b3ab-bd75ba42392a"
    },
    {
      "id": "26019a02-ccfb-4661-96b6-318865ff56f4",
      "name": "Polyak Averaging Techniques Extensions Extensions Extensions",
      "categoryId": "d82a717a-5aed-483a-985c-31daec95cb81"
    },
    {
      "id": "88326218-3c3a-4b20-82f4-975f1923a17a",
      "name": "Variance Reduction in Stochastic Optimization",
      "categoryId": "d82a717a-5aed-483a-985c-31daec95cb81"
    },
    {
      "id": "7ee0561a-b820-4641-bf51-8f79f994f0cb",
      "name": "Convergence Acceleration",
      "categoryId": "d82a717a-5aed-483a-985c-31daec95cb81"
    },
    {
      "id": "25da901a-89a1-4a43-92fa-59c64e79daf5",
      "name": "Momentum-based Optimization",
      "categoryId": "d82a717a-5aed-483a-985c-31daec95cb81"
    },
    {
      "id": "3422c7bd-672f-4cb4-abb5-a36586948235",
      "name": "Adaptive Averaging Methods",
      "categoryId": "d82a717a-5aed-483a-985c-31daec95cb81"
    },
    {
      "id": "3656cfc0-af2b-4b4f-9cb5-58f165646b22",
      "name": "Optimization Algorithms in Machine Learning",
      "categoryId": "d82a717a-5aed-483a-985c-31daec95cb81"
    },
    {
      "id": "dbee770b-75b6-4bf5-ad80-af7b9ba749a0",
      "name": "Polyak Averaging Techniques Extensions Extensions Extensions Enhancements Techniques",
      "categoryId": "3f72f147-f36e-4a6b-ba3d-8be862ab91b3"
    },
    {
      "id": "8bdfe8e0-0e52-484f-90bd-6c3d5680ad71",
      "name": "stochastic optimization",
      "categoryId": "3f72f147-f36e-4a6b-ba3d-8be862ab91b3"
    },
    {
      "id": "406807cd-8a62-432a-811d-5f1b59e4c781",
      "name": "parameter averaging",
      "categoryId": "3f72f147-f36e-4a6b-ba3d-8be862ab91b3"
    },
    {
      "id": "1e0f90f8-65fe-469e-93cd-c25e89438d78",
      "name": "convergence acceleration",
      "categoryId": "3f72f147-f36e-4a6b-ba3d-8be862ab91b3"
    },
    {
      "id": "ba173515-a4d7-4444-bc03-8a5bb6ad93dc",
      "name": "machine learning training methods",
      "categoryId": "3f72f147-f36e-4a6b-ba3d-8be862ab91b3"
    },
    {
      "id": "711203c1-d3f6-4311-b8dd-cfd97499b9a0",
      "name": "optimization algorithms",
      "categoryId": "3f72f147-f36e-4a6b-ba3d-8be862ab91b3"
    },
    {
      "id": "191193e6-03c0-418e-be21-752f9254ff23",
      "name": "gradient descent improvements",
      "categoryId": "3f72f147-f36e-4a6b-ba3d-8be862ab91b3"
    },
    {
      "id": "655dfd10-45d4-41b1-bdd5-ac550616d6fc",
      "name": "variance reduction",
      "categoryId": "3f72f147-f36e-4a6b-ba3d-8be862ab91b3"
    },
    {
      "id": "573e9e01-baaf-4aa3-acd7-5fb6682445f4",
      "name": "model stability enhancements",
      "categoryId": "3f72f147-f36e-4a6b-ba3d-8be862ab91b3"
    },
    {
      "id": "4786674c-5365-468f-a504-b8b5f5fbacc1",
      "name": "adaptive averaging methods",
      "categoryId": "3f72f147-f36e-4a6b-ba3d-8be862ab91b3"
    },
    {
      "id": "c7789e1c-e870-4098-8363-10963f7bf1a5",
      "name": "advanced convergence techniques",
      "categoryId": "3f72f147-f36e-4a6b-ba3d-8be862ab91b3"
    },
    {
      "id": "b2d1102e-d9ec-4c86-839e-608473ccb8e0",
      "name": "Polynomial Features",
      "categoryId": "0238721b-3693-4f2c-81a2-ddaa11fad71d"
    },
    {
      "id": "af893db8-0142-42e8-a319-d302436637b3",
      "name": "Feature Engineering",
      "categoryId": "0238721b-3693-4f2c-81a2-ddaa11fad71d"
    },
    {
      "id": "98e45552-dc2d-4169-a1f6-b75e371fff7f",
      "name": "Non-linear Transformation",
      "categoryId": "0238721b-3693-4f2c-81a2-ddaa11fad71d"
    },
    {
      "id": "680c653a-87b6-438d-9d3e-be9d1e264203",
      "name": "Regression",
      "categoryId": "0238721b-3693-4f2c-81a2-ddaa11fad71d"
    },
    {
      "id": "97f568af-f22d-433c-9a3e-49e658be2098",
      "name": "Supervised Learning",
      "categoryId": "0238721b-3693-4f2c-81a2-ddaa11fad71d"
    },
    {
      "id": "7f8d2b3e-0d95-42be-b691-1d93bc99360d",
      "name": "Data Preprocessing",
      "categoryId": "0238721b-3693-4f2c-81a2-ddaa11fad71d"
    },
    {
      "id": "fad176a4-85fd-4cbe-aa65-44673b31a614",
      "name": "Model Enhancement",
      "categoryId": "0238721b-3693-4f2c-81a2-ddaa11fad71d"
    },
    {
      "id": "81f9d698-43e4-43a8-afbb-bd62a90c83f0",
      "name": "Feature Expansion",
      "categoryId": "0238721b-3693-4f2c-81a2-ddaa11fad71d"
    },
    {
      "id": "901ce0ab-210c-482f-b638-be06ffb06885",
      "name": "Polynomial Networks",
      "categoryId": "25fb22cf-839b-4373-afe3-14b1b7f75e55"
    },
    {
      "id": "a27e10f2-9fde-4438-9ee9-cf7e69448f3e",
      "name": "Deep Learning Architectures",
      "categoryId": "25fb22cf-839b-4373-afe3-14b1b7f75e55"
    },
    {
      "id": "df55e05b-c856-466c-8b86-b5ad67624ec3",
      "name": "Non-linear Function Approximation",
      "categoryId": "25fb22cf-839b-4373-afe3-14b1b7f75e55"
    },
    {
      "id": "af6b981c-ded0-4fbd-b0d7-3943fa80df30",
      "name": "Activation Functions",
      "categoryId": "25fb22cf-839b-4373-afe3-14b1b7f75e55"
    },
    {
      "id": "f73c8497-f295-4120-a113-e7c181324e58",
      "name": "Layered Neural Models",
      "categoryId": "25fb22cf-839b-4373-afe3-14b1b7f75e55"
    },
    {
      "id": "818bec1d-d80a-4c58-bc3e-495e7660eca0",
      "name": "Kernel Methods",
      "categoryId": "25fb22cf-839b-4373-afe3-14b1b7f75e55"
    },
    {
      "id": "90b176b7-ac40-4536-a0d6-b28770a48011",
      "name": "Feature Mapping",
      "categoryId": "25fb22cf-839b-4373-afe3-14b1b7f75e55"
    },
    {
      "id": "319c100c-2c16-41dd-896d-d80365d8a504",
      "name": "Hierarchical Models",
      "categoryId": "25fb22cf-839b-4373-afe3-14b1b7f75e55"
    },
    {
      "id": "89e0c031-cd9c-491f-84ce-c567d5ec5bc8",
      "name": "Non-linear Neural Networks",
      "categoryId": "25fb22cf-839b-4373-afe3-14b1b7f75e55"
    },
    {
      "id": "0dc099a6-f049-4e25-99c3-c54cad421858",
      "name": "Regression Analysis",
      "categoryId": "54457308-8214-4333-868f-259d5bed7d25"
    },
    {
      "id": "d7689b69-09e7-46db-b60c-ac193e5d9ea2",
      "name": "Non-linear Regression",
      "categoryId": "54457308-8214-4333-868f-259d5bed7d25"
    },
    {
      "id": "ca2cd0c3-e0db-4b10-92d1-5588bfd1d121",
      "name": "Polynomial Features",
      "categoryId": "54457308-8214-4333-868f-259d5bed7d25"
    },
    {
      "id": "bf057190-ec98-4446-b63e-d9949cd4a2fe",
      "name": "Machine Learning Regression Models",
      "categoryId": "54457308-8214-4333-868f-259d5bed7d25"
    },
    {
      "id": "05df759d-4da8-40b0-a1a2-8e5a74e74f1f",
      "name": "Curve Fitting Techniques",
      "categoryId": "54457308-8214-4333-868f-259d5bed7d25"
    },
    {
      "id": "7be59a04-646b-48b4-a523-87e2646bcc8f",
      "name": "Supervised Learning",
      "categoryId": "54457308-8214-4333-868f-259d5bed7d25"
    },
    {
      "id": "30bdb166-d533-458f-96c8-9b4c952907a8",
      "name": "Data Modeling",
      "categoryId": "54457308-8214-4333-868f-259d5bed7d25"
    },
    {
      "id": "b8c090d2-6acc-44df-ab3e-1052eeae54ce",
      "name": "Parameter Estimation",
      "categoryId": "54457308-8214-4333-868f-259d5bed7d25"
    },
    {
      "id": "9a31f17d-695b-43d7-adbf-94da65ca1e4f",
      "name": "Image Processing",
      "categoryId": "b398ed36-5c3f-4aad-aafd-21421e6c3a30"
    },
    {
      "id": "9dea828d-8519-417f-b8f2-6f1a00291699",
      "name": "Deep Learning",
      "categoryId": "b398ed36-5c3f-4aad-aafd-21421e6c3a30"
    },
    {
      "id": "873a4d64-872f-4623-8b13-b96b52a2bf12",
      "name": "Convolutional Neural Networks (CNNs)",
      "categoryId": "b398ed36-5c3f-4aad-aafd-21421e6c3a30"
    },
    {
      "id": "35672103-c691-428c-a40c-bd489dfc8746",
      "name": "Feature Extraction",
      "categoryId": "b398ed36-5c3f-4aad-aafd-21421e6c3a30"
    },
    {
      "id": "da389c07-393b-46ae-a02d-eadcb263c29a",
      "name": "Spatial Pooling",
      "categoryId": "b398ed36-5c3f-4aad-aafd-21421e6c3a30"
    },
    {
      "id": "71046d65-0ffc-407e-9dd3-c94149a8c917",
      "name": "Max Pooling",
      "categoryId": "b398ed36-5c3f-4aad-aafd-21421e6c3a30"
    },
    {
      "id": "b548b9e4-d118-496a-8338-cdb96ddf15a6",
      "name": "Average Pooling",
      "categoryId": "b398ed36-5c3f-4aad-aafd-21421e6c3a30"
    },
    {
      "id": "6d584a6f-35b3-4dda-abc4-0b29410e04d2",
      "name": "Pooling Operations",
      "categoryId": "b398ed36-5c3f-4aad-aafd-21421e6c3a30"
    },
    {
      "id": "b8a59693-fe9a-41db-8512-289b01c4e464",
      "name": "Downsampling",
      "categoryId": "b398ed36-5c3f-4aad-aafd-21421e6c3a30"
    },
    {
      "id": "4be76067-1efc-4d49-97a9-1173051a855b",
      "name": "Data Reduction",
      "categoryId": "b398ed36-5c3f-4aad-aafd-21421e6c3a30"
    },
    {
      "id": "28f6acbc-f3a6-419d-8855-988beb4cf23d",
      "name": "Neural Network Architecture",
      "categoryId": "b398ed36-5c3f-4aad-aafd-21421e6c3a30"
    },
    {
      "id": "31823a6d-6fd8-4603-92c6-1e3fdad3392b",
      "name": "Pooling Layers",
      "categoryId": "a14cfc34-aca7-4cfd-9482-2b1d5b5559d5"
    },
    {
      "id": "5f4a735a-fa6d-41e0-a2f2-9dddcf034555",
      "name": "Max Pooling",
      "categoryId": "a14cfc34-aca7-4cfd-9482-2b1d5b5559d5"
    },
    {
      "id": "95df7ed5-b5bc-4a19-9d73-dcfc7f1af217",
      "name": "Average Pooling",
      "categoryId": "a14cfc34-aca7-4cfd-9482-2b1d5b5559d5"
    },
    {
      "id": "5748ff4b-6f08-48b0-9fd5-8fe56060d7e8",
      "name": "Spatial Pooling",
      "categoryId": "a14cfc34-aca7-4cfd-9482-2b1d5b5559d5"
    },
    {
      "id": "895aaec3-4d56-413d-875a-b1825a178d07",
      "name": "Downsampling",
      "categoryId": "a14cfc34-aca7-4cfd-9482-2b1d5b5559d5"
    },
    {
      "id": "eaaf8457-f0d6-401a-94d1-5ceb9e7bbc6a",
      "name": "Feature Extraction",
      "categoryId": "a14cfc34-aca7-4cfd-9482-2b1d5b5559d5"
    },
    {
      "id": "5e5e16e9-634e-48b3-96ae-e0e413bb9b68",
      "name": "Convolutional Neural Networks (CNNs)",
      "categoryId": "a14cfc34-aca7-4cfd-9482-2b1d5b5559d5"
    },
    {
      "id": "4a5005c1-d97c-4594-8644-ffb81beafb59",
      "name": "Image Processing",
      "categoryId": "a14cfc34-aca7-4cfd-9482-2b1d5b5559d5"
    },
    {
      "id": "3c954567-5d0c-434c-bf63-771a20c2ca83",
      "name": "Dimensionality Reduction",
      "categoryId": "a14cfc34-aca7-4cfd-9482-2b1d5b5559d5"
    },
    {
      "id": "b07966f5-3cc5-49fd-9f3c-cb131d8b7b34",
      "name": "Pooling Operations",
      "categoryId": "a14cfc34-aca7-4cfd-9482-2b1d5b5559d5"
    },
    {
      "id": "d723bd8c-a7ca-4160-a9be-34147177e1a4",
      "name": "Statistical Sampling",
      "categoryId": "254cf1d5-ad68-42ea-8f45-76e4372a7117"
    },
    {
      "id": "11a46b8d-5737-4cf7-ab76-c9f410478beb",
      "name": "Dataset Analysis",
      "categoryId": "254cf1d5-ad68-42ea-8f45-76e4372a7117"
    },
    {
      "id": "48093e74-fece-4b4b-8c26-7bc1876889f3",
      "name": "Data Distributions",
      "categoryId": "254cf1d5-ad68-42ea-8f45-76e4372a7117"
    },
    {
      "id": "ebabe900-e1a3-4187-9ee6-265e1e19230e",
      "name": "Population Parameters",
      "categoryId": "254cf1d5-ad68-42ea-8f45-76e4372a7117"
    },
    {
      "id": "53e4dad2-ea68-427a-af63-572ce59dd52c",
      "name": "Population Studies",
      "categoryId": "254cf1d5-ad68-42ea-8f45-76e4372a7117"
    },
    {
      "id": "e1ed9cb7-bdb0-47e7-87a1-32a2750742b1",
      "name": "Demographics",
      "categoryId": "254cf1d5-ad68-42ea-8f45-76e4372a7117"
    },
    {
      "id": "0e317222-3384-42c7-8af9-96f483fd59c0",
      "name": "Census Data",
      "categoryId": "254cf1d5-ad68-42ea-8f45-76e4372a7117"
    },
    {
      "id": "28825bec-e862-4e7d-98dc-8cf0e114c6b9",
      "name": "Biological Populations",
      "categoryId": "254cf1d5-ad68-42ea-8f45-76e4372a7117"
    },
    {
      "id": "41e39f4b-94fc-4f8b-b92a-a06cb2cbedd5",
      "name": "Sampling Techniques",
      "categoryId": "254cf1d5-ad68-42ea-8f45-76e4372a7117"
    },
    {
      "id": "9e90a341-a0c6-41d2-8d70-a43e6737ae4d",
      "name": "Population-Based Training (PBT)",
      "categoryId": "342ac1a3-a364-4416-a936-860e0936c195"
    },
    {
      "id": "fbd9b1da-3315-4b04-8c2e-57f0a61f6d80",
      "name": "Hyperparameter Optimization",
      "categoryId": "342ac1a3-a364-4416-a936-860e0936c195"
    },
    {
      "id": "ac36ee5e-f010-4102-80ef-dcf0a16e372a",
      "name": "Adaptive Machine Learning",
      "categoryId": "342ac1a3-a364-4416-a936-860e0936c195"
    },
    {
      "id": "c5826e65-ad06-4a9a-9d81-feb8c38e2df0",
      "name": "Automated Tuning",
      "categoryId": "342ac1a3-a364-4416-a936-860e0936c195"
    },
    {
      "id": "9da1ac1c-89d5-442c-a9b4-ae1142dd303a",
      "name": "Model Training Strategies",
      "categoryId": "342ac1a3-a364-4416-a936-860e0936c195"
    },
    {
      "id": "0a71ed44-7266-4361-b323-469c8bfebac4",
      "name": "Progressive Hyperparameter Adjustment",
      "categoryId": "342ac1a3-a364-4416-a936-860e0936c195"
    },
    {
      "id": "5af0913f-1c26-4ab5-886a-d360ceaf3fe4",
      "name": "Dynamic Learning Rate",
      "categoryId": "342ac1a3-a364-4416-a936-860e0936c195"
    },
    {
      "id": "6ff85f7a-c173-49bc-895c-4b7e1d1b524b",
      "name": "Controller Algorithms",
      "categoryId": "342ac1a3-a364-4416-a936-860e0936c195"
    },
    {
      "id": "8d62edd2-395a-4870-94ae-28d756e52b16",
      "name": "Self-Improving Systems",
      "categoryId": "342ac1a3-a364-4416-a936-860e0936c195"
    },
    {
      "id": "cd69ed2e-a524-4d79-b2f3-32516bcb9b08",
      "name": "Optimization Techniques",
      "categoryId": "342ac1a3-a364-4416-a936-860e0936c195"
    },
    {
      "id": "e03f2718-6157-4f54-bedb-fec77b374420",
      "name": "AutoML",
      "categoryId": "602c83f9-44b1-40ec-b3fa-ec4a0eefb9e1"
    },
    {
      "id": "3143752e-f16e-4cf5-b275-be517dc35f15",
      "name": "Hyperparameter Optimization",
      "categoryId": "602c83f9-44b1-40ec-b3fa-ec4a0eefb9e1"
    },
    {
      "id": "36bbf046-4e78-4afa-be84-4aa491bd127e",
      "name": "Model Training",
      "categoryId": "602c83f9-44b1-40ec-b3fa-ec4a0eefb9e1"
    },
    {
      "id": "33b04518-36b2-49fb-9b5f-2478ede69d20",
      "name": "Neural Architecture Search",
      "categoryId": "602c83f9-44b1-40ec-b3fa-ec4a0eefb9e1"
    },
    {
      "id": "d3424255-2cbc-42fa-b89c-5fccaf9e9b6a",
      "name": "Machine Learning Pipelines",
      "categoryId": "602c83f9-44b1-40ec-b3fa-ec4a0eefb9e1"
    },
    {
      "id": "928e453d-dc80-4f97-bda6-07e47fcde63f",
      "name": "Reinforcement Learning",
      "categoryId": "602c83f9-44b1-40ec-b3fa-ec4a0eefb9e1"
    },
    {
      "id": "6d524857-3fa6-4301-842b-7febcbb2c98c",
      "name": "Meta-Learning",
      "categoryId": "602c83f9-44b1-40ec-b3fa-ec4a0eefb9e1"
    },
    {
      "id": "93e1073f-47a1-4668-b8ac-0fb2fe38c794",
      "name": "Optimization Algorithms",
      "categoryId": "602c83f9-44b1-40ec-b3fa-ec4a0eefb9e1"
    },
    {
      "id": "b97fa65f-a67b-4f5f-898b-b4ee38e35380",
      "name": "Pose Estimation",
      "categoryId": "ffdb9d1f-02d8-4c6c-b49b-6e3343d4b51d"
    },
    {
      "id": "f628b3ab-ea1c-4015-84a4-5c572e46eb31",
      "name": "Human Pose Detection",
      "categoryId": "ffdb9d1f-02d8-4c6c-b49b-6e3343d4b51d"
    },
    {
      "id": "1f53386c-7058-48e9-b0a6-b8795735f26e",
      "name": "Body Landmark Detection",
      "categoryId": "ffdb9d1f-02d8-4c6c-b49b-6e3343d4b51d"
    },
    {
      "id": "113c789a-9aa4-4f9d-860f-632cff2d5c9a",
      "name": "Skeleton Tracking",
      "categoryId": "ffdb9d1f-02d8-4c6c-b49b-6e3343d4b51d"
    },
    {
      "id": "3cb3be1d-471d-4e7d-9afb-96642caf79e4",
      "name": "2D Pose Detection",
      "categoryId": "ffdb9d1f-02d8-4c6c-b49b-6e3343d4b51d"
    },
    {
      "id": "5d12514f-6f80-445e-a26a-3ef1564c6319",
      "name": "3D Pose Estimation",
      "categoryId": "ffdb9d1f-02d8-4c6c-b49b-6e3343d4b51d"
    },
    {
      "id": "3a987b5b-53d2-4ea8-9bb6-05f4a05b0ceb",
      "name": "Computer Vision",
      "categoryId": "8a721960-fff7-4813-a4f2-8f77e254e8db"
    },
    {
      "id": "815234fa-ad9e-4f85-845c-6712aa72dc04",
      "name": "Human Pose Estimation",
      "categoryId": "8a721960-fff7-4813-a4f2-8f77e254e8db"
    },
    {
      "id": "6b06b2af-5a67-4543-a01a-7d3bb55b2d96",
      "name": "2D Pose Estimation",
      "categoryId": "8a721960-fff7-4813-a4f2-8f77e254e8db"
    },
    {
      "id": "268a4dce-dc9c-4668-97eb-837fe7713fcb",
      "name": "3D Pose Estimation",
      "categoryId": "8a721960-fff7-4813-a4f2-8f77e254e8db"
    },
    {
      "id": "25dff3f1-2655-45ee-931c-477cd2671a10",
      "name": "Keypoint Detection",
      "categoryId": "8a721960-fff7-4813-a4f2-8f77e254e8db"
    },
    {
      "id": "a9aa86ef-6ad3-424d-a6e7-88e523b9fdf7",
      "name": "Skeleton Tracking",
      "categoryId": "8a721960-fff7-4813-a4f2-8f77e254e8db"
    },
    {
      "id": "9e15c927-91dc-4bbe-959a-8d48890c7ef9",
      "name": "Deep Learning",
      "categoryId": "8a721960-fff7-4813-a4f2-8f77e254e8db"
    },
    {
      "id": "0e395b53-0f9c-4123-a69e-3b020e42888b",
      "name": "Convolutional Neural Networks (CNNs)",
      "categoryId": "8a721960-fff7-4813-a4f2-8f77e254e8db"
    },
    {
      "id": "2b6b2e60-a48f-43f7-9ac1-e8f974a1bb7e",
      "name": "Keypoint Localization",
      "categoryId": "8a721960-fff7-4813-a4f2-8f77e254e8db"
    },
    {
      "id": "5ecd11d6-6168-48e4-aef3-1ab194542975",
      "name": "Positional Encoding",
      "categoryId": "f34d19d0-a386-44a1-8827-fdbb79251700"
    },
    {
      "id": "3a3dd668-4f14-4ec4-a7b7-648765116ac7",
      "name": "Sequence Modeling",
      "categoryId": "f34d19d0-a386-44a1-8827-fdbb79251700"
    },
    {
      "id": "12fbe8ad-5182-41e6-b046-3347b2454961",
      "name": "Attention Mechanisms",
      "categoryId": "f34d19d0-a386-44a1-8827-fdbb79251700"
    },
    {
      "id": "3c1b9dd0-fbf8-4b53-8518-6ec43fccead8",
      "name": "Transformers",
      "categoryId": "f34d19d0-a386-44a1-8827-fdbb79251700"
    },
    {
      "id": "ed6b3594-ce58-443f-98ee-02ed64e14a65",
      "name": "NLP",
      "categoryId": "f34d19d0-a386-44a1-8827-fdbb79251700"
    },
    {
      "id": "6d30db0a-086a-43c8-9219-922dd01fc332",
      "name": "Deep Learning",
      "categoryId": "f34d19d0-a386-44a1-8827-fdbb79251700"
    },
    {
      "id": "616869d0-ea84-4376-a1de-3e11e9dfac26",
      "name": "Embeddings",
      "categoryId": "f34d19d0-a386-44a1-8827-fdbb79251700"
    },
    {
      "id": "20d3deb7-428f-4760-ab27-91ae289c4ab4",
      "name": "Spatial Encoding",
      "categoryId": "f34d19d0-a386-44a1-8827-fdbb79251700"
    },
    {
      "id": "fe9f9e50-bc0b-4788-ace0-2fdb69d3223f",
      "name": "Temporal Encoding",
      "categoryId": "f34d19d0-a386-44a1-8827-fdbb79251700"
    },
    {
      "id": "bb0e36a6-a68d-47af-b7b7-bc622fa5bc82",
      "name": "Positional Encoding Techniques",
      "categoryId": "23715765-4079-4d61-b87a-247d3c78c7a9"
    },
    {
      "id": "df3f9ecf-ae54-4cee-9b2b-b70160464ad6",
      "name": "Sequence Modeling",
      "categoryId": "23715765-4079-4d61-b87a-247d3c78c7a9"
    },
    {
      "id": "31bf8c83-2924-4d93-82f9-573b3f07f19e",
      "name": "Transformer Architecture",
      "categoryId": "23715765-4079-4d61-b87a-247d3c78c7a9"
    },
    {
      "id": "07e17e99-cf6d-4c33-a658-a9a23c852d9c",
      "name": "NLP",
      "categoryId": "23715765-4079-4d61-b87a-247d3c78c7a9"
    },
    {
      "id": "e79b0741-0f79-49d4-95cf-9ace48f1e5e2",
      "name": "Attention Mechanisms",
      "categoryId": "23715765-4079-4d61-b87a-247d3c78c7a9"
    },
    {
      "id": "6a690ec7-4d00-4ef6-9a36-ebef43c03078",
      "name": "Deep Learning",
      "categoryId": "23715765-4079-4d61-b87a-247d3c78c7a9"
    },
    {
      "id": "e206467b-9668-4220-b9a1-b90efd443a88",
      "name": "Embedding Methods",
      "categoryId": "23715765-4079-4d61-b87a-247d3c78c7a9"
    },
    {
      "id": "a78f0e72-34fc-4104-81e5-599ada87f031",
      "name": "Model Optimization",
      "categoryId": "23715765-4079-4d61-b87a-247d3c78c7a9"
    },
    {
      "id": "39ee87d0-0518-4aa5-9183-f5dec07885d8",
      "name": "Sequential Data",
      "categoryId": "23715765-4079-4d61-b87a-247d3c78c7a9"
    },
    {
      "id": "a58d2887-72e2-4364-8907-247b7e47df79",
      "name": "Contextual Encoding",
      "categoryId": "23715765-4079-4d61-b87a-247d3c78c7a9"
    },
    {
      "id": "52edbded-bcc9-4848-9486-81a2e0c20933",
      "name": "Classification Metrics",
      "categoryId": "3b2fdf5c-5393-45ad-90a7-ad7f56f591d1"
    },
    {
      "id": "25fca681-cd9f-4e52-a42b-87980c4beca9",
      "name": "Predictive Validity",
      "categoryId": "3b2fdf5c-5393-45ad-90a7-ad7f56f591d1"
    },
    {
      "id": "88335458-10b7-4762-8992-9c5cf97fee97",
      "name": "Model Evaluation",
      "categoryId": "3b2fdf5c-5393-45ad-90a7-ad7f56f591d1"
    },
    {
      "id": "c68b177f-1874-41b8-a418-62ef70f64975",
      "name": "Statistical Metrics",
      "categoryId": "3b2fdf5c-5393-45ad-90a7-ad7f56f591d1"
    },
    {
      "id": "71387ace-389c-4be8-b2bf-45729e6a9fc0",
      "name": "Machine Learning Evaluation",
      "categoryId": "3b2fdf5c-5393-45ad-90a7-ad7f56f591d1"
    },
    {
      "id": "b2463f9c-a1e5-43bf-852b-cfe8428c37d5",
      "name": "Confusion Matrix Components",
      "categoryId": "3b2fdf5c-5393-45ad-90a7-ad7f56f591d1"
    },
    {
      "id": "693e85ae-9d66-420f-bf18-423068458241",
      "name": "Diagnostic Testing",
      "categoryId": "3b2fdf5c-5393-45ad-90a7-ad7f56f591d1"
    },
    {
      "id": "70681450-65cb-4823-b39f-7349ed0a593b",
      "name": "Model Performance Metrics",
      "categoryId": "3b2fdf5c-5393-45ad-90a7-ad7f56f591d1"
    },
    {
      "id": "100c227d-d01c-4c85-bfee-147cb2d3de7d",
      "name": "semi-supervised learning",
      "categoryId": "e6628bfb-ee12-497e-b253-1a3f8b959dcf"
    },
    {
      "id": "3ced3a46-285a-4004-b2d8-5cba8258c8a4",
      "name": "positive-unlabeled learning",
      "categoryId": "e6628bfb-ee12-497e-b253-1a3f8b959dcf"
    },
    {
      "id": "6fed4e08-6232-4be5-8371-3754ac3e6b6c",
      "name": "PU learning",
      "categoryId": "e6628bfb-ee12-497e-b253-1a3f8b959dcf"
    },
    {
      "id": "1923be93-9659-44ce-8e40-faeab0f2fd5f",
      "name": "weak supervision",
      "categoryId": "e6628bfb-ee12-497e-b253-1a3f8b959dcf"
    },
    {
      "id": "c06ccfbb-e42b-4cd4-a5ec-bc16549de513",
      "name": "label noise",
      "categoryId": "e6628bfb-ee12-497e-b253-1a3f8b959dcf"
    },
    {
      "id": "0d1812ba-c3a0-4211-94a3-56aac79e1e53",
      "name": "anomaly detection",
      "categoryId": "e6628bfb-ee12-497e-b253-1a3f8b959dcf"
    },
    {
      "id": "f208499f-5bef-4177-917d-57fb0b9a09e0",
      "name": "data sampling strategies",
      "categoryId": "e6628bfb-ee12-497e-b253-1a3f8b959dcf"
    },
    {
      "id": "5b9b0ee7-b58a-4d38-b480-0739c8b838c3",
      "name": "Post-hoc Interpretability",
      "categoryId": "b2f02031-5e66-4570-b8da-ba3f0443f1e3"
    },
    {
      "id": "0c3d69f0-e7aa-406f-9c7a-7173a619db40",
      "name": "Model Explanation",
      "categoryId": "b2f02031-5e66-4570-b8da-ba3f0443f1e3"
    },
    {
      "id": "aef02fb1-b207-46f1-8dc0-8219cf0a24c5",
      "name": "Explainable AI (XAI)",
      "categoryId": "b2f02031-5e66-4570-b8da-ba3f0443f1e3"
    },
    {
      "id": "b3a02038-d317-4185-b7f6-48817d710251",
      "name": "Model Transparency",
      "categoryId": "b2f02031-5e66-4570-b8da-ba3f0443f1e3"
    },
    {
      "id": "9bee2039-75f7-4d30-bd37-8d708fd6dc41",
      "name": "Post-hoc Analysis",
      "categoryId": "b2f02031-5e66-4570-b8da-ba3f0443f1e3"
    },
    {
      "id": "d31b9070-a415-485b-948c-cde62dc9afe4",
      "name": "Interpretability Techniques",
      "categoryId": "b2f02031-5e66-4570-b8da-ba3f0443f1e3"
    },
    {
      "id": "29503f15-cd97-44d2-a9ac-31ee9aeea1ee",
      "name": "Explainability Methods",
      "categoryId": "b2f02031-5e66-4570-b8da-ba3f0443f1e3"
    },
    {
      "id": "8749f113-5af0-49dd-a1be-86d40b286eff",
      "name": "Model Debugging",
      "categoryId": "b2f02031-5e66-4570-b8da-ba3f0443f1e3"
    },
    {
      "id": "53ded6dc-593c-4611-bbca-9e440bd1614f",
      "name": "Transparent AI",
      "categoryId": "b2f02031-5e66-4570-b8da-ba3f0443f1e3"
    },
    {
      "id": "5b278721-516b-4846-b45a-65ead30bd6ba",
      "name": "Black-box Models",
      "categoryId": "b2f02031-5e66-4570-b8da-ba3f0443f1e3"
    },
    {
      "id": "33eecbc5-6987-4e33-84d2-cb69dde8a5a9",
      "name": "Model Optimization",
      "categoryId": "0caf7b8c-8da8-4375-b22f-895c516668cc"
    },
    {
      "id": "e016c8fc-c951-4658-abd2-17015c7172e4",
      "name": "Quantization",
      "categoryId": "0caf7b8c-8da8-4375-b22f-895c516668cc"
    },
    {
      "id": "7e1454c6-6b03-4de1-83cd-9fca88fe496a",
      "name": "Post-Training Compression",
      "categoryId": "0caf7b8c-8da8-4375-b22f-895c516668cc"
    },
    {
      "id": "e63659fb-8a2e-4e3d-8fed-441f08e9997c",
      "name": "Quantization-Aware Training",
      "categoryId": "0caf7b8c-8da8-4375-b22f-895c516668cc"
    },
    {
      "id": "f9ea7ceb-3634-43bf-bfab-fd0021a2b4d0",
      "name": "Model Deployment",
      "categoryId": "0caf7b8c-8da8-4375-b22f-895c516668cc"
    },
    {
      "id": "1498c648-bb83-47f5-a971-59e63404035f",
      "name": "Neural Network Pruning",
      "categoryId": "0caf7b8c-8da8-4375-b22f-895c516668cc"
    },
    {
      "id": "891cc3f2-c4f9-4082-907f-16ef9be4addb",
      "name": "Hardware Acceleration",
      "categoryId": "0caf7b8c-8da8-4375-b22f-895c516668cc"
    },
    {
      "id": "bc0cf7ac-6c63-46a8-9b0d-db8b646219be",
      "name": "Model Optimization",
      "categoryId": "0c4cce23-7ea5-44bc-beda-411af30e330b"
    },
    {
      "id": "6e8b660e-cd3f-421c-9df9-ca74da798267",
      "name": "Quantization Techniques",
      "categoryId": "0c4cce23-7ea5-44bc-beda-411af30e330b"
    },
    {
      "id": "b5e183a2-e777-43e8-a4d8-0a8eaafd596d",
      "name": "Post-Training Quantization",
      "categoryId": "0c4cce23-7ea5-44bc-beda-411af30e330b"
    },
    {
      "id": "f7c32a16-fdf8-485b-9ad3-71074aa9c82e",
      "name": "Deep Learning",
      "categoryId": "0c4cce23-7ea5-44bc-beda-411af30e330b"
    },
    {
      "id": "3cd0b0f3-54ae-4a1e-98a8-2c77ec999bee",
      "name": "Neural Network Compression",
      "categoryId": "0c4cce23-7ea5-44bc-beda-411af30e330b"
    },
    {
      "id": "0126a3c9-d31b-459a-b844-79f1c08e4e58",
      "name": "Model Deployment",
      "categoryId": "0c4cce23-7ea5-44bc-beda-411af30e330b"
    },
    {
      "id": "e1ea4160-941c-4970-9f0d-c866969fd358",
      "name": "Precision Reduction",
      "categoryId": "0c4cce23-7ea5-44bc-beda-411af30e330b"
    },
    {
      "id": "950b3d10-761a-47d5-af83-eae8b4ba7729",
      "name": "Quantization-Aware Training",
      "categoryId": "0c4cce23-7ea5-44bc-beda-411af30e330b"
    },
    {
      "id": "37321d91-600a-4180-95ca-2f83572a3d60",
      "name": "Edge AI",
      "categoryId": "0c4cce23-7ea5-44bc-beda-411af30e330b"
    },
    {
      "id": "d23db6b2-bb38-4a7f-9bc0-f6cd60ec7e77",
      "name": "Inference Optimization",
      "categoryId": "0c4cce23-7ea5-44bc-beda-411af30e330b"
    },
    {
      "id": "fcd0f858-e1a9-4f54-b8d0-1b9538703f31",
      "name": "Bayesian Methods",
      "categoryId": "0ea3390d-96ff-42b2-bef7-c0076524920a"
    },
    {
      "id": "684db5ba-8377-4d02-b69e-d055f23440d6",
      "name": "Inference Algorithms",
      "categoryId": "0ea3390d-96ff-42b2-bef7-c0076524920a"
    },
    {
      "id": "f4a39b39-690f-4d51-981a-a89e6e6f7b69",
      "name": "Probabilistic Models",
      "categoryId": "0ea3390d-96ff-42b2-bef7-c0076524920a"
    },
    {
      "id": "5cf0a57f-19eb-40f1-822b-e284345bf91e",
      "name": "Estimation Theory",
      "categoryId": "0ea3390d-96ff-42b2-bef7-c0076524920a"
    },
    {
      "id": "61474cc6-070b-4d4e-81bd-ed5eeec07286",
      "name": "Statistical Power Analysis",
      "categoryId": "44b99a4d-6562-472e-abca-2c13e9503d1f"
    },
    {
      "id": "f790fe7c-a2be-448f-ae8d-578870d27275",
      "name": "Sample Size Calculation",
      "categoryId": "44b99a4d-6562-472e-abca-2c13e9503d1f"
    },
    {
      "id": "ddade37d-79ba-4824-9b98-b9cdec3eaac4",
      "name": "Effect Size",
      "categoryId": "44b99a4d-6562-472e-abca-2c13e9503d1f"
    },
    {
      "id": "947faa73-10fc-4210-a281-bea5e1fb11e1",
      "name": "Significance Level",
      "categoryId": "44b99a4d-6562-472e-abca-2c13e9503d1f"
    },
    {
      "id": "b3ee45e9-60d9-4f85-8c02-17484d441987",
      "name": "Power (1 - \u03b2)",
      "categoryId": "44b99a4d-6562-472e-abca-2c13e9503d1f"
    },
    {
      "id": "4f7335ab-0f81-4bbd-bbd1-158f4db0269b",
      "name": "Type I and Type II Errors",
      "categoryId": "44b99a4d-6562-472e-abca-2c13e9503d1f"
    },
    {
      "id": "af5e34b9-5884-4ab7-90fb-26fe82f968df",
      "name": "Hypothesis Testing",
      "categoryId": "44b99a4d-6562-472e-abca-2c13e9503d1f"
    },
    {
      "id": "8d81715a-2555-4e23-9e08-53f17c9f2e1e",
      "name": "Experimental Design",
      "categoryId": "44b99a4d-6562-472e-abca-2c13e9503d1f"
    },
    {
      "id": "643b37f3-7311-491f-901c-595a4046cb7a",
      "name": "Sensitivity Analysis",
      "categoryId": "44b99a4d-6562-472e-abca-2c13e9503d1f"
    },
    {
      "id": "0be1e202-22b1-497b-aafd-e6671e90599d",
      "name": "Eigenvalue algorithms",
      "categoryId": "fdccc823-9f42-4e83-8af3-614834277df4"
    },
    {
      "id": "70fd474c-c860-4cae-9b0b-92f15cad2f07",
      "name": "Spectral methods",
      "categoryId": "fdccc823-9f42-4e83-8af3-614834277df4"
    },
    {
      "id": "476bf1a2-a7ca-4bd4-9089-8233887380e0",
      "name": "Matrix power techniques",
      "categoryId": "fdccc823-9f42-4e83-8af3-614834277df4"
    },
    {
      "id": "fb6b85ea-1b35-4dfa-b9e5-67361d77e45d",
      "name": "Iterative algorithms",
      "categoryId": "fdccc823-9f42-4e83-8af3-614834277df4"
    },
    {
      "id": "bd1365b9-190e-4ddb-b464-0edaf46fba71",
      "name": "Numerical linear algebra",
      "categoryId": "fdccc823-9f42-4e83-8af3-614834277df4"
    },
    {
      "id": "8c40edd3-cbb8-4d1d-a0af-5b7631e5f079",
      "name": "Principal component analysis (PCA)",
      "categoryId": "fdccc823-9f42-4e83-8af3-614834277df4"
    },
    {
      "id": "fedb6bba-ae78-4b4f-8f76-37b12f966b32",
      "name": "Eigenvector computation",
      "categoryId": "fdccc823-9f42-4e83-8af3-614834277df4"
    },
    {
      "id": "1ab5d623-1760-4680-862a-1c3fff200f5a",
      "name": "Spectral decomposition",
      "categoryId": "fdccc823-9f42-4e83-8af3-614834277df4"
    },
    {
      "id": "018ec202-7510-4eae-b3ec-2f18c04923e5",
      "name": "Matrix analysis",
      "categoryId": "fdccc823-9f42-4e83-8af3-614834277df4"
    },
    {
      "id": "b47581ee-f92d-42ba-88f3-9650c2686383",
      "name": "Linear algebra subfields",
      "categoryId": "fdccc823-9f42-4e83-8af3-614834277df4"
    },
    {
      "id": "324eb9c8-bd2a-4deb-8a2f-c7e6d0196718",
      "name": "Normalization techniques",
      "categoryId": "0f61dbd9-d17b-4dc4-afe8-50e26577fae3"
    },
    {
      "id": "174e63c3-fccf-4042-ab4f-0618eed5cc9b",
      "name": "Data preprocessing",
      "categoryId": "0f61dbd9-d17b-4dc4-afe8-50e26577fae3"
    },
    {
      "id": "ca754288-c1c0-4843-90d0-e62ca812db29",
      "name": "Feature scaling",
      "categoryId": "0f61dbd9-d17b-4dc4-afe8-50e26577fae3"
    },
    {
      "id": "5349647f-6037-4a19-9fe3-f2ed6a0053f3",
      "name": "Machine Learning preprocessing",
      "categoryId": "0f61dbd9-d17b-4dc4-afe8-50e26577fae3"
    },
    {
      "id": "75f1f33e-7df4-48e0-83f7-9aed42088e57",
      "name": "Data standardization",
      "categoryId": "0f61dbd9-d17b-4dc4-afe8-50e26577fae3"
    },
    {
      "id": "2cdee3fd-8c66-480c-b047-25662f7b9e68",
      "name": "Data normalization methods",
      "categoryId": "0f61dbd9-d17b-4dc4-afe8-50e26577fae3"
    },
    {
      "id": "018eae7b-cb77-4699-be1e-497e11fc1b84",
      "name": "Statistics",
      "categoryId": "5e878ac9-6c86-4cd7-a5ae-8f2817780720"
    },
    {
      "id": "8575cab6-f992-4f8a-ae22-1d59ad76bf20",
      "name": "Hypothesis Testing",
      "categoryId": "5e878ac9-6c86-4cd7-a5ae-8f2817780720"
    },
    {
      "id": "8a63c893-0374-43ee-acb4-57ad9010854e",
      "name": "Type I and Type II Errors",
      "categoryId": "5e878ac9-6c86-4cd7-a5ae-8f2817780720"
    },
    {
      "id": "7d465b30-db4d-43d0-9365-a8a06c581de3",
      "name": "Significance Level",
      "categoryId": "5e878ac9-6c86-4cd7-a5ae-8f2817780720"
    },
    {
      "id": "6757b87a-6876-4bb5-bb78-f449c4726dd3",
      "name": "Critical Region",
      "categoryId": "5e878ac9-6c86-4cd7-a5ae-8f2817780720"
    },
    {
      "id": "143f47b8-0601-4b3f-a071-0368af1b57b0",
      "name": "Statistical Power",
      "categoryId": "5e878ac9-6c86-4cd7-a5ae-8f2817780720"
    },
    {
      "id": "65c3404e-9065-4557-9f2d-0fa6d6abda9a",
      "name": "Confidence Intervals",
      "categoryId": "5e878ac9-6c86-4cd7-a5ae-8f2817780720"
    },
    {
      "id": "f235d2a2-2a26-49e4-8288-b9a2e1a97b31",
      "name": "Null Hypothesis",
      "categoryId": "5e878ac9-6c86-4cd7-a5ae-8f2817780720"
    },
    {
      "id": "36e67317-f8b1-48f1-9f69-bd4a0e40ed4e",
      "name": "Alternative Hypothesis",
      "categoryId": "5e878ac9-6c86-4cd7-a5ae-8f2817780720"
    },
    {
      "id": "2e2bf9b5-c168-455b-b126-092cb708a81c",
      "name": "Sample Size",
      "categoryId": "5e878ac9-6c86-4cd7-a5ae-8f2817780720"
    },
    {
      "id": "933277a5-e2cf-4199-90bc-40207a6e3247",
      "name": "Effect Size",
      "categoryId": "5e878ac9-6c86-4cd7-a5ae-8f2817780720"
    },
    {
      "id": "a35c2188-6396-422c-9a69-92a9053c97e0",
      "name": "Graph Theory",
      "categoryId": "a21ebbb6-559b-4556-bf43-82f68c6ffd5c"
    },
    {
      "id": "421e91f8-6603-4220-9184-e6d903b1ec33",
      "name": "Network Science",
      "categoryId": "a21ebbb6-559b-4556-bf43-82f68c6ffd5c"
    },
    {
      "id": "3759b95c-9ecd-494d-8f9b-ced7d566eaf9",
      "name": "Complex Networks",
      "categoryId": "a21ebbb6-559b-4556-bf43-82f68c6ffd5c"
    },
    {
      "id": "781b3271-065a-43bc-a193-bcb64a39ec5f",
      "name": "Cluster Analysis",
      "categoryId": "a21ebbb6-559b-4556-bf43-82f68c6ffd5c"
    },
    {
      "id": "f9cd6d3f-25f7-4d0d-96ca-144b847ad43e",
      "name": "Power-Law Distributions",
      "categoryId": "a21ebbb6-559b-4556-bf43-82f68c6ffd5c"
    },
    {
      "id": "38a2bbe7-bd3c-43ac-8ed8-986189ffeca5",
      "name": "Scale-Free Networks",
      "categoryId": "a21ebbb6-559b-4556-bf43-82f68c6ffd5c"
    },
    {
      "id": "1aa17cae-ffd5-44b7-9527-31011858deb0",
      "name": "Graph Clustering",
      "categoryId": "a21ebbb6-559b-4556-bf43-82f68c6ffd5c"
    },
    {
      "id": "34cc2969-1797-412b-98d7-af703e9972b7",
      "name": "Hierarchical Clustering",
      "categoryId": "a21ebbb6-559b-4556-bf43-82f68c6ffd5c"
    },
    {
      "id": "6ef7451b-7f4c-406a-879a-0788d11e0ce2",
      "name": "Network Topology",
      "categoryId": "a21ebbb6-559b-4556-bf43-82f68c6ffd5c"
    },
    {
      "id": "b00c09cd-1c15-4a5d-b2e0-e39637acfabc",
      "name": "Community Detection",
      "categoryId": "a21ebbb6-559b-4556-bf43-82f68c6ffd5c"
    },
    {
      "id": "29b69913-6a58-4d72-999f-0ea4a37b14f3",
      "name": "Graph Theory",
      "categoryId": "e5dbd346-fd12-437c-9370-43110d575dbb"
    },
    {
      "id": "39d9961a-e8c4-4b91-824a-8fe14a752af3",
      "name": "Network Science",
      "categoryId": "e5dbd346-fd12-437c-9370-43110d575dbb"
    },
    {
      "id": "e089b54d-fb8c-472d-9254-df86eaf9fa4d",
      "name": "Scale-Free Networks",
      "categoryId": "e5dbd346-fd12-437c-9370-43110d575dbb"
    },
    {
      "id": "a5668c0a-94fd-4d6a-9760-d299b2f8c205",
      "name": "Degree Distribution",
      "categoryId": "e5dbd346-fd12-437c-9370-43110d575dbb"
    },
    {
      "id": "3d8f5cd4-2b73-4d61-af76-5f7e0541203b",
      "name": "Power-Law Distribution",
      "categoryId": "e5dbd346-fd12-437c-9370-43110d575dbb"
    },
    {
      "id": "7b447127-a2ce-4cf0-b22f-5173bf3153c0",
      "name": "Network Topology",
      "categoryId": "e5dbd346-fd12-437c-9370-43110d575dbb"
    },
    {
      "id": "c165b34e-2e9d-4a40-a04a-3ad505b404c6",
      "name": "Complex Networks",
      "categoryId": "e5dbd346-fd12-437c-9370-43110d575dbb"
    },
    {
      "id": "60de5f1b-b554-4b14-938a-d94d7de8a359",
      "name": "Structural Properties",
      "categoryId": "e5dbd346-fd12-437c-9370-43110d575dbb"
    },
    {
      "id": "55e88973-ed64-414e-b6ae-53132b31809e",
      "name": "Precision-Recall curve",
      "categoryId": "af8462e9-347c-4046-97e4-10c6a5dd0262"
    },
    {
      "id": "0bf1d026-fcc6-4f58-a475-b56b75a9badb",
      "name": "PR curve",
      "categoryId": "af8462e9-347c-4046-97e4-10c6a5dd0262"
    },
    {
      "id": "15b28734-7297-4e38-a15e-d82fe3764b6f",
      "name": "Classification metrics",
      "categoryId": "af8462e9-347c-4046-97e4-10c6a5dd0262"
    },
    {
      "id": "ef790c04-b1c0-4f6e-a90a-6267ae2ff4df",
      "name": "Imbalanced datasets",
      "categoryId": "af8462e9-347c-4046-97e4-10c6a5dd0262"
    },
    {
      "id": "ce76156c-ab7c-487a-a91a-19f1cd7ebcf9",
      "name": "Model evaluation",
      "categoryId": "af8462e9-347c-4046-97e4-10c6a5dd0262"
    },
    {
      "id": "e9255ef4-401d-4d57-9680-3f324524ae6c",
      "name": "Binary classification",
      "categoryId": "af8462e9-347c-4046-97e4-10c6a5dd0262"
    },
    {
      "id": "cf20ca1a-04d6-49f8-84cc-e470d354421d",
      "name": "True positives",
      "categoryId": "af8462e9-347c-4046-97e4-10c6a5dd0262"
    },
    {
      "id": "26086ecd-dca5-4ed9-bd23-c450b7040047",
      "name": "False positives",
      "categoryId": "af8462e9-347c-4046-97e4-10c6a5dd0262"
    },
    {
      "id": "f7a47b2a-3d22-4ef9-9b89-8fb17a40669c",
      "name": "Recall",
      "categoryId": "af8462e9-347c-4046-97e4-10c6a5dd0262"
    },
    {
      "id": "b177ab2f-fe43-47b9-9f98-522fee06dca3",
      "name": "Precision",
      "categoryId": "af8462e9-347c-4046-97e4-10c6a5dd0262"
    },
    {
      "id": "2fa1756b-7401-4135-b272-47a5d24dec2c",
      "name": "Threshold analysis",
      "categoryId": "af8462e9-347c-4046-97e4-10c6a5dd0262"
    },
    {
      "id": "d3ab7827-8992-4523-9ead-e991087a388f",
      "name": "Statistical Significance",
      "categoryId": "fbc93b19-5a13-47da-a46d-5c870b28f358"
    },
    {
      "id": "21755801-166d-483a-a604-8ab9b0600355",
      "name": "p-value",
      "categoryId": "fbc93b19-5a13-47da-a46d-5c870b28f358"
    },
    {
      "id": "558d40b4-b152-4f90-98b1-ec6e6a9a7fc9",
      "name": "Hypothesis Testing",
      "categoryId": "fbc93b19-5a13-47da-a46d-5c870b28f358"
    },
    {
      "id": "205dd129-b8fb-4251-889c-d97491b6c52b",
      "name": "Effect Size",
      "categoryId": "fbc93b19-5a13-47da-a46d-5c870b28f358"
    },
    {
      "id": "a78dedea-607d-4bab-93f4-20d141d53d2c",
      "name": "Confidence Intervals",
      "categoryId": "fbc93b19-5a13-47da-a46d-5c870b28f358"
    },
    {
      "id": "20cbafd2-30ba-45f2-83a5-abde1b87480a",
      "name": "Variance Analysis",
      "categoryId": "fbc93b19-5a13-47da-a46d-5c870b28f358"
    },
    {
      "id": "92a9e6af-b6fb-4a1c-b935-6b5bd715a06b",
      "name": "Sample Size",
      "categoryId": "fbc93b19-5a13-47da-a46d-5c870b28f358"
    },
    {
      "id": "fce93d46-ac5a-4153-b776-fe3fb5eb1407",
      "name": "Power Analysis",
      "categoryId": "fbc93b19-5a13-47da-a46d-5c870b28f358"
    },
    {
      "id": "79c50b58-c501-41bc-ada1-419900047ca3",
      "name": "Significance Level",
      "categoryId": "fbc93b19-5a13-47da-a46d-5c870b28f358"
    },
    {
      "id": "de80747f-8375-42be-915f-ffb4b69ce4e3",
      "name": "Type I and Type II Errors",
      "categoryId": "fbc93b19-5a13-47da-a46d-5c870b28f358"
    },
    {
      "id": "70155a2a-017d-49a1-9d29-e14adc8d2fb9",
      "name": "Validity of Results",
      "categoryId": "fbc93b19-5a13-47da-a46d-5c870b28f358"
    },
    {
      "id": "01bd95da-1e24-4a50-a6f4-96cd63589cc6",
      "name": "Natural Language Processing (NLP)",
      "categoryId": "0e7685d9-3956-4b90-85d5-c9dcddadfbe2"
    },
    {
      "id": "3163d03c-c6ea-409f-be53-478b405b03a9",
      "name": "Word Embeddings",
      "categoryId": "0e7685d9-3956-4b90-85d5-c9dcddadfbe2"
    },
    {
      "id": "a5fdf74e-7e67-4709-b3a4-3f423afcb7cc",
      "name": "Deep Learning",
      "categoryId": "0e7685d9-3956-4b90-85d5-c9dcddadfbe2"
    },
    {
      "id": "a73fead9-ad01-4a5b-b97a-530485dff66a",
      "name": "Representation Learning",
      "categoryId": "0e7685d9-3956-4b90-85d5-c9dcddadfbe2"
    },
    {
      "id": "51e71297-6517-4295-8351-d517cafb9b64",
      "name": "Unsupervised Learning",
      "categoryId": "0e7685d9-3956-4b90-85d5-c9dcddadfbe2"
    },
    {
      "id": "4177dfb7-43c0-4330-a420-ff83c29d3861",
      "name": "Transfer Learning",
      "categoryId": "0e7685d9-3956-4b90-85d5-c9dcddadfbe2"
    },
    {
      "id": "1d8becb5-3da1-4264-8d8b-440fed584300",
      "name": "Pre-trained Models",
      "categoryId": "01d46999-1f9b-49e8-a572-2fbf2e928780"
    },
    {
      "id": "2ec69354-4805-4387-9aa8-5e209020285e",
      "name": "Language Representations",
      "categoryId": "01d46999-1f9b-49e8-a572-2fbf2e928780"
    },
    {
      "id": "b4b52667-a14d-404f-80c5-9c935c9d6ca3",
      "name": "Transfer Learning",
      "categoryId": "01d46999-1f9b-49e8-a572-2fbf2e928780"
    },
    {
      "id": "2c63f09d-7f3c-4d5e-bd8a-86ed89bc85da",
      "name": "Neural Networks",
      "categoryId": "01d46999-1f9b-49e8-a572-2fbf2e928780"
    },
    {
      "id": "1adf760f-3e1a-475b-a3f9-108a32034d4f",
      "name": "NLP Transformers",
      "categoryId": "01d46999-1f9b-49e8-a572-2fbf2e928780"
    },
    {
      "id": "2cb45e3d-477f-449c-b600-e640371077e2",
      "name": "BERT",
      "categoryId": "897c2c2e-937b-4766-86c1-76802d7edaa8"
    },
    {
      "id": "46cfc955-687b-4859-9e63-2bc06fe8deaf",
      "name": "GPT",
      "categoryId": "897c2c2e-937b-4766-86c1-76802d7edaa8"
    },
    {
      "id": "b1205d03-ba5e-4d42-a1af-612b97fa4467",
      "name": "ResNet",
      "categoryId": "897c2c2e-937b-4766-86c1-76802d7edaa8"
    },
    {
      "id": "77ca9097-c9d4-4399-bc6d-11fcea87a575",
      "name": "Transformer Models",
      "categoryId": "897c2c2e-937b-4766-86c1-76802d7edaa8"
    },
    {
      "id": "3a516efc-2d63-4698-8c1b-a45a0ab09170",
      "name": "Convolutional Neural Networks",
      "categoryId": "897c2c2e-937b-4766-86c1-76802d7edaa8"
    },
    {
      "id": "b6c3637c-cf0b-4040-8b7d-a7fe13f3d28a",
      "name": "Language Models",
      "categoryId": "897c2c2e-937b-4766-86c1-76802d7edaa8"
    },
    {
      "id": "ba90eeff-6dd7-4073-9b2d-7f627dbe9394",
      "name": "Image Recognition",
      "categoryId": "897c2c2e-937b-4766-86c1-76802d7edaa8"
    },
    {
      "id": "0f293f2c-2250-48d3-b666-07332000443e",
      "name": "Model Fine-tuning",
      "categoryId": "897c2c2e-937b-4766-86c1-76802d7edaa8"
    },
    {
      "id": "05daecb0-77bb-42d7-8582-f91d0ff22351",
      "name": "Transfer Learning Techniques",
      "categoryId": "897c2c2e-937b-4766-86c1-76802d7edaa8"
    },
    {
      "id": "dcb81dbd-6450-4ee6-a1f4-257365d3448f",
      "name": "AI Model Architectures",
      "categoryId": "897c2c2e-937b-4766-86c1-76802d7edaa8"
    },
    {
      "id": "671cf91d-29a8-496a-b47f-947533c0e0af",
      "name": "Pre-training is primarily associated with sub-categories such as Self-supervised Learning",
      "categoryId": "a1e1de27-1094-4660-88be-3b3e14f6996a"
    },
    {
      "id": "93e73ce3-9aad-4cb5-a0c8-e861caac3868",
      "name": "Transfer Learning",
      "categoryId": "a1e1de27-1094-4660-88be-3b3e14f6996a"
    },
    {
      "id": "592beb45-f9af-4752-b498-b4cea9110825",
      "name": "Unsupervised Learning",
      "categoryId": "a1e1de27-1094-4660-88be-3b3e14f6996a"
    },
    {
      "id": "a158642a-6620-4b6b-9f15-e9325c93baaa",
      "name": "and Deep Learning. It also intersects with Natural Language Processing (NLP)",
      "categoryId": "a1e1de27-1094-4660-88be-3b3e14f6996a"
    },
    {
      "id": "736db009-3be4-4a74-a9a2-0a133345ebc3",
      "name": "Computer Vision",
      "categoryId": "a1e1de27-1094-4660-88be-3b3e14f6996a"
    },
    {
      "id": "59c02a9b-aef5-4d39-94d3-db4427aef92a",
      "name": "and Speech Recognition as domains where pre-training techniques are extensively employed to improve downstream task performance.",
      "categoryId": "a1e1de27-1094-4660-88be-3b3e14f6996a"
    },
    {
      "id": "e62e8647-16ed-4ffc-be78-cecf74fad76d",
      "name": "Precedent Cases",
      "categoryId": "92657e19-1bbe-499b-ad86-900e5df98be5"
    },
    {
      "id": "f1734613-9809-4011-a746-45cbb9b7e6e8",
      "name": "Legal Cases in AI",
      "categoryId": "92657e19-1bbe-499b-ad86-900e5df98be5"
    },
    {
      "id": "39d657ce-0b00-4d0a-b3ac-b11e16cfc70b",
      "name": "AI Regulation",
      "categoryId": "92657e19-1bbe-499b-ad86-900e5df98be5"
    },
    {
      "id": "a3d3eb97-42c9-41fe-8c6e-ac0e995bb1c4",
      "name": "AI Ethics",
      "categoryId": "92657e19-1bbe-499b-ad86-900e5df98be5"
    },
    {
      "id": "6e5ddd02-ba34-4cd2-a3f1-9ac7692407a8",
      "name": "Judicial Decisions",
      "categoryId": "92657e19-1bbe-499b-ad86-900e5df98be5"
    },
    {
      "id": "2aaab042-daf0-4edc-88e2-5b0d9b25a041",
      "name": "Machine Learning Law",
      "categoryId": "92657e19-1bbe-499b-ad86-900e5df98be5"
    },
    {
      "id": "f84dda41-27b8-4e99-8f30-c67c1e472d92",
      "name": "AI Legal Frameworks",
      "categoryId": "92657e19-1bbe-499b-ad86-900e5df98be5"
    },
    {
      "id": "e10c4b8f-50be-49cd-a365-d126db98a981",
      "name": "Technology Litigation",
      "categoryId": "92657e19-1bbe-499b-ad86-900e5df98be5"
    },
    {
      "id": "ef4fed92-e191-4b55-81dd-799f787e68ce",
      "name": "Classification Metrics",
      "categoryId": "593c069f-2068-41c7-a64d-ca30ca5d4bb9"
    },
    {
      "id": "20d72691-100d-4b5e-81cd-9263d892db50",
      "name": "Evaluation Metrics",
      "categoryId": "593c069f-2068-41c7-a64d-ca30ca5d4bb9"
    },
    {
      "id": "d8f0d30e-c9bc-49e2-8de8-a4b909dd0f05",
      "name": "Model Performance",
      "categoryId": "593c069f-2068-41c7-a64d-ca30ca5d4bb9"
    },
    {
      "id": "8961df50-9fad-44c7-bd6b-5c41d2df5a85",
      "name": "Confusion Matrix",
      "categoryId": "593c069f-2068-41c7-a64d-ca30ca5d4bb9"
    },
    {
      "id": "e9b3dcae-d129-434c-9817-f9c323597507",
      "name": "Precision-Recall Curve",
      "categoryId": "593c069f-2068-41c7-a64d-ca30ca5d4bb9"
    },
    {
      "id": "745fec49-db64-4d76-9f0f-21602c576b9c",
      "name": "Binary Classification",
      "categoryId": "593c069f-2068-41c7-a64d-ca30ca5d4bb9"
    },
    {
      "id": "f4d08776-7b18-48ec-81bb-4311659d1453",
      "name": "Multi-class Classification",
      "categoryId": "593c069f-2068-41c7-a64d-ca30ca5d4bb9"
    },
    {
      "id": "09c2c3b9-e382-4f83-b917-745d53ac5b09",
      "name": "Classification metrics",
      "categoryId": "04764e46-ed48-4cfb-a223-c4c9f52888fc"
    },
    {
      "id": "62eda610-e776-4709-97ca-b5fc875bb713",
      "name": "Model evaluation",
      "categoryId": "04764e46-ed48-4cfb-a223-c4c9f52888fc"
    },
    {
      "id": "322e39d1-d134-4968-a62a-b1aa47fd726e",
      "name": "Binary classification",
      "categoryId": "04764e46-ed48-4cfb-a223-c4c9f52888fc"
    },
    {
      "id": "80e5ba09-4062-456f-8e16-fdccdac4f06f",
      "name": "Performance metrics",
      "categoryId": "04764e46-ed48-4cfb-a223-c4c9f52888fc"
    },
    {
      "id": "71e94bdd-6507-4cdc-96d3-bca3f1b415a5",
      "name": "Confusion matrix",
      "categoryId": "04764e46-ed48-4cfb-a223-c4c9f52888fc"
    },
    {
      "id": "aa5caec0-afc8-4c8d-82e8-36379e8f8c35",
      "name": "True positives",
      "categoryId": "04764e46-ed48-4cfb-a223-c4c9f52888fc"
    },
    {
      "id": "5945052a-ad02-469b-b844-0c18b92e9f82",
      "name": "False positives",
      "categoryId": "04764e46-ed48-4cfb-a223-c4c9f52888fc"
    },
    {
      "id": "ad8c3a41-75b7-461e-b281-6fc8d475d52f",
      "name": "True negatives",
      "categoryId": "04764e46-ed48-4cfb-a223-c4c9f52888fc"
    },
    {
      "id": "e3badd49-40ef-4929-afec-ff7dee1b9942",
      "name": "False negatives",
      "categoryId": "04764e46-ed48-4cfb-a223-c4c9f52888fc"
    },
    {
      "id": "23c6f9ea-5e61-46f6-b497-aa38536f637c",
      "name": "Threshold analysis",
      "categoryId": "04764e46-ed48-4cfb-a223-c4c9f52888fc"
    },
    {
      "id": "dcca43af-5890-46b8-9157-baf4b340911a",
      "name": "Model diagnostics.",
      "categoryId": "04764e46-ed48-4cfb-a223-c4c9f52888fc"
    },
    {
      "id": "a8023855-d302-4703-bd92-bfb8d8a1ceb6",
      "name": "Quantization",
      "categoryId": "40f4817f-5014-4bf7-9918-d6ee35b5476b"
    },
    {
      "id": "111eb156-f022-4419-8387-3a3314dfe7da",
      "name": "Model Compression",
      "categoryId": "40f4817f-5014-4bf7-9918-d6ee35b5476b"
    },
    {
      "id": "3dd2ce40-e899-4cf8-bc85-5b23f76e670d",
      "name": "Neural Network Optimization",
      "categoryId": "40f4817f-5014-4bf7-9918-d6ee35b5476b"
    },
    {
      "id": "3e8351fc-3a37-455a-bdec-5bc41f84990e",
      "name": "Reduced Precision Computing",
      "categoryId": "40f4817f-5014-4bf7-9918-d6ee35b5476b"
    },
    {
      "id": "015932d4-061c-483b-9693-0be4224e092f",
      "name": "Fixed-Point Arithmetic",
      "categoryId": "40f4817f-5014-4bf7-9918-d6ee35b5476b"
    },
    {
      "id": "6d266e64-07e2-4c19-889c-0085c60f7b37",
      "name": "Model Size Reduction",
      "categoryId": "40f4817f-5014-4bf7-9918-d6ee35b5476b"
    },
    {
      "id": "43f64583-30d0-4b40-a908-f57bb4cd8200",
      "name": "Hardware Acceleration",
      "categoryId": "40f4817f-5014-4bf7-9918-d6ee35b5476b"
    },
    {
      "id": "67584a4d-bb40-4783-bc51-0caa617faa28",
      "name": "Low-Precision Training",
      "categoryId": "40f4817f-5014-4bf7-9918-d6ee35b5476b"
    },
    {
      "id": "f592f895-b3e2-47ed-bf18-057c3e717186",
      "name": "Bit-Width Reduction",
      "categoryId": "40f4817f-5014-4bf7-9918-d6ee35b5476b"
    },
    {
      "id": "a4016c4e-430f-4291-9840-e48ad3e5fe5f",
      "name": "Numerical Approximation",
      "categoryId": "40f4817f-5014-4bf7-9918-d6ee35b5476b"
    },
    {
      "id": "a3e13acc-050a-4d20-82f9-aeac9ab633d1",
      "name": "Classification Metrics",
      "categoryId": "54144812-b5c6-47e9-a2b9-c1b4eaece433"
    },
    {
      "id": "b36e9bf1-9245-4f36-a456-9cbd2244042e",
      "name": "Model Evaluation",
      "categoryId": "54144812-b5c6-47e9-a2b9-c1b4eaece433"
    },
    {
      "id": "bc243726-b5df-4117-891a-0246346fac19",
      "name": "Performance Metrics",
      "categoryId": "54144812-b5c6-47e9-a2b9-c1b4eaece433"
    },
    {
      "id": "4440d631-5482-45f9-b626-1f7fa995ab5a",
      "name": "Binary Classification",
      "categoryId": "54144812-b5c6-47e9-a2b9-c1b4eaece433"
    },
    {
      "id": "3b4f6a10-324b-4ecc-9381-972fd95f6392",
      "name": "Multi-class Classification",
      "categoryId": "54144812-b5c6-47e9-a2b9-c1b4eaece433"
    },
    {
      "id": "fc6e0f35-2f49-48b8-aaea-f19352c2a5fc",
      "name": "Threshold Analysis",
      "categoryId": "54144812-b5c6-47e9-a2b9-c1b4eaece433"
    },
    {
      "id": "1d021052-4709-4714-b968-a4d780ec7640",
      "name": "Trade-off Analysis",
      "categoryId": "54144812-b5c6-47e9-a2b9-c1b4eaece433"
    },
    {
      "id": "af7e000c-8c08-4669-ba92-ff063bd2b2b1",
      "name": "Classification Metrics",
      "categoryId": "869423ad-aa97-4e5e-a138-35a40720da9d"
    },
    {
      "id": "b014f11b-e936-4503-8d31-0483979a086b",
      "name": "Model Evaluation",
      "categoryId": "869423ad-aa97-4e5e-a138-35a40720da9d"
    },
    {
      "id": "7812005d-e57d-4763-963c-b618a3d9b7ac",
      "name": "Precision",
      "categoryId": "869423ad-aa97-4e5e-a138-35a40720da9d"
    },
    {
      "id": "d1af6e0b-2808-4560-8946-026cb692812c",
      "name": "Recall",
      "categoryId": "869423ad-aa97-4e5e-a138-35a40720da9d"
    },
    {
      "id": "a54bd3a9-58bc-444e-a2cc-f65f50263e9d",
      "name": "Binary Classification",
      "categoryId": "869423ad-aa97-4e5e-a138-35a40720da9d"
    },
    {
      "id": "0d51e4c0-270f-46ca-98f4-51393a141dd6",
      "name": "Threshold Tuning",
      "categoryId": "869423ad-aa97-4e5e-a138-35a40720da9d"
    },
    {
      "id": "ad63cdf7-2403-4619-a01a-7e738d629153",
      "name": "Performance Metrics",
      "categoryId": "869423ad-aa97-4e5e-a138-35a40720da9d"
    },
    {
      "id": "35aeeb52-25b8-413e-af36-9873bd54fa32",
      "name": "Confusion Matrix",
      "categoryId": "869423ad-aa97-4e5e-a138-35a40720da9d"
    },
    {
      "id": "66673cf2-2738-4ad7-be58-336e0c16f70d",
      "name": "Tradeoff Analysis",
      "categoryId": "869423ad-aa97-4e5e-a138-35a40720da9d"
    },
    {
      "id": "d8bc35ce-0b8f-4967-ae07-bb8021c6374c",
      "name": "Model Optimization",
      "categoryId": "869423ad-aa97-4e5e-a138-35a40720da9d"
    },
    {
      "id": "702501d5-0b30-47b1-b7ff-22f54d3e041c",
      "name": "Predictive Coding",
      "categoryId": "d35134fe-74d5-4c52-8a55-b846c7dfb9e6"
    },
    {
      "id": "70d9c123-089c-4eec-92f5-c5aba24cc5e1",
      "name": "Hierarchical Learning",
      "categoryId": "d35134fe-74d5-4c52-8a55-b846c7dfb9e6"
    },
    {
      "id": "0e0cdc5b-3a25-4a0a-af6f-4bc482ba3e77",
      "name": "Bayesian Models",
      "categoryId": "d35134fe-74d5-4c52-8a55-b846c7dfb9e6"
    },
    {
      "id": "6bf95e45-f690-4edb-b823-7b928fa2ebc6",
      "name": "Neural Coding",
      "categoryId": "d35134fe-74d5-4c52-8a55-b846c7dfb9e6"
    },
    {
      "id": "9d86451e-26d1-4bf4-9a4d-8ba27044b1d9",
      "name": "Brain-inspired AI",
      "categoryId": "d35134fe-74d5-4c52-8a55-b846c7dfb9e6"
    },
    {
      "id": "92ba6d48-9284-4569-af61-aa3027b30a58",
      "name": "Cognitive Science",
      "categoryId": "d35134fe-74d5-4c52-8a55-b846c7dfb9e6"
    },
    {
      "id": "c6519c9a-996b-46c8-9438-82d02dfefbc3",
      "name": "Sensory Processing",
      "categoryId": "d35134fe-74d5-4c52-8a55-b846c7dfb9e6"
    },
    {
      "id": "33c56e72-c1f3-41be-8442-eb3395fe1caf",
      "name": "Hierarchical Inference",
      "categoryId": "d35134fe-74d5-4c52-8a55-b846c7dfb9e6"
    },
    {
      "id": "3f6bce7b-97d6-432e-b9c9-589ee1ead3a6",
      "name": "Probabilistic Models",
      "categoryId": "d35134fe-74d5-4c52-8a55-b846c7dfb9e6"
    },
    {
      "id": "c423cd52-1881-4411-ace3-c3edc86cc665",
      "name": "Predictive Data Mining",
      "categoryId": "3c0d64d6-9e10-475e-8d53-bf7f060921de"
    },
    {
      "id": "8fc2d1c4-b929-4afa-883a-57cacfc97659",
      "name": "Supervised Learning",
      "categoryId": "3c0d64d6-9e10-475e-8d53-bf7f060921de"
    },
    {
      "id": "d1236303-8de4-41f4-940c-9c5c4088ccc2",
      "name": "Classification",
      "categoryId": "3c0d64d6-9e10-475e-8d53-bf7f060921de"
    },
    {
      "id": "210576ab-d2c4-4d43-be0e-afd5f218d0f1",
      "name": "Regression",
      "categoryId": "3c0d64d6-9e10-475e-8d53-bf7f060921de"
    },
    {
      "id": "314c7a6c-f1c5-4948-b84b-88bd0c0d6323",
      "name": "Pattern Recognition",
      "categoryId": "3c0d64d6-9e10-475e-8d53-bf7f060921de"
    },
    {
      "id": "33d153c8-5beb-4121-bea5-4846c4645a82",
      "name": "Data Analysis",
      "categoryId": "3c0d64d6-9e10-475e-8d53-bf7f060921de"
    },
    {
      "id": "39dbed63-6df8-4bb0-bf21-77e6e142231f",
      "name": "Knowledge Discovery",
      "categoryId": "3c0d64d6-9e10-475e-8d53-bf7f060921de"
    },
    {
      "id": "60c427da-7735-4385-9f86-c057737b4cbe",
      "name": "Data Mining Techniques",
      "categoryId": "3c0d64d6-9e10-475e-8d53-bf7f060921de"
    },
    {
      "id": "62a3d9fa-1dda-4554-a625-d4123bf9c751",
      "name": "Predictive Analytics",
      "categoryId": "3c0d64d6-9e10-475e-8d53-bf7f060921de"
    },
    {
      "id": "6bcf7e2e-f618-467c-a9d2-3d041ad5738d",
      "name": "Data Science",
      "categoryId": "3c0d64d6-9e10-475e-8d53-bf7f060921de"
    },
    {
      "id": "d8ee5b13-81fe-4002-854b-8713c4d99de8",
      "name": "Predictive Modeling",
      "categoryId": "92ab1c3c-a858-434f-80fc-338a184c3d67"
    },
    {
      "id": "0dfa356e-de91-41a4-8e7d-57314f559aa7",
      "name": "Regression",
      "categoryId": "92ab1c3c-a858-434f-80fc-338a184c3d67"
    },
    {
      "id": "af0e1f5e-aa70-4c1e-9525-62ba1633eb62",
      "name": "Classification",
      "categoryId": "92ab1c3c-a858-434f-80fc-338a184c3d67"
    },
    {
      "id": "572f09bc-d71b-40c1-b2a4-a86f96373915",
      "name": "Supervised Learning",
      "categoryId": "92ab1c3c-a858-434f-80fc-338a184c3d67"
    },
    {
      "id": "173a0b85-f3df-4a7f-8125-d016e77012fd",
      "name": "Data Analytics",
      "categoryId": "92ab1c3c-a858-434f-80fc-338a184c3d67"
    },
    {
      "id": "c4042c44-4e51-4518-a6dd-39a241a2c177",
      "name": "Statistical Modeling",
      "categoryId": "92ab1c3c-a858-434f-80fc-338a184c3d67"
    },
    {
      "id": "164122dd-5a87-45ad-ae4a-ac3c2d9cb01c",
      "name": "Machine Learning",
      "categoryId": "92ab1c3c-a858-434f-80fc-338a184c3d67"
    },
    {
      "id": "ccbb15e5-4057-4c2f-89e3-2588e0b66c73",
      "name": "Data Mining",
      "categoryId": "92ab1c3c-a858-434f-80fc-338a184c3d67"
    },
    {
      "id": "fbd3802c-7853-46e1-bf2a-95d77bb2b0cd",
      "name": "Quantitative Analysis",
      "categoryId": "92ab1c3c-a858-434f-80fc-338a184c3d67"
    },
    {
      "id": "11a50e18-7d15-4bcd-b9c1-d5c3db577177",
      "name": "Forecasting",
      "categoryId": "92ab1c3c-a858-434f-80fc-338a184c3d67"
    },
    {
      "id": "d6c81df0-24c8-4c7e-8408-ecaf0d814f3e",
      "name": "Pattern Recognition",
      "categoryId": "92ab1c3c-a858-434f-80fc-338a184c3d67"
    },
    {
      "id": "43233124-ce42-4faa-be02-6ad2fb674979",
      "name": "Probabilistic Models",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "678768b0-4c88-48db-ac0d-562634927521",
      "name": "Classification",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "a79b027d-9eff-46ca-baf5-30007831dc2a",
      "name": "Regression",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "ee15ff7f-ef5e-4708-976c-3b6b9c4b902e",
      "name": "Bayesian Inference",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "134de141-a38a-4768-be2d-1130edf8abab",
      "name": "Statistical Modeling",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "ab442b5c-adbb-419d-aae9-459b61d83797",
      "name": "Uncertainty Quantification",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "62f61e14-0c23-4951-afb9-0fce9a944330",
      "name": "Machine Learning Foundations",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "0cc9a447-55cc-4f80-8101-2aee1be8ad2f",
      "name": "Predictive Analytics",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "5ff395ce-bd7c-4f13-a7cf-112e66f21a65",
      "name": "Model Validity",
      "categoryId": "c2e50132-7174-4331-a50e-bed60c0dbe0c"
    },
    {
      "id": "ef9522ee-9c33-4a7c-8d39-ffb9eae7d796",
      "name": "Predictive Modeling",
      "categoryId": "c2e50132-7174-4331-a50e-bed60c0dbe0c"
    },
    {
      "id": "9030a9cb-d2ff-4cd7-90ca-1890fef59651",
      "name": "Validation Metrics",
      "categoryId": "c2e50132-7174-4331-a50e-bed60c0dbe0c"
    },
    {
      "id": "f3b1b057-074c-4dae-b975-2e7a22ac23d1",
      "name": "Performance Evaluation",
      "categoryId": "c2e50132-7174-4331-a50e-bed60c0dbe0c"
    },
    {
      "id": "1365f06f-20b7-4680-abc7-baf84a4320d2",
      "name": "Forecasting Models",
      "categoryId": "c2e50132-7174-4331-a50e-bed60c0dbe0c"
    },
    {
      "id": "a779de61-b413-4c49-b101-ea237ec176c5",
      "name": "Predictor Variable",
      "categoryId": "d90c8e4d-13d2-43fb-9e31-b459a14372de"
    },
    {
      "id": "9ba30c0c-2f0f-419f-b646-0cbd1d4a50a9",
      "name": "Features",
      "categoryId": "d90c8e4d-13d2-43fb-9e31-b459a14372de"
    },
    {
      "id": "be4eb4e6-4599-4a43-b5c1-1ed3a13dde7f",
      "name": "Variables",
      "categoryId": "d90c8e4d-13d2-43fb-9e31-b459a14372de"
    },
    {
      "id": "b6f9c34e-f668-4d1b-888f-cea40214dc32",
      "name": "Data Preprocessing",
      "categoryId": "d90c8e4d-13d2-43fb-9e31-b459a14372de"
    },
    {
      "id": "0d50d199-ca66-44f8-bc20-3a09faa939cb",
      "name": "Feature Selection",
      "categoryId": "d90c8e4d-13d2-43fb-9e31-b459a14372de"
    },
    {
      "id": "5bdfee17-8e2e-4a40-b9e1-2276ce104fad",
      "name": "Dimensionality Reduction",
      "categoryId": "d90c8e4d-13d2-43fb-9e31-b459a14372de"
    },
    {
      "id": "4fc6fd7d-5798-4d45-9a34-13f0bdcf5382",
      "name": "Model Inputs",
      "categoryId": "d90c8e4d-13d2-43fb-9e31-b459a14372de"
    },
    {
      "id": "01e3e714-dc5b-4703-ae6f-8ef06c612379",
      "name": "Variable Importance",
      "categoryId": "d90c8e4d-13d2-43fb-9e31-b459a14372de"
    },
    {
      "id": "dbe6b24d-7ee6-454e-8d1e-e44df4085f54",
      "name": "Graph Theory",
      "categoryId": "47aadffe-07c5-4d14-a9af-f735545fdd0c"
    },
    {
      "id": "0456b013-176f-4b8d-9cb4-a3189eec22ef",
      "name": "Network Models",
      "categoryId": "47aadffe-07c5-4d14-a9af-f735545fdd0c"
    },
    {
      "id": "b73fff3a-d1c8-4c03-8430-bc7eca018894",
      "name": "Complex Networks",
      "categoryId": "47aadffe-07c5-4d14-a9af-f735545fdd0c"
    },
    {
      "id": "9759c440-968c-48f3-a2f0-11c8525915e1",
      "name": "Scale-Free Networks",
      "categoryId": "47aadffe-07c5-4d14-a9af-f735545fdd0c"
    },
    {
      "id": "87654db0-928a-4af5-87de-27b4deaea3b0",
      "name": "Network Growth Models",
      "categoryId": "47aadffe-07c5-4d14-a9af-f735545fdd0c"
    },
    {
      "id": "6e4074e6-2456-420d-8910-0f21172ef6ee",
      "name": "Degree Distribution",
      "categoryId": "47aadffe-07c5-4d14-a9af-f735545fdd0c"
    },
    {
      "id": "88478724-d772-4c2d-a562-2958ed307467",
      "name": "Network Evolution",
      "categoryId": "47aadffe-07c5-4d14-a9af-f735545fdd0c"
    },
    {
      "id": "88df9959-1e4f-4af2-a675-3325a0d2ce31",
      "name": "Structural Properties",
      "categoryId": "47aadffe-07c5-4d14-a9af-f735545fdd0c"
    },
    {
      "id": "869f129c-4da2-4b0a-baf7-703a7d70caee",
      "name": "Network Science",
      "categoryId": "05f2a543-5a39-4f64-a14c-0d93475106c6"
    },
    {
      "id": "a5b78030-a90f-45c3-9266-a306b62fc462",
      "name": "Complex Networks",
      "categoryId": "05f2a543-5a39-4f64-a14c-0d93475106c6"
    },
    {
      "id": "336f4e59-902a-4f7e-8556-770b7c0ec281",
      "name": "Scale-Free Networks",
      "categoryId": "05f2a543-5a39-4f64-a14c-0d93475106c6"
    },
    {
      "id": "d59db091-d404-4b5e-8a54-8f330cc5a7dd",
      "name": "Graph Theory",
      "categoryId": "05f2a543-5a39-4f64-a14c-0d93475106c6"
    },
    {
      "id": "96b4de4c-6bc0-4ea0-a90c-d2a40caa0130",
      "name": "Network Growth Models",
      "categoryId": "05f2a543-5a39-4f64-a14c-0d93475106c6"
    },
    {
      "id": "6a8069a4-f9b8-47bf-a494-c05a7b8fa15a",
      "name": "Social Network Analysis",
      "categoryId": "05f2a543-5a39-4f64-a14c-0d93475106c6"
    },
    {
      "id": "3dbf65fb-cb3c-4b5a-968c-bf64faf22537",
      "name": "Network Topology",
      "categoryId": "05f2a543-5a39-4f64-a14c-0d93475106c6"
    },
    {
      "id": "d60002d3-d8c3-45d8-8760-0bfac4a8a3fb",
      "name": "Connectivity Patterns",
      "categoryId": "05f2a543-5a39-4f64-a14c-0d93475106c6"
    },
    {
      "id": "53794895-66b1-440a-ace9-70c14916b488",
      "name": "Degree Distribution",
      "categoryId": "05f2a543-5a39-4f64-a14c-0d93475106c6"
    },
    {
      "id": "b1e4e9e9-560c-4bc7-b12a-a6410dbac93a",
      "name": "Network Dynamics",
      "categoryId": "05f2a543-5a39-4f64-a14c-0d93475106c6"
    },
    {
      "id": "cfe5362c-c179-4ea2-b217-bad21319fd2d",
      "name": "Natural Language Processing",
      "categoryId": "92e8f341-0ee0-43e7-8fd4-090d9642bff0"
    },
    {
      "id": "57114b63-6182-4db5-8278-158f2f7b003b",
      "name": "Transfer Learning",
      "categoryId": "92e8f341-0ee0-43e7-8fd4-090d9642bff0"
    },
    {
      "id": "6a870e15-0867-4466-95d8-4703e5b70ec4",
      "name": "Parameter-Efficient Fine-Tuning",
      "categoryId": "92e8f341-0ee0-43e7-8fd4-090d9642bff0"
    },
    {
      "id": "2324b054-c845-48c5-9ba2-38b9258a74f0",
      "name": "Few-Shot Learning",
      "categoryId": "92e8f341-0ee0-43e7-8fd4-090d9642bff0"
    },
    {
      "id": "cd9daa61-c4db-49f2-b037-da116a94da3e",
      "name": "Model Adaptation",
      "categoryId": "92e8f341-0ee0-43e7-8fd4-090d9642bff0"
    },
    {
      "id": "921bb85b-ed27-49de-b4cd-94a24e5df0b5",
      "name": "Language Models",
      "categoryId": "92e8f341-0ee0-43e7-8fd4-090d9642bff0"
    },
    {
      "id": "185bcff1-c253-4f72-afad-6cd9214d331a",
      "name": "Prompt Tuning",
      "categoryId": "92e8f341-0ee0-43e7-8fd4-090d9642bff0"
    },
    {
      "id": "2edf31cb-ef85-48b6-a45f-17fc9c03894d",
      "name": "Embedding Optimization",
      "categoryId": "92e8f341-0ee0-43e7-8fd4-090d9642bff0"
    },
    {
      "id": "6230ebd2-34c7-4c6f-a134-08fd1766a810",
      "name": "Large Pretrained Models",
      "categoryId": "92e8f341-0ee0-43e7-8fd4-090d9642bff0"
    },
    {
      "id": "eeccb48f-9579-4f9f-82e8-14af1a9ccba2",
      "name": "Natural Language Processing (NLP)",
      "categoryId": "c1b289fc-1fcb-4d24-a770-fc528e43d6ee"
    },
    {
      "id": "bdf70940-9958-4054-8f0c-3baf493184bb",
      "name": "Text Generation",
      "categoryId": "c1b289fc-1fcb-4d24-a770-fc528e43d6ee"
    },
    {
      "id": "16cf3fbb-4e93-484a-8a8a-afb2e5fd937f",
      "name": "Language Models",
      "categoryId": "c1b289fc-1fcb-4d24-a770-fc528e43d6ee"
    },
    {
      "id": "a9aa7eec-f25f-4ecd-8968-767d11cce947",
      "name": "OpenAI GPT",
      "categoryId": "c1b289fc-1fcb-4d24-a770-fc528e43d6ee"
    },
    {
      "id": "88c5e7b2-ddf9-4ef0-895f-005344c6d8e9",
      "name": "Transformer Architecture",
      "categoryId": "c1b289fc-1fcb-4d24-a770-fc528e43d6ee"
    },
    {
      "id": "da24262b-0a9a-4de1-b63d-55452a05ed4b",
      "name": "Text Repetition Control",
      "categoryId": "c1b289fc-1fcb-4d24-a770-fc528e43d6ee"
    },
    {
      "id": "681a036e-504a-4b3d-9c94-35de6bcfdde3",
      "name": "AI Text Synthesis",
      "categoryId": "c1b289fc-1fcb-4d24-a770-fc528e43d6ee"
    },
    {
      "id": "0838fc9f-83a4-4eeb-8134-24dfdd39b682",
      "name": "Pretext Task",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "aa0d171f-ee5d-4474-a9c2-f419c730ebfd",
      "name": "Self-supervised Learning",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "39df3cf2-2c77-419f-98c8-6cef33d78ef1",
      "name": "Pretraining",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "fd7942cd-f442-49ff-a8db-9105ef604ee7",
      "name": "Neural Networks",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "b8678472-1f76-4d11-915d-18259a178d26",
      "name": "Model Initialization",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "cfec4b5c-827c-4fa2-9935-71b01bf3efe4",
      "name": "Transfer Learning",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "c7c29bde-a318-45d7-b2be-28fa7509619b",
      "name": "Pretrained Models",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "6cdcc7f2-c55d-4a9a-bea5-76b975bf59a0",
      "name": "Fine-tuning",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "a902820a-d431-41de-8f15-f9407fc129c9",
      "name": "Natural Language Processing",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "745fd042-f078-438c-aa6b-783cee37be91",
      "name": "Transfer Learning Techniques",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd"
    },
    {
      "id": "0c6f0ec0-471f-4995-a61f-9b02dd352875",
      "name": "Pretraining",
      "categoryId": "8954a6e5-05c9-4f6c-98c8-a9f60179badc"
    },
    {
      "id": "15add49e-ff72-4f4a-b3db-810cf5515649",
      "name": "Unsupervised Learning",
      "categoryId": "8954a6e5-05c9-4f6c-98c8-a9f60179badc"
    },
    {
      "id": "c809d250-40b0-4744-9365-a96306d5cbcb",
      "name": "Self-supervised Learning",
      "categoryId": "8954a6e5-05c9-4f6c-98c8-a9f60179badc"
    },
    {
      "id": "43321d03-0b9d-481b-9f3d-9eebb4a1a283",
      "name": "Transfer Learning",
      "categoryId": "8954a6e5-05c9-4f6c-98c8-a9f60179badc"
    },
    {
      "id": "a64b8567-61ee-4774-9b78-1fde14fad2c3",
      "name": "Language Models",
      "categoryId": "8954a6e5-05c9-4f6c-98c8-a9f60179badc"
    },
    {
      "id": "3a0c0996-1710-4f20-a961-acd0f724ed42",
      "name": "Deep Learning",
      "categoryId": "8954a6e5-05c9-4f6c-98c8-a9f60179badc"
    },
    {
      "id": "ab242f39-6dfa-4a33-965d-10f7d2324258",
      "name": "Representation Learning",
      "categoryId": "8954a6e5-05c9-4f6c-98c8-a9f60179badc"
    },
    {
      "id": "635048a3-99a1-44fb-b10a-005c7e75f242",
      "name": "Embeddings",
      "categoryId": "8954a6e5-05c9-4f6c-98c8-a9f60179badc"
    },
    {
      "id": "f20b4176-451c-4991-bba2-68b0b95a71cf",
      "name": "Large-scale Models",
      "categoryId": "8954a6e5-05c9-4f6c-98c8-a9f60179badc"
    },
    {
      "id": "106a25b9-48e0-4a36-8281-2d470a2ff9c4",
      "name": "Fine-tuning",
      "categoryId": "8954a6e5-05c9-4f6c-98c8-a9f60179badc"
    },
    {
      "id": "813524e0-0b8b-4616-9d54-803b1ed66326",
      "name": "Pretraining and Fine-Tuning Paradigm",
      "categoryId": "064f4ae6-0b6b-4972-b926-5577e8ba4472"
    },
    {
      "id": "835d2e52-3552-4303-b704-d41fffb76476",
      "name": "Transfer Learning",
      "categoryId": "064f4ae6-0b6b-4972-b926-5577e8ba4472"
    },
    {
      "id": "29403518-6d44-45b1-9679-bdb4ca997cc2",
      "name": "Supervised Learning",
      "categoryId": "064f4ae6-0b6b-4972-b926-5577e8ba4472"
    },
    {
      "id": "ab6e83ec-00ee-47d4-abf5-cb6a26d8ab0b",
      "name": "Unsupervised Learning",
      "categoryId": "064f4ae6-0b6b-4972-b926-5577e8ba4472"
    },
    {
      "id": "81104903-ab4b-4293-8ef5-596cc7ecc1f8",
      "name": "Deep Learning",
      "categoryId": "064f4ae6-0b6b-4972-b926-5577e8ba4472"
    },
    {
      "id": "c4e7fca1-6726-4ab0-be08-a834c21cbcbe",
      "name": "NLP Pretraining",
      "categoryId": "064f4ae6-0b6b-4972-b926-5577e8ba4472"
    },
    {
      "id": "928d2560-26f1-4378-a70a-1fa500cbbacc",
      "name": "Domain Adaptation",
      "categoryId": "064f4ae6-0b6b-4972-b926-5577e8ba4472"
    },
    {
      "id": "ec51d067-ad85-42e3-8d2c-42929245a7c5",
      "name": "Model Fine-tuning",
      "categoryId": "064f4ae6-0b6b-4972-b926-5577e8ba4472"
    },
    {
      "id": "43183b13-148c-4f8e-8a9d-fc0a306d2f06",
      "name": "Representation Learning",
      "categoryId": "064f4ae6-0b6b-4972-b926-5577e8ba4472"
    },
    {
      "id": "d85c9870-9ce3-4465-869a-930d7c471571",
      "name": "Large-Scale Pretraining",
      "categoryId": "064f4ae6-0b6b-4972-b926-5577e8ba4472"
    },
    {
      "id": "aa165982-6a88-4de7-91a6-eb1e74e2b293",
      "name": "Dimensionality Reduction",
      "categoryId": "73064999-8c6b-46d0-9348-504e41976f45"
    },
    {
      "id": "05259814-08d0-4447-8494-9e24a4fb3890",
      "name": "Unsupervised Learning",
      "categoryId": "73064999-8c6b-46d0-9348-504e41976f45"
    },
    {
      "id": "dff6f0b5-215e-4bcc-a622-d73e4383f3d1",
      "name": "Data Visualization",
      "categoryId": "73064999-8c6b-46d0-9348-504e41976f45"
    },
    {
      "id": "3e4b61c0-4800-4ee5-871d-b56930578b96",
      "name": "Feature Extraction",
      "categoryId": "73064999-8c6b-46d0-9348-504e41976f45"
    },
    {
      "id": "3bf530ac-c7b9-4624-b1aa-3ed82c6d88b2",
      "name": "Machine Learning Techniques",
      "categoryId": "73064999-8c6b-46d0-9348-504e41976f45"
    },
    {
      "id": "514106a7-e8c6-4135-acb5-277c5b27e602",
      "name": "Dimensionality Reduction",
      "categoryId": "2433bd03-6d3a-4bd2-8695-cbc38078bf91"
    },
    {
      "id": "c443f0b9-07d4-4095-9e7a-a243be883038",
      "name": "Unsupervised Learning",
      "categoryId": "2433bd03-6d3a-4bd2-8695-cbc38078bf91"
    },
    {
      "id": "ae5504be-81b9-495d-8096-09cc4cf9483e",
      "name": "Feature Extraction",
      "categoryId": "2433bd03-6d3a-4bd2-8695-cbc38078bf91"
    },
    {
      "id": "615a6cd5-2b3c-4827-9dc4-c4fae2809a06",
      "name": "Embedding Techniques",
      "categoryId": "2433bd03-6d3a-4bd2-8695-cbc38078bf91"
    },
    {
      "id": "dd3297f0-3337-4f57-abd9-79433659d381",
      "name": "Data Visualization",
      "categoryId": "2433bd03-6d3a-4bd2-8695-cbc38078bf91"
    },
    {
      "id": "8a266f8f-d5c0-41a4-849e-202a2fd35116",
      "name": "Data Preprocessing",
      "categoryId": "2433bd03-6d3a-4bd2-8695-cbc38078bf91"
    },
    {
      "id": "e22ce3c5-5660-4b0b-9378-90cfd2b2c084",
      "name": "Dimensionality Reduction",
      "categoryId": "659f680a-5d62-4775-b990-ede10c2b51e2"
    },
    {
      "id": "71beb96c-91c0-4a92-aae8-b6c8dd94efd0",
      "name": "Regression Analysis",
      "categoryId": "659f680a-5d62-4775-b990-ede10c2b51e2"
    },
    {
      "id": "48d6712c-0586-4f49-8016-05c11ec9e795",
      "name": "PCA",
      "categoryId": "659f680a-5d62-4775-b990-ede10c2b51e2"
    },
    {
      "id": "2dceabd8-8671-401b-b32e-a57b4f7abcb5",
      "name": "Multicollinearity",
      "categoryId": "659f680a-5d62-4775-b990-ede10c2b51e2"
    },
    {
      "id": "569e8e7c-9aa4-4d8c-b1af-fd70efb8ed89",
      "name": "Feature Transformation",
      "categoryId": "659f680a-5d62-4775-b990-ede10c2b51e2"
    },
    {
      "id": "b2e2f71c-cf34-421f-a43b-955976873efa",
      "name": "Linear Models",
      "categoryId": "659f680a-5d62-4775-b990-ede10c2b51e2"
    },
    {
      "id": "9a9df14b-0070-4b6b-b387-43cbc0dd34fb",
      "name": "Data Preprocessing",
      "categoryId": "659f680a-5d62-4775-b990-ede10c2b51e2"
    },
    {
      "id": "728083c0-4922-4f8c-b873-ae1ae54f9124",
      "name": "Feature Extraction",
      "categoryId": "659f680a-5d62-4775-b990-ede10c2b51e2"
    }
  ],
  "terms": [
    {
      "id": "225a85e7-7b5e-4593-af2c-1bbed1f620d5",
      "name": "Characteristic Function",
      "definition": "A characteristic function is a fundamental concept in probability theory and statistics that uniquely characterizes the probability distribution of a random variable. Formally, it is defined as the expected value of e^{itX}, where X is a random variable, t is a real number, and i is the imaginary unit. The characteristic function encapsulates all the information about the distribution of X and serves as a powerful tool for analyzing probability distributions, deriving properties, and proving limit theorems.",
      "categoryId": "24430edb-10c0-43cb-9b75-8fdbdc45840a",
      "subcategoryIds": [
        "6c47bd37-2db1-40bd-adae-9aa30501ca29",
        "129a4108-dd6a-434e-88be-b88062582846",
        "e4a65769-fac3-4068-ac78-633cf5d19295",
        "3f103c61-15f1-4bbb-ab32-25dc4b87c8fd",
        "e7c190e4-3b0a-4339-a8da-a2c0e750699b",
        "be0600ab-9716-46b9-88f2-dd75cf423bd5",
        "2c458641-363d-4f24-a343-314e260c149a",
        "070f4405-f8cf-4767-964c-02239a7afeb4",
        "040592a3-8dcd-4572-ba79-434385d2bf78"
      ]
    },
    {
      "id": "150705ef-2536-47df-9e15-b66f5b33c34a",
      "name": "Chebyshev Distance",
      "definition": "Chebyshev Distance, also known as L-infinity norm or maximum metric, is a measure of distance between two points in a multidimensional space. It calculates the greatest difference across any single coordinate dimension between the two points, effectively capturing the maximum deviation. Mathematically, for two points p and q in n-dimensional space, Chebyshev distance is defined as the maximum absolute difference among their corresponding components: D(p, q) = max(|p_i - q_i|) for i in 1 to n.",
      "categoryId": "d62019f9-c4a2-4dac-bf32-19c7b17d3511",
      "subcategoryIds": [
        "34023b8c-934c-49d0-bfb9-1f23817ab605",
        "467f276f-e9af-44f0-918d-c5cf5aea5304",
        "7824a821-e907-44e3-8698-5a48d6695bf5",
        "77205f67-efda-45ee-925e-cc4f68bb3aaf",
        "f15e99de-ecf1-443a-b512-26126a5fe70e",
        "fa8f3824-92f3-4de1-9f6f-8d8d47c50679",
        "15877e0d-8b09-4ebc-af71-24a4200e86cd",
        "85a76467-7619-4c18-aa37-421ac7a1301b"
      ]
    },
    {
      "id": "bd9c76a7-0ad7-4b71-8179-37b7748b3ca0",
      "name": "Chebyshev Networks",
      "definition": "Chebyshev Networks are a class of neural network architectures that utilize Chebyshev polynomials as activation functions or basis functions. These networks leverage properties of Chebyshev polynomials to approximate complex functions efficiently, offering advantages in spectral approximation, stability, and convergence. They are often employed in scenarios requiring high-precision function approximation and can be adapted for various regression and classification tasks within the field of machine learning.",
      "categoryId": "84f64004-4381-4e35-8046-d42c8bfffdd6",
      "subcategoryIds": [
        "60d6bd0d-bc22-4868-85b0-bd6c422437f4",
        "9c3c68f6-94a0-43ba-bf06-003391a4eb8c",
        "3c28777d-f943-4f3b-aa62-188083f799d2",
        "0fa8e7b3-3387-476a-8bed-8c363fec32b0",
        "4e7d7774-a7f2-4430-83da-02da3d30a7b0",
        "34e1d7da-5e7c-471f-baff-a02284aed23b",
        "e12a2544-cb39-4659-adf6-262534a5c6fa",
        "8c78428e-541c-44f4-9b6c-4aea4edaf5e2",
        "c692a9ee-fc1d-4ce2-928b-d8b4690452a9"
      ]
    },
    {
      "id": "cc6cb902-d871-436c-96d9-1957fd1d9986",
      "name": "Chebyshev Polynomial Networks",
      "definition": "Chebyshev Polynomial Networks are a class of neural network architectures that leverage Chebyshev polynomials to perform function approximation and spectral filtering within the network. They are designed to efficiently approximate complex functions by exploiting the mathematical properties of Chebyshev polynomials, which are a sequence of orthogonal polynomials with remarkable approximation capabilities. These networks incorporate polynomial expansions directly into their architecture, allowing for effective modeling of non-linear relationships while maintaining computational efficiency and stability.",
      "categoryId": "8c0e1c2e-eb30-460a-97b2-0797d71996cd",
      "subcategoryIds": [
        "1f166ca4-8073-469a-ae9d-6f78ea6797f0",
        "234c3d94-e212-4819-9792-86f3c48ca6ec",
        "f83b3d41-7919-49d6-8336-0785c13f700a",
        "85526b76-ab8a-40bb-8645-2a4cc7f88fc0",
        "a12939c1-2b27-4b61-8e58-6f1c1b586b41",
        "9d2a1fd9-f138-4046-9d0f-c36dfd142efc",
        "93ed3b0d-9653-48f7-809d-58c832e01b4d",
        "c67938dc-949a-4d9f-aff7-f7eb5aaf7608",
        "861bdce6-c6b4-4356-ae88-4a3b716216e2",
        "a00f01a9-7893-41c7-802e-1f52ce3819c8"
      ]
    },
    {
      "id": "4b343552-09bf-4d0a-9c3f-eaf8a9397885",
      "name": "Chebyshev Polynomials in Neural Networks",
      "definition": "Chebyshev polynomials are a sequence of orthogonal polynomials that arise in approximation theory and numerical analysis. In the context of neural networks, Chebyshev polynomials are used as activation functions or as basis functions within neural network architectures to improve approximation capabilities, enhance numerical stability, and facilitate spectral methods. Their properties allow neural networks to approximate complex functions efficiently by leveraging the polynomials' recurrence relations and orthogonality properties.",
      "categoryId": "3f71e9b9-bb0b-4036-87eb-bc44b0c3c5da",
      "subcategoryIds": [
        "661d400d-a8ea-488d-8583-1dc911d3c9c9",
        "8fa6603f-4d76-41a4-b086-468e7bb1ab78",
        "e7382829-1d71-4d8e-bf0c-940ab3b4ee28",
        "789a8b3a-f5bd-4888-87dc-d1544b425272",
        "d98d1b85-8641-4693-be2e-6cbcc4ef92a7"
      ]
    },
    {
      "id": "43125fa7-5900-4283-944e-4c11e44eaa9e",
      "name": "Check-pointing in Training",
      "definition": "Check-pointing in training refers to the process of saving the current state of a machine learning model during the training process. This typically involves storing the model's parameters, optimizer states, and other relevant information at specific intervals or after significant events. These saved states, known as checkpoints, can be used to resume training from that point in case of interruptions, or for later evaluation and model deployment. Check-pointing is an essential technique to prevent loss of progress, enable experimentation with different training strategies, and facilitate model versioning.",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd",
      "subcategoryIds": [
        "54a720bd-17fb-4cad-bf47-3dccb1679e2b",
        "32db80b0-0ef2-47c9-b227-3e63cebf2db2",
        "cb69d289-f1a0-4cd5-8148-a64fccff19f8",
        "7b476f9d-7967-407d-a30a-f2f3de2b1a94",
        "e22a322b-c857-4f79-8c60-fe68bdde682c",
        "0a8a68b9-5cc7-4512-b4da-69167657435d",
        "30ce13ba-9142-4d4e-aa54-aede57ae2fde",
        "11a99ad8-dd0f-4eda-ab71-d6adaeded918",
        "a2d89ad8-6052-4d6b-81e8-08247610a145",
        "b49489ec-0d3f-4bfc-804f-ad9b2508fde8"
      ]
    },
    {
      "id": "ed39aa61-ace7-4968-a9a6-b96667b3740c",
      "name": "Checkerboard Artifacts",
      "definition": "Checkerboard artifacts are visual distortions observed in images generated or processed by certain AI and machine learning models, especially in the context of image synthesis, super-resolution, and generative adversarial networks (GANs). These artifacts manifest as a regular grid-like pattern resembling a checkerboard, often leading to undesirable visual irregularities such as blockiness, uneven textures, or unnatural repetitive patterns that detract from the realism and quality of the generated images.",
      "categoryId": "318494f6-733c-4be8-85a2-d4be1f934dff",
      "subcategoryIds": [
        "c15871bc-184b-4201-97c3-86d6090fdc6f"
      ]
    },
    {
      "id": "75996ba4-87e5-4cb8-96f9-a3ab020c7b9a",
      "name": "checkpoint averaging",
      "definition": "Checkpoint averaging is a technique used during the training of machine learning models, particularly neural networks, where multiple model checkpoints (saved states at different training iterations) are combined, typically by averaging their parameters. This process helps produce a more generalized and stable model by smoothing out fluctuations that occur during the stochastic optimization process. Instead of relying solely on the final checkpoint, checkpoint averaging leverages the collective information from several intermediate models to improve performance and robustness.",
      "categoryId": "d4762a61-7adc-436f-873e-25c13a01da66",
      "subcategoryIds": [
        "a864922f-3b7b-41af-b453-d3095a365705",
        "2719ef0e-d520-49da-a8ed-6fbcef4409a0",
        "e44bb249-0cc4-470c-9c4a-c7fbed6f1be1",
        "5224a462-802d-4a6f-b4a0-9c5c391a4679",
        "00999fa0-7b6e-4dda-8dd0-a41ca58638d3"
      ]
    },
    {
      "id": "77ef65fc-4e71-4fb1-a854-81492a239569",
      "name": "Checkpoints",
      "definition": "In the context of AI and machine learning, 'checkpoints' refer to saved states of a model during training, allowing practitioners to pause and resume training, evaluate model performance at different stages, or recover from interruptions. These snapshots capture the model's learned parameters such as weights and biases, enabling continuity and efficient experimentation.",
      "categoryId": "8deff07a-6590-4a5a-9069-4b995d98f743",
      "subcategoryIds": [
        "41880e1e-ef8b-482d-96f4-69197f9d6e1d",
        "b778e25b-e6eb-44fd-b387-ef034943f36d",
        "4a5a1cf5-efd7-428a-bcc1-2459af4736cd",
        "39b44b1d-2d5e-4b1e-b460-481afac47ba8",
        "ed6430f6-5372-4a94-b3b9-740cc018904e",
        "df55dc63-b88b-4bad-be3a-b167ced4f23f",
        "ac341139-44b0-4176-babb-816267ae621c",
        "292a8972-61a1-43dc-a671-571f5db0ee63",
        "c788e192-7f51-45c8-a7fe-77ae9715558a",
        "e7cea6ec-511f-41f2-9164-39b49f65d2cd"
      ]
    },
    {
      "id": "d3457a2c-9ea5-42c0-9b10-b98d316ae03e",
      "name": "Cheminformatics",
      "definition": "Cheminformatics, also known as chemoinformatics, is an interdisciplinary field that combines principles of chemistry, computer science, and information technology to store, analyze, model, and visualize chemical data. It involves the application of computational techniques to solve chemical problems, facilitate chemical data management, and accelerate the discovery and development of new compounds, drugs, and materials.",
      "categoryId": "dd8ebb43-0c92-420a-baaa-a4cc713818d2",
      "subcategoryIds": [
        "3c7c2b09-fd9f-4f58-a7a1-d6fef3731426",
        "6aadce8e-6db7-4d0b-983b-bda36429dfd2",
        "15f20fe5-6016-4c0e-b608-8903fa28b420",
        "19ccb3e7-d73c-49f9-9e8a-e48c7fe7a8cf",
        "d30538df-d43b-43d3-a7a9-ff18bd1a37a4",
        "ffbd43dd-c9ce-49e2-a4c3-dec10f0c8419",
        "b3fb4322-bf35-4f2d-8227-74bee8bfdbcb",
        "f16f8c4e-2ed5-4b2f-a723-0e7d27de2371",
        "755d15b6-f6eb-4964-8de8-9146f85ea4c7"
      ]
    },
    {
      "id": "a7468a45-fce2-4de8-9094-a91c985b4e07",
      "name": "Chi-Square Test",
      "definition": "The Chi-Square Test is a statistical method used to determine whether there is a significant association between two categorical variables. It assesses how well observed data fit the expected distribution under the assumption of independence. Essentially, it compares the observed frequencies in each category with the frequencies expected if there were no association, helping to identify relationships or dependencies within data sets.",
      "categoryId": "e4b7a0a6-4954-42e8-8fd8-f3a8835c53fe",
      "subcategoryIds": [
        "08d0c847-b084-41ea-b1ce-211d5710c73e",
        "8ef09230-c21f-4d47-b5cd-165effc20578",
        "425d62e3-72a0-4e29-a2ab-920d70d73b58",
        "cb7efa9c-96d0-4520-a6ae-0728a057faa6",
        "f3db8a84-a411-4169-bd84-f61b644d0dbc",
        "a841c5c8-4e22-4b0e-aafd-803106ac63cd",
        "1437017e-cccd-4e1f-96e4-6b9a4acea8a4",
        "c3a51864-a3d4-4aeb-a484-3fda89663159",
        "37dfbdc7-7875-45e8-9d31-7d7eca61c156"
      ]
    },
    {
      "id": "2fa69260-5ed4-4363-abde-6732b58457ec",
      "name": "Chi-Square Tests",
      "definition": "Chi-Square Tests are statistical tools used to determine whether there is a significant association between categorical variables or to assess how well an observed distribution fits an expected distribution. These tests evaluate the independence of variables in contingency tables or the goodness-of-fit of an observed frequency distribution against a theoretical model. They are widely used in data analysis to identify relationships and to validate hypotheses involving categorical data.",
      "categoryId": "4a584d60-b7fc-408a-953d-1145285d0408",
      "subcategoryIds": [
        "462e906f-4a28-4031-ad2e-10f0861203f0",
        "0690e099-277c-4725-ab55-31d79cc8f44f",
        "d22e4df0-7139-4feb-8252-331c32e0f5c9",
        "ba51d876-501a-477e-b61a-7aa69a530ca3",
        "59847c90-1ee5-4d7b-a1d1-c12beb384399",
        "85f41635-c790-4208-904c-9a0ccb88e41c",
        "a7f2deab-4771-4a38-a350-328abe874b19",
        "85842a69-6acd-4042-80d5-1b3c184ad4b2",
        "ab17754a-d9ed-4690-b6e5-aa662cdca485"
      ]
    },
    {
      "id": "92565c75-a4d8-4f6b-b5db-07e7c6a25076",
      "name": "Cholesky Decomposition",
      "definition": "Cholesky Decomposition is a numerical method used in linear algebra for decomposing a symmetric, positive-definite matrix into the product of a lower triangular matrix and its conjugate transpose. Specifically, for a given matrix A, the Cholesky decomposition finds a lower triangular matrix L such that A = LL\u1d57. This technique simplifies solving systems of linear equations, matrix inversion, and covariance matrix operations in various scientific and engineering computations.",
      "categoryId": "735a2dd8-6fc3-4bd6-a899-852cbdf23c99",
      "subcategoryIds": [
        "1243d634-a4ca-4032-b833-2a2a6fbe7d5d",
        "a4628d48-7610-4b65-b676-2571ae6044c9",
        "10d5197f-39b2-4ba9-9af8-921002878a87",
        "2e2a265b-7c08-4aac-bcca-af1b9133d00e",
        "7df808c1-1b55-4fe7-9328-d72ec328eabb",
        "a4d527bd-826e-4ea7-b214-897592c131db"
      ]
    },
    {
      "id": "45a31078-0b73-4ad6-97c6-3dd3ac9699cf",
      "name": "Cholesky Decomposition in Optimization",
      "definition": "Cholesky Decomposition is a numerical method used to factorize a symmetric, positive-definite matrix into the product of a lower triangular matrix and its transpose. In the context of optimization, it is often employed to efficiently solve systems of linear equations, perform matrix inversions, and compute covariance matrices, thereby facilitating many algorithms in machine learning and statistical modeling.",
      "categoryId": "7e9c0771-3e57-4601-8772-4357a34d7bba",
      "subcategoryIds": [
        "ba25f462-bbd4-4a27-af39-9f26f054c6fc",
        "c7e0ec75-dda6-40ca-bf13-e14d1c42d336",
        "8610311e-2751-48d1-bb4c-d35cde4c7785",
        "fafb901f-600c-49c0-91bc-c52eb7be810f",
        "493194ba-7686-42b5-ba7a-5b3d4473513c",
        "1ef856b2-3d96-488e-afb0-1d48127688f3",
        "9ac4f4a5-930a-4b5e-992a-94db60c2c8de",
        "39be0018-920a-4311-a209-f0d61a5d04e9",
        "abcd3fe0-e817-4944-bee2-396de4de9cbd"
      ]
    },
    {
      "id": "0439318e-7f4e-44ec-95fa-c3f8411ae046",
      "name": "Chromatic Aberration Correction",
      "definition": "Chromatic Aberration Correction refers to the process of identifying and mitigating color fringing and blurring artifacts in digital images and optical systems caused by the dispersion of light through lenses. This correction aims to enhance image clarity, color fidelity, and overall visual quality by compensating for the chromatic aberration that occurs when different wavelengths of light focus at different points in the optical path.",
      "categoryId": "48eee011-823f-46be-8f3b-9feca7df5778",
      "subcategoryIds": [
        "ca8f7f5e-cad6-4bbc-8ab9-dd172342bf19",
        "6fb43a79-1f52-4f9f-beec-81de704b3ca0",
        "cc1b6ce4-ac19-4f62-9980-1ab697c26d0c",
        "3eae8a88-3c20-4253-a3a5-0ed90853ba53",
        "b26da4c0-cf76-4b0e-b01e-6e98690ad842",
        "88e96a98-5bd7-4f6c-8559-b3b971b150b9",
        "40ec2e38-4882-4296-9f87-146e8b27ca15",
        "3f09bb9e-509d-43ca-8590-2a61b2591614"
      ]
    },
    {
      "id": "f302c945-827e-417c-a5db-4d1dc62f9743",
      "name": "Chung\u2013Lu Model",
      "definition": "The Chung\u2013Lu Model is a random graph generation model used in network science to produce networks with a specified degree distribution. It falls under the category of inhomogeneous random graphs, where the probability of an edge existing between two nodes depends on assigned weights or propensities related to each node. This model is particularly useful for modeling complex networks such as social networks, biological networks, and information networks that exhibit heterogeneous degree distributions.",
      "categoryId": "e7ce8e8b-1e14-485b-95f2-8fffc742834b",
      "subcategoryIds": [
        "18d67120-bfa6-49a7-be24-b5ecb239fdea",
        "053f3e66-667b-4b2a-8560-4c69b7d95c2d",
        "70108c4e-1e0b-433e-8347-187ce3a0a7d9",
        "fabb2418-8f89-4ddd-8daf-f2d275b0b10c",
        "355fccbb-b2b4-4304-9233-c453b76010ca",
        "a7f175da-a4e4-4553-9435-cb7172800a55",
        "5ee5f190-e618-4d21-83d7-d6467ba53d5b",
        "40f65e4d-5ecd-4f16-92bb-9cddc3fb329b",
        "5f8023a9-efdb-44f8-819f-5b928ee7e3fa",
        "d05ad420-77a6-4985-b68a-532c4d7de485"
      ]
    },
    {
      "id": "f388008b-a6cf-43ed-ab73-23f1def61422",
      "name": "Chunking",
      "definition": "Chunking in the context of AI and machine learning refers to the process of dividing data, sequences, or information into smaller, manageable, and meaningful segments called 'chunks.' This technique is used to simplify complex data, improve learning efficiency, and enhance the interpretability of models. In neural networks, especially in natural language processing (NLP) and speech recognition, chunking often involves segmenting continuous data streams into discrete units for better processing.",
      "categoryId": "b40e6a87-616a-4670-a592-0f497a51851d",
      "subcategoryIds": [
        "eaf3b6d7-b11b-40c1-8ab7-395ac90a81a7",
        "8e3b1a95-023e-4e8f-8a83-882fe8c99405",
        "1b8e4fb2-306f-4625-bbf8-371b1c83cd3e",
        "965d30c7-032f-40a9-a5dc-551cb89d91fe",
        "852eb2eb-a9df-4aa1-a3b9-25682992208b",
        "42f0a72d-c01b-4dde-ba2a-65e1241c15d8",
        "5852fd65-47db-4c8f-9ff8-ca6ccde1060c",
        "0749f99c-f658-4ed4-912b-d3a5492a76a5",
        "18212fb9-17b9-4460-8cbe-8c79a70877d3",
        "30c3e320-e190-4b18-a0bb-5a203ab4b4da"
      ]
    },
    {
      "id": "470e2691-d7cc-45b8-9066-5bf8d4b3686c",
      "name": "Chunking in NLP",
      "definition": "Chunking in NLP (Natural Language Processing) is a technique used to segment and group words or tokens in a sentence into meaningful units called 'chunks.' These chunks typically represent syntactic constituents such as noun phrases, verb phrases, or other grammatical components. The process involves dividing text into these manageable segments to facilitate further analysis, understanding, or processing tasks like parsing, information extraction, and question answering. Unlike sentence-level parsing, chunking focuses on identifying and labeling these non-overlapping segments without necessarily constructing a complete hierarchical syntactic structure.",
      "categoryId": "dbd57fe6-631d-48dd-ada6-5e05c05ed81b",
      "subcategoryIds": [
        "274c2045-864c-4ebd-94b2-bcbcbd9f65c8",
        "f021f5f5-b46e-413f-bc8b-2f6a79fbf496",
        "319379e0-e362-4024-b584-3feb5817046c",
        "dcbeec32-62b5-4cc3-b87e-79f2d0c92d43",
        "6e7c7e9a-29bc-454b-ad6a-eed7bbf3e8f9"
      ]
    },
    {
      "id": "1186fe20-9683-4832-8b34-d8edf1a9cc54",
      "name": "CIDEr Score",
      "definition": "The CIDEr (Consensus-based Image Description Evaluation) score is an automated metric used to evaluate the quality of image captions generated by machine learning models. It measures how closely a machine-generated caption aligns with human reference captions by analyzing the consensus among multiple references based on n-gram overlap, emphasizing the relevance and descriptiveness of the language used. CIDEr is designed to address the limitations of earlier metrics such as BLEU and ROUGE, by incorporating semantic importance and human consensus, making it particularly useful in tasks like image captioning and multimodal content description.",
      "categoryId": "48cf7045-f678-452c-af24-2af663372278",
      "subcategoryIds": [
        "d4628219-df88-4cae-8ba1-0b33072801d5",
        "826ac484-7fb2-4191-926b-2dce323c3436",
        "fc5451d7-a277-4a50-93ef-8927d188662f",
        "eb106bb0-7af4-4614-98c0-ddfc06697c39",
        "ec09cd8d-3943-4258-94cc-9acf66adbe66",
        "3649ba56-03d1-4d8e-b1d3-8d3b857b27a8"
      ]
    },
    {
      "id": "5d294a26-cb72-431c-9379-2cb26f8aa98a",
      "name": "CIFAR-10 Dataset",
      "definition": "The CIFAR-10 dataset is a widely used benchmark dataset in the field of machine learning and computer vision. It consists of 60,000 32x32 color images divided into 10 distinct classes, with 6,000 images per class. The dataset is split into 50,000 training images and 10,000 test images, providing a foundation for developing and evaluating image classification algorithms. CIFAR-10 is designed to challenge models with its variety and complexity of images, making it a popular choice for assessing the performance of neural networks and other image recognition methods.",
      "categoryId": "786a9a94-7a56-4185-a591-b22a21025404",
      "subcategoryIds": [
        "c5e03689-1391-49f8-a791-88adf22f1f4e",
        "4f47ba87-799d-47cd-9ad5-c44e1544be0e",
        "1b5d75d7-b539-4d49-8e9c-ed16f8548c82",
        "0577c12a-8cc2-41e1-b92d-a2aa6be34fa1",
        "e5c7380d-4def-4a1b-8bdc-b69415a7288d",
        "31e52cf6-2a53-4120-ba34-12fbd80df6ed",
        "70c22687-d182-4a52-97a5-bd6039e62ea5",
        "a75a1cad-ce3e-440e-9912-6cd73ea54fc2",
        "75fa8c2a-7309-4452-92ef-79e645524080",
        "0d955c26-ae39-4462-9772-f5050f060792"
      ]
    },
    {
      "id": "12e12797-ba54-4a45-8480-c3a57f4c6f50",
      "name": "CIFAR-100 Dataset",
      "definition": "The CIFAR-100 Dataset is a widely used benchmark dataset in the field of machine learning and computer vision research. It consists of 60,000 color images divided into 100 different classes, with 600 images per class. The dataset is split into 50,000 training images and 10,000 test images. Each image is of size 32x32 pixels and has a corresponding label indicating its class. The dataset is designed to facilitate the development and evaluation of image classification algorithms, providing a challenging yet manageable dataset due to its diversity and complexity.",
      "categoryId": "5032c5e9-c216-4409-b331-6956f5df4c8f",
      "subcategoryIds": [
        "c371ea5b-ccb9-483b-b022-b53fea61e61c",
        "852f6281-f6d1-42d6-9fc7-7c87edaa5ea5",
        "de5026de-9a6a-4bcc-bc04-5385747cc109",
        "b1294857-06c7-4655-b30d-7e26a5bba257",
        "b8a9a437-a7d3-4be8-8df5-aff884c11b73",
        "d3fa8795-10f3-4cea-952e-eac0ba000c43",
        "3d16b948-e030-4159-9e53-f1580b55b6b7",
        "90dc9c35-05a3-4162-bf54-0693296f23a3",
        "548275d6-b6b1-46aa-b0fb-e57c15bccb4a",
        "990cd93b-f999-49bd-bc6b-53bd3e27f6c0"
      ]
    },
    {
      "id": "5f05d622-9662-4eef-9e36-4d99a5aaef65",
      "name": "CIL (Class Incremental Learning)",
      "definition": "Class Incremental Learning (CIL) is a subset of continual learning where a model learns to recognize new classes over time without forgetting previously learned classes. It involves sequentially updating a classifier with new class data while maintaining high accuracy on earlier classes, effectively mimicking human-like learning abilities. CIL aims to address the challenges of dynamic environments where data and class distributions evolve, enabling AI systems to adapt incrementally rather than requiring retraining from scratch.",
      "categoryId": "8a32ca49-a730-42ed-9b0e-ff477cbaedb0",
      "subcategoryIds": [
        "91bd5334-959f-4e3b-9ae9-4e9b0bd29b21",
        "75e15e6f-6aff-42cb-8de3-4392b25dca84",
        "4cd03244-8511-43f6-9a09-f6e3b5d390bc",
        "0464a548-f4e7-4924-a027-9627258f6f0e",
        "86ba27da-40a2-4c21-8d1e-498531487836",
        "39ec3cba-3139-4940-a7d9-37b2b9ee91b4"
      ]
    },
    {
      "id": "73e1afaf-c964-4c7f-8c27-c3f5ed965651",
      "name": "Circuit Analysis",
      "definition": "Circuit Analysis refers to the process of systematically understanding and evaluating electrical circuits to determine the behavior of current, voltage, and power within the network. It involves applying fundamental electrical principles and mathematical techniques to analyze how circuits respond under various conditions, enabling engineers and scientists to design, troubleshoot, and optimize electronic systems and devices.",
      "categoryId": "2ee5dd7e-b360-4cd3-a7c5-64294a8eedd6",
      "subcategoryIds": [
        "a78b9ccc-36dd-4b5d-a390-80d4da62f7f3",
        "b7df4158-8dd3-4d0f-ac19-53e7fe5cf19e",
        "f6e67462-7e55-42ae-8046-93cf73cb9278",
        "57f67967-be74-4dc9-9b14-03193d6534c2",
        "4a37d945-2beb-4cde-a1c8-bcc0637c7ae5",
        "ac9ce9b9-867e-45ce-bbe2-36b00913b833",
        "ff9e011a-09cd-4c23-b55a-c8c77ee226a2",
        "27ecd275-8b81-4956-8073-dc689d51bc37",
        "eeaec218-eb91-42ba-9ee4-a3798e0d779a",
        "16395455-79d4-43fc-84ba-d12187bf32bd",
        "e934ddcc-03bf-46e6-8b90-3b44988b3e49"
      ]
    },
    {
      "id": "67a99ebb-f6e9-4718-a9eb-34293795084a",
      "name": "Circuit Complexity",
      "definition": "Circuit complexity is a branch of computational complexity theory that focuses on quantifying the minimum resources required to compute a boolean function or perform a computation using logical circuits. It involves analyzing the size, depth, and gate count of combinational and sequential circuits necessary to implement specific functions, providing a measure of the computational difficulty and efficiency of implementing boolean functions in hardware or logical systems.",
      "categoryId": "93554169-5d1b-40f0-8055-a66f5ccab707",
      "subcategoryIds": [
        "a7da6a21-c17f-41f3-8325-73c323f10e8f",
        "09d6e802-385c-46eb-8c9e-09194810febe",
        "fc3a4ed9-fe59-4975-93fc-03e14db9145c",
        "bb2d90da-6ac0-47c7-a178-c49859d78b3e",
        "7034591d-8a68-45e9-9a8f-08228ba57201",
        "104c8ca5-fa05-4603-bda8-033956c2fc2b",
        "cf9bf69f-b4b1-4ea2-8b1d-028f3f431835",
        "766628db-5d29-454b-b00d-37a68d8f675a",
        "6edab30f-6684-4aae-90ba-d66cf65d52ad",
        "e8e5be7e-f04d-4c6c-bfa8-26f54707a832"
      ]
    },
    {
      "id": "854b6faf-cc03-4087-ae21-49576e59ca89",
      "name": "Circuit-level Analysis",
      "definition": "Circuit-level Analysis is a fundamental technique used in electronic engineering and computing to examine and understand the behavior of circuits at the individual component and connection level. In the context of AI/ML, it involves analyzing the hardware implementation of AI models, particularly neural networks, by studying the electrical and logical operations within the circuitry that execute these algorithms. This approach allows engineers and researchers to optimize hardware performance, detect faults, improve energy efficiency, and enhance the overall reliability of AI systems.",
      "categoryId": "a36dd3a1-7144-4917-a772-4719bfaba07b",
      "subcategoryIds": [
        "fb87a3c4-8c8e-4c70-9be7-4840db7531bc",
        "6a345bc7-3a3a-48f1-8a54-6d1efc751b58",
        "762de29f-9a34-4943-8a93-e2500e5f78e9",
        "836aa276-8a31-4a00-ad1a-8252330f3b89",
        "66589c39-63a2-4496-868b-e04e1645b436",
        "0bcbb600-46c9-4ae7-b562-ec7dfd6fc678",
        "e82e1ba7-8308-4c74-9190-09af35ffbf1a",
        "b30a82f6-a0f7-4745-9012-26839c03fa88",
        "e32657f3-48cc-4381-8fa8-cf0db43a6000",
        "a2177c51-ce9b-4b53-9b9c-be9cd36b1334"
      ]
    },
    {
      "id": "7f1a5aeb-8410-46b2-a534-8f8a2c9746bc",
      "name": "Circular Convolution",
      "definition": "Circular convolution is a mathematical operation used to combine two finite sequences (or signals) to produce a third sequence, representing their combined effect under periodic or cyclic conditions. Unlike linear convolution, which considers signals to be of infinite length or zero-padded outside their original domain, circular convolution assumes the signals are periodic with a fixed period, effectively wrapping around at the boundaries. This operation is fundamental in digital signal processing, especially in contexts involving discrete Fourier transforms (DFT) and fast Fourier transforms (FFT), where it enables efficient computation of convolutions through frequency domain multiplication.",
      "categoryId": "39be3d34-0ca3-4a3e-9043-67f635a219ad",
      "subcategoryIds": [
        "9f6a86e7-a75e-4d4d-9107-b55507ba4b6c",
        "068c335a-539f-4d2d-8e57-9a88e9dc2ed4",
        "ae96917d-d1d6-47d5-8cbb-01ec973227ba",
        "ba018d72-0c28-43df-b55e-308be4cb9690",
        "32443b84-f383-47d5-b5e3-1c9cf7cb2212",
        "2c7cd79c-b0d3-4562-b280-a8526e5badd3",
        "b1cd60a9-d3d7-497f-b3e3-cbb3dcf45e56",
        "cffdfdb9-44a2-4fa6-893d-a89e74b76238",
        "b25bdc9c-895d-4cc4-be8b-e7ab3ecc519c"
      ]
    },
    {
      "id": "ba92bbb4-8d68-4506-9ceb-6a459286eb4a",
      "name": "Circular Padding",
      "definition": "Circular padding is a padding technique used in convolutional neural networks (CNNs) where the input data is padded by wrapping around its own boundary elements, creating a seamless, circular extension of the original data. This method ensures that the convolutional kernels can process all regions of the input without losing information at the edges, effectively treating the data as if it were on a continuous loop.",
      "categoryId": "0dfcee6a-536d-4ef4-a0de-559d865483b1",
      "subcategoryIds": [
        "99803fc0-b4d6-4a2f-8f82-672db91aa90f",
        "f07c5938-e5fb-46d7-a3a4-1dc5091bb2a8",
        "afdd16b2-d26b-473f-8656-8cf0007d40d8",
        "59b08657-0894-4af2-bf46-f29c4006bd9a",
        "90dcc8c5-23e7-4344-969f-5bf606390e90",
        "2dcdf16b-beb0-45ef-9168-ad71201b9b76",
        "0fa71e0c-b543-4d49-beec-29dd983ab33d",
        "098e416a-cb46-4b80-94dc-b5850ec839d9"
      ]
    },
    {
      "id": "951de744-1f2e-4130-87f0-16e34f171d39",
      "name": "Circular Padding in CNNs",
      "definition": "Circular Padding in Convolutional Neural Networks (CNNs) is a padding technique where the input feature map is extended by wrapping around its edges, allowing the values from one edge to be used to pad the opposite edge. Unlike zero-padding, which adds zeros around the borders, circular padding treats the input as if it is connected in a loop, creating a seamless wrap-around effect. This approach helps preserve the continuity of features at the borders, which can be particularly beneficial for tasks requiring seamless edge handling, such as in signal processing or image analysis where boundary artifacts need to be minimized.",
      "categoryId": "8736cab5-b049-49ba-8ecb-d6adf52db283",
      "subcategoryIds": [
        "53ae827d-bb7e-4aa1-a8aa-786650f18f0d",
        "d71f2724-25c5-4aff-89b9-1019fac34837",
        "ba41131b-5f1a-4f78-aff5-b3ca0483ccd9",
        "2b4f013d-d911-40f4-99e8-1ec825eb76b2",
        "1e513e4a-9908-45d5-a048-0758dd7e10d7",
        "822005a8-cbee-4d1b-b428-7685d814e004",
        "562f0c21-0104-4c67-9852-4dc7d61901f6",
        "f0a478b6-ee0a-481d-89ba-64d33a762812"
      ]
    },
    {
      "id": "c4543e60-ecf0-4b13-b148-ba9e1cb71196",
      "name": "Class Activation Mapping (CAM)",
      "definition": "Class Activation Mapping (CAM) is a visualization technique used in convolutional neural networks (CNNs) to identify the regions of an input image that are most influential in the model's decision-making process. CAM generates heatmaps indicating the areas within an image that contribute significantly to the predicted class, thereby providing interpretability and insight into the model's focus during classification tasks.",
      "categoryId": "770275c8-501e-43f4-9122-a75655ed7702",
      "subcategoryIds": [
        "cefc4c28-db9d-4bde-963f-8cbedf61839b",
        "c68ccb81-ea6c-4f96-b490-02f203a5c05d",
        "77aeb250-c61f-47c4-90f9-8bf009329a2a",
        "b1d6116d-48fc-427d-9140-fdbbdea21915",
        "6c2b839b-1f55-41c3-9b1f-a2bc9038b010",
        "44aa0380-e7d2-4023-a19e-7fb13df50010",
        "4c8069ee-53a8-4ef4-94c2-a36c6e96f45d"
      ]
    },
    {
      "id": "fda0cf97-6dbe-40b7-889a-0cf286c86452",
      "name": "Class Activation Maps (CAM)",
      "definition": "Class Activation Maps (CAM) are visualization techniques used in convolutional neural networks (CNNs) to identify the regions in an input image that are most relevant for a specific class prediction. CAMs generate heatmaps that highlight these discriminative areas, providing insights into how the model interprets visual data and making it easier to understand model decisions at a localized level.",
      "categoryId": "e0e205da-d6bb-4974-a029-a7874bb8fbb9",
      "subcategoryIds": [
        "6ad06b00-86ca-48dc-bdde-847eee23b4c1",
        "ebb4ee88-b3c8-41e4-9578-b3607e4b1399",
        "b6b58096-5423-43b0-932c-6b3ebf6abd79",
        "478d7314-410d-4143-af6b-892364bdec98",
        "639a9e7a-d4b2-4563-b4d1-7247517d7be9",
        "989fc5db-194f-4789-9a95-f0a462ab04e0",
        "77cc7b22-7de4-411b-bb0d-a0bc0e1a7cb8",
        "5cf8a927-8feb-48cd-9320-225dfc9102e9",
        "0a5e30b6-df7d-4e4f-ac81-d1fb122e6d21",
        "9dbdb4dd-4d99-4ee2-88bc-238da52bedb4"
      ]
    },
    {
      "id": "48d4b3c4-5e97-4f49-ae6a-b9427eedc730",
      "name": "Class Balanced Sampling",
      "definition": "Class Balanced Sampling is a data sampling technique used in machine learning to address class imbalance within a dataset. It involves selecting samples from each class in such a way that each class is equally represented during training, regardless of their original frequencies. This approach helps in reducing bias toward majority classes and improving the model\u2019s ability to learn minority class patterns, ultimately leading to more balanced and fair predictions.",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd",
      "subcategoryIds": [
        "fd6ee4dd-8d34-4f24-9460-c4646b1c9276",
        "dcc46fa0-54dd-4658-b6b7-b6a55428e1bd",
        "9f55c405-c2e2-4474-8242-f2e770ab3cb5",
        "7014656d-e428-4f6c-8ca2-444896468b65",
        "657fe139-3202-40fb-8316-ef6ab4d25d5b",
        "c011bef1-a7e6-418c-af21-bcbc17155a23",
        "b8ae509c-d63e-4acc-b6cf-bf856f0b7296",
        "427e4b56-0011-471f-9317-c58110cbc8af",
        "4615ea88-6d9e-48c3-aa87-48b769100862"
      ]
    },
    {
      "id": "b8dfc22d-7168-4d4d-b012-7c7aa344a579",
      "name": "Class Imbalance",
      "definition": "Class imbalance refers to a situation in machine learning classification tasks where the distribution of classes within a dataset is uneven, with some classes significantly underrepresented compared to others. This imbalance can adversely affect the performance of models by causing them to be biased towards the majority classes, often leading to poor recognition or prediction accuracy for the minority classes. Addressing class imbalance is critical for developing robust and reliable AI systems, especially in applications where identifying rare events or minority class instances is vital, such as fraud detection, medical diagnosis, and anomaly detection.",
      "categoryId": "0908d6eb-5bba-4add-bb6e-b82240de00c4",
      "subcategoryIds": [
        "2bf35fa7-0554-4bbd-86f1-3b5c56b7d15b",
        "73a155e3-8766-49f5-982a-f2296e2b6698",
        "2ca2835d-40b3-47d7-bbef-bbd1c581865e",
        "5d2da559-c9e4-400e-8da4-555bdfc24fa8",
        "a6542fdb-c757-4372-ba7e-8ae4e0ca6adf",
        "40cd1335-7af5-49a7-bf31-5621435a1926",
        "8e2f5c52-e028-413e-9805-73bc3292d022",
        "6f9a0ff6-94a5-4c2a-a65d-3172d9480214",
        "fe66d1d1-d784-4111-a027-8959686a63e5",
        "37f89ee0-98d6-4bd1-9c54-3d29b8bc2ebe"
      ]
    },
    {
      "id": "e97dda7a-15f0-496a-a860-2a5782a6c3bb",
      "name": "Class Weighting",
      "definition": "Class weighting is a technique used in machine learning to address class imbalance in classification tasks. It involves assigning different weights to different classes during model training, typically giving higher weights to underrepresented classes and lower weights to overrepresented ones. This approach helps the model pay more attention to minority classes, improving overall performance and fairness in imbalanced datasets.",
      "categoryId": "64b1cb6c-0424-4d85-9ddb-cfaa727c482e",
      "subcategoryIds": [
        "a35c0d6c-aca0-4e68-b0de-f64a5ac565eb",
        "5ebcb93c-600f-4d63-9dcd-2821769e7e6c",
        "4779a425-44ab-4be2-9ad4-a8b38cdf03db",
        "a0397b3a-5390-4355-884f-053d3750e926",
        "2da28884-fde8-4983-9297-6e1fa0971730",
        "d80a09bc-5d5b-416d-84c1-398badf9483e",
        "4f623fff-ab20-4286-8d54-ee90918e522c",
        "8a2beb20-22b9-4e36-9f1f-1196ce90c69e"
      ]
    },
    {
      "id": "4ff5343e-f7bc-4f1b-b711-ccd3fa6e59e4",
      "name": "Class-balanced Loss",
      "definition": "Class-balanced Loss is a loss function designed to mitigate the challenges posed by imbalanced datasets in machine learning. It emphasizes balancing the contribution of each class to the loss, ensuring that minority classes receive appropriate attention during training. This approach helps models perform better across all classes, especially when certain classes are underrepresented, by adjusting the loss computation to counteract class imbalance effects.",
      "categoryId": "16a15cef-10ad-4515-8117-d55207019792",
      "subcategoryIds": [
        "c50da3a6-7488-4cd5-ad5d-747a201ee147",
        "c43a45a9-f124-42ab-9039-fa1a97e04623",
        "99fb2d53-bdf3-4b99-ba40-0bb1190cc6da",
        "5b10b478-4f78-400f-90e1-2a57eb66d852",
        "0fb66f7b-3c7e-44fc-814d-ca3600bb4cc4",
        "b923b4be-fa5f-4115-b62b-f318b73286f2",
        "219a5812-b3bf-45a0-9ce2-30c244e1f53f",
        "9794cf81-5856-497a-8ecb-a3726f333fd4",
        "0a687f38-2da7-47f5-8242-1c7c9abaec79",
        "42304231-905a-4c51-a537-acd81e651a65"
      ]
    },
    {
      "id": "363a273b-6d32-41b8-871a-29853f24cb7d",
      "name": "class-balanced sampling",
      "definition": "Class-balanced sampling is a technique used in machine learning to address class imbalance within datasets. It involves adjusting the probability of selecting samples from different classes during training to ensure that each class is adequately represented, thereby preventing the model from becoming biased towards the majority class. This can be achieved through methods such as oversampling minority classes, undersampling majority classes, or applying weighted sampling strategies. The goal is to improve model performance, especially in tasks where certain classes are underrepresented, by providing a more balanced training process.",
      "categoryId": "cf218244-1683-4c33-a1a1-d49146732ac2",
      "subcategoryIds": [
        "6c97db1a-3406-4140-a6f7-7488e058f026",
        "1c3fd716-627a-4822-a339-ee6e34d071f6",
        "0abc31de-bfe9-4dd5-a1c6-8af88d029834",
        "cd9b6b6b-4533-49b5-9481-6b64ebfda008",
        "f90c1e7e-02da-4e83-9771-06da91390a28",
        "d676a47c-8356-4e84-bc8d-e890979bafd4"
      ]
    },
    {
      "id": "5d7c7c6e-2e32-4bbb-bfad-7841f80abf2f",
      "name": "Class-weighted Loss",
      "definition": "Class-weighted Loss is a technique used in machine learning to address class imbalance during model training. It involves assigning different weights to different classes in the loss function, thereby increasing the penalty for misclassifying minority classes and helping the model pay more attention to less frequent classes. This approach modifies the standard loss function to incorporate class-specific weights, aiming to improve overall model performance, especially when dealing with skewed datasets.",
      "categoryId": "eb5dbbce-e8ae-43b2-8571-74697de70585",
      "subcategoryIds": [
        "bcdf0a78-c033-4871-94a7-3f5d4a8166d1",
        "c34d1443-ac6f-4392-8471-5db3f2095870",
        "44f99bd9-6ff5-4e4a-b466-6a348444ea93",
        "28212bfb-b91c-4b45-930b-89a4fc05dbef",
        "f6f7ab0a-8668-49e3-a990-e48f529902a4",
        "ca3ba83b-6e26-4f96-b594-8aa4ced27be7"
      ]
    },
    {
      "id": "e0cc938b-fabd-42b3-b36a-2a31d26a6779",
      "name": "Classification",
      "definition": "Classification is a supervised machine learning technique where an algorithm learns to categorize data points into predefined classes or labels based on input features. It involves training a model on labeled datasets, enabling it to assign new, unseen data to one of the established categories. The primary goal of classification is to accurately predict the class label for each data instance, facilitating decision-making processes across various applications.",
      "categoryId": "4cd7a78e-22b9-4a6f-92c8-fec5215dd5ca",
      "subcategoryIds": [
        "1403bea6-a9ba-4ff1-837b-f9ab6b6387ff",
        "55a0e243-1f9b-406f-820a-6c4f42352ddb",
        "d40b6333-2f70-43d0-8053-7b78bfeb3620",
        "275ddcf4-34c4-4cf0-b595-f97334d08e5e",
        "66c85043-cd1c-4fb9-a94a-f51957d27942",
        "c3422152-5aba-41af-a64c-14ccfa6ac248",
        "87fb5bb1-25db-4cef-ba01-aa32536c70a0",
        "5ff98483-b47d-47d8-afa3-b9e655003aac",
        "9099fc24-6497-4a44-b5f9-7aac929621a7",
        "aedc4a52-7555-49bc-9034-d424f3608502",
        "ea511476-b2d3-4ebe-ba7e-bce338494060",
        "56d086f4-defb-4263-9814-9158a21a5d4e",
        "9d386735-b193-4aec-bd32-05fe6070ad67",
        "45547030-2353-48de-b273-dd457ecc7eec",
        "dfa82ecc-72c5-4f1b-9898-cbd0301c6bb7"
      ]
    },
    {
      "id": "45d9ed6c-08aa-4bfa-9adc-d87618eaee20",
      "name": "Classification and Regression Trees (CART)",
      "definition": "Classification and Regression Trees (CART) is a decision tree algorithm used for supervised machine learning tasks, primarily classification and regression. It constructs binary trees by splitting data based on feature values, aiming to improve predictive accuracy. The CART algorithm produces a tree structure where internal nodes represent feature-based splits, and leaf nodes represent output predictions, enabling easy interpretation of the model's decision-making process.",
      "categoryId": "4e43c1a3-acc6-4d34-b276-32b8da3cb08e",
      "subcategoryIds": [
        "6df5175c-0d25-4c01-adbd-b2e080490328",
        "7f1c7c0e-260b-4f85-907a-04375eb48743",
        "46103924-eef7-4e65-8b0e-f3fd829cfb29",
        "b59457fb-12a5-458f-84bd-6c01b5f2986c",
        "4c07456d-abdf-41fd-8bb4-2fd417cf805c",
        "05d49ef6-f8cc-44f1-9b6d-a3762962ca2c",
        "338d828f-5be0-4051-94f5-898e29c8b7c7",
        "6e450527-3d8e-4d37-b36d-75a3dfc0ff91",
        "6c505fd8-c25c-4326-9b2e-f173ff89e6da",
        "b081d55c-fa1f-489e-b9f1-dff91d294f66"
      ]
    },
    {
      "id": "a416a612-d4fe-42bf-bbcf-adf6371eee12",
      "name": "classification evaluation",
      "definition": "Classification evaluation refers to the process of assessing the performance of a classification model, which is designed to predict categorical labels for data instances. It involves using various metrics and methods to determine how accurately and efficiently the model assigns inputs to the correct classes, thereby enabling practitioners to understand the model's effectiveness and identify areas for improvement.",
      "categoryId": "79ba7f32-fdd2-44b9-bd97-b00865bb917f",
      "subcategoryIds": [
        "def9a902-8545-4876-8f99-c306d64c3584",
        "046f2b4c-f77e-45ce-b8e5-8160e8135dc4",
        "ad530c7a-cf92-4219-ae26-8966be21348c",
        "7119d0bc-5b1b-4fd0-9368-a98983b0888d",
        "6809adf5-6162-4a50-b226-9e2b95f2ffb2",
        "571e05d2-21de-4010-89ef-203a44368a54",
        "48d1832b-6b17-4148-8c7c-34e808254b07",
        "97150dea-4543-4f7e-a907-69027361063c",
        "94ebc067-9077-456c-8abb-4de79df7b1bf",
        "f7fd1069-b209-434b-b676-9dba7e2bc105",
        "a83552cb-d2db-4e92-b1a0-3c699ad7a1bf",
        "5b69a638-b482-41d6-ad43-5bf2efffdbdb",
        "af12bb0c-804a-44e3-b1b1-7dee6a3de9af"
      ]
    },
    {
      "id": "d9af2dbf-9017-4d35-b703-a82c13923f29",
      "name": "Classification Problem",
      "definition": "A Classification Problem in machine learning involves categorizing data points into predefined classes or categories based on their features. The goal is for the model to learn patterns from labeled training data so that it can predict the class labels of new, unseen data accurately. This type of problem is fundamental in environments where decision-making is based on categorization, such as spam detection, image recognition, and medical diagnosis.",
      "categoryId": "6a5b4220-758f-46c3-903d-a19f8c1fca15",
      "subcategoryIds": [
        "756d2a6e-ecfc-40e9-8c9e-9082c5080c62",
        "02e9c202-223b-4242-b59f-b2ef3d0577f1",
        "069fe3d5-729d-46b5-a16c-4bab63e88c4d",
        "484a4a1b-915b-44d7-bd7c-82014821b6a6",
        "1d00fa5d-79c4-4fb2-9db6-67f2b1f09704",
        "f1ece903-ae1f-4551-b3e7-38033874d0fb",
        "77d5e538-e072-4cfb-85be-842b92dc7c4c",
        "58caebb7-6e3d-4589-8dd3-8f087c8d256a",
        "7231e8ec-9679-470b-9dd5-a908747b3572",
        "4a8a486c-656a-4000-852c-5cf0f73b35fa"
      ]
    },
    {
      "id": "d162d694-9f0e-4019-96e4-bafdbfe778cf",
      "name": "classification report",
      "definition": "A classification report is a comprehensive evaluation tool in machine learning that provides detailed metrics to assess the performance of a classification model. It summarizes key performance indicators such as precision, recall, F1-score, and support for each class in a classification task, offering insights into how well the model distinguishes between different categories. Typically generated after predictions are made on test data, the classification report helps practitioners understand the strengths and weaknesses of their models in terms of class-wise performance.",
      "categoryId": "cb6a0d23-dd1e-4a42-aeb4-4e0cd863dc82",
      "subcategoryIds": [
        "9a9d4451-ea63-48cd-820f-67dd889f83e1",
        "3d61b3fa-0b84-40b3-b46d-9fa25358bcb2",
        "9c5c5e8c-7ba0-4b07-b097-32861aeeca3c",
        "ba9a1086-d95a-4293-a30b-d2dbdd252abb",
        "81970d60-c427-4bb4-888b-da3caaecf0ea",
        "64dd26f5-8292-4186-83d3-9c466beaaf28",
        "4e437b7c-ea78-48a6-82e2-2f882e1d9346",
        "f4be5dc0-3361-4e05-abbf-fc1a4fca90c9",
        "9151f609-6a52-409c-bfc1-13605fe39eb2",
        "a2712890-42c4-445c-bc9e-9b7de1de4b14",
        "a09d66ce-d835-40bf-9215-0269f22423b3"
      ]
    },
    {
      "id": "2afa3c68-dffd-4a17-ab13-ac128bd5bd3c",
      "name": "Classifier Chains",
      "definition": "Classifier Chains are a method used in multi-label classification tasks where multiple labels are predicted simultaneously for a given instance. This technique involves chaining individual binary classifiers, each responsible for predicting a specific label, with each classifier taking into account the predictions of previous classifiers in the chain. The goal is to exploit label correlations and interdependencies, improving overall classification accuracy in multi-label scenarios.",
      "categoryId": "e1f090cb-48c8-45b1-aedf-b83a8fd93f54",
      "subcategoryIds": [
        "eeabe272-7a5d-4fb4-9059-affb0fcbb8ba",
        "baedb52a-1f65-4c67-9339-71b579dafb50",
        "7bfab04f-365e-413c-a7aa-d5c11765230a",
        "a518d45c-9f80-4864-b8fe-f8d38a99c05d",
        "8e5c822f-7e2a-47aa-9c88-ebb23549b9a3",
        "f5583359-aa05-4a5b-b3c1-3789d24e69ac",
        "7bee405a-23f4-42bc-b1e2-d8dfb2fbd2eb",
        "cca57a83-6346-4eb9-b099-fe8718bd51a5",
        "55957176-6bf9-41cb-bd7a-982bbd378d2e"
      ]
    },
    {
      "id": "f16607ce-0735-41b5-88d7-e0220adfa9d4",
      "name": "Classifier-Free Guidance",
      "definition": "Classifier-Free Guidance is a technique employed in generative models\u2014particularly in tasks like image synthesis and text generation\u2014that enhances the quality and diversity of generated outputs without relying on explicit classifier models. Instead of using an external classifier to steer the generation process, this approach integrates guidance directly into the model's sampling or inference procedure, allowing the model to produce high-fidelity results that adhere to desired attributes or prompts. It leverages learned, conditional information within the generative model itself, enabling more flexible and efficient control over the output while reducing dependence on separate classification components.",
      "categoryId": "d933572d-ce55-41ce-8049-2f630032e5b1",
      "subcategoryIds": [
        "749a0dff-a55e-4148-a702-123e8bd0b2e1",
        "28c323ce-af45-4352-87f4-413673f61f87",
        "1d84b63c-b83d-497e-b065-b16563a9221f",
        "7390497e-4264-4c05-b620-d9f85d7cd9fa",
        "04d3f8b4-4b73-4056-8a5b-fc8236418b16",
        "b72cbcda-e275-478c-b9d5-8deacef4f123",
        "dd2f27f4-1e7f-4a07-a982-50bd0c96234d",
        "e24e3405-0424-468f-a755-35d9a0efa6a9",
        "9b6c7531-ca69-40e8-ad38-803d454c76cc",
        "951aeb43-8008-4399-af1e-d40ab05c1958"
      ]
    },
    {
      "id": "195d4307-4ebc-4653-82c0-032f7d5afc40",
      "name": "Claude Security Impact in Sentiment Analysis",
      "definition": "Claude security impact in sentiment analysis refers to the potential vulnerabilities, risks, and ethical considerations associated with the use of the Claude AI model (developed by Anthropic) when analyzing and interpreting sentiment data. This impact encompasses how the deployment of Claude can influence user privacy, data security, bias propagation, and the accuracy of sentiment detection, which in turn affects decision-making processes based on sentiment insights.",
      "categoryId": "735e4475-77a8-44e0-93d6-73b5d712a5e5",
      "subcategoryIds": [
        "2b30ccc5-8b43-4b6e-b67d-7a50278b22ad",
        "f444cf0e-95fe-40fc-8d62-097c8b4ca8bf",
        "8fcacbed-fc2d-451c-8fe6-2bdd994b408a",
        "713db711-a14c-4a84-bbc2-9381fdb64076",
        "10727c44-2588-4be9-aece-1d9fd5649a2d",
        "87ed3b59-3693-442e-aa45-b2203823a398",
        "0cbefed9-5086-4f97-9c53-e9f35aaabaae",
        "037a3a21-4475-4d13-ab04-2ed9918cc2a6",
        "1f49b699-ae63-48e3-97de-48cfe71748ed",
        "fb338b5e-7d17-4bf8-ba11-926415398cc4",
        "be561b7a-a322-4df3-9923-900f4c9480c8",
        "2dcb1458-b481-423d-9c54-add1d57b6da6",
        "f845faa9-8ace-4dc9-afc0-be45649f540d",
        "a0f4fdc6-bebe-45d3-b12f-24e8166244cf",
        "0b8fc966-c2ec-4272-93ec-3c6c9f8e4e66"
      ]
    },
    {
      "id": "09eaf667-625b-4025-bc19-e9158acadf62",
      "name": "Clausius-Clapeyron Relation in AI Thermodynamics",
      "definition": "The Clausius-Clapeyron relation is a fundamental thermodynamic equation that describes the phase transition between two states of matter, typically relating temperature and pressure during processes such as vaporization, condensation, sublimation, or melting. In the context of AI thermodynamics, this relation provides insights into how energy, entropy, and phase stability interact within models that emulate or simulate thermodynamic behaviors, often in the pursuit of optimizing energy-efficient AI hardware or understanding thermodynamic-inspired training algorithms.",
      "categoryId": "842a056b-d568-4c6a-b997-7e3878be579b",
      "subcategoryIds": [
        "87898fad-b1a1-48c7-9198-2cbf30294823",
        "330e42c1-cba9-4271-b477-5a028821700b",
        "3f0b150d-94da-468b-bd8a-65a87f1f467e",
        "442ea14d-ceef-44b7-9351-e83febf2b17d",
        "74d3fcb8-27f1-4e19-a47e-729e1c17d6bc",
        "305de64b-bf50-4b3e-974b-a8fec2c69a4f",
        "6e961d82-1b7b-43b6-9610-8b58ab995c98",
        "52b253b3-c288-4814-9d9c-71c4d9924fa5",
        "0408db7b-583c-435f-8b38-74dfe1c79d4d",
        "e497da26-3634-4233-81e3-8f9e13090871"
      ]
    },
    {
      "id": "d1912451-0605-43ec-adea-075c2b0c606c",
      "name": "ClearML",
      "definition": "ClearML is an open-source platform designed to facilitate end-to-end machine learning workflows, encompassing experiment management, orchestration, and deployment. It provides tools for tracking, managing, and automating AI/ML projects, enabling data scientists and engineers to streamline development, collaboration, and reproducibility of models within a unified environment. By integrating various components such as experiment tracking, model versioning, and pipeline automation, ClearML aims to enhance efficiency and transparency in machine learning operations.",
      "categoryId": "3efc32f9-535b-46af-b5db-48762ecfb4e1",
      "subcategoryIds": [
        "65924ac7-dea0-4456-b27f-4d336d5c6713",
        "1e559057-9567-46a1-a704-953fd54f3db0",
        "b99ed36c-e629-4e47-9193-4822bd7e3467",
        "7235aedd-2d9e-48d1-a732-eb0a1a990170",
        "951f80ac-b468-4ff1-abb6-78ecf5708cdd",
        "deb688e5-dc3e-4902-b225-65c85bbb75c5",
        "3a1c6dba-2cc2-4751-8ab4-f75cb3d6c774",
        "6d088c0f-8b83-4a57-b6e1-de3c85d87395",
        "3ec0886c-e9fe-42aa-a0b6-7029a838d757",
        "c782168c-b407-4935-9348-6b986046f08a",
        "4a9ea3e7-2868-40cc-913e-4e0776d7446b",
        "aad3b1a0-83ee-4667-a480-be3416637994"
      ]
    },
    {
      "id": "d9bb51eb-eeb8-402e-8366-6475e6d5952f",
      "name": "CLIP (Contrastive Language-Image Pretraining)",
      "definition": "CLIP (Contrastive Language-Image Pretraining) is a neural network model developed by OpenAI that learns to connect visual concepts with their corresponding natural language descriptions. By jointly training on large-scale datasets of images and their associated textual captions, CLIP can recognize and retrieve images based on textual queries and generate descriptive captions, effectively bridging the gap between visual perception and language understanding in AI systems.",
      "categoryId": "338ee975-7f21-4bc9-a2c0-cd6f6e575fb6",
      "subcategoryIds": [
        "4366df86-1b73-4951-a4a3-a4cd9f0ba9b3",
        "0086522e-b9e7-4808-8c1f-b58c8cc9f9c1",
        "8c508a86-0c50-44a5-bade-6ef82b3ce596",
        "37775fbe-a7d9-4b62-bdca-3fb7181cc6d1",
        "b0c0b75f-c5f7-4278-9166-5e8490f21e3f",
        "72918302-afb5-4e76-aa75-d38e5f03f449",
        "fdacea9b-7f78-46e8-8391-1be3254e8fb3",
        "c9a46e32-dd32-459d-8b77-dc35815ea271",
        "69497ceb-0707-434a-bf74-947fd01fddca",
        "ffed9715-58dd-4ebf-93e0-55045b2fe59f"
      ]
    },
    {
      "id": "59978f09-b7d1-4b84-8954-f7c65a13c129",
      "name": "CLIP (Contrastive Language\u2013Image Pretraining)",
      "definition": "CLIP (Contrastive Language\u2013Image Pretraining) is an advanced machine learning model developed by OpenAI that is designed to understand and relate visual and textual data. It is trained to connect images and their accompanying descriptive text by learning a shared embedding space, enabling it to perform tasks such as image classification, retrieval, and zero-shot recognition without specific task-specific training. CLIP's architecture combines natural language processing and computer vision techniques, allowing it to interpret complex visual concepts based on language inputs.",
      "categoryId": "29861353-f354-406d-b64b-c1255eb0bc79",
      "subcategoryIds": [
        "fcfa290f-a571-4009-8af8-bd94e1d70441",
        "3b16d54f-5662-48fc-8045-fc12879ea45d",
        "03f19420-1cae-4c50-867e-758cda1b0ae6",
        "c3e1a4f7-12cf-4896-a8a9-6e299bda90a9",
        "714e5029-0842-4b0f-b480-487899cda169",
        "8423663d-ccc0-402c-ad68-fd7e9201ceb5",
        "2e6370b5-1720-4609-9ca9-d51081960cdd",
        "ac18f352-cf61-4f6b-b2c8-e7f8a90d2ddb",
        "e95de642-e062-462d-ab72-8cc697cac54f",
        "ae097d10-749b-4fc2-869f-e07c2c6b756a"
      ]
    },
    {
      "id": "0a7e3caf-eb89-46af-9d57-f3916ca20852",
      "name": "Clipped Gradient",
      "definition": "A clipped gradient refers to a technique in machine learning where the magnitude of the gradient vector is restricted or limited during training. This process, known as gradient clipping, involves setting a threshold and ensuring that the computed gradients do not exceed this value, effectively 'clipping' the gradient to a specified maximum norm or value. This approach helps prevent excessively large updates to model parameters, which can destabilize the training process, especially in models with deep architectures or recurrent neural networks. The primary goal of gradient clipping is to improve training stability and convergence by controlling the scale of weight updates.",
      "categoryId": "4e19ff42-f774-4f1a-aae9-ee741a2f033f",
      "subcategoryIds": [
        "7fd3376e-ffa4-4747-bd1f-0a0ab6503f34",
        "1ce4e162-06b4-46bd-947e-eb5a7792d454",
        "034eb329-c0ce-4f41-8e38-4a1b3247082c",
        "6bd36fe2-cfe8-425e-8e60-99586f45430b",
        "aef56896-4250-4857-88f6-5706e16d67ba",
        "37b010a4-06ad-44a3-98fe-2f154ee96771"
      ]
    },
    {
      "id": "7d8f252f-05a6-4670-b180-7248fdb2de07",
      "name": "Clipping Gradients",
      "definition": "Clipping gradients is a technique used in training neural networks to prevent the explosion of gradient values, which can destabilize the training process. It involves setting a threshold (clip value) and scaling down the gradients for parameters whose gradients exceed this threshold, ensuring they remain within a manageable range. This process helps maintain stable convergence and improves training efficiency, especially in models with deep or recurrent architectures.",
      "categoryId": "132f71da-5411-4af4-8707-39e1d829d524",
      "subcategoryIds": [
        "ff4a4af6-a3d2-4d46-b43e-3ebae96ce99c",
        "60cee353-defb-4c4a-ba58-97e4e1bfddd4",
        "d61a4972-2531-45c4-b8af-c16c47cafe93",
        "1e84a3e2-e56c-4910-99b9-f7710385f963",
        "4bfabe03-d265-494a-b474-b091daca3ef5",
        "5f843708-9186-4f32-a682-5f3212280a38",
        "fb2e92da-c616-4045-a266-c0d266516b0f",
        "913d05f2-0c32-4a64-bced-3deca8639e6d"
      ]
    },
    {
      "id": "2b2c9575-9930-45dd-a4a0-2e3eff131234",
      "name": "Clipping Gradients Techniques",
      "definition": "Clipping gradients is a technique in machine learning used to prevent the problem of exploding gradients during the training of neural networks. It involves limiting or 'clipping' the magnitude of the gradients to a specified maximum value before updating the model parameters. This process helps stabilize training, especially in deep networks or recurrent neural networks, by ensuring that gradients do not become excessively large, which can cause numerical instability and impede convergence.",
      "categoryId": "31e5e921-c0ea-446c-b277-d0e5087f429e",
      "subcategoryIds": [
        "201bd87f-0364-4583-9710-efbe06c02ded",
        "1f9bbaeb-7068-48e8-ac51-80862781ecb6",
        "60b41a1e-698d-4b3b-a22c-f47f05d10732",
        "36f19103-70d9-48c7-87b8-a8d0f491cdbb",
        "a9b59f56-e831-43bf-98ef-e341324c2473",
        "15be79f4-5f8b-4d15-8785-416cb4cdc0bf",
        "05c193fd-3a56-4209-a27b-4c511e967e36"
      ]
    },
    {
      "id": "e4b1ba3f-507c-40f8-a45a-cae709247930",
      "name": "Clipping Gradients Techniques Extensions",
      "definition": "Clipping Gradients Techniques Extensions refer to methods used in deep learning to modify or restrict gradient values during the backpropagation process, aiming to improve training stability and model performance. Gradient clipping involves capping the magnitude of gradients to prevent issues such as exploding gradients, which can cause unstable updates and hinder convergence. Extensions of these techniques encompass various methods that adapt or enhance basic gradient clipping to better suit specific architectures, optimize training efficiency, or address unique challenges encountered in complex neural networks.",
      "categoryId": "7851dab6-0159-4632-b1a8-2727b621239e",
      "subcategoryIds": [
        "35cf59bc-c7ff-4061-a897-ded695937579",
        "5d498705-5b6a-43c3-b634-876f00a82eb6",
        "d23dffbb-6bd3-46ce-9b69-c0deea65e02d",
        "baf99f5b-05c7-4715-a1fd-3479cb9a4677",
        "30c01681-435e-486d-bee6-5497e2fb7911",
        "4e0d3398-9b0c-4f73-95e9-4e33c685ce26",
        "51b936bc-7b33-4610-a031-9f8f45335f5a"
      ]
    },
    {
      "id": "09d08d80-f7c4-4656-b8f7-58afe0aea54b",
      "name": "Clipping Norms in Gradient Descent",
      "definition": "Clipping norms in gradient descent refer to a regularization technique used to prevent excessively large gradients during the training process of neural networks. This method involves constraining the magnitude of the gradients by scaling them down whenever they exceed a predefined threshold, known as the clipping norm. The primary goal is to stabilize training, improve convergence, and prevent issues such as exploding gradients, which can hinder model performance and training efficiency.",
      "categoryId": "08a9ddbc-4d8c-4169-b290-ed00d67cac62",
      "subcategoryIds": [
        "7ab1f490-d38e-431e-95e1-162dc2f99e70",
        "fd1aa10a-5907-41e6-b859-593497b3f381",
        "f04134a0-b35c-4aa0-a55a-2b5783fbfaba",
        "adf0c19e-5324-4919-8dba-54252ba31aac",
        "11a1bd26-ae6b-4ae5-b7cd-e0b762574113"
      ]
    },
    {
      "id": "22f9596a-7aa1-4d55-85b5-dde6b6d1a040",
      "name": "Clique",
      "definition": "In the context of graph theory and network analysis within AI and machine learning, a 'clique' is defined as a subset of nodes in a graph where every pair of nodes is directly connected by an edge. In other words, a clique forms a complete subgraph, meaning all nodes within the subset are mutually adjacent. This concept is used to identify tightly-knit groups within a network, where each member interacts with every other member, highlighting dense regions of connectivity relevant for various analysis tasks.",
      "categoryId": "f37bc20e-3988-4a7a-8f7e-67706018b22a",
      "subcategoryIds": [
        "9b32c61b-e182-4c0e-ad0d-42d3105f5f72",
        "cef86594-250c-4a7f-b650-287b04411842",
        "c856731e-2bf8-4dff-85a3-0b0232fe7bba",
        "32167212-d593-4f63-b98e-3fa31d1c7b27",
        "a44d1f1b-5858-4f59-9b3f-46108dce4473",
        "b2c4d1f7-9ce8-4843-8b31-c995ff81fd06",
        "e32d431b-f1bc-49fa-b307-b80aad393916",
        "d4a1ea50-b33c-47d3-b0ff-cf44f0ebd43e",
        "415faf8a-ce63-43cc-baa7-e5d32e9e655c",
        "e837ffde-60dc-4075-833f-e25ac75e0fbb"
      ]
    },
    {
      "id": "2f8db6ab-fbc8-44bd-aea7-a41907435c63",
      "name": "Closed Frequent Itemsets",
      "definition": "Closed Frequent Itemsets are a specialized concept in the field of data mining and pattern discovery. They refer to itemsets within transactional datasets that are both frequent\u2014appearing in at least a specified minimum number of transactions (support threshold)\u2014and closed, meaning there is no super-set of the itemset with the same support. This ensures that closed frequent itemsets provide a compact, lossless representation of all frequent itemsets, capturing maximum information without redundancy. They serve as a fundamental component for generating association rules and for understanding the underlying structure of transactional data.",
      "categoryId": "c3149487-ed2e-48a6-bd04-df8f2b3fbe43",
      "subcategoryIds": [
        "39eb75e6-710b-4d5e-82a2-f86f0b2e7757",
        "3fd73781-7083-4a3f-abbc-073f015fd606",
        "53c286e8-ca51-4cae-9530-6dcb43d98f06",
        "01825527-4827-4268-bb31-03ebde8e12d4",
        "12bf043b-8b26-46d9-8867-6a12a05be2c1",
        "f3dbebdf-6370-4b26-9365-325398f96216",
        "5b37a58f-6e0f-4dda-809e-4b891cd55416",
        "ec68221f-f336-4fbb-8c51-63c724377be1",
        "941fa2c3-a8f0-4939-8cba-87bdc56dbaeb",
        "86a4a5fa-8b6a-4e67-a4fb-3cc20f2fc70f",
        "12bb8154-3c85-45c0-ada1-967d73ff3071",
        "aca4f14e-9294-4aab-874d-85cf51449a24"
      ]
    },
    {
      "id": "2897aec9-b798-4f3b-a70b-af582155d453",
      "name": "Closeness Centrality",
      "definition": "Closeness Centrality is a measure used in network analysis to determine how close a node is to all other nodes within a graph. It quantifies the average shortest path distance from a given node to all other nodes, with higher closeness centrality values indicating nodes that are strategically positioned to quickly reach all others in the network. This metric is particularly useful for identifying influential or central nodes within social, communication, or transportation networks, facilitating the understanding of network efficiency and information flow.",
      "categoryId": "84112320-ad22-42f2-9735-c85511c0f915",
      "subcategoryIds": [
        "51eda58c-7e3c-4a4a-a383-f2e0748c57a0",
        "2555b002-ef73-448b-a195-d24d3eb2e3e2",
        "379ce0ce-630c-49d5-8b66-090eadb317a0",
        "f3d2afa5-0967-4b0a-836d-50c9043b7017",
        "2722416a-bf0b-4ba6-afff-384462ffb445",
        "c25fba21-6ae1-429f-a5c2-4a6ac10fa518",
        "9d8d64e6-962e-4fd8-a280-46f1444a0250",
        "a9d3736a-f471-49c9-8b27-5f910ff28b76"
      ]
    },
    {
      "id": "ca1861a9-5726-4854-a99a-0da887727a78",
      "name": "CLUSTER (Clustering with Ubiquitous Structural Time-series)",
      "definition": "Clustering with Ubiquitous Structural Time-series (CLUSTER) is an advanced machine learning technique designed to identify inherent groupings within large-scale time-series data by incorporating structural and contextual information. This approach leverages clustering algorithms tailored to handle the complexities of temporal sequences, emphasizing the preservation of temporal patterns and structural features to reveal meaningful patterns across various domains such as finance, healthcare, and IoT systems.",
      "categoryId": "59376e95-8def-47a5-9da6-5a794a7efff1",
      "subcategoryIds": [
        "86dd30a4-af02-4fb2-aa61-e061e239abd5",
        "439b03c9-1312-4050-8ed7-be05b82bbc44",
        "4a8ee780-3dff-4ebb-a291-922295f356c0",
        "52396076-2eb7-49a8-b72b-5eb0372861dd",
        "1eb319d9-4eee-49d0-b98b-68f9df08deed",
        "67d0d3a8-2bf7-4c52-8b67-11281cfdbed6"
      ]
    },
    {
      "id": "46d6eb99-4af5-49ad-a485-51082fabdfe3",
      "name": "Cluster Assumption",
      "definition": "The 'Cluster Assumption' is a fundamental concept in semi-supervised learning, which posits that data points within the same cluster are likely to share the same class label. It suggests that the decision boundary should lie in a low-density region, effectively separating clusters of different classes, thereby enabling classifiers to leverage unlabeled data by assuming that similar data points form coherent groups.",
      "categoryId": "5a4142a9-9691-40a0-9063-8f11bd0a5d29",
      "subcategoryIds": [
        "ba5e7125-a0b9-4c9d-8fbd-b9bdff14c56b",
        "6448f50f-5de9-42f3-9e12-793f77ec3454",
        "5de04d54-039e-40c0-8dff-ef7072f63380",
        "abf74358-c944-46d0-8426-3dc200fe79fe",
        "6a08d032-60a0-45bd-ac59-b2b07a2b870e",
        "778c028a-1a3e-4f46-ab88-0305bc18b2af",
        "5d378e97-507f-49e8-8fd7-daa50aa5e09f",
        "0e907fa3-4541-484d-a43e-7ae0923c92ee",
        "9806c5d7-a273-492a-a01b-120ee2ef2d79"
      ]
    },
    {
      "id": "d8721c85-4b10-4604-91c8-d5d34dc182c9",
      "name": "cluster purity",
      "definition": "Cluster purity is a metric used to evaluate the quality of clustering algorithms by measuring the extent to which each cluster contains data points belonging predominantly to a single class or category. It quantifies how well the clusters correspond to predefined ground-truth labels, providing insight into the homogeneity of the clusters. A higher cluster purity indicates that the clusters are more homogeneous and that the clustering algorithm has effectively distinguished between different groups in the data.",
      "categoryId": "20a457f0-417c-4066-ac64-615d61e8be8f",
      "subcategoryIds": [
        "58c0d6fa-2a8c-46b1-af2a-8cd0575882f4",
        "72003ed7-7579-411f-be50-22e9a89a41c8",
        "32a65952-f12f-4119-819b-7a70ed6ba2be",
        "1fa6568b-8378-4413-a3f1-7f457788135b",
        "50a6c3ac-913e-4c83-85ad-6233a25c4679",
        "47c62f0b-2408-4cdb-ba5c-68d2f059163b",
        "58807af5-f61c-4620-a00c-d42b405f550c"
      ]
    },
    {
      "id": "d66bb5f1-e1a2-42ff-9bfd-4c7c4cb4182e",
      "name": "cluster sampling",
      "definition": "Cluster sampling is a statistical sampling technique used to select a subset of data from a population by dividing the entire population into distinct groups, or clusters, and then randomly selecting entire clusters for analysis. Instead of sampling individual data points, this method focuses on sampling whole groups, which simplifies data collection especially when the population is large or geographically dispersed. It is commonly used in survey research, quality control, and data collection processes within AI/ML workflows to efficiently gather representative data for training, testing, and analysis.",
      "categoryId": "ff6dd850-f324-4a1a-ab5f-4fa6b16af311",
      "subcategoryIds": [
        "248911d8-479d-4139-ae5f-287d20db8574",
        "898650b4-0060-4f20-91d2-cf6eeb6b727f",
        "e836e78f-36a5-4301-a529-d12e7cd1673c",
        "bf0c84ac-1ac2-48ed-94a2-ec276eb6cc37",
        "468afc5a-d4ae-4093-a4d6-962ce659f354",
        "21af501a-4133-47eb-858b-04657da186d8",
        "cc07459f-19f9-4b51-ab0d-5edce9e8a7d0",
        "7b8ccd90-117c-4cad-8c74-9d47cc8035ad",
        "bf89511d-f5a3-4833-8222-544c5cb86dfa",
        "ef71cfe5-14bc-4cb0-b43d-8a987a5f34ca"
      ]
    },
    {
      "id": "e12c2263-7285-4642-8979-5a2d6d1921f6",
      "name": "Clustering",
      "definition": "Clustering is an unsupervised machine learning technique used to group a set of objects or data points into clusters such that those within each cluster are more similar to each other than to those in other clusters. The primary goal of clustering is to discover natural groupings in data without prior labels or classifications, enabling insights into the underlying structure and patterns within the dataset. It is widely used in various applications, including customer segmentation, image analysis, market research, and pattern recognition.",
      "categoryId": "5ba93cee-718b-45bb-b10d-3485d6fdfaa5",
      "subcategoryIds": [
        "a1343fcb-e805-4144-b419-a7fd39eff1dd",
        "82fb0b77-aa32-47ef-8765-fcd58b84cd14",
        "244f808a-da96-43d6-83f2-bb1180cea54b",
        "eb774660-7ae9-4852-a9d3-f42dcd269681",
        "2851cb7c-51d1-4602-bc9e-6b63a9199194",
        "f68d550c-02ff-4211-a4cc-2dfcf23e6ba2",
        "6556665c-2400-41bf-b711-6172a7be1f92",
        "2a84ad9c-bd0c-4373-9450-917d0fc76a13",
        "39f5a0d5-0b61-4796-81db-94d50b77b7a6"
      ]
    },
    {
      "id": "d88cbd5b-3de0-41f1-ae1e-b92d3a2fea66",
      "name": "Clustering Algorithms",
      "definition": "Clustering Algorithms are a category of unsupervised machine learning techniques used to group a set of objects or data points into clusters such that items within the same cluster are more similar to each other than to those in other clusters. The primary goal is to identify inherent structures or patterns in unlabeled data, facilitating insights, segmentation, and exploration without prior knowledge of class labels.",
      "categoryId": "7bca72b2-ccb3-4792-9a4b-a3e0b5c70f0e",
      "subcategoryIds": [
        "80c7b06b-d146-4b35-b765-4e7b8ef0df4a",
        "cfa6898f-825e-42e1-90b3-944be73afaed",
        "afd69127-9038-47e5-9118-4c2e8d672d6c",
        "73ce5bee-f669-4ce9-abd7-701f7819f14f",
        "63cfaf61-b5fc-462a-9e49-e20cc0735947",
        "e2fe69e7-9944-4e45-bbb3-28e526f3ccae",
        "5dc8280a-9d6e-46d1-ad23-0ed7491e0023",
        "1c029ef8-f048-498a-9c88-588b969c216f",
        "25bf3837-2c0e-4c81-b814-2decd72c6427"
      ]
    },
    {
      "id": "141a2ba6-614d-4431-a721-6cb22685c413",
      "name": "Clustering Algorithms (e.g., K-means, Hierarchical Clustering)",
      "definition": "Clustering algorithms are a class of unsupervised machine learning techniques used to group a set of objects or data points into clusters based on their features and similarities. The goal is to ensure that data points within the same cluster are more similar to each other than to those in other clusters. Popular examples include K-means clustering, which partitions data into a predefined number of clusters by minimizing intra-cluster variance, and Hierarchical Clustering, which builds a hierarchy of clusters either through agglomerative (bottom-up) or divisive (top-down) methods.",
      "categoryId": "5394ac47-fef5-4f9f-b0da-0b99ae41111c",
      "subcategoryIds": [
        "893bffe3-b10e-43b0-b017-8da602001c6a",
        "57391bce-6426-413a-b3ba-e8e79dd1a800",
        "3df37f91-6f05-4239-81d8-9863cd116b0c",
        "1690a188-2dbb-4501-a2c2-5dde94851aa4",
        "a0c216b9-7c57-4e3c-8379-0f7308c405f6",
        "a643332f-587f-4b06-a937-1821d7c8de73",
        "7d48ab81-1c7a-4ed8-b974-e1bfad01964c",
        "1955350b-4ae4-4cf2-aa60-c20f61d94bf6",
        "9b58a542-3db9-46e4-b938-f33ac58819b8",
        "724cfc99-5213-4b14-8fcb-2b979121ac7b"
      ]
    },
    {
      "id": "40519282-cf10-4a12-9389-c735535f926f",
      "name": "Clustering Evaluation Metrics (e.g., silhouette score, Davies-Bouldin index)",
      "definition": "Clustering evaluation metrics are quantitative measures used to assess the quality and effectiveness of clustering algorithms. They help determine how well the data has been grouped into clusters, especially when true labels are unknown. The silhouette score and Davies-Bouldin index are two widely used metrics that provide insights into the cohesion and separation of clusters, enabling comparison between different clustering results and parameter settings.",
      "categoryId": "a975a25a-a3a5-4596-99a9-862442cccce1",
      "subcategoryIds": [
        "1e61356a-24d0-44a3-9496-73dbf1d1d62f",
        "b00dbc91-8848-4aa6-9b5a-e646ff700de4",
        "34275f6a-8755-4206-9d4e-10f35f830c72",
        "8aad9ded-5a91-4215-8b71-560bd03ce5a0",
        "d480e653-9e90-46dc-9f33-70389b30bcd6",
        "bb83d4ac-de54-4e06-953e-94852d96d68b",
        "acab43d8-6ce9-4684-8c4f-e6ccd3ba7c21"
      ]
    },
    {
      "id": "ad725ecb-a066-4a03-a94b-a42cdc793731",
      "name": "Clustering Stability",
      "definition": "Clustering Stability refers to the consistency of clustering results when the clustering process is applied multiple times under varying conditions, such as different initializations, data perturbations, or parameter settings. It measures how reliably a clustering algorithm can produce similar groupings, indicating the robustness of the identified clusters to changes in data or algorithmic parameters. High stability suggests that the discovered groups are meaningful and not artifacts of random initialization or noise, while low stability may indicate unreliable or unstable clustering outcomes.",
      "categoryId": "44cfac13-dfd8-4ca6-ad99-b41ec0e161f5",
      "subcategoryIds": [
        "7982894b-f2ef-4bf2-9a62-4598ec11f256",
        "33755ca6-1e0c-48b7-b885-b6ae702973cb",
        "5e0ee60d-d4fd-4e7e-ae7c-16b036843bd5",
        "25d1cd53-baab-4af8-a12b-f269aedf5f17",
        "9f340f39-4184-4946-a880-845bd4e2b380",
        "fa084d2f-6ebf-4599-9d6b-4e1f66ccfd3c",
        "c06d4f13-9f8d-4690-8bfd-f8f48c22c461"
      ]
    },
    {
      "id": "20c28d25-2441-4297-a8ab-ce859f3af437",
      "name": "Emotion Generation",
      "definition": "Emotion Generation refers to the process by which artificial intelligence systems are designed to recognize, simulate, or produce human-like emotional responses. It involves leveraging algorithms and models to generate emotions that can influence interactions, decision-making, or content creation within AI systems. This capability aims to enhance human-AI interactions by making them more natural, empathetic, and engaging.",
      "categoryId": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7",
      "subcategoryIds": [
        "c2c07c7b-75b6-42f5-8aee-516d66a76d0f",
        "4cffe854-5641-451b-9619-04c8315add28",
        "56c497b0-b034-4e87-b92f-88b383cca0f9",
        "4eee277c-6125-445a-aa7d-3ee83f0d0f19",
        "05c792b3-14d2-4699-8341-93dcb377a217",
        "d1cf2058-08b8-49d1-84f6-5b06ccecd26a",
        "1943ab8f-404d-4f24-b873-ead1cc6ead16",
        "9c1d06c3-c218-4963-b8cb-810e1d073238",
        "a4841aa2-5031-49b0-a879-d6249295656c",
        "02c54c7f-87a2-4396-8181-89fbcf5f53d4"
      ]
    },
    {
      "id": "8b846793-6293-4a63-8571-3c64d2bbda62",
      "name": "Emotion Modeling",
      "definition": "Emotion Modeling in AI/ML refers to the process of designing systems that can recognize, simulate, interpret, or respond to human emotions. It involves creating computational frameworks that can analyze emotional cues, such as facial expressions, vocal tones, physiological signals, or contextual data, to understand emotional states or generate appropriate emotional responses. This field aims to endow machines with the ability to interact more naturally and empathetically with humans, enhancing user experience and enabling applications across diverse domains.",
      "categoryId": "6c0a135e-5723-414c-8eca-4553332e06a6",
      "subcategoryIds": [
        "195ec9c1-13d0-4fca-a516-199f12cba964",
        "75a88342-9cb9-4a5e-90c1-6ebb9793e4ce",
        "10b72751-b2b9-4e02-9e5e-b60ad1185dee",
        "1b9664e9-804b-413b-9b47-c82da4bcecd4",
        "2cc88727-ab9a-42c4-92d6-33eacfb65ea4",
        "d16093cb-f54d-4de4-b0d2-360472c37453",
        "92dfe109-5c50-4454-bfac-71926bfd1c9b",
        "b68fafaa-43e3-4a9b-9bbd-1a6b5e479b2d",
        "d09fcc71-f594-4012-8427-2808c9b2a533",
        "bc91897f-f364-4beb-b981-629cba812284"
      ]
    },
    {
      "id": "e4d8b568-81fe-4e1c-80b1-870fff869cba",
      "name": "Emotion Recognition",
      "definition": "Emotion Recognition refers to the process by which AI systems identify, interpret, and classify human emotions from various data sources such as facial expressions, voice intonations, body language, and physiological signals. This technology aims to understand human emotional states in real-time or from recorded data, enabling more natural and effective human-computer interactions. It plays a crucial role in applications ranging from customer service to mental health monitoring, facilitating empathetic and context-aware AI systems.",
      "categoryId": "b5f3852a-42f1-409f-8c33-3ebf90322065",
      "subcategoryIds": [
        "b4e7a5de-98c5-4721-ac3d-33687a3ebfb3",
        "0487175b-1ee0-465e-afa0-0e1f026b2381",
        "5429f511-d650-46bb-a616-1c11ba2df9ca",
        "b3f385c1-1586-48ce-a04d-72ee5508ce51",
        "e4acc021-3c9e-43d0-b327-a8104dfc6522",
        "4db73c2d-0075-4cab-b44c-2ac3ef670795",
        "2461d205-8f18-4365-b256-df60f5624e8c",
        "acb5b0e2-7d5b-429a-b15a-66f7e54343e2"
      ]
    },
    {
      "id": "7faeaf03-427b-4be2-8063-a19f0c5edb02",
      "name": "Emotion-aware Machine Learning",
      "definition": "Emotion-aware Machine Learning refers to a subset of artificial intelligence systems designed to detect, interpret, and respond to human emotions. These systems utilize various data inputs such as facial expressions, voice tone, physiological signals, and textual cues to understand emotional states. The goal is to enhance human-computer interaction by enabling machines to recognize emotional context and adapt their responses accordingly, thereby creating more empathetic and effective communication channels.",
      "categoryId": "16001270-4117-4055-bac1-24aa99217acc",
      "subcategoryIds": [
        "ceb141e9-9901-4d3c-b0f6-a0ac9597acc1",
        "28619885-ba82-475b-935a-af6533fb4d32",
        "edaf8729-09f9-4844-88da-cecc6f41b1b9",
        "48b3e2c1-510a-4c99-84e4-d990d631e62d",
        "497c64ee-9717-4ef0-90df-fb156ab322ac",
        "c6b9d7b2-9241-4b4e-bcd1-ea730c66ec46",
        "cd7f7786-542c-4a56-b5e5-80577bc5a7f5",
        "ef91de5b-a459-48e1-9f7b-6d80307fc117"
      ]
    },
    {
      "id": "4151a578-05e9-46aa-8c07-b640e951d7bd",
      "name": "Emotion-Aware Text Generation",
      "definition": "Emotion-Aware Text Generation refers to the development of AI systems capable of producing written content that not only conveys factual information but also detects, interprets, and expresses human emotions effectively. These systems analyze emotional cues within input data\u2014such as tone, context, or explicit sentiment indicators\u2014and generate text that aligns with or appropriately responds to these emotional signals, enhancing human-computer interaction through more empathetic and contextually appropriate communication.",
      "categoryId": "15b2cdf2-e2a1-427f-acea-cfab1ae3ee2a",
      "subcategoryIds": [
        "9e0203ff-ada2-4302-a912-b2cbdffb7d70",
        "6c9eb0ed-53ed-4f89-a60f-22a8751bbd38",
        "57b1393e-df09-433a-b7e8-2297f082656e",
        "54406bc9-7a6b-44fb-b92f-6bddd5d5df69",
        "e934a42b-41f8-42d1-b589-ed651ccfdc65",
        "47467dda-6c93-4461-be5c-3d6bd9f870ed",
        "7f4beb49-5eb3-40ff-a039-ac4499b55207",
        "ea4020e6-1d94-417f-a665-54a845a33612"
      ]
    },
    {
      "id": "da578649-bea8-4949-bfd2-c3c70c53b4e2",
      "name": "Emotional AI",
      "definition": "Emotional AI, also known as affective computing, refers to the branch of artificial intelligence focused on recognizing, interpreting, processing, and simulating human emotions. It aims to enable machines to understand and respond to human affective states in a manner that is contextually appropriate, thereby creating more natural and empathetic interactions between humans and technology.",
      "categoryId": "5f9e90a7-6ff5-4684-ac26-6214dad5d2f8",
      "subcategoryIds": [
        "75c266cb-4e73-44d6-9e6a-c929e5c93f71",
        "33dd7829-233a-4afe-8c62-fbcf1c8f7d9f",
        "40361f4c-d55c-4476-a7e3-bfcd0bd1669e",
        "0267707f-0b8e-412c-a6c4-093e0cd39fc6",
        "63f149e3-6066-46ae-93fa-5d3eb0e52c6b"
      ]
    },
    {
      "id": "a3ed209a-dacf-4c46-b00d-444898c52377",
      "name": "Emotional Intelligence in AI",
      "definition": "Emotional Intelligence in AI refers to the development and integration of systems capable of recognizing, understanding, managing, and responding to human emotions. It involves designing AI models that can interpret emotional cues from speech, text, facial expressions, and physiological signals to facilitate more natural and effective human-AI interactions. Unlike traditional AI systems that operate purely on logical or statistical data, emotionally intelligent AI aims to emulate human-like emotional awareness to improve communication, empathy, and user experience across various applications.",
      "categoryId": "3b965a30-30b0-4ffd-9f6e-2db43fd41dd7",
      "subcategoryIds": [
        "3c661cc3-16a2-4419-8a6c-cc37c166cf0a",
        "c198b285-3484-4a1b-b341-252b15a6bf60",
        "fd1d7c8e-92fe-42bd-8f7a-268fbb6351e3",
        "6670e3e1-7ba4-4ef4-80ce-26d502dfa7b2",
        "24d2b379-02c5-4372-a93c-460aa22cad43",
        "80251df4-fbee-46b9-981c-148f0981902b",
        "5233eca0-441f-4eba-9359-e8c283724132",
        "ebc867ea-7f71-4c25-a2eb-700afe3480bd",
        "ae5bae0a-9b65-4d3d-b493-0810abdabfb2",
        "3d6adda5-709f-44f7-adb2-560701e6aeec"
      ]
    },
    {
      "id": "5d239e33-232e-4c79-9cae-79cf4fcb27f3",
      "name": "Empirical Bayes Regression",
      "definition": "Empirical Bayes Regression is an advanced statistical technique that combines elements of Bayesian inference and frequentist estimation to perform regression analysis. It leverages observed data to estimate prior distributions empirically, enabling more adaptive and data-driven modeling, particularly in contexts with multiple related regression problems or high-dimensional data. The approach typically involves estimating hyperparameters from the data and then using these estimates for Bayesian inference in the regression task, resulting in a blending of empirical data insights with Bayesian probabilistic modeling.",
      "categoryId": "c6abdafa-cc24-471f-92fc-852c8a5955a3",
      "subcategoryIds": [
        "634f8580-c704-4703-aa7d-b41499bd8b65",
        "c7a3b438-bc26-4682-b48a-ffd0ccd4eee7",
        "6473308b-3949-4188-ade3-336f8a3420cf",
        "46c19fd6-a28b-4160-92f0-2fcecafd1c86",
        "4d38bbec-695e-4eaf-b202-80f8755b1c87",
        "431c2176-4095-4f26-8022-2bbd0106dd16",
        "6b885947-1f43-4fdd-af20-1490f8d929ad"
      ]
    },
    {
      "id": "ac244bbd-da36-43b9-8ef4-0776f098be30",
      "name": "empirical probability",
      "definition": "Empirical probability refers to the probability of an event determined by observed data or actual experiments rather than theoretical calculations. It is calculated by dividing the number of times an event occurs by the total number of trials or observations, providing an empirical measure based on real-world evidence. This concept is fundamental in statistics and data analysis, serving as a basis for understanding uncertain phenomena through observed frequencies rather than assumptions or models.",
      "categoryId": "c8e0b57e-b1ec-4230-96a2-c87039468c58",
      "subcategoryIds": [
        "84511211-466a-4436-846d-2741d4300c1a",
        "d2a500cd-0f69-4e7e-b047-0712223c2d4b",
        "ee686539-660b-439c-b773-d7f712c3879f",
        "1067cd76-8dd0-4dfd-88a1-608e32a0c20a",
        "430891fe-fb00-44b2-af87-a0cb3592274a"
      ]
    },
    {
      "id": "7402143b-25c6-402b-8bfb-73024d763b97",
      "name": "Empowerment",
      "definition": "In the context of AI/ML, 'Empowerment' refers to the process of enabling systems, algorithms, or human stakeholders to make informed decisions, exert control, and enhance their capabilities through data, tools, and intelligent automation. It emphasizes augmenting capacity and fostering autonomy, allowing users and AI systems to operate more effectively within complex environments. Empowerment in AI often involves developing models and interfaces that provide users with clear insights and actionable options, thus promoting confidence and independence in decision-making processes.",
      "categoryId": "0cc93a0f-09d5-48af-a538-f2cdc749c5ba",
      "subcategoryIds": [
        "8804e026-4d25-42e2-8141-8909f65541cf",
        "da2dd8d2-a015-44b4-89cc-2b4342fb2080",
        "2ddae9d0-4eb5-4d48-b6b9-ac198948a2b2",
        "7e8fe9ad-b044-4279-bb52-318f67493694",
        "46e1ad1a-bc50-40ce-931c-ea695f7e3bc3",
        "3b6dcbcf-6057-4699-874b-a020c9edcfd8",
        "9abbb42c-d626-4767-8e4e-9cc783290dd1",
        "0d9020b9-2872-487e-9f55-7c323a06bfee",
        "90afc993-9b3d-4dbb-8c6f-75a126164954",
        "d3b8ddcd-51ef-49cc-a592-76b7d1d2d8ff"
      ]
    },
    {
      "id": "88109101-309e-4364-8c38-7d29b6227210",
      "name": "Encoder",
      "definition": "An encoder in machine learning and deep learning is a component or model responsible for transforming raw data into a more suitable or condensed representation, often capturing the essential features of the input. It maps high-dimensional, complex data into a lower-dimensional space, facilitating easier processing and understanding by subsequent model components. Encoders are fundamental in various architectures, including autoencoders, transformers, and sequence models, serving as the mechanism to extract meaningful features from raw data such as text, images, or signals.",
      "categoryId": "36ac7ae2-674b-4f49-ab52-5044c7cf59ce",
      "subcategoryIds": [
        "906afea9-77d3-4958-a838-5882818bf542",
        "45fa3c14-906f-4cc4-acd4-0eb43fdb9086",
        "54b967fb-6e7d-4d20-9b07-5ba6ea32ab0c",
        "c19d89e5-29ce-407a-b1ad-72e798ba93e8",
        "9ca53ef4-7b78-4c49-a946-484069a5263e",
        "69add8c6-a1c2-44a6-9986-60e084393cc1",
        "c4eb5a6b-0168-4206-b693-a29521284584",
        "dae3f131-e14b-4c3f-b6b0-77174d3939de",
        "8fe56e89-0719-44f7-b927-f6621dee5a5b",
        "b0cfafae-ecfd-4360-8028-ea23c8fecb9a",
        "6c89e3f5-b313-4f33-8239-c09111cad8e6",
        "b73b6e20-7153-4ab7-b786-68903216e673",
        "a9b0ca12-fe72-478c-8f95-2811090bd9cd"
      ]
    },
    {
      "id": "d00ecf49-5dff-464f-8d71-92158b143f0e",
      "name": "Encoder Attention",
      "definition": "Encoder Attention refers to a mechanism used within neural network architectures, particularly in sequence-to-sequence models, that allows the model to selectively focus on different parts of the input sequence during processing. It enables the encoder to dynamically weigh the importance of each input token or feature, improving the contextual understanding and feature extraction necessary for tasks such as translation, summarization, and other NLP applications. Essentially, Encoder Attention enhances the encoding process by emphasizing relevant input information, which is then utilized by subsequent decoder modules.",
      "categoryId": "7acda575-f117-43da-a398-ae116ac3b8be",
      "subcategoryIds": [
        "19a861fb-718e-475a-be37-21f1dd203388",
        "1f1aa4ce-c415-4352-b2ba-865c5198f80d",
        "3eb07ada-2765-48cd-a86b-5f8a3090d5fd",
        "2ae21979-c3b3-42cd-84d9-2d3f9f5995ad",
        "091072b9-b296-44fe-9e17-4f3b1c36d7a1",
        "2cc477ee-40d2-4ed3-a5e9-4f217a875da7",
        "72c8fe94-2719-4914-8d43-c3c9dad8266c",
        "9cdaa5f8-7c1f-4d3a-bb3f-b910fd0aeef1"
      ]
    },
    {
      "id": "d829b44b-eb31-4c46-830c-270be4d2c708",
      "name": "Encoder-Decoder Architecture",
      "definition": "The Encoder-Decoder Architecture is a neural network framework primarily used for sequence-to-sequence tasks, where an input sequence is transformed into an output sequence. This architecture consists of two main components: the encoder, which processes and encodes the input data into a fixed-dimensional context vector or a series of hidden states; and the decoder, which generates the output sequence based on this encoded representation. It is widely used in applications such as machine translation, text summarization, and speech recognition, enabling models to handle variable-length sequences effectively.",
      "categoryId": "f48b8da7-416f-4bf5-9d8a-4638ff6f7a39",
      "subcategoryIds": [
        "5de64c15-c877-4e9c-a334-e1974d2f1e44",
        "082904c6-8be2-4ed7-8340-c922c26fb465",
        "89ca30a3-1a41-4c7d-8bb1-cfed9356b6fa",
        "4c020ab3-e75d-44cc-8dd3-d3418ef16ff7",
        "5b60d46a-62f6-48a3-8018-2db974196fa2",
        "6bdb618e-aa02-4deb-8055-ff7592c2f02b",
        "704ffe15-3065-40df-b120-27a17d39d5dc"
      ]
    },
    {
      "id": "9249aaa3-df36-4e4b-98f1-248ab865a040",
      "name": "Encoder-Decoder Models",
      "definition": "Encoder-Decoder Models are a specialized class of neural network architectures designed to process input data into a different form or representation, often for tasks involving complex transformations such as language translation, image captioning, and sequence-to-sequence prediction. These models consist of two main components: the encoder, which converts the input into a fixed-length or variable-length internal representation, and the decoder, which generates the output from this representation. This setup enables flexible handling of structured input and output data, especially when the input and output differ in length or format.",
      "categoryId": "5a0ec7db-6b3a-4e39-ac6d-b851adc590a8",
      "subcategoryIds": [
        "77810795-2b89-43ae-a1a2-b6021b4b4b9f",
        "93dfc528-6d52-4947-8d68-73006623e4c1",
        "ae3f9912-0fd5-470a-a06a-f0a0e76aaf35",
        "ab3c0651-0cdf-46a7-a882-15967b25b3d9",
        "70cb21f5-0562-491b-a309-205220b737b7",
        "3913b623-e6d1-43fb-aac2-bf432ed0112a",
        "de7de3bf-a780-4067-a5d3-660627611a66",
        "e712490f-71c4-4f72-869c-d70a7c49f24b",
        "0829b084-5e21-4363-970f-e8930633e0c7",
        "a618e317-c819-405b-a70e-c9d381f358f1"
      ]
    },
    {
      "id": "dc677b9c-aa79-4f30-be76-28d4e18c3c83",
      "name": "Encoder-Decoder Models Extensions",
      "definition": "Encoder-Decoder Models Extensions refer to advanced modifications and enhancements of traditional encoder-decoder architectures used in neural networks. These extensions aim to improve the models' ability to handle complex tasks such as sequence-to-sequence learning, language translation, and image captioning by incorporating additional mechanisms like attention, multi-head attention, pointer networks, and hierarchical encoding. They build upon the foundational encoder-decoder framework to address limitations such as fixed context size and to enable more flexible, accurate, and efficient data processing.",
      "categoryId": "3f53aefa-f781-4d9f-b5d8-cc8cd9933ca0",
      "subcategoryIds": [
        "c6f5f24d-5807-47bf-8e76-2895fbea9d8b",
        "63265821-0634-4b76-acf2-e859068e1d8f",
        "360fb862-1d4f-4b6a-93f0-1f7f275ceb69",
        "296a9093-e9db-4e16-8154-f0b45e49d554",
        "a6e89843-8b5a-49d2-9897-035cae5a5c90",
        "5e7aa69d-94cb-4680-93cf-1982568e787d",
        "65fb52ac-1ccf-43d5-99ba-7160cba85567",
        "193a254c-6356-4a74-bfad-123cf77fea8a",
        "2ba79f8f-3a71-4e4d-84fe-51c1cbb794ef",
        "e67e8940-e9e5-4644-8572-775a477a1857"
      ]
    },
    {
      "id": "9ef9f6d8-bd45-4b10-b18e-de46fd5e03c5",
      "name": "Encoder-Decoder Models Extensions Extensions",
      "definition": "Encoder-Decoder Models Extensions refer to advanced architectures and modifications built upon basic encoder-decoder frameworks used in neural network models. These extensions aim to enhance functionality, efficiency, and performance in various sequence-to-sequence tasks such as machine translation, speech recognition, and image captioning. By integrating techniques like attention mechanisms, multi-head attention, or hierarchical structures, these extensions improve the model's ability to capture complex dependencies and context within data, thereby expanding the capabilities of standard encoder-decoder systems.",
      "categoryId": "16e6d0ac-ce65-4d4d-9576-9987b3def357",
      "subcategoryIds": [
        "43940ebb-9d7e-4f00-b570-bdd588d4a248",
        "0bbb35c2-9793-4dea-ab12-7a9097497bed",
        "c12fe7f9-04e8-4ed8-b6db-24cff3b9cdbf",
        "1f3b0274-9b13-49cd-a7de-9f3741d3b8f7",
        "bf959b0a-0540-4e4d-a39a-fd5d16659b04",
        "9462a58a-00da-4b29-83c9-356b698d9ece",
        "5e17cb98-5d20-4a28-a08c-87d55270f6ae",
        "1b0d9bea-d219-4efb-97a6-2d039f0e2b8d",
        "82794aa4-c445-4e50-9844-e497fc8f25e9",
        "9fe34b61-6168-40ad-8e77-6063c553d9d0",
        "ab30186f-fe85-4a1b-a5fa-aa05014c2511",
        "75f4cb0a-b898-46a7-875d-fe830cfea2fd",
        "37e95053-0bd1-49ca-970c-2d3918d66495",
        "347ca840-0e65-413b-b578-c04dbaca1ec8"
      ]
    },
    {
      "id": "da7c4021-e360-4f16-b95d-0bc91f87bfbc",
      "name": "Encoder-Decoder Models Extensions Extensions Techniques Enhancements Techniques",
      "definition": "Encoder-Decoder Models Extensions Techniques Enhancements Techniques refer to a range of advanced methods and modifications applied to the core encoder-decoder architecture commonly used in sequence-to-sequence tasks. These extensions aim to improve model performance, efficiency, and capability by incorporating additional mechanisms such as attention mechanisms, multi-head attention, transformer architectures, and other optimization strategies. They facilitate better encoding of input data and more effective decoding to generate accurate and contextually relevant outputs across various AI and machine learning applications.",
      "categoryId": "78fd06a3-b168-4f92-91b5-d402ba3bebb2",
      "subcategoryIds": [
        "20aaff3b-2bb4-4a8a-bba5-ad5575c4be97",
        "f7e0211c-88be-4e89-9704-3a3cc8e4474e",
        "e5c48b39-350c-477e-aa77-032498d573da",
        "b829f598-c4af-486b-a144-26f3a8eb601f",
        "aa2c26db-f5e2-43ab-b6cd-811138aadce9",
        "4ea56eb5-f930-443e-a53f-dd3ed277e860",
        "5a7f5b3e-8d7a-4993-b8c3-fdbd581e45c5",
        "79778c57-ac08-4984-bee4-75a7d26de084",
        "4138f6fe-7cbb-4f4e-91ad-ea2011f08d02",
        "b9aec470-e31f-4ff0-b9b0-14004bde800a",
        "94c45be1-d01c-4772-b3b4-6aa5253ff255",
        "55ebf19c-935f-461a-b85e-bad66a8b72da",
        "c318cabf-11e7-432a-b00b-0ac5c720cd49"
      ]
    },
    {
      "id": "f40ae978-cb9f-418a-a442-380874a63a26",
      "name": "Encoder-Decoder Models Extensions Techniques",
      "definition": "Encoder-Decoder Models Extensions Techniques refer to a collection of methods and architectural modifications designed to enhance the capabilities, efficiency, and flexibility of encoder-decoder frameworks in machine learning. These techniques aim to improve the performance of sequence-to-sequence tasks such as machine translation, speech recognition, and image captioning by extending the basic encoder-decoder architecture with mechanisms like attention, residual connections, multi-head attention, and hierarchical encodings. They often address limitations related to handling long sequences, capturing complex dependencies, and improving model interpretability.",
      "categoryId": "e9c6dc15-77d2-4a96-8ac0-231e7f8065d0",
      "subcategoryIds": [
        "2fea7433-e3b1-43fd-a671-e92c0417f759",
        "6abe589e-9109-4a24-90e7-141630e8e41f",
        "754db3fe-2e28-49b9-a3cb-0f6fd7a8bef0",
        "8653ea23-a2b5-4828-a67b-deda859b12b7",
        "61b9b684-73f6-4246-bce2-0ed1de7a0fff",
        "c5388222-8a9c-4990-81e9-24f6b23061c1",
        "672881c6-6c60-45ee-9731-cd35d02046ee",
        "b0212338-e70f-4f22-9c4c-412b8b87b93e",
        "9afe9eac-20cf-4cf0-ac25-b00c3da60731",
        "c24210b0-803f-4958-acfa-cab866de3c6e"
      ]
    },
    {
      "id": "ca1aaf6e-5fad-4ac0-ba8a-f5e6e93ad01c",
      "name": "Encoder-decoder pretraining",
      "definition": "Encoder-decoder pretraining is a training paradigm in machine learning where models are trained to understand and generate sequential data by first learning to encode input information into a meaningful internal representation and then decode that representation into a desired output. This approach is often used in natural language processing (NLP) and other sequence modeling tasks, enabling models to perform complex transformations such as translation, summarization, and question answering. During pretraining, the model learns general language understanding or feature extraction which can be later fine-tuned for specific tasks.",
      "categoryId": "2ea05092-e306-4d8c-a752-f9d04a2b2810",
      "subcategoryIds": [
        "e91489a6-5104-4e2a-883d-e88507d03aad",
        "4b55a054-2f35-49a1-8d6c-e8367df9ce7a",
        "c05268f3-d43d-47ea-8b33-e9e983eb53cb",
        "d54820be-d967-4c67-992a-58d0288d1faa",
        "24b65279-8ed1-4213-a3c5-35845ae55883",
        "bb5a8925-dca4-4a3b-a6b9-f9c61e3b736a",
        "0b6cbaa5-9a95-4403-b6f6-4c14ed444d3c",
        "11fdfa50-178b-42b1-83b8-be41b448fc49",
        "1bb4dbe1-ac1a-4b13-9e54-017d633f451c",
        "0d36489c-a132-4707-b480-81ab44dcd39c"
      ]
    },
    {
      "id": "d488f5dc-0a91-46b1-9817-be74b9e90f26",
      "name": "Encoding",
      "definition": "In the context of AI and machine learning, 'Encoding' refers to the process of converting data, information, or features into a particular format or representation that can be efficiently processed by algorithms. This transformation often involves translating categorical or textual data into numerical formats or compressing data to reduce its complexity while preserving essential information. Encoding is a fundamental step in data preprocessing, enabling models to interpret and learn from diverse types of data effectively.",
      "categoryId": "c3dc9eea-c0a5-43b6-8e06-1c2e238927e1",
      "subcategoryIds": [
        "5e34ad7f-f4e3-40ff-a507-7a9f3a692df4",
        "a0f4b5ec-9f75-4cbe-a8d2-e60ad6e5c300",
        "1789f423-01f3-4221-b8da-fe1bc6a40a7f",
        "2cc4b890-1569-44b5-a20b-7b7aa2643cac",
        "710fbfd1-9dcb-4dc3-9b4c-efdd80070484",
        "1dfd22c5-ddc4-4368-9d7e-400c05bfe6ab",
        "ddc333ba-dff8-469b-85bf-0b8ba20cc265",
        "b9ab7654-4327-4d0a-b6b2-88af8079c2cb"
      ]
    },
    {
      "id": "88d9976d-1546-44b8-b593-b964bab916a2",
      "name": "End-to-End Dialogue Systems",
      "definition": "End-to-End Dialogue Systems are sophisticated artificial intelligence systems designed to facilitate natural, coherent, and contextually relevant conversations with users, typically through natural language processing (NLP). These systems handle the entire dialogue process from user input to response generation within a unified framework, minimizing the need for manual feature engineering or modular pipeline components. They aim to produce human-like interactions by integrating various AI components such as language understanding, context management, and response generation into a seamless, end-to-end trainable model.",
      "categoryId": "4b0507ca-c08c-413d-b21d-fcd5dd7e515a",
      "subcategoryIds": [
        "1ed26969-d740-47dc-95a2-8debaa21bdf6",
        "c75ab5cd-2913-45ff-b719-106caf62c3e1",
        "a3adf8cc-c096-4836-8a26-464fb09c2850",
        "21253aa9-4c4c-4b7a-ad0a-60a72947d842",
        "f5a7f1c1-7d1d-44b6-a407-031bc9427d46",
        "32e4061f-8242-4625-9df1-87ef41b22acc",
        "e9a477df-6898-42cf-8d5a-5269f86ef357",
        "7aee1761-b275-42f5-8f03-f765b41a8cbb",
        "e642a5fa-6e3c-4965-8187-16ff9a3d1a7f",
        "717245df-7243-4e68-bd48-af164b734e18"
      ]
    },
    {
      "id": "63b818ad-a269-4c7c-9025-610f772d80d5",
      "name": "energy-based distillation",
      "definition": "Energy-based distillation is a machine learning technique that involves leveraging energy functions or energy landscapes to guide the process of model compression, transfer learning, or knowledge distillation. It derives its name from the concept of using energy metrics to evaluate and optimize the transfer of information from a teacher model to a student model, aiming to improve the efficiency and effectiveness of the distillation process by framing it within an energy minimization paradigm.",
      "categoryId": "a9561565-4162-4df7-9ded-b102c1f03d66",
      "subcategoryIds": [
        "c349a650-3ef2-4ad8-a9d8-57cec2bb6258",
        "298920d9-3ec3-4085-8ab0-e5637d25dd39",
        "839f299c-3efb-48f4-818d-de605d4fe04a",
        "28b36fef-2005-438d-b42a-8f9fb21cca0d",
        "124b9dc7-30d7-498c-89b1-32362c5323ea",
        "e31aeaff-71dd-4495-be7a-0c39543f5d06",
        "df7e4c06-0ce4-4cf1-81a6-497754a67e81"
      ]
    },
    {
      "id": "1fb1ddc9-2d89-484e-bc09-c480914e9ba8",
      "name": "Energy-Based GANs (EBGANs)",
      "definition": "Energy-Based Generative Adversarial Networks (EBGANs) are a class of generative models that utilize an energy function to guide the training process. Unlike traditional GANs, which rely on a discriminator to classify real versus fake data, EBGANs employ an energy function as a measure of data authenticity, where lower energy indicates closer resemblance to real data. The generator aims to produce samples that minimize the energy, effectively learning the data distribution by training with a simple autoencoder as the energy function.",
      "categoryId": "512e1bf0-d1b6-4015-b768-875b1d3b19e6",
      "subcategoryIds": [
        "5b09eec1-5ac0-45cb-95b2-9b426e4e67b4",
        "a58b1dca-5ff8-487b-a128-fd5aaf05d33c",
        "dbe6a900-86e3-435d-98e5-5df57effa953",
        "4bdeac16-49e0-498e-99e4-68cb3eadd768",
        "92434764-b319-45b0-82b7-d44feec3d57a",
        "7f21d26a-c852-4f47-84d7-e37adeedaa4f",
        "4b013ae5-ce3f-4a87-9542-94f264b0b0cc",
        "e52bd599-7ab1-4acd-9c57-2e1a6e5139b1"
      ]
    },
    {
      "id": "6a87261f-5ad9-4b0e-9d7f-35db9f3e3a04",
      "name": "Energy-Based Models",
      "definition": "Energy-Based Models (EBMs) are a class of probabilistic models in machine learning that define a scalar energy function over data points or configurations. The core idea is that data points with low energy values are more likely or preferable, while those with high energy are less likely. Unlike traditional probabilistic models that explicitly specify probability distributions, EBMs focus on learning an energy function such that the probability of a data point is proportional to the exponential of the negative energy. EBMs can be used for tasks such as density estimation, generative modeling, classification, and reinforcement learning by leveraging the energy landscape to represent complex data distributions.",
      "categoryId": "bae25fb5-0be2-4b34-b716-dcdb45299ae1",
      "subcategoryIds": [
        "b4cd2712-5453-4665-bd5c-5a5399aa9b2e",
        "800c3a66-d80e-4193-a3ad-add52bd9a068",
        "ed561405-7b23-4ea0-9329-370e2c36f43a",
        "42d4a71f-2a42-4626-b63e-def98aabc851",
        "504c5bae-79cb-4019-9c7b-6132f7cf31a8",
        "998f2046-4635-41f6-8fa0-8be9776c8287",
        "2c1257c3-eaf2-4012-804b-5d2c09bb8266",
        "d8d4854d-7749-4272-b072-25c6310f0d47",
        "5c312b6d-c261-4808-8789-2b34e69eed97",
        "5cc41e4b-5b70-4ae9-a87b-fcde50d2b66d"
      ]
    },
    {
      "id": "a6f0e7f7-8fc4-429e-90eb-1ba19ee17f32",
      "name": "Energy-Based Models (EBMs)",
      "definition": "Energy-Based Models (EBMs) are a class of probabilistic models in machine learning that define a scalar energy function over input configurations, where lower energy indicates higher likelihood. Instead of explicitly modeling probability distributions directly, EBMs assign energy values to data points and learn to assign low energies to observed data while assigning higher energies to unlikely configurations. This approach enables modeling complex data distributions and facilitates tasks such as density estimation, generative modeling, and unsupervised learning.",
      "categoryId": "6120da77-9162-49b0-8d06-e2affbf6368b",
      "subcategoryIds": [
        "e73cbccd-cc08-4fb8-a7d2-afda94a45abc",
        "17afd917-2c1b-4947-8202-1fb6ca01efe8",
        "76fba6d6-c063-488c-b8a9-17649d43857f",
        "586b969b-e47b-4524-ad38-650005e17501",
        "0c4b2da4-b226-4a5b-a7a1-5bf03ef7fb2a",
        "3f4c714c-f633-41af-9984-e07f1f70b084",
        "83a5c83d-7118-42ec-9ebf-f7c747c9510a",
        "e0eb2b77-b2ef-4241-93ab-253fb9abfbfc",
        "5a79a72b-8d6f-4569-8d60-afa9d0a614d2",
        "09ae481f-f05f-42b0-99e7-1891a265fc26"
      ]
    },
    {
      "id": "96d83a74-b59e-4fdd-83b1-b0c2028f9e4d",
      "name": "Energy-Based Models Extensions",
      "definition": "Energy-Based Models Extensions refer to the advanced variations and adaptations of fundamental energy-based models (EBMs) in machine learning. EBMs are a class of probabilistic models that associate an energy value with each configuration of variables, where lower energies correspond to more probable configurations. Extensions of these models incorporate new architectures, training techniques, and applications that build upon the core principles of EBMs, aiming to improve their expressiveness, efficiency, and practicality in various tasks such as generation, classification, and representation learning.",
      "categoryId": "969e5af5-df4f-4149-a078-161d08490472",
      "subcategoryIds": [
        "0f2fcad0-6521-4da1-9f64-e9b3aa8334bc",
        "4caa6b48-ef3e-4214-969c-30b9b7015509",
        "685edbb0-e6ec-4f95-9c97-ca40ac795afa",
        "6715e3ab-815b-47f1-9580-0e0fc130f2c6",
        "953681cd-1eaa-47ea-94ba-5d1e56ff141b",
        "11a5cad9-3cb3-4c28-94b4-037aea5cb74e",
        "398ff695-4778-42a3-bd6a-d8dfbddb1cd0",
        "96d0ddb5-f13e-41a0-ae21-843e335f4eb2"
      ]
    },
    {
      "id": "64e1a339-f988-41fd-80f9-4ee2d79101d7",
      "name": "Energy-Based Reinforcement Learning",
      "definition": "Energy-Based Reinforcement Learning (EBRL) is an approach that integrates principles from energy-based models into the reinforcement learning framework. It conceptualizes the agent's goal as minimizing or managing an energy function associated with states and actions, enabling the system to learn policies that prefer low-energy configurations which correspond to desirable or optimal behaviors. This paradigm often involves defining an energy landscape where policy optimization is achieved through energy minimization, facilitating more flexible and expressive representations of complex decision-making tasks in environments with high-dimensional or structured data.",
      "categoryId": "99457e6b-e884-42ed-ba3d-a7395d94a4c2",
      "subcategoryIds": [
        "1a1bc431-1319-4d6d-b92c-1146acc30a52",
        "2e242b6f-4536-439f-ab94-9b80b8fc084c",
        "22c84b2e-28e4-4643-a343-568adae50d2d",
        "c3d705b4-5782-493d-a569-db4c9e12e95a",
        "95197374-21c5-4544-af48-8f16a7a668b8",
        "c9edc101-8614-484c-95d6-999638347e27",
        "21b378f0-4b22-4700-9caf-1263f8f71d77"
      ]
    },
    {
      "id": "27c4c7a5-e148-4ff9-b4fb-737d295bf3d0",
      "name": "Ensemble Averaging",
      "definition": "Ensemble Averaging is a statistical technique in machine learning where predictions from multiple models or multiple instances of a model are combined by averaging their outputs. This approach aims to enhance prediction accuracy and stability by reducing the variance associated with individual models, thereby producing a more robust and reliable estimate of the target variable or class.",
      "categoryId": "e2289c8c-e79b-4bd0-8a7d-3dc127a1309a",
      "subcategoryIds": [
        "e6df9889-a011-4ddf-ab18-1aa5c509be59",
        "fa676f91-395e-40bc-9ae7-5e8c0a5977a2",
        "88b2bf2b-20e3-4a97-8e93-c78c54e2b61e",
        "186815d1-9683-48cc-823d-d7e152fad8cc",
        "b69a5442-a6be-4eea-8e7a-e8bd8a715c99",
        "464e0379-4d26-4ea2-a117-079b6f403895",
        "1dfbd33c-dcdb-4677-a255-0769a382e16e",
        "eddf0a08-46a7-4536-8ddd-9205e9380b2f",
        "febedeb8-8545-400a-9b85-af8ef2ae2a03",
        "fdd9ad1c-3957-4b96-9ec6-71993eb7cfec"
      ]
    },
    {
      "id": "db91278f-c177-48c6-9c4e-71ff82aac99f",
      "name": "ensemble distillation",
      "definition": "Ensemble distillation is a machine learning technique that involves transferring the collective knowledge of an ensemble of models into a single, compact model. By doing so, it aims to combine the high accuracy and robustness of ensembles with the efficiency and simplicity of a single model, typically through a process known as knowledge distillation. In essence, ensemble distillation involves training a single model (the student) to replicate the predictions of an ensemble (the teacher), thereby capturing the ensemble\u2019s performance while reducing computational complexity.",
      "categoryId": "1de445c8-b813-4cbc-9f75-a5a97a746487",
      "subcategoryIds": [
        "f6fb417c-612d-4734-8c95-fdd1f80b2184",
        "c25e4b67-8135-43a4-8cec-0c6b04ba1a95",
        "27b2110e-a0ae-4918-82a8-c96fc3d14546",
        "a4572711-e527-4c02-86e5-49f168e70871",
        "bfbe2e8e-fda2-4915-a93d-cdfbe15aaf81",
        "b5f9a416-c324-406e-86ee-9a64a132b7f1",
        "e5b67d1f-a062-4c69-95a3-0242f469ca16",
        "ec607c93-7b2c-4035-b9cd-e3a4e2d9e63d",
        "1eb4d2fb-3672-45e5-9dca-71598d768355",
        "473aa82c-0441-4181-86fe-4bd8b2898374"
      ]
    },
    {
      "id": "50b21cff-a4cd-4180-9ec3-b497aef7b663",
      "name": "Ensemble Diversity",
      "definition": "Ensemble Diversity refers to the measure of variability or difference among the individual models within an ensemble method in machine learning. It quantifies how distinct the predictions of the constituent models are, which is crucial because higher diversity among models generally leads to better ensemble performance by reducing correlated errors and improving generalization. Ensemble methods, such as Random Forests or Boosting, leverage diversity to combine the strengths of multiple models, thus enhancing overall prediction accuracy and robustness.",
      "categoryId": "944bb1ca-fa35-4433-81f5-6b852ab72f13",
      "subcategoryIds": [
        "94bb6346-8b89-4b7c-9a60-109fe5495062",
        "117cea17-15b3-45a7-9314-64749303bad0",
        "7a4f8b68-d61d-48b6-b818-30f235381c79",
        "fceda41b-06f2-4fb1-9c20-8ebc22a6d670",
        "5ee4fbe7-303f-4e1f-a831-c9c299c03c54",
        "390765ba-ff94-4788-8a39-44ab8ea352a3",
        "9db2408c-dc15-4d86-90d4-42cdd6c6cdeb",
        "daa1ae47-d0a7-4e46-9ac6-c1e0f05be59e",
        "ffda6c5a-c5a1-47ef-86f7-79fcc49650a8",
        "e5106d10-c369-4d25-a649-61b6ab40811b",
        "cd4cd33a-5b6d-4552-b3e7-197832b00a55",
        "a74f1e70-880e-476d-8b0d-cc9d4bc0da02"
      ]
    },
    {
      "id": "d1c29197-1ce4-4f5e-91cc-b9bcd20c6f54",
      "name": "Ensemble Diversity Techniques",
      "definition": "Ensemble Diversity Techniques refer to methods that aim to increase the diversity among individual models within an ensemble. These techniques are designed to ensure that models make different errors or predictions, thereby enabling the ensemble to benefit from their varied perspectives. By promoting diversity, ensemble methods can improve overall predictive performance, robustness, and generalization capabilities beyond what individual models can achieve alone.",
      "categoryId": "25863d08-512d-43c1-a19b-2bd7767cf470",
      "subcategoryIds": [
        "06cc5c16-4a03-4706-98d5-b6a27fde5edf",
        "86ad7be1-1831-4a51-b476-b92f32cbc32d",
        "e0a47b8a-45b0-4dbb-8fa7-fcb585383567",
        "1a33021d-4693-496a-ae82-8c7b51f74e04",
        "5df926d7-785f-42f2-9cab-50ed799f59ca",
        "2f8bda75-894e-40d5-a9ba-bcaec3dcb037",
        "49a351f9-fd72-421f-b2de-5e067639e1b4",
        "af86ba8d-5255-4c4c-b0b6-72a4c25188e6",
        "6e200c29-b277-4fc3-8ec6-f81170197490",
        "270b03a3-2d0d-4f07-9580-b6ccec2d2a57",
        "a53d35f6-3133-4995-a495-853ba768e1c4",
        "b1313bae-789c-40f7-b055-b053c20739bc"
      ]
    },
    {
      "id": "9dfbcd2c-6879-4d9d-a4d5-571a90db9ba2",
      "name": "Ensemble Diversity Techniques Extensions",
      "definition": "Ensemble Diversity Techniques Extensions refer to advanced methods and strategies used to enhance the diversity within ensemble learning models. Ensemble learning combines multiple models, such as classifiers or regressors, to improve overall performance and robustness. These extensions specifically focus on promoting diversity among the individual models to reduce correlation and errors, leading to more accurate and reliable ensemble predictions. Techniques include various methods for encouraging varied model behaviors, such as specialized training procedures, data manipulation strategies, and model architecture modifications, tailored to extend or improve upon traditional diversity techniques.",
      "categoryId": "f02f4855-4f1b-482c-b37d-48eb3ed9985b",
      "subcategoryIds": [
        "a22a3f0b-141b-4d70-a7fa-bdecfb69992f",
        "b76775fc-8b85-4cd1-93c2-ebdc4d60e306",
        "701413fc-ab3b-4492-a799-a191994e87da",
        "238cd09b-e5c7-4eed-91fd-5b7fd9e1e9f6",
        "29083773-63ca-4e5d-a139-21d8946f30c8",
        "646dfdfa-ffcb-4732-9df7-98e0a4313caf",
        "230e8fe7-0e9f-4e6c-a192-020e363ad30b",
        "53e60e98-3555-4561-9987-5eda40ff8d07",
        "a160babc-5241-4c99-9fbe-b58adda1b33d",
        "fc2c7a73-7a1f-4bf8-a2b0-818824aa3131",
        "a0027f51-8858-4144-b904-a537ac843b22",
        "0a529784-cfaf-40dd-ab67-567e8297ba2d",
        "62efac06-91b3-466e-9e6b-8ed28e571b64",
        "f8ee0aec-549a-402d-89d5-fb2f8290828c"
      ]
    },
    {
      "id": "8e09133f-4807-4daf-880c-0ad866142671",
      "name": "Ensemble Gradient Boosting",
      "definition": "Ensemble Gradient Boosting is a machine learning technique that combines multiple weak learners, typically decision trees, to produce a strong predictive model. It builds an ensemble sequentially, where each subsequent model attempts to correct the errors of the combined preceding models, utilizing gradient descent techniques to optimize model performance. This approach enhances prediction accuracy, robustness, and generalization capabilities compared to individual models.",
      "categoryId": "78e07f25-31b4-4a98-a921-7638e74bf57a",
      "subcategoryIds": [
        "bcf8c119-9d94-41ec-98f3-890214f15391",
        "492da1ad-0abf-4009-ab45-f85df635a460",
        "a101a37b-8ccc-41b9-95c6-98765f5f1d0d",
        "c2a4fc3a-84a7-4d78-8eec-d215ed0bf6df",
        "03d045ca-ad9f-4d3e-9c85-85369213f6ca"
      ]
    },
    {
      "id": "5c71a863-eb88-4a19-82f2-d99488ac62ee",
      "name": "Fisher Information",
      "definition": "Fisher Information is a fundamental concept in statistical estimation theory, quantifying the amount of information that an observable random variable carries about an unknown parameter upon which the probability depends. It is mathematically defined as the expected value of the squared score, which is the gradient of the log-likelihood function with respect to the parameter. Essentially, Fisher Information measures the sensitivity of the likelihood function to changes in the parameter, providing insights into the precision with which the parameter can be estimated from data.",
      "categoryId": "714319b2-d242-4389-b6bc-0e0b75344899",
      "subcategoryIds": [
        "35724c5a-a932-46da-b78d-72945fd5e06b",
        "96ef18e4-e513-4ec3-bbf0-75fb6e256a5b",
        "1b2d912f-0d1c-41ac-98eb-b8e01e34118f",
        "05275a2c-126e-4272-b31d-5d962bd4dd8a",
        "95d4fc7f-3132-4f2b-bd48-9477a6fb8592",
        "5aed19f7-8a38-43f2-a209-27a2bd1262b2",
        "75f8cdf2-ab39-42cd-a1f6-1e471af0fcf4",
        "d4ae7c25-277b-4ef6-a7c8-1a43f14544b8",
        "153ffbc6-c548-4025-a4c0-e70f0acfd646",
        "c5a99d93-f707-4815-9739-46082aa80977"
      ]
    },
    {
      "id": "a4926546-205c-49f0-a730-59c6331cc077",
      "name": "Fisher Information Matrix",
      "definition": "The Fisher Information Matrix (FIM) is a fundamental concept in statistics and information theory that quantifies the amount of information that an observable random variable carries about unknown parameters upon which the probability depends. Mathematically, it is a matrix of second-order partial derivatives of the log-likelihood function with respect to the parameters, representing the curvature of the likelihood surface. In the context of AI and Machine Learning, the FIM is used to analyze parameter estimability, optimize training processes, and understand model sensitivity.",
      "categoryId": "54657172-948c-4c95-892c-db97877bd6b4",
      "subcategoryIds": [
        "662f37ba-374d-4848-9fdc-bcee114c3b4d",
        "e239da8a-04e8-43b7-b5a4-5bf3390f644d",
        "9aa421bf-b2d3-4923-adcd-960e07f5c9d4",
        "8abffc8f-15fc-4f69-b405-dc3a7ecde333",
        "1e70007e-128f-48eb-b29a-fbc46baba4a8",
        "0479bb53-9c7b-4f23-bb7d-948ed37bc86c",
        "439e22f6-9e4c-45d6-a1ec-f2642e1785e7",
        "52f47fe3-eccd-431c-9228-516a6375f065",
        "5be94237-8781-45ad-b2e0-7e1faedeffe1",
        "d0b0090c-8d1a-4b1e-9804-dd611885417b"
      ]
    },
    {
      "id": "338b8140-0ba0-47f7-adcf-b340b57e89cb",
      "name": "Fisher Vector",
      "definition": "The Fisher Vector is a powerful encoding method used in computer vision and pattern recognition tasks to represent sets of local features, such as SIFT descriptors, in a fixed-length, discriminative feature vector. It combines the benefits of probabilistic modeling and feature aggregation by encoding deviations of data points from a generative model, typically a Gaussian Mixture Model (GMM). This approach yields a compact and informative representation useful for tasks like image classification, object recognition, and clustering.",
      "categoryId": "24d9cc18-577d-412b-b205-fdb83f4a243e",
      "subcategoryIds": [
        "4ab1d589-4953-40ef-b23b-7b4f3bd6a9da",
        "9e5599b5-b45a-4b5a-b3e9-ab7d0cd17d3d",
        "3322b975-f08b-4d19-b62f-edfa05393083",
        "7c4103cf-9afe-4add-924b-88e899818f7b",
        "d783816d-a6e3-4a7e-ac44-a7b79070f70a",
        "b2e1e413-56e5-4d91-b96e-ee6eed2c692d",
        "7d62b8d7-dd0e-4f6c-9e38-012f23ba3903"
      ]
    },
    {
      "id": "67221bf4-4bae-4a9b-b444-77236f4869d9",
      "name": "Fisher Vector Encoding",
      "definition": "Fisher Vector Encoding is a technique used in computer vision and machine learning to represent a set of local image features as a fixed-length, high-dimensional vector. It encodes the distribution of local descriptors (such as SIFT features) relative to a learned probabilistic model, typically a Gaussian Mixture Model (GMM). This encoded representation captures rich statistical information about the local features, making it suitable for tasks like image classification, retrieval, and object recognition. The Fisher Vector method combines the ideas of generative modeling and discriminative classification, offering a powerful tool for feature aggregation and representation in high-dimensional spaces.",
      "categoryId": "02ab2145-e941-490d-8eee-8ec589e9b859",
      "subcategoryIds": [
        "58420cd8-2f9e-4659-a97e-ab745597f4cc",
        "dde2174d-6121-420c-8670-b27100b636c2",
        "29d46347-5740-421d-8948-41687b470feb",
        "1018f1f4-fae6-4f11-ac33-1b75dbe57c1b",
        "0145ecba-91be-40d3-a495-d30e4981711d",
        "1713b1f9-f710-4086-9dbb-153f9e87763d",
        "6e965eb6-08e3-4358-954b-119bae62121c",
        "a750d6f6-d516-44e0-bf5a-9ea233eef3fe",
        "b91d8775-74b2-4f9a-ae89-97ab875bba02"
      ]
    },
    {
      "id": "3543270b-84e0-45cf-963a-9f1dd079cc88",
      "name": "Fisher's Exact Test",
      "definition": "Fisher's Exact Test is a statistical significance test used to determine if there are nonrandom associations between two categorical variables in a contingency table, especially in cases with small sample sizes. It computes the exact probability of observing the data under the null hypothesis of independence, making it a precise alternative to the Chi-squared test when sample sizes are limited.",
      "categoryId": "d9bb06da-c538-40e6-bda6-1c82daa49aba",
      "subcategoryIds": [
        "35651d15-bfe4-4a28-b1a3-72fd7cf984ee",
        "0732cd35-e0f7-47e7-84aa-32ae20794022",
        "6b5ea34b-4e4e-41cc-b694-494b549aea3f",
        "ef22c8ac-84ef-4868-b85c-ab5f6a19d91a",
        "54d93b6f-4656-4b57-9090-2987c3bb020a",
        "5bca7cbb-db1c-4562-82eb-60c561af428d"
      ]
    },
    {
      "id": "93bdd027-2d61-4d0f-b2f1-8e954fb2c35b",
      "name": "Fitness Function",
      "definition": "A fitness function is a fundamental component in optimization algorithms, particularly within evolutionary algorithms and genetic algorithms. It is a function that evaluates and assigns a fitness score to a given solution or individual within a population. The score quantifies how well the solution performs relative to the problem's objectives, serving as a guide for selecting better solutions and generating subsequent generations. By providing a scalar measure of solution quality, the fitness function enables the optimization process to progressively improve the solutions over iterations.",
      "categoryId": "4e903654-196d-4f4c-b9fb-8d532eb1df9a",
      "subcategoryIds": [
        "df08ab0c-732c-4ae4-8084-bd3a5b528997",
        "fa80ee8d-05b2-40b3-879f-d028e90b7272",
        "4064b5f3-5f96-4990-ab8f-25cab3547296",
        "27ccc73b-ea6d-43d0-887d-0d887a800eb7",
        "9a8fcd5f-08b2-45e7-87c7-313baf3d6a6f"
      ]
    },
    {
      "id": "23957c29-0933-478e-bd9d-4075c4659b35",
      "name": "flash attention",
      "definition": "Flash attention is an advanced attention mechanism designed to optimize the traditional transformer attention process by significantly reducing computational complexity and memory usage. It achieves this by approximating or selectively focusing on relevant parts of the input sequence, enabling faster and more efficient processing, especially for long sequences. This technique allows models to handle larger inputs and longer context windows without the prohibitive resource demands associated with conventional attention mechanisms.",
      "categoryId": "6c645899-ecab-4301-942b-765c54ceb964",
      "subcategoryIds": [
        "aab702b5-654d-472c-bcc6-db78595b26d8",
        "29d248f8-85f0-4f97-8e72-8c4fa29de47c",
        "98dcf5da-b243-4843-822a-371144eddd57",
        "90be9248-af4a-4458-87da-f4e54252e98e",
        "bbf96e62-eeda-46b0-a4c0-d058fffab6f5"
      ]
    },
    {
      "id": "f3f29365-75a9-40d8-89d7-73b625ddd42d",
      "name": "flash distillation",
      "definition": "Flash distillation is a separation process primarily used in chemical engineering and distillation industries, where a mixture is rapidly vaporized and condensed to separate its components based on differences in volatility. In an AI/ML context, the term is metaphorically adapted to describe a rapid, focused process of distilling complex data, models, or knowledge into simpler, more manageable representations, often facilitating efficient model training or interpretability.",
      "categoryId": "2ce7f3e4-418e-4479-8ed3-b7b072e43bc4",
      "subcategoryIds": [
        "c73adb84-1a57-426c-afc3-b0b1b6a1d5d6",
        "094f68f7-c4ac-4c5a-b350-5b9a4879c2ac",
        "d13de930-20ee-4736-8f8e-d82975bd7f36",
        "1fbcebfe-2ce8-4804-b3c5-e1b891f151d1",
        "6066af39-26d1-4727-b29c-5d8af7ee4b9b",
        "fea3bbcc-13d7-411f-84bf-4e2636cd1a5b",
        "c14dd674-d29c-4a0e-bbec-fc20181d46f8",
        "bd7d8aaa-5d96-4c71-abc0-d512947b4e73",
        "83ecad5f-8403-4499-b028-1ff66dba8711",
        "96a8f087-f742-48f6-be65-49fec0f09aa0"
      ]
    },
    {
      "id": "cd0bdc9e-75f5-42cd-b781-7685fac52edb",
      "name": "Flexible Neural Networks",
      "definition": "Flexible Neural Networks are a class of neural network architectures designed to adapt their structure, parameters, or activation functions dynamically during training or inference to better suit specific tasks or data distributions. Unlike traditional fixed-architecture models, flexible neural networks can modify their configuration to enhance learning efficiency, generalization, and robustness, enabling more versatile and efficient AI systems.",
      "categoryId": "a9d6d3a1-5af7-48a2-961e-af5c3b79af4d",
      "subcategoryIds": [
        "2813303d-86ce-4466-b2fb-46b6d71bb574",
        "6ded9fba-dd91-49ea-971d-792b3e184ab9",
        "9387d6cf-c939-4165-9016-80dfc0071c76",
        "9e898181-c9c6-48c4-ad5a-0bd8471d12b1",
        "263dbb60-7575-41d0-afe6-dd503e42cf95",
        "1124e7f2-ebfe-4ec4-aa49-b3d7fc104e39",
        "9a2e4c6b-d0f9-4270-a5f9-b3d76fbfaaae",
        "930d2f10-e40d-460b-858d-6f05864aa8bb",
        "d4107d82-a172-43d1-a90f-2d286bcbfb6a",
        "d36bbe3f-c25c-4770-ace0-fbc2e5dd7cac"
      ]
    },
    {
      "id": "60091352-9b3d-41aa-917e-2564fe4b34b2",
      "name": "Flow-based Generative Models",
      "definition": "Flow-based Generative Models are a class of deep learning models designed to generate complex data such as images, audio, and text by learning invertible transformations of simple probability distributions into data distributions. They leverage a series of invertible functions, enabling exact likelihood computation and efficient sampling, making them a powerful tool for generative tasks where precise data modeling is essential.",
      "categoryId": "4aac71e7-1c4f-4c40-a0e8-561dfaf8815c",
      "subcategoryIds": [
        "92aeca13-e773-425a-9eb2-5109cdd0fcda",
        "85cae706-2d69-4815-820f-73b504e4827e",
        "3cb99a3f-2cc2-4819-b0f7-1ab66841514c",
        "4bd2e42d-254a-442e-adff-8bc74ae5590d",
        "80f917f8-6a27-4faa-81d1-a23bfdd54537",
        "5462719f-3f41-4589-a36d-8e410dff5d0a",
        "d76c0783-52a1-4b24-9813-9271259d3091",
        "8590fbdb-7e83-4b5f-bf2d-89b93475d678"
      ]
    },
    {
      "id": "0e982fa1-372f-4de9-aa44-38a49999aafd",
      "name": "Flow-Based Generative Models Enhancements",
      "definition": "Flow-Based Generative Models Enhancements refer to advanced techniques and modifications aimed at improving the efficiency, scalability, and quality of flow-based generative models. These models are a class of probabilistic models that learn to generate data by transforming simple distributions into complex ones through a series of invertible mappings. Enhancements focus on optimizing these transformations, making them computationally more efficient and capable of capturing intricate data distributions more accurately.",
      "categoryId": "6fd51f9a-c4ce-46ba-b80e-d22987891638",
      "subcategoryIds": [
        "cc4d9ec4-e309-4833-ab20-eeeec21fa083",
        "08b581e2-e2d0-48c6-8b87-6286634f018c",
        "d9c2e5af-ab20-40aa-a92a-a7c42bb61de7",
        "96c167f6-93f7-4919-826b-325c613bb0ab",
        "036aa319-c6c0-4d62-ab7b-cd833ca8acbe",
        "c7cc0370-bb6a-4f82-b948-3cb0ca9bdcb2",
        "0e19518d-03db-4c8e-909b-85d00914589d",
        "ffd9a9cc-9bf5-4329-a9f5-6cfabe54537d",
        "4ceacd94-7d03-4997-aa2b-5502af401d60",
        "5a32e1de-73d4-4025-a01e-40eb10ddbac0"
      ]
    },
    {
      "id": "0b78a2bf-aa47-4e57-8d80-308d7ae06af2",
      "name": "Flow-based Generative Models Extensions",
      "definition": "Flow-based Generative Models Extensions refer to advanced developments and modifications of existing flow-based generative models, which are a class of probabilistic models used to generate new data by learning invertible transformations between complex data distributions and simple base distributions. These extensions aim to improve the models' expressiveness, scalability, computational efficiency, and quality of generated samples, often by integrating novel architectures, training techniques, or hybrid approaches to address the limitations of traditional flow-based models.",
      "categoryId": "ce17e4a6-9194-4757-b9b3-89571f5b4b89",
      "subcategoryIds": [
        "cee9f6bf-890d-4c02-b6e2-78531552bc05",
        "1497788d-ba6e-4124-a665-6dc8b5e86206",
        "ca328beb-cb67-43d6-894c-182bf237c8bf",
        "07d182e4-d79c-4f98-87ed-e37cab95509b",
        "e37f5b8b-e42a-4eb5-9fde-e77d2711c36b",
        "120c5d0b-e0a5-47d0-8e94-2e64d7bd37cc",
        "f6c2e4ee-882a-485e-b8a8-846dd4d42b35",
        "74e5eca9-2749-446a-a117-ce49aaa4e2d2",
        "fc48450f-9d4c-48b7-8461-84cd4f7f09ba",
        "c640c5d2-f511-4c10-977a-85e18e543be4",
        "050ca11a-22f6-43a3-9a06-f99ae437a981",
        "15a0e153-647c-4283-9e3a-d215470ee359",
        "d765fe0d-2533-44cb-9aca-19e0864b8400",
        "b5258d98-d68e-4e60-9fe8-7feb519a021b"
      ]
    },
    {
      "id": "fdef7635-28ce-40c3-911f-e47e275ee19d",
      "name": "Flow-based Generative Models Techniques",
      "definition": "Flow-based Generative Models Techniques are a class of generative models in machine learning that utilize invertible transformations, or 'flows,' to model complex data distributions. These models transform simple base distributions, such as Gaussian noise, into complex data distributions through a series of invertible, differentiable mappings. The key advantage of flow-based models is their ability to efficiently compute both the likelihood of data points and generate new samples, making them highly valuable for tasks requiring exact density estimation and high-quality sample generation.",
      "categoryId": "e6eee2f4-4a75-4bc5-9417-a01e69186236",
      "subcategoryIds": [
        "9bca3162-7bbe-436b-a5b3-18c2e15cca9a",
        "62d258d7-b94c-4ccc-9c64-a1b951f3349c",
        "6ffbf7a5-b500-46f2-bc8f-3b0924fc63c7",
        "f9d8f6dd-a564-421e-bda4-684df3f0ba4a",
        "45b4f56c-d502-4986-9415-8feac6b16599",
        "8b2881bd-5380-431f-b063-dfce03a1f230"
      ]
    },
    {
      "id": "0353ca98-f6ed-4f09-bd3b-a006948f0683",
      "name": "Flow-based Models",
      "definition": "Flow-based models are a class of generative models in machine learning that utilize invertible neural networks to map complex data distributions to simple latent distributions, typically Gaussian. These models employ a series of invertible transformations, allowing for both efficient data generation by sampling from the latent space and precise data likelihood computation. Unlike other generative models such as GANs or VAEs, flow-based models provide exact and tractable likelihood estimation, making them highly suitable for tasks requiring detailed density modeling.",
      "categoryId": "4272bf25-2ab7-41ca-b9d5-336a0dc25db2",
      "subcategoryIds": [
        "37672243-2471-4d37-ac8b-a647773f1206",
        "35841a53-ca05-48e9-9b25-90ead685c07e",
        "4b2ad471-0cc4-4e8a-b4f9-1120f3c851b3",
        "43d1b49f-2d06-4234-9ac7-b7e601daf2e8",
        "3ba42570-0303-4903-bbaa-f9742489f28d",
        "a117421f-d4a7-4924-ad06-b66857e6f17e",
        "c54d87c1-c4fa-4f69-a0d6-feab59389779"
      ]
    },
    {
      "id": "da465507-4496-4ba2-802b-d74add94084a",
      "name": "Flow-Based Models Enhancement",
      "definition": "Flow-Based Models Enhancement refers to the techniques and strategies employed to improve the performance, efficiency, and applicability of flow-based generative models in machine learning. These models leverage invertible transformations to map simple probability distributions to complex data distributions, facilitating high-quality data generation and density estimation. Enhancements in this domain aim to address challenges such as computational complexity, scalability, and the quality of generated samples, often by optimizing network architectures, training procedures, or combining flow-based models with other methods to better capture data intricacies.",
      "categoryId": "c4c86b52-e5d5-49d1-bb14-e949f7b44d3a",
      "subcategoryIds": [
        "4db5a521-298c-4c77-abfa-ab69e9b793a0",
        "3e9b5006-8ca1-476a-bf98-49d5ce0e1036",
        "f8883398-bc74-49ca-bf59-da3967925fb4",
        "99e71975-1a1f-4949-a112-e5a5b1f6fa8c",
        "4e714b20-e3ab-4d25-aac3-5e9cbd22c188",
        "898cf850-24e4-4fe4-ad60-4ba429aa8e76",
        "6c9bce8b-f961-4fb7-aa5e-33616276c247",
        "5a567a44-ce61-4305-ba1b-d75e94f0456b",
        "8ed6132b-e32c-4e07-8952-cced08408770",
        "ef5e9210-9703-455d-b223-9915968d1c06"
      ]
    },
    {
      "id": "f1b9c58d-4ff8-471e-a499-430fbe456763",
      "name": "Flow-Based Models Enhancements",
      "definition": "Flow-Based Models Enhancements refer to the recent advancements and refinements made to flow-based generative models, which are a class of likelihood-based generative models that utilize invertible transformations to map complex data distributions to simple latent spaces. These enhancements aim to improve model performance, stability, scalability, and expressiveness, enabling more accurate data generation, better sampling quality, and more efficient training processes. By integrating new architectures, optimization techniques, and regularization methods, flow-based model enhancements seek to address challenges such as limited capacity, computational complexity, and the ability to model high-dimensional data effectively.",
      "categoryId": "e59325d7-7709-44b4-978e-c02403a92210",
      "subcategoryIds": [
        "ee7c19f0-3062-4361-b21c-7cc57093d741",
        "3594dfcf-8028-44c6-97d3-dd10cfd6ba1d",
        "912a4ba9-fa9f-4bc6-857f-2572626f0c13",
        "c0b94e41-47e5-4f85-bfc8-32c2e161a30b",
        "d0e1f4c2-2163-48e3-806a-0ed65c47774a",
        "9671d548-cd2e-4bdd-9cfc-47a81e98c426",
        "b1885fb7-f138-49c5-b398-295ea5ea1368",
        "e07be0ce-6264-488a-81d2-b5a810db484e",
        "922dcbbe-5b47-4703-a465-9bcc7bf86ce2",
        "18ee9e69-2d20-4c76-806a-daa35862256d"
      ]
    },
    {
      "id": "483e51ac-6dd7-430a-bada-b5ecbb289475",
      "name": "Flow-Based Models Techniques",
      "definition": "Flow-Based Models Techniques are a class of probabilistic generative models that utilize invertible transformations to map complex data distributions onto simpler latent spaces. By achieving invertibility, these models can efficiently compute exact likelihoods and generate high-quality samples, making them particularly effective for density estimation and data generation tasks. Examples include RealNVP, Glow, and NICE. These models leverage a sequence of invertible, differentiable functions, allowing both sampling and likelihood evaluation to be performed efficiently within the same framework.",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd",
      "subcategoryIds": [
        "bc6543ae-3d85-4c7f-b5f7-835e7db5376d",
        "38b25d6a-854b-4775-9d08-3f7dab22ac41",
        "cb611912-3704-467c-a786-31e788ec184f",
        "1564649f-e8ed-40f1-ab4f-fd27c95075a3",
        "74a7fab9-704c-40c5-8036-864ac883318f",
        "7c6c9491-e045-47e9-aeca-85f6979a52b7",
        "3baf6b9c-18e2-4df4-84fc-43c609ea3579",
        "af1647ba-b09a-4b5a-9cb3-c72a50ed6cdf",
        "4579a975-e42e-4241-ab11-9eedd0d57db5",
        "76b08f10-511f-4a15-83c2-d42b8efeeec2"
      ]
    },
    {
      "id": "cceea3a3-3af1-45cf-a923-732bd7005f80",
      "name": "Flow-Based Models Techniques Enhancements",
      "definition": "Flow-Based Models Techniques Enhancements refer to advanced methods and innovations designed to improve the capabilities, efficiency, and applicability of flow-based generative models in machine learning. Flow-based models are a class of probabilistic models that leverage invertible transformations to map complex data distributions to simple latent spaces, enabling both efficient sampling and exact likelihood computation. Enhancements in these techniques aim to address limitations such as computational complexity, model expressiveness, and scalability, thereby broadening the scope of flow-based models in various AI applications.",
      "categoryId": "843a89a2-8af1-4dda-9327-69c5c76d0cc2",
      "subcategoryIds": [
        "8b955677-9615-40b5-96df-e91dd412c4fe",
        "4389b554-8ebb-4516-9fce-decf0e56f15a",
        "9d713d4a-2e34-426e-9878-165971686b51",
        "764144fc-52bb-4b2c-912b-34758dcda2bd",
        "65251a2d-5a3e-4078-af69-07bb8c8b998c",
        "74829be2-b6df-4488-93f3-b19d17009a00",
        "b0feaf2e-81b7-4dec-8fee-f7066189c4cf",
        "5625ae99-f34e-4138-b0a1-fc7e2194e1bd",
        "fb639603-f116-4101-af73-cf80caae3eac",
        "817acac0-048c-4226-9be9-6761225ffb5e"
      ]
    },
    {
      "id": "b5b99f06-97ae-49b3-8f57-8611659d2737",
      "name": "Flow-Based Models Variants",
      "definition": "Flow-Based Models Variants refer to a class of generative models in machine learning that leverage invertible neural networks to transform simple probability distributions into complex data distributions through a sequence of invertible transformations. These models enable exact likelihood computation and high-quality data generation by modeling the data distribution through reversible mappings, making them an important subset within the broader landscape of generative modeling techniques.",
      "categoryId": "ecc8f434-102e-4398-aac2-975c763d83c1",
      "subcategoryIds": [
        "e27eaeba-8bf2-4da0-852e-aa8910f26daf",
        "79c94fbf-9d41-4ae5-9193-d4cbd23d9974",
        "dbd64ed2-ff17-4704-b4c0-b116e264548c",
        "e402bf0b-281c-4ff2-832d-c13089358cc5",
        "ce13c8dd-ca31-4d6f-ba43-1a02fbff998a",
        "f129b99b-c604-45e1-b17f-877e9c2bb0c8",
        "a5fe0948-f54e-4d05-b5e7-c7992ca31715",
        "a1ee8849-1154-419f-a4d9-ef8ae2069b78",
        "caa190e3-0445-456d-963f-924818fc5853",
        "8ce04018-b5fe-40d6-8201-b6f4f13aee21",
        "969535aa-c827-4f74-86f6-ceded487ca02",
        "9f5c5975-2e1a-4c59-ab97-9d46402d7a2c",
        "59c80a85-dfc1-424f-9222-b13ee244d506"
      ]
    },
    {
      "id": "5ce7ad4c-c1c6-436c-89c3-72bd7ecaec4b",
      "name": "Flow-Based Models Variants Techniques",
      "definition": "Flow-Based Models Variants Techniques refer to a class of generative models in machine learning that utilize invertible transformations to map data distributions to latent spaces and vice versa. These models leverage the concept of flow-based transformations, which are designed to be reversible and computationally efficient, enabling exact likelihood evaluation and efficient sampling. Variants and techniques within this category improve upon basic flow models by introducing more flexible architectures, better scalability, improved generative capabilities, and enhanced training methods.",
      "categoryId": "d4518c8e-94a3-4dd5-afca-2b05dd659da5",
      "subcategoryIds": [
        "07eb82bf-3d98-456a-819f-514b8515976f",
        "78d22f3b-1eb0-4eed-beed-a4c269fbec7b",
        "0969e931-cb28-4949-bfd9-8e2a9ec80696",
        "c698eb1a-4239-44f0-a5aa-f13cd5538488",
        "24f452b9-547e-4408-bce0-f62deeb1afdd",
        "04c2dbc5-8907-485a-b61e-3b7dfbadbac1",
        "0203c61a-98a8-479e-a10a-5aba20f50dd8",
        "db63e1d4-8ee5-4b7e-9d7e-9b665b382f37",
        "77e75472-4aed-499e-a9c2-54b94e37226c",
        "6fb725f4-b0da-4ad3-9d6a-e09c9c2629e7",
        "21435c36-9361-43d9-97c6-6291a52d8925",
        "495b3a5c-3c28-4f98-bd5f-bae73ee84226",
        "b7b483ad-2995-441b-9647-89567b412bb0"
      ]
    },
    {
      "id": "f2e57b44-9039-48f3-a1fe-aaaad1f5673f",
      "name": "Flow-based Neural Networks",
      "definition": "Flow-based Neural Networks (FBNNs) are a class of neural network architectures that leverage continuous, invertible transformations\u2014often called 'flows'\u2014to model complex probability distributions and enable efficient sampling, density estimation, and data transformation. These models are grounded in the idea of transforming simple, prior distributions (like Gaussian) into complex data distributions through a series of learned, invertible functions, allowing exact likelihood computation and flexible modeling of data structures.",
      "categoryId": "957f2139-1efb-4a66-a185-38ede62f8f54",
      "subcategoryIds": [
        "1f1e7e39-5b70-4de2-9377-9022c126befe",
        "d9494ac7-7f84-4d6e-a530-7b5c72245945",
        "2c9b28f3-9f97-45ab-9276-fa0046fd510d",
        "6d0f4a83-d466-4389-9054-c1ef51701753",
        "6651fd86-2a77-441c-a1ca-0cc005a93398"
      ]
    },
    {
      "id": "92627cf3-afde-454a-812b-e7e0a618d494",
      "name": "Fluency Metrics",
      "definition": "Fluency Metrics refer to quantitative measures used to evaluate how smoothly, efficiently, and confidently a language model or AI system generates text. These metrics serve as indicators of the naturalness and coherence of AI-generated language outputs, assessing aspects such as grammatical correctness, lexical diversity, and the ease of understanding by human users. In the context of AI/ML, fluency metrics are essential tools for evaluating the quality of language generation models and ensuring that their outputs are human-like and contextually appropriate.",
      "categoryId": "973d890b-a84d-4a5a-b44c-a716c6dead14",
      "subcategoryIds": [
        "dae4b247-7008-419c-8569-b45ebd81a218",
        "e7e9a4d6-1119-4e33-a2f6-6e87091e5726",
        "fc9ab8f0-12bb-46b2-bfd0-5e1a072661e2",
        "c7738f0f-f05f-44bb-8004-5478b49afac8",
        "1e0ca352-2cca-4860-ab8f-76d0cf220ba2",
        "92e01007-ca38-4adb-b69d-c4820329e8aa",
        "1ff1b94f-ec7c-4a1d-a3fa-77d8ce646ecc",
        "7e54866a-fd41-41c5-8f80-b523c1beb2b0"
      ]
    },
    {
      "id": "1a2481f6-b8a6-4339-88ac-0b4435b91089",
      "name": "Focal Loss",
      "definition": "Focal Loss is a specialized loss function designed to address class imbalance in machine learning tasks, particularly in object detection scenarios. It modifies the traditional cross-entropy loss by down-weighting well-classified examples, thereby focusing the training process on hard, misclassified examples. This encourages the model to learn more effectively from challenging samples, improving overall detection performance.",
      "categoryId": "42e40f84-c9b0-4f25-b5d4-0c34790af60f",
      "subcategoryIds": [
        "c83af698-a8aa-4a46-891e-8db7ca9be8e0",
        "c0c78187-c6e7-4a0c-91ea-ba4142c7e48c",
        "412e740a-42a9-4158-a0ff-c139d62ac5a2",
        "d7f71540-98bf-4d9b-8613-80d79e555f07",
        "a8bc50dd-22d3-4afd-aa91-bb3e287f4ac7",
        "92b52cc9-bd0c-4be4-88ce-cf769a767c77",
        "293dab50-c8ce-4091-9ee5-906c408919d4",
        "f5c28473-3e99-4c57-93a8-38d63c8119db",
        "b3e6e8e9-edb6-456c-b02f-d2345491ff9d",
        "e7697985-5947-47d0-9a11-5194620f6fe5"
      ]
    },
    {
      "id": "920d9c1d-4d03-4e9c-a5b6-9d50c10d2b13",
      "name": "Focal Loss (already in your list as \"Focal loss\")",
      "definition": "Focal Loss is a specialized loss function designed to address the issue of class imbalance in classification tasks, particularly in object detection scenarios. It modifies the standard cross-entropy loss by emphasizing hard-to-classify examples and down-weighting the contribution of well-classified instances, thereby improving model performance on imbalanced datasets.",
      "categoryId": "df739862-bae0-4210-9f66-9b055113586a",
      "subcategoryIds": [
        "0684941b-01e0-41b6-8b86-5bf8953317a3",
        "394ba8cf-2acd-4da0-8852-5b1a938a9f15",
        "d58276f9-ebc0-4b5f-b6d9-10aff392bae7",
        "ad91daa1-18a9-42ad-b797-b50b3f394a52",
        "09e812f0-67ae-468a-bdc8-723c51bfbd81",
        "ea6ce5c5-3956-4004-b598-63bf1ac0ae0d",
        "9b7f2d57-3a09-4e42-8805-aeb5440a4f70",
        "e5d972e6-feee-4562-9c1d-58fea9440819",
        "d9ac3110-9416-4934-be9b-9d426f5933d3",
        "f2390170-2aa3-4747-9c6f-57f69b6a6e94",
        "c798338f-dc42-4eb9-9143-7234e511ec89",
        "390cc0c9-5446-4cc6-bdbe-4cbcf38eb787"
      ]
    },
    {
      "id": "f497387d-c280-4548-a005-af152739ebea",
      "name": "Focal Loss Extensions",
      "definition": "Focal Loss Extensions refer to modifications and enhancements of the original Focal Loss function, designed to address class imbalance and improve model performance in complex classification tasks. These extensions adapt the core principles of Focal Loss to various scenarios, tailoring their focus on difficult or misclassified examples while reducing the influence of well-classified instances, thus aiding models in learning more effective representations in imbalanced datasets.",
      "categoryId": "4fa9a208-7d11-437c-befa-fffe78f99a86",
      "subcategoryIds": [
        "00c758d7-5335-4e61-8f1a-402454b28c30",
        "edaedcd1-4aa9-4202-8d71-669dc8381ca5",
        "c0f30d68-c8d4-4554-a6d4-6542b0d98dbe",
        "8df02740-5c51-4f77-8e60-a490257e0073",
        "2773c7d9-cafb-4182-bb59-c59065806e7e"
      ]
    },
    {
      "id": "be4d60b6-f559-44c0-a434-d084ff4d400a",
      "name": "Focal Loss Extensions Enhancements",
      "definition": "Focal Loss Extensions Enhancements refer to modifications and improvements made to the original Focal Loss function, aiming to address specific challenges or improve performance in machine learning models, particularly within the context of imbalanced datasets. These extensions often involve tuning parameters, incorporating additional mechanisms, or combining Focal Loss with other loss functions to better handle difficult examples, improve convergence, or enhance model robustness.",
      "categoryId": "39cfd723-0190-4e71-8217-138dace0895f",
      "subcategoryIds": [
        "cae28a31-bf4f-4d2e-89ce-9ccf649f749a",
        "a9bc3e5c-4c4c-4606-82e5-4632445c9ee4",
        "9fb01d15-9a72-4ad6-84da-c0b5d1db3800",
        "8081668b-5534-45bf-b727-71c671df76da",
        "08bb7023-3b98-473e-b2ec-f5dc8cd212db",
        "42578ef3-d57f-4e57-880b-4e9ac8c90f50",
        "c44242dd-ea0b-4105-9e53-64260c1a6b90",
        "88ff4de2-fd7a-4d6d-a32e-b8885927a085",
        "abc76939-d527-4366-ac69-8cb3d4b7a41e"
      ]
    },
    {
      "id": "5bc72e60-0c6b-45a3-901b-c84a910c0f74",
      "name": "Focal Loss Extensions Techniques",
      "definition": "Focal Loss Extensions Techniques refer to a set of methods and modifications developed to enhance the original focal loss function, primarily aimed at improving the training of deep learning models for tasks such as object detection, class imbalance handling, and hard example mining. These techniques modify or extend the basic focal loss to better address challenges like false positives, class imbalance, and difficult examples, thereby improving model performance and robustness in complex scenarios.",
      "categoryId": "78dc0827-64c0-4774-aec4-dc8f9e055ff7",
      "subcategoryIds": [
        "5151712d-d0b1-4f0d-8d5d-c969a569871f",
        "d495ce10-0eda-440f-b7ca-fab4c2958a98",
        "a9768bff-0341-45b2-9f5d-effd378cbe47",
        "6ccdad98-fe5c-4e4f-b5a8-f2ce3cb4c26d",
        "dbd3e618-a43f-4b8b-a235-633615d80c2e",
        "7d97eacc-ded0-4ce2-ac42-c16b9ec975ae",
        "c2c8bdce-e97e-4293-8233-0cb43f12a0bf",
        "c78ce56f-b5a1-4d2d-94c2-a1d10b20b44f"
      ]
    },
    {
      "id": "64fec3a2-e594-48fe-b43f-41e3d54134ba",
      "name": "Focal Loss Extensions Techniques Enhancements",
      "definition": "Focal Loss Extensions Techniques Enhancements refer to various modifications and improvements applied to the original Focal Loss function to overcome its limitations and extend its applicability. Focal Loss was initially designed to address class imbalance in object detection tasks by down-weighting easy negatives and focusing the training on hard, misclassified examples. Extensions and enhancements involve incorporating additional parameters, adaptive weighting schemes, or integrating with other loss functions to improve model performance, robustness, and convergence in diverse scenarios.",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd",
      "subcategoryIds": [
        "08a5f498-c4d3-4af3-a8a1-26e9a2d87d8b",
        "2d916cf1-709f-41cb-a494-d0d77247835a",
        "1d370d9e-acd1-44b1-9ffd-d722506949ed",
        "50675867-c864-4095-adea-ca3922399d1a",
        "d5d3bdef-dc1b-440c-9856-80e660936666",
        "b453e9e2-760a-4310-9bd1-dcc085dad16c",
        "9b01d2c2-ddb2-49b1-b665-f72a54412d02",
        "8e200c99-4f53-4a95-b401-8ac67f4d93f8",
        "45c200f3-a790-4915-b77c-8edf688c1c52",
        "68dc94ce-b541-4911-978b-b1adc0501b7a"
      ]
    },
    {
      "id": "ddb343b9-9ad0-4254-80de-fb521d825870",
      "name": "Focal Loss for Object Detection",
      "definition": "Focal Loss is a specialized loss function designed for addressing class imbalance in object detection tasks, particularly in scenarios where there are vastly more background or easy negative examples than foreground or hard positive examples. It modifies the standard cross-entropy loss by down-weighting well-classified examples, thereby focusing more on difficult, misclassified instances. This approach enhances the training of models like RetinaNet, leading to improved detection accuracy, especially for small or hard-to-detect objects.",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd",
      "subcategoryIds": [
        "7f0d8673-04a2-4ffb-a0ff-35f778a5ba12",
        "71f2aeee-1939-4dd1-8a3c-48dae5305c89",
        "4446a74b-8197-4c40-a261-de889d713d6b",
        "3b4f328d-7af4-4300-8787-93860575ae8f",
        "bdc60920-8b86-4702-b15d-4b59087d7f8d",
        "a447d138-4f06-416f-9e19-c6ce5a432867",
        "c2f2fbbf-e117-4cf2-8c4e-9a06663a565e",
        "1ad7b1fb-67e2-4d7c-b788-0bbd218726db",
        "efce71a1-7084-4891-ba45-a561da7b03e9",
        "79469b15-18e1-4ed0-88f2-0ed61783d9ef",
        "da4ead74-3f0b-4429-812b-438471d1d425"
      ]
    },
    {
      "id": "5849010e-b2ec-48dd-867d-6618005a59ae",
      "name": "Focal Loss Variants",
      "definition": "Focal Loss Variants are a family of loss functions designed to address class imbalance and hard example mining in classification tasks, particularly in object detection and imbalanced datasets. These variants modify the original Focal Loss to improve model focus on challenging, misclassified, or less frequent examples by dynamically scaling the loss assigned to each example based on its predicted probability, thereby enhancing the model's ability to learn from difficult cases while reducing the influence of well-classified examples.",
      "categoryId": "fcab9090-3a37-4c25-9007-ee92aade01ca",
      "subcategoryIds": [
        "050ac1e4-5978-486f-813b-1904949d537b",
        "cf18afab-b72d-4c60-882f-ffdfcc078ff1",
        "4d84f93d-673c-4980-b955-a1c80ee2953f",
        "fd86ce3d-ddbd-40a0-bafb-b225e45dd61f",
        "f8e326af-a9fe-4275-a22e-7b7ebebe86ce",
        "f1130865-f628-4d92-be10-5831cb831e1e",
        "6624906f-a732-4848-bb1a-ddd63be3bbdb",
        "849deb73-4ece-45f0-a802-6247f7300e69",
        "89aec7a7-a49b-4fef-be34-7b9c2bd0d0e0",
        "0b19ba03-2613-433c-80de-c7fc12d0003c"
      ]
    },
    {
      "id": "b64f2ffa-6685-44ca-b57d-eccf0b5b18b8",
      "name": "Focal Loss Variants and Extensions",
      "definition": "Focal Loss Variants and Extensions refer to a family of modifications and enhancements to the original focal loss function, which was introduced to improve object detection models' ability to handle class imbalance and hard-to-classify examples. These variants aim to adapt the core principles of focal loss to different applications, incorporate additional parameters, or address specific challenges in training deep neural networks by modifying the loss function to focus more on difficult samples and suppress easy ones.",
      "categoryId": "c3957990-579c-4aea-a9bf-fb099c300202",
      "subcategoryIds": [
        "46591f87-b0a6-447e-944e-afd374d3c02c",
        "5fe3a877-4e45-423b-a969-6d7c055b3755",
        "08e8d3fd-98e2-4b16-872f-631f4be5e260",
        "15d7d275-b1c2-4095-8b5a-835e3d2c0751",
        "5be13538-ccc2-440d-a4c0-09289f147cd9",
        "c28949c6-94d2-4d09-9002-cefb07fc2f5e",
        "28c0745f-1df8-4402-9daf-c3b7e9c62da7",
        "772851c0-92ee-40f9-89a4-692b4f45f1b9",
        "5f69963c-0c17-4ece-a5a5-c912f54c12c8"
      ]
    },
    {
      "id": "d7cf0fe9-ab7c-4516-a927-2ee6168e06cf",
      "name": "Focal Loss Variants and Extensions Extensions",
      "definition": "Focal Loss Variants and Extensions refer to a class of modifications and improvements to the original Focal Loss function, designed to enhance the training of deep neural networks, particularly in addressing class imbalance and difficult-to-classify examples. These variants adapt the core idea of assigning different weights to hard and easy examples, enabling models to focus more on challenging cases, thus improving performance in tasks such as object detection, segmentation, and classification where class imbalance is prevalent.",
      "categoryId": "939cf1aa-be0d-494f-942e-5ce8fd4c0cac",
      "subcategoryIds": [
        "40914cde-af1a-406d-adc3-bc02e2da7857",
        "26cd2879-dfb5-4650-aa3d-eb1fca71f332",
        "d3f63400-39f5-408f-9c62-759cc0809ed8",
        "ff000fca-9b8a-4ab5-9e58-d35a3c247c4e",
        "874e7ec1-93c8-4abd-9950-5885a49496dd",
        "247b9c7d-ed78-441a-8e56-c3887fa08d9c",
        "b00b98c8-35c4-40d0-83bc-e6cf39830641",
        "a6e03008-9cf6-482e-b79e-32c47ffe936e",
        "3588561e-5610-4aad-99be-bf445c716f95",
        "5ead222c-a5ce-43f3-a16a-fe597b2b318a"
      ]
    },
    {
      "id": "42d0cb0d-052c-4a45-baa5-0f48c7179259",
      "name": "Focal Loss Variants and Extensions Techniques",
      "definition": "Focal Loss Variants and Extensions Techniques refer to a collection of loss functions and methodological adaptations designed to address specific challenges in training machine learning models, particularly in object detection and class imbalance scenarios. These techniques build upon the original Focal Loss, introducing modifications such as class-specific adjustments, multi-scale extensions, and adaptive weighting schemes to improve model performance in complex tasks involving difficult or minority class samples.",
      "categoryId": "cd89f926-dc73-4f45-8d67-50e79ce24bfb",
      "subcategoryIds": [
        "2ff8f475-1e34-4f61-9a55-49c58dce43b7",
        "9cc0e005-6827-4922-a879-41a21ddc0ab3",
        "511b8533-bc0b-450f-8bd3-167fd830d7c4",
        "7da9e308-f27b-41d8-81cb-2edafff636c2",
        "a264c767-6cfe-4b4c-9774-d176463db725",
        "4017a3f6-87aa-471d-9580-f347fb398731",
        "94b02683-068c-47a0-99f2-8e03fbd5c9bc",
        "c541dec6-884f-4c1b-969f-ebf86737aed5",
        "4067ec5f-064a-468e-aad7-70538d44ba96",
        "9fda80c1-b1a8-4587-81fc-14ca26e3e596"
      ]
    },
    {
      "id": "cd653d53-9177-4b54-b286-d51c1f57d2ee",
      "name": "Forced decoding",
      "definition": "Forced decoding is a technique used in sequence-to-sequence models, particularly in natural language processing tasks such as machine translation and speech recognition. It involves using the true, ground-truth output sequence (or a partially correct sequence) as part of the decoding process during training, rather than relying solely on the model's own predictions. This approach helps stabilize training by guiding the model towards correct output sequences and reducing the impact of accumulated errors that can occur during autonomous decoding.",
      "categoryId": "419675d7-ae0a-4c0f-96ba-054f283f98b4",
      "subcategoryIds": [
        "74154382-f12b-47ab-bfe7-6415d692e6a4",
        "52f956cc-98da-409d-ae5a-a12eeda21856",
        "56cbfb3b-2cf3-4b6a-8fb2-bdea957beea0",
        "d2706d47-e832-47c5-9b2d-e3ef458485f0",
        "3234e3af-d285-4f54-8765-abe74fbe114e"
      ]
    },
    {
      "id": "39dcafb8-6fd6-4f17-87e9-eece8dda8f98",
      "name": "Forecasting",
      "definition": "Forecasting in AI and machine learning refers to the process of predicting future data points, trends, or outcomes based on historical data. It involves analyzing temporal data to estimate future values, aiding in decision-making across various domains such as finance, weather prediction, supply chain management, and more. By leveraging statistical models, machine learning algorithms, and deep learning techniques, forecasting aims to provide accurate and reliable predictions that inform strategic planning and operational efficiency.",
      "categoryId": "bbb72a6f-b434-4e52-a24b-f27f88bbd3b3",
      "subcategoryIds": [
        "56b91047-0024-4ad6-bd91-5d7dd1ea5047",
        "486a82a8-e7ba-4d41-9e86-1988cacc2880",
        "fe565c30-d905-4b0a-83d8-84d50664e93a",
        "fae948c0-a63b-4b24-94b5-cfe74abeefe3",
        "b43b2dba-eb26-41ab-814a-a0717f82dbc8"
      ]
    },
    {
      "id": "eae49c7f-ee18-4950-a2b1-cc365f8eed7c",
      "name": "Forest Fire Model",
      "definition": "The Forest Fire Model is a type of cellular automaton used to simulate the spread of forest fires within a forested landscape. It employs a grid-based system where each cell represents a tree or an empty space, and the fire propagates based on state transitions governed by simple rules. This model serves as a simplified abstraction to study complex phenomena such as wildfire dynamics, propagation patterns, and the conditions that influence fire spread.",
      "categoryId": "5baa0f49-4426-4a94-b834-3a383880e600",
      "subcategoryIds": [
        "75b57e86-8fce-4203-a589-5a7dc71b4848",
        "39696f9d-a7a6-4b46-8040-7e07a8bdab1c",
        "07940cf2-1e64-4df0-a600-b6ffbacd04ee",
        "2dd7ae5c-bd7f-48c1-9285-8df072192035",
        "a2e46d98-ecd0-4087-841e-cb5d98a91d02",
        "4711bf82-a873-4777-a7e7-bea8e56f304d",
        "fa7986b9-5417-4267-beaa-f402b1a9d73b",
        "36bbbf59-b1e6-4dea-9b32-884a851d4b9e",
        "122ffd8e-9267-4ec5-ab59-f5de962b49a3",
        "2b80c746-9349-4c8d-ba55-834e27aa779d"
      ]
    },
    {
      "id": "ffde41eb-5e69-4df2-8bcc-6d0c4c0b1329",
      "name": "Formal Concept Analysis",
      "definition": "Formal Concept Analysis (FCA) is a mathematical framework and method for data analysis that facilitates the discovery of inherent relationships and groupings within data sets. It is based on lattice theory and provides a systematic way to derive conceptual hierarchies from data, typically represented through formal contexts. FCA enables the identification of formal concepts, which are pairs consisting of a set of objects and a set of attributes that precisely describe a particular grouping, thus revealing the conceptual structure of data in an interpretable form.",
      "categoryId": "16aaf306-d2c1-4e9d-a38c-7491db5206f2",
      "subcategoryIds": [
        "b642beb3-0e50-4755-8c5a-fb6e0fbbcc64",
        "18cae8ff-c395-4909-b809-d16aadfedac1",
        "8b335e7f-e657-424f-a9a7-b5ff9ec20dd7",
        "34cb7d87-25d4-4426-8365-afc46e7fcd60",
        "fabae72d-8473-4b96-bf90-5a742dc05ab7",
        "963e1cf7-2020-4cba-b4df-f634961b2d2c",
        "c045278f-53fa-4ecd-895b-83e877437486",
        "faa8a433-5522-4639-8ff3-06ca7ea859a9",
        "331af683-ecc4-43f1-803e-c393534a65c5",
        "afa95a94-b8e3-42d9-9549-f084a801a8c6",
        "641e65b1-3c81-492f-a53e-8558ff186e80"
      ]
    },
    {
      "id": "5b94ad91-46d2-4209-b837-22763eda9798",
      "name": "Forward and Inverse Reinforcement Learning",
      "definition": "Forward and Inverse Reinforcement Learning are two advanced paradigms within the field of reinforcement learning that focus on understanding and inferring decision-making policies. Forward Reinforcement Learning involves an agent learning a policy to maximize cumulative reward through interactions with an environment. Inverse Reinforcement Learning, on the other hand, aims to deduce the underlying reward function or objectives that an expert agent appears to optimize, based on observing its behavior. These techniques are essential for applications where explicit reward functions are difficult to specify, but expert demonstrations are available, facilitating the development of intelligent systems that learn from human or expert behaviors.",
      "categoryId": "67b9e9a4-e629-4c13-99d4-8f8276a45b8c",
      "subcategoryIds": [
        "9e93c556-feb3-4388-8a7f-0939d92c3bfd",
        "802af3d2-eb0f-4682-8e0a-755b74bccb6c",
        "2d136b3f-d079-413c-b717-731f16f522c8",
        "171ad0f7-a010-4aae-bc52-114f87543696",
        "bacf3252-81b5-4ba1-a690-388bc75df644",
        "0a138d9c-8215-4c34-ad38-5d50c9545b63",
        "157d1b4c-098d-429b-9956-b1bd7122ebc7",
        "0f29b288-ffd5-4755-94df-23f0b06eb2fe",
        "56d4a737-d585-4ec1-9570-c2bda163400f",
        "a4f59ebf-a75a-4ae2-9ed3-00efe6bb887d",
        "52552f26-6351-4e6d-82b2-7423ec9551ac"
      ]
    },
    {
      "id": "4f8edb11-e160-48d4-aaf5-db3404005ec1",
      "name": "Forward Chaining",
      "definition": "Forward chaining is a method used in rule-based systems and expert systems within artificial intelligence to derive conclusions or make decisions. It operates by starting with known facts or data and applying inference rules sequentially to infer new facts, progressing forward toward a goal. The process continues until the goal is achieved or no further inference is possible, effectively working in a data-driven manner to build up conclusions from existing information.",
      "categoryId": "ec67470b-edfe-42a3-89b8-85670f52d1cf",
      "subcategoryIds": [
        "0dc15975-9663-498a-8c14-eed6b5481fa1",
        "8c2c6d72-f304-4808-bfd2-01fc6b267d80",
        "75a6a5de-6256-435d-8c3d-17996eafa79c",
        "23e934f1-43d2-4374-ae22-12b1b91b2086",
        "64f2cab6-ca00-4fb0-93c3-a5bb07709593",
        "6dbb6e0e-f212-4062-8113-3645882cd7c8",
        "d2add922-c9e3-4df0-87e9-5385429c0870",
        "778c33ee-c319-4cd5-8535-86f2b8a897ae",
        "97acb04b-710b-4c91-8730-18f356543d91",
        "65452514-bed4-4f05-aaa7-0dd3faaded44"
      ]
    },
    {
      "id": "4be08e70-b2f6-46a3-8031-fc076c0843c3",
      "name": "Forward Diffusion Process",
      "definition": "The Forward Diffusion Process is a fundamental concept in generative modeling, particularly within diffusion-based generative models. It describes the process of gradually adding random noise to a data sample over a series of steps, transforming it into pure noise. This process is inverted during generation, where noise is systematically denoised to produce new data samples that resemble the original data distribution. Essentially, forward diffusion models how data degrades with added noise, serving as a preparatory step for the reverse process that generates new data.",
      "categoryId": "82b1c223-ea8a-4d43-af4f-39ad20e7708b",
      "subcategoryIds": [
        "30c3fda6-e3e8-45b7-927f-edf58eb7620f",
        "dd6d13c7-496e-4a65-a99d-cdea6c66c954",
        "2a20d572-1661-423b-9fc5-67343646a9aa",
        "202799fc-33ab-4f06-8efe-f2eb6639586a",
        "9db3513a-54e1-424f-8767-c196e2490b12",
        "dc43530e-295b-433b-a3bb-91a0606c19a0",
        "9c9ce4ab-7ba5-4cdb-b62b-df65390d08fc",
        "e0919597-2efd-446d-b977-7fce76ddc7ef"
      ]
    },
    {
      "id": "415aee7a-a0f2-4304-a2d4-aacd3f6a8d93",
      "name": "Forward Pass",
      "definition": "The 'Forward Pass' in AI/ML refers to the process of propagating input data through a neural network to generate an output or prediction. It involves computing the output of each neuron or layer by applying mathematical operations such as weighted sums followed by activation functions, moving sequentially from the input layer to the output layer. This process is fundamental in prediction tasks, enabling the model to transform raw data into meaningful results.",
      "categoryId": "f32b4ce5-e751-440e-800e-0e6245cb1033",
      "subcategoryIds": [
        "34cb6e84-965f-421e-a73b-8692aa8aa04e",
        "669ae29c-4242-4fda-83bd-bd4fa9336152",
        "97e58290-74fb-4f9a-b508-1167aca4abc7",
        "dd2cde1f-94a3-46ea-89f6-eb62de4d27e3",
        "32392216-e87d-4fbc-b9ca-c55396b7fd77",
        "7d830319-54a0-43bb-b379-8f595bcec235",
        "c2e271d6-a98b-4910-81da-1cbd17b8c38d",
        "79237587-ee39-41d8-b1aa-124c9896547d"
      ]
    },
    {
      "id": "8d608cef-a250-4af3-9a74-e740090c9fdf",
      "name": "Foundation Model",
      "definition": "A Foundation Model is a large-scale, pre-trained machine learning model that has been trained on broad, diverse datasets and can be adapted to a wide range of downstream tasks with minimal additional training. These models serve as versatile bases for many applications, enabling developers to leverage extensive pre-existing knowledge encoded within them, thereby reducing the need to train models from scratch for specific tasks.",
      "categoryId": "37f413f4-2e00-48ec-99e6-8eac4f70df87",
      "subcategoryIds": [
        "19b2dafc-2ebd-49c9-87ac-7b447880a3a8",
        "0d794903-56d3-4685-bf0d-19da895ba0c9",
        "86f0e8f9-5c11-49e9-9c78-eac2e63d9829",
        "ab25166a-65c2-4f14-ba7a-e98832f6ae2f",
        "fc2ddb38-b02c-4819-bc8a-750279ba05d0",
        "6ff78a3a-eff7-41dc-8ec6-3a9f1bd4d1c7",
        "7b182862-c531-47b9-a9f1-922c91a8b6d2",
        "734896e7-04a0-4c79-acd4-18650c5f8349",
        "31b3c4df-7510-41f6-9fb6-08e627025826",
        "ad57baf7-fd49-49d9-ab7a-688d6d8ec737"
      ]
    },
    {
      "id": "f74baa51-f6b3-4e7f-a367-2ba57b82fef7",
      "name": "foundation model-based segmentation",
      "definition": "Foundation model-based segmentation refers to the application of large-scale, pre-trained foundational models\u2014such as those based on transformer architectures\u2014to the task of segmenting images, videos, or other data modalities. These models serve as versatile backbone frameworks that can be fine-tuned or adapted to produce precise and context-aware segmentation masks, effectively enabling the automated delineation of objects, regions, or features within complex data. This approach leverages the extensive knowledge encoded in the foundation models to improve segmentation accuracy, robustness, and generalization across diverse datasets and tasks.",
      "categoryId": "8f374a2a-5e60-472f-bb50-83656c4b798f",
      "subcategoryIds": [
        "9a3f38d3-9c1c-47db-ace2-c224cbda377e",
        "819c7bd9-23c8-48d9-99a2-789419a9b249",
        "b02ea9cc-7d59-4302-993c-3c142a2519fc",
        "e511168a-e9d4-42c1-99e9-9f3be627f203",
        "af7a843a-553e-4ce3-bfc8-96e28f3210b2",
        "f047e472-0562-49b9-8cdc-1e450d9b22bc",
        "761fa5b8-ecfd-4183-8824-fc9059af9139",
        "7c1bb0ab-4f81-457e-8401-a1ef52169e3a"
      ]
    },
    {
      "id": "edebfbd3-43f1-482a-b8c5-a950632b9579",
      "name": "Foundation Models",
      "definition": "Foundation Models are large-scale machine learning models trained on broad, diverse datasets that serve as a base for a wide range of downstream tasks. These models are designed to learn general representations of data, enabling them to be fine-tuned or adapted to specific applications with minimal additional training. Examples include models like GPT, BERT, and CLIP, which can perform various natural language processing, computer vision, and multimodal tasks effectively across multiple domains.",
      "categoryId": "6e3eea6d-6338-44f4-8991-3e73a0747f57",
      "subcategoryIds": [
        "535b73c2-79b9-4844-acbf-694efecbf6cd",
        "3000f57a-6731-4f3a-90ec-d54dadc258ed",
        "43f0ce96-03c4-430f-ab43-7dbd1593d776",
        "b37180cf-0dac-4cfa-adc5-07cae90089f6",
        "f1187de2-fb9d-4a51-9ca8-aaf47ec23fee",
        "b698638e-f7b9-4f11-bea2-cfad65640f62",
        "61214d8d-2be2-4fb6-87ed-1424d6f2cbb0",
        "f819d97f-2728-4407-b4b5-013afbdab638",
        "59202fd7-41ee-4698-9261-a49308c28a81",
        "150dd296-8814-440f-8ad6-851da266af11",
        "eae322d8-d378-434c-9b56-70c0dce631ad"
      ]
    },
    {
      "id": "a327eeb6-e575-4b91-9d88-3639f000d3cd",
      "name": "Foundational AI Model",
      "definition": "A Foundational AI Model refers to a large-scale, pre-trained artificial intelligence model that is designed to serve as a general-purpose platform for various downstream tasks across multiple domains. These models are typically trained on massive datasets and encapsulate broad knowledge, enabling them to be fine-tuned or adapted for specific applications such as language understanding, image recognition, or other AI tasks. They act as the base upon which specialized AI systems can be built, reducing the need for training from scratch and accelerating development processes in AI/ML.",
      "categoryId": "e0597348-9c6f-44f3-8e63-0a3d655bcaea",
      "subcategoryIds": [
        "52d1323f-6aef-42d8-99e8-10480bd656f4",
        "19f77755-8509-4d46-bbb2-c9b86aa11e61",
        "0ef42f7e-29f3-4238-b98d-a73b3831a509",
        "3cd8d5ea-5646-4593-9897-11036775b09f",
        "4c7c1a3d-e552-45d9-9dfc-9af42238a0c5",
        "925f2ff0-9a64-442c-bf9d-b509b4e8a848"
      ]
    },
    {
      "id": "51e3e7be-2041-4aba-a2b2-6b0de199f1c7",
      "name": "Fourier Features",
      "definition": "Fourier Features refer to a technique in machine learning and signal processing where data is transformed into a feature space using Fourier basis functions. This approach involves projecting input data onto a set of sinusoidal functions (sines and cosines) with varying frequencies, enabling the model to effectively capture and represent complex patterns and periodicities within the data. Fourier Features are commonly employed to enhance the expressiveness of models, particularly in tasks requiring the modeling of high-frequency components and long-range dependencies.",
      "categoryId": "193aa14f-9991-4cf7-9ce5-b852f98b7cbb",
      "subcategoryIds": [
        "a57b9d45-f17f-4825-8488-b24ee46da68c",
        "1e5b737f-1179-489d-b65f-a85467790774",
        "33aff227-e107-4670-9768-ff7e7a836027",
        "d2cf19e3-25d0-4115-9210-bcfc2d0e60e1",
        "9e12627b-5e0f-43ca-b2b7-2c681fd043ad",
        "67da95d8-8c10-43ae-b640-03b993a2300f",
        "181bab85-52e9-4fa5-bacc-9dcf2aebd8c0",
        "b0d4718e-b2b4-4018-8615-371f2508c0bb"
      ]
    },
    {
      "id": "e3abaaae-116b-4831-8219-41124cde4615",
      "name": "Fourier Features in Neural Networks",
      "definition": "Fourier features in neural networks refer to a technique where input data is mapped into a high-dimensional space using sinusoidal functions based on Fourier transformations. This approach leverages the properties of Fourier transforms to enable neural networks to better capture and represent high-frequency variations and intricate patterns within the data, thereby enhancing the model's expressive capacity and generalization, especially in tasks involving signals, images, and other complex data distributions.",
      "categoryId": "b7c35577-03d9-4f63-bb37-54771c921f5b",
      "subcategoryIds": [
        "1c86374e-cb89-4ae5-a356-cff6ca8f6a19",
        "b12c94ac-a226-42a6-b25c-8eaed8e4d889",
        "a948409d-2da5-4e97-9a3e-39b5cc8eafd1",
        "481a2440-b685-49b8-ad1f-53981c23b5b9",
        "9cd20cb0-a94f-4b65-82e9-6f586d10713d",
        "02d9b98f-c2ac-4f83-ba32-ed6c95ec252c",
        "192cbe09-1692-4490-bf34-7bed0bc212be",
        "b1da605e-0099-419f-b5b5-73814c94ad0c",
        "093d408d-f00e-48d5-b2df-d79b34042a90",
        "21856d8a-b1d3-40e0-b6fa-307646746b20"
      ]
    },
    {
      "id": "b20b8150-0cb9-4f9e-b12d-e22ff3e25267",
      "name": "Fourier Neural Operator",
      "definition": "The Fourier Neural Operator (FNO) is a type of neural network architecture designed for efficiently learning mappings between functions, particularly those governed by partial differential equations (PDEs). It leverages Fourier transforms to capture global information and facilitate faster, more accurate approximations of complex functional relationships across different domains. FNOs are especially useful in scientific computing, physics-informed modeling, and numerical simulations where traditional neural networks may struggle with high-dimensional data or require extensive computational resources.",
      "categoryId": "a23a0fb2-b968-42dd-9eb7-950e8cb66d93",
      "subcategoryIds": [
        "5e787697-be28-4691-966d-a0daac18af54",
        "e66ab9a0-d583-4551-a2e2-180407f6f7b1",
        "b7bc2e7e-772d-4299-981a-2b635150759f",
        "28fde690-ab44-4791-be25-ef9090923482",
        "7aed1131-b11d-404f-a258-52706d80f019",
        "2df98b65-552e-4fc6-a474-f8fba62be927",
        "06084247-a5f4-45c1-bbc4-947bb20285c0",
        "b451881f-a0e3-455a-a891-e79e20ecb838",
        "d6ace6f4-f545-4a0b-8f94-923e86459ea3",
        "3c2e8fd0-c8e0-47c8-9cee-fc5ba3f1b0db",
        "c90d77b9-cae5-4861-b9b8-6abe5f30e3f3",
        "6a1e9e3a-cd69-429b-9d00-aafe9f49c262"
      ]
    },
    {
      "id": "e2ccadae-bf39-4790-85d5-6d66579ee18e",
      "name": "Fourier Neural Operators",
      "definition": "Fourier Neural Operators (FNOs) are a class of deep learning models designed to learn mappings between infinite-dimensional function spaces. They extend the concept of neural operators by incorporating Fourier transforms to efficiently capture integral and differential operators. This approach enables FNOs to model complex physical systems described by partial differential equations (PDEs) with high accuracy and computational efficiency, making them powerful tools for tasks such as simulation, modeling, and control in scientific computing.",
      "categoryId": "68ad24ff-10c9-4528-8cf4-90e1fced8c2f",
      "subcategoryIds": [
        "7e75d7e0-9484-40bc-ad9c-ee374cba823a",
        "f54992e2-8f53-4889-8b57-891a771d08c1",
        "42fca705-04a3-4e2b-9e5f-42d37b0811e2",
        "4b6f4478-2080-4db3-a85e-1edc037599ae",
        "87d50110-3218-4c15-9bb6-2d40a002ac25",
        "46b7086d-093c-4816-8ea0-3515bd9e42b3",
        "7f958407-5b45-4085-9ff1-b6711931e0ff",
        "0afc6002-0df6-4a5a-a44b-dd50a152c500",
        "8d210700-fe11-49d7-b24b-4668576d3103",
        "91765d64-d600-4fb8-b93f-f646a9ba6c5e"
      ]
    },
    {
      "id": "82d8cd65-d97a-4825-877d-27dc2f0c0508",
      "name": "Fourier Neural Operators Enhancements",
      "definition": "Fourier Neural Operators (FNOs) are a class of neural network architectures designed to approximate solutions to partial differential equations (PDEs) efficiently. They leverage Fourier transforms to parameterize integral operators, enabling the neural network to learn mappings between infinite-dimensional function spaces. Enhancements of Fourier Neural Operators refer to recent modifications and improvements aimed at increasing their accuracy, computational efficiency, and applicability to complex or high-dimensional PDE problems. These enhancements often include advanced spectral methods, improved network architectures, and optimized training techniques that extend the capabilities of the original FNO framework.",
      "categoryId": "1a28632c-3afc-41d1-a337-8229d387d2ef",
      "subcategoryIds": [
        "41b5a32c-bac8-4251-a5b5-0488fa7dd952",
        "579f5438-087f-41fb-bcbc-5d565bbe9fc5",
        "5f29070f-07b6-44bc-8411-543214b94ff5",
        "edcb629c-ff60-4cfa-9429-ef34cfcf0289",
        "9d888f90-005a-4930-b5e9-603adc850d34",
        "f4b34965-2fbd-47aa-811f-c328cb92e373",
        "e4960def-517d-4e1b-bb18-2789938e7cdd",
        "48badc81-98aa-466c-a2fa-e44f54824aaf",
        "c6936b7a-8251-4274-9b52-277e05d7d569",
        "128301b2-fbbb-421d-b740-8d22d25a8e0d"
      ]
    },
    {
      "id": "39c6d5e6-38b2-4204-9756-cdc3d7665886",
      "name": "Fourier Neural Operators Extensions",
      "definition": "Fourier Neural Operators (FNOs) are a class of neural network architectures designed to efficiently learn operators that map between infinite-dimensional function spaces. They extend traditional neural networks by incorporating Fourier transforms to handle complex, high-dimensional problems such as solving partial differential equations (PDEs). The 'extensions' of Fourier Neural Operators refer to various modifications and enhancements aimed at improving their accuracy, efficiency, and applicability across different types of problems and data regimes.",
      "categoryId": "4af4314e-f98c-49a8-ab66-4db689665013",
      "subcategoryIds": [
        "b85e775d-fe31-4dd8-b5cc-86f4f02a0090",
        "46d7f8cf-752b-4a76-b482-3666fdcb585d",
        "a694290f-a60f-47cd-bc9d-96115a14b5eb",
        "901f9b5f-62a5-4ee0-ab31-2aba37e411c7",
        "88857b93-b2b8-4dc8-a39e-ba46fd0494d6"
      ]
    },
    {
      "id": "ca8139e7-6817-4460-bad7-81ce2bd2fe46",
      "name": "Fourier Neural Operators Techniques",
      "definition": "Fourier Neural Operators (FNOs) are a class of neural network architectures designed to efficiently learn mappings between functions, especially those arising in the context of partial differential equations (PDEs). They leverage the Fourier transform to operate in the frequency domain, enabling the models to capture global and multiscale features of functions. Unlike traditional neural networks that approximate pointwise mappings, FNOs are capable of learning operators that map entire functions to other functions, making them highly effective for parametric PDE problems, model reduction, and scientific computing applications.",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd",
      "subcategoryIds": [
        "19b717bc-5709-4e83-a4b1-d6eb58c375a9",
        "54d347f9-3baa-4bd2-9466-239fea9b264f",
        "18cbaa78-319e-4e56-90da-f9468ddc853b",
        "e14f30cd-22b1-4e8b-9a1c-3da9ec6d9850",
        "4a44e9c4-1be4-4910-9f40-5fc27c67a5b3",
        "4446a74b-8197-4c40-a261-de889d713d6b",
        "9ae644f9-5614-4cb8-a067-f3a9a6cdb0b2",
        "47bdb55c-fc19-404a-9685-08a13747271b"
      ]
    },
    {
      "id": "37a1bbb7-5c3c-4068-9dc7-7d4ed0a7beb9",
      "name": "Fourier Neural Operators Techniques Enhancements",
      "definition": "Fourier Neural Operators Enhancements refer to advanced techniques and modifications applied to Fourier Neural Operators (FNOs), which are a class of machine learning models designed to efficiently learn mappings between infinite-dimensional function spaces. These enhancements aim to improve the accuracy, scalability, and generalization capabilities of FNOs, enabling them to solve complex partial differential equations (PDEs) and related scientific computing tasks more effectively. By integrating additional methods such as improved spectral representations, multi-resolution analysis, or hybrid architectures, these techniques push the boundaries of FNO performance and applicability in various scientific and engineering domains.",
      "categoryId": "44ee7168-0e06-4906-92da-c4c16c8f3dbb",
      "subcategoryIds": [
        "c2132859-b961-42f3-b1cb-978b1f0fa697",
        "6f55ea2c-1647-4015-9421-277132b44966",
        "15039e52-44f4-4f93-a4fa-a44661573745",
        "1e671810-1318-44bf-b213-49d0117b36a7",
        "25ca99a0-d276-40cc-a4d2-fa60bd35df2f",
        "1c08a553-6942-4523-9cf8-62dcb9d5a7a2",
        "da83db62-096c-4cbf-a396-ebc314f12e32",
        "47ac5278-dc3d-413e-8ecf-3938c3108d60",
        "1809a6e9-47ce-4ebc-bed6-8056f15411e5",
        "a6c596a2-791d-4f55-bbef-308c4965b096",
        "2a86e61f-d3e3-41c6-8221-e4f790a63b74",
        "1a742647-5d27-470b-a658-5bfed6204f33",
        "95931671-2dec-46a1-b339-02a3fb929bb0"
      ]
    },
    {
      "id": "0c048154-e544-4cae-a115-3bdf632e1b67",
      "name": "Fourier Neural Operators Techniques Extensions",
      "definition": "Fourier Neural Operators (FNOs) are a class of advanced neural network architectures designed to efficiently learn mappings between functions, especially in the context of solving partial differential equations (PDEs). They extend traditional neural networks by integrating Fourier transforms within the model structure to capture complex, multiscale patterns in data. By leveraging Fourier transforms, FNOs enable the neural network to handle high-dimensional, continuous spatial-temporal data directly, making them powerful tools for simulating physical systems, fluid dynamics, and other scientific computing tasks.",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd",
      "subcategoryIds": [
        "099961ae-2aec-4941-a861-3634f74ee1e6",
        "18cbaa78-319e-4e56-90da-f9468ddc853b",
        "5c322c83-583a-4ace-8729-832d2d47fd7f",
        "2dbd8ade-bae4-491d-a64b-21b46ef28dfb",
        "e14f30cd-22b1-4e8b-9a1c-3da9ec6d9850",
        "4446a74b-8197-4c40-a261-de889d713d6b",
        "45b4a8a5-9904-48d8-8d1f-53fa92552996",
        "881b9265-fc77-48ae-be9d-a0ada8df01f8",
        "9ae644f9-5614-4cb8-a067-f3a9a6cdb0b2",
        "37cc67e0-c06d-4990-a7c9-2fdaf0821b2f"
      ]
    },
    {
      "id": "901204c9-0c03-4df0-b700-13e66b829dff",
      "name": "Fourier Neural Operators Techniques Extensions Techni...(truncated 32118 characters)...xical semantics embeddings",
      "definition": "Fourier Neural Operators (FNOs) are a class of neural network architectures designed to efficiently learn mappings between functions, particularly in the context of solving parametric partial differential equations (PDEs). These models extend traditional neural networks by incorporating the Fourier transform to operate directly in the frequency domain, enabling rapid and accurate approximations of solutions to complex mathematical problems. The goal of FNOs is to combine the strengths of neural networks and spectral methods, facilitating their application to high-dimensional, continuous problems prevalent in scientific computing and engineering simulations.",
      "categoryId": "d9632ffa-d344-412c-91fa-612311a084fd",
      "subcategoryIds": [
        "e639037d-6879-4a25-bf9e-cd6fb1affae1",
        "22b15b57-8baa-48d0-a232-eacc3affb434",
        "ed6faf2b-5a34-4925-bc02-e6331b91a424",
        "a32a594a-9d2e-4550-86e9-cc53df7ecbb6",
        "4f6234d4-7ca6-4a37-80d8-1985dbeb936f",
        "abcd3448-0fc9-4726-8a79-99208e6e4721",
        "5891c68f-3d5c-49a6-b885-252f9b2ae8ce",
        "3991f542-31c6-4555-8061-577475a90a0f",
        "33ea631f-1931-433c-94ea-ad561342f5b2",
        "517ea337-afb0-402e-bd56-c3f746f7e2d1"
      ]
    },
    {
      "id": "2b4d08b5-7012-4801-a926-808e71831143",
      "name": "Fourier Neural Operators Techniques Extensions Techniques",
      "definition": "Fourier Neural Operators (FNOs) are a class of machine learning models that leverage the mathematical framework of Fourier transforms to efficiently learn solution operators of Partial Differential Equations (PDEs). Extensions and techniques associated with Fourier Neural Operators involve various methods aimed at improving their accuracy, efficiency, and applicability to complex problems. These techniques include modifications to the neural network architecture, integration of multi-scale features, incorporation of physics-informed constraints, and adaptations to handle non-linear or high-dimensional problems, thereby broadening the scope and performance of FNOs in scientific computing and AI applications.",
      "categoryId": "4cdc6590-04bd-4428-b186-d0180bae17a5",
      "subcategoryIds": [
        "ac1a044c-9ed3-4fb1-bdde-4695f936db19",
        "5a7e568c-f644-4164-8ab1-1258803dbfa2",
        "98b0b0e0-4eb2-461e-bb5c-1fb307cac71a",
        "cab8b8ac-6704-4dba-baf3-fe8cd9527a1f",
        "0fc1f251-10ac-4351-9232-0cccf2e97ca9",
        "52e9a2c5-7d84-48ab-9a9e-b2c10747a103",
        "9bc556e0-20cb-47df-88dc-6889ea7e3cb3"
      ]
    },
    {
      "id": "bfc246a4-1579-45ca-a2a2-1a5d1b9e248f",
      "name": "Fourier Neural Operators Techniques Extensions Techniques Enhancements Techniques",
      "definition": "Fourier Neural Operators (FNOs) are an innovative class of neural network architectures designed to efficiently learn operators that map between infinite-dimensional function spaces. They extend traditional neural network capabilities by incorporating Fourier transforms to capture global frequency information, enabling the modeling of complex, nonlinear, and high-dimensional partial differential equations (PDEs). Techniques, extensions, and enhancements related to Fourier Neural Operators refer to various improvements, modifications, and adaptations aimed at increasing their accuracy, efficiency, robustness, and applicability across different scientific and engineering domains, often involving novel architectures, training algorithms, or integration with other AI methods.",
      "categoryId": "20ffb055-e2ec-409b-9c61-fb1e86158272",
      "subcategoryIds": [
        "465c0d4d-7e87-453d-85db-9e32a449675c",
        "f296985a-e601-47ec-8b94-83a05fc51462",
        "69010cb1-d200-4102-a299-ca92c56eb595",
        "9ba6128a-5c9c-45cc-8151-5740101a40e9",
        "04d4029a-00a7-4085-99f0-98a4f25fe950"
      ]
    },
    {
      "id": "5d4a4dfc-465b-47d2-9b17-2cbdac65eff1",
      "name": "Fourier Transform in CNNs",
      "definition": "The Fourier Transform in CNNs refers to the application of Fourier analysis techniques to convolutional neural networks (CNNs). It involves transforming data, such as images or feature maps, from the spatial domain into the frequency domain. This transformation allows for more efficient processing, analysis, and understanding of the frequency components within the data, which can enhance various tasks like feature extraction, filtering, and model efficiency.",
      "categoryId": "bb9827c8-518a-4dae-ba99-ef114de5a35f",
      "subcategoryIds": [
        "514ddf69-2166-4d8b-abe0-22001a2aba34",
        "91ac82c2-3a39-473e-8360-c2b26b3a84cf",
        "c33e8979-f51b-40f3-95bf-e56ca0072589",
        "5522b166-8ece-45a0-88ea-c8ec508a8472",
        "6e1b4d3e-4a83-4c8c-8be0-b9014e748f73",
        "66ab3e55-6278-4f67-a0ae-681edda8d086"
      ]
    },
    {
      "id": "f3264109-3745-441c-989d-a19bde71990b",
      "name": "Fowlkes-Mallows Index",
      "definition": "The Fowlkes-Mallows Index is a statistical measure used to evaluate the similarity between two clusterings or partitions of a dataset. It quantifies the agreement between the clusters by considering the number of pairs of points that are either clustered together or separated in both partitionings. The index ranges from 0 to 1, where a value closer to 1 indicates higher similarity, and a value near 0 reflects dissimilar clusterings. This metric is widely used in clustering validation to assess the quality of clustering algorithms and their results.",
      "categoryId": "67e320dd-1113-4cb1-b52a-f1b9e1fe06d9",
      "subcategoryIds": [
        "810abc3d-1803-4622-9d26-c4fbb0273637",
        "645dd955-146f-4049-a9c5-e9456b097fea",
        "5dbe8259-7e81-4b95-b7d0-44646b896d8e",
        "a4000619-7e59-4a76-8905-b960beac9b24",
        "bb2f2ed5-5831-4c75-81ac-7807dc9bdf12",
        "12678578-6d75-4a96-ab09-6732e239be71"
      ]
    },
    {
      "id": "91eb7b6b-1c72-4de0-a628-0d3d83d2dbcc",
      "name": "FP-Growth Algorithm",
      "definition": "The FP-Growth (Frequent Pattern Growth) Algorithm is a popular data mining technique used for discovering frequent itemsets within large transactional databases. Unlike traditional algorithms such as Apriori, FP-Growth employs a compact data structure called the FP-tree to efficiently compress the database, enabling faster discovery of frequent patterns without candidate generation. This method is particularly effective for market basket analysis, where identifying items that frequently co-occur can inform decision-making and strategic planning.",
      "categoryId": "4935a6fe-6ca3-4fe0-9dbe-b9813d81ed6e",
      "subcategoryIds": [
        "272d89e2-8e0c-4d4c-ba37-ae6be70a4c32",
        "893df46f-bc5e-4363-9e6c-cfdd44434851",
        "825edbd0-398f-43ed-8c1e-4bde2d014c22",
        "9c249d7f-29c2-464c-8271-5a2a29efab1c",
        "564e4d36-9764-4325-8f40-0a51d2a34010",
        "a8110664-a1b6-43ee-abcd-27ab8c82b2ce",
        "47e236c9-4947-4621-aa95-466184e1386c"
      ]
    },
    {
      "id": "51fc7f44-bef4-445b-89b2-4a3ab3d3db9e",
      "name": "fp16 quantization",
      "definition": "FP16 quantization, also known as half-precision floating-point quantization, is a technique used to reduce the numerical precision of floating-point values in neural network models from 32-bit single-precision (FP32) to 16-bit (FP16). This process involves converting model parameters, activations, and weights to FP16 format, thereby decreasing memory usage and computational load. By employing FP16 quantization, models can run faster and more efficiently, especially on hardware that supports half-precision operations, without significantly compromising accuracy in many cases.",
      "categoryId": "0f76ba94-08bc-41eb-b63a-5705db90e221",
      "subcategoryIds": [
        "bdc8be07-28f5-4d97-b2a2-279626c5d5a3",
        "db568aa5-e990-4bbc-b982-51984dce4068",
        "407cc221-565b-479b-9df7-a099b78e044d",
        "1490d191-3ef4-4690-93b7-ac9495dc2a2f",
        "373cb468-533f-4441-af41-cead74d6f451",
        "46cde395-2bc9-4ff1-b724-df83f5850302",
        "e0862afe-73ed-4637-8395-c0595dfe0024",
        "44a33139-e677-4a9d-8f61-49d268d6c1cc",
        "f124f75f-d720-4ae4-a293-1c30dd411faa"
      ]
    },
    {
      "id": "417e2aa1-67ce-4757-985e-fc5551294c0b",
      "name": "FPGAs for AI",
      "definition": "FPGAs (Field-Programmable Gate Arrays) are integrated circuits that can be configured by a customer or a designer after manufacturing, enabling tailored hardware acceleration for various tasks. In the context of AI, FPGAs are utilized to execute neural networks and other computationally intensive algorithms with high throughput and low latency, often outperforming traditional CPUs and even GPUs in certain applications. They offer a flexible platform for deploying AI models directly in hardware, facilitating rapid customization and optimization for specific AI workloads.",
      "categoryId": "51215db2-fd1d-40fe-b551-e2e05fa03457",
      "subcategoryIds": [
        "22f13abb-ef18-4c60-87b8-0131e4c8b177",
        "b6b260e0-7538-4952-8f00-1a14aad7a969",
        "813f7299-cffe-47a1-a347-e0bfb106e104",
        "28143cfe-ffac-4354-8e39-92e7356a3bd8",
        "d3cefc96-7631-4817-b161-d5f87dd6b13a",
        "081c2234-02e5-41c9-94da-ad7f1ee81768",
        "ac3182e9-0088-4db4-8644-cb2f5a5d9e89",
        "cbbfa679-0c75-4837-9a52-710ccaaadbf9",
        "7ca16575-5f61-4d97-985e-d82ababe42d6",
        "2a2dea26-a5b8-4882-a63c-b018a3d70869"
      ]
    },
    {
      "id": "e06576f7-8380-474e-a029-b28bc3c45d71",
      "name": "Fractal Network Models",
      "definition": "Fractal Network Models are a class of computational frameworks that incorporate the principles of fractal geometry into the design and analysis of neural networks and other AI architectures. These models utilize self-similar, recursive structures to represent complex, hierarchical, and irregular patterns found in data, allowing for efficient modeling of intricate natural phenomena and complex systems. They often mimic the fractal patterns observed in nature, such as coastlines, snowflakes, and vascular systems, enabling more flexible and robust learning representations.",
      "categoryId": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7",
      "subcategoryIds": [
        "18a8e2e3-9203-410c-b7f8-b3d3abce6225",
        "ab4bf596-b672-4ee9-a32b-bc430457c82e",
        "98aa0882-4f64-412a-adb6-1cb90c53785c",
        "b74131c3-d351-447e-8312-e783559dbeb6",
        "bea2db31-29eb-40e3-a4d1-2365f911ee25",
        "f7b38d6a-5e32-44d7-bc0e-e3c0943f1ee6",
        "c150cd50-5ea8-4e5a-91f5-bde594dc3409",
        "75985cef-b1fa-4615-bf71-213e651f8bd6",
        "e6d685c6-edd4-4ac1-aea3-aa1d87afd914"
      ]
    },
    {
      "id": "9fa2b9d3-f039-466e-80eb-032c020415ec",
      "name": "Fractal Networks",
      "definition": "Fractal Networks refer to neural network architectures that incorporate fractal geometries or self-similar patterns into their design. These networks utilize fractal principles to enable multiscale feature extraction, hierarchical organization, and efficient parameter sharing. By embedding fractal structures within neural architectures, they aim to capture complex, multiscale patterns in data more effectively than traditional architectures, often resulting in improved learning capabilities and generalization.",
      "categoryId": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7",
      "subcategoryIds": [
        "6aa6e1eb-8bd9-4553-b23a-48ca039793fe",
        "fbe332ce-4916-49db-aada-ba8bc450644a",
        "b32cb1ba-1edf-4d59-aaa2-5a4dc669c819",
        "cc6a158e-550b-40c2-9603-c740b0a6035f",
        "3f351a61-416b-4d03-8b87-d5d044a81719",
        "485bdb94-d384-45a0-9fa0-0663469db644",
        "98aa0882-4f64-412a-adb6-1cb90c53785c",
        "ff66d00c-ff08-48cb-a053-01edbb5b56ab",
        "8396e0f8-91cd-4346-97a8-25e84f84f2db",
        "370a83cb-d0ad-424a-8b85-5eee1a647925"
      ]
    },
    {
      "id": "91982cfb-1610-4347-acd5-185ad93dc7b6",
      "name": "Fractional Calculus",
      "definition": "Fractional Calculus is a branch of mathematical analysis that extends the concepts of derivatives and integrals to non-integer (fractional) orders. Unlike traditional calculus, which deals with integer-order differentiation and integration, fractional calculus allows for derivatives and integrals of arbitrary, non-integer orders, providing a powerful tool for modeling complex, memory-dependent, and anomalous processes. It encompasses various definitions, such as the Riemann-Liouville, Caputo, and Gr\u00fcnwald-Letnikov formulations, each suited to different applications and problem types.",
      "categoryId": "5445f1f8-954a-48c1-b83f-5ab771ffdefa",
      "subcategoryIds": [
        "64beabe5-03fb-4b2e-bec2-c2385ffeb67e",
        "041a6eb0-21af-49c0-9cde-31a9ae4a6a7d",
        "5edd84fd-a4dd-49dc-802e-42b73a958d13",
        "13e1fdb6-eaf6-49a1-af47-27db16c0b8c8",
        "1e40a541-6dcf-4835-84d2-572940326e3a",
        "3ca5d322-cd95-45df-aa0a-b009b1fa228a",
        "ea9550f3-a8be-4f0d-a836-a41b6189f96f",
        "a900abfc-5d97-46c3-8a61-ad7ce22989f4",
        "6e20959c-6e57-41f1-8c25-666a57eccb94"
      ]
    },
    {
      "id": "bd81a3e3-3df0-483d-9f6e-c463822ea111",
      "name": "Frame Stacking",
      "definition": "Frame stacking is a technique used in machine learning, particularly in processing sequential data such as audio or video signals. It involves combining multiple consecutive frames or data slices into a single, extended feature vector. This approach allows models to leverage temporal context, capturing the dynamics and transitions between frames more effectively than considering each frame independently.",
      "categoryId": "c772f870-7b52-4777-b60a-c3dc0d394d53",
      "subcategoryIds": [
        "5a5340aa-cfeb-4d76-9a9b-4457ff474ca5",
        "ee9f1a36-f247-4ad7-9c53-68723f4e933b",
        "d76fe95a-c437-4d6d-a4e8-a0dc02d77684",
        "1a34c41a-99cd-43de-bb23-0cdc983e78da",
        "67a6f150-c44b-4b31-bccd-3b53506cffc2",
        "2d4a1aeb-1b23-4877-8bbb-cb3675707799"
      ]
    },
    {
      "id": "f33bd054-e321-4828-9060-cd3116d493a6",
      "name": "Frame-based Representation",
      "definition": "Frame-based Representation is a symbolic knowledge representation technique used in artificial intelligence to model and organize information about the world. It employs structures called 'frames' to encapsulate stereotyped data about objects, situations, or concepts, including attributes (slots) and their associated values, as well as relationships between frames. This approach allows AI systems to simulate human-like understanding by structuring knowledge in a way that captures various aspects of entities and their interconnections systematically.",
      "categoryId": "ee2f3a89-50db-4d87-a0ce-6745e7f25d99",
      "subcategoryIds": [
        "226b9190-a94f-4784-a1b3-8a37fae9eebd"
      ]
    },
    {
      "id": "9b14bd8a-7985-4f14-ae14-ff9373b8c5bf",
      "name": "Fr\u00e9chet Inception Distance (FID)",
      "definition": "Fr\u00e9chet Inception Distance (FID) is a quantitative metric used to evaluate the quality of images generated by generative models, such as Generative Adversarial Networks (GANs). It measures the similarity between the distribution of generated images and real images by calculating the Fr\u00e9chet distance (also known as Wasserstein-2 distance) between their feature distributions. In practice, features are extracted from a pre-trained Inception network, and the mean and covariance of these features are compared to assess how closely the generated images mimic real data in terms of visual quality and diversity.",
      "categoryId": "a2f160cb-c882-4fc0-8e76-7a20a28f347c",
      "subcategoryIds": [
        "6e7011e3-26b1-42fd-ab26-6602ee89e1bf",
        "ec7b0855-c2f7-4933-ab4d-6bcae9cebace",
        "85b7442a-98e0-444e-a9d4-480cc7fe9aac",
        "25b19541-915f-4b78-b384-663941a50de4",
        "febca8e4-e0e5-422e-a4ad-0aaf79b288e4"
      ]
    },
    {
      "id": "7f695493-d301-4b37-acd6-d43158749d12",
      "name": "Frequency Based Algorithm",
      "definition": "A Frequency Based Algorithm is a type of algorithm that analyzes data by examining the frequency at which certain events, patterns, or elements occur within a dataset. These algorithms leverage statistical measures of frequency to identify, classify, or predict outcomes based on how often specific features or signals appear. Commonly used in areas like signal processing, pattern recognition, and data mining, frequency-based algorithms are fundamental in extracting meaningful insights from large volumes of data by focusing on the prevalence of specific attributes.",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd",
      "subcategoryIds": [
        "abe8f879-91ad-4677-b6db-9a7dad85c00b",
        "167a31e8-7370-4fd5-9eb5-0454d5f66d98",
        "04c7b842-59c0-4a0f-87a1-3d502dd5bb5d",
        "0fd40162-f566-43e7-bd99-9f71772a864a",
        "69dc0e7e-560c-4419-bd49-2669f4351534",
        "f308d66f-0f63-423d-b9e7-a04f51d43c05",
        "6ace9e41-867f-4bf0-8913-291ff79e4751",
        "1587bc94-7401-41d4-8538-c50f950cbd30",
        "bab5dec4-8e9e-4590-9cde-fb72736b3e8a",
        "0625ea87-701b-47a6-a839-7164e95c19fe",
        "13e62cee-361b-4d45-8ce2-d40e3a13601f"
      ]
    },
    {
      "id": "609d236e-9862-4cbf-88b4-2ea8b86c1c12",
      "name": "Frequency Encoding",
      "definition": "Frequency Encoding is a categorical data encoding technique used in machine learning to convert categorical variables into numerical format by replacing each category with its corresponding frequency or count within the dataset. This method transforms categories into numerical values based on how often they appear, facilitating their use in algorithms that require numerical input.",
      "categoryId": "3fe5ddd5-daa7-493d-9ff3-95fbe4bfe43b",
      "subcategoryIds": [
        "1a008793-4731-4084-9348-32e63d686fd9",
        "d8df8aed-1d00-40d9-bdd3-5709d986acef",
        "7f4874d8-05c6-4812-a035-47761728e9f6",
        "e4695129-6574-4265-82fe-af3209ee8f2d",
        "5b42ba77-3413-4438-8994-c6531c8670ae",
        "c93d8d84-9014-44e8-aa17-fdeff745a0a5"
      ]
    },
    {
      "id": "81362117-8f99-4214-adff-b087994ffc2e",
      "name": "Frequency Penalty",
      "definition": "Frequency Penalty is a parameter used in natural language processing models, particularly in text generation tasks, to influence the diversity of the generated outputs. It functions by adjusting the likelihood of repeated tokens or phrases, effectively penalizing the model for generating the same or similar tokens multiple times. By modulating this penalty, developers can control the repetitiveness of the output, encouraging more varied and creative responses from the language model.",
      "categoryId": "04371312-beca-4cb2-8360-ec20748cdaae",
      "subcategoryIds": [
        "a46251c2-cc81-4d72-814a-71d603c3d010",
        "4e7cbfd2-2b5f-42a0-880d-646bdc17ecd3",
        "51fff397-b821-4ed0-b629-7668824d3369",
        "23a55128-9bbc-4f0f-91b8-c3f2324f3b7a",
        "fc43f6b0-7583-4ea7-84e3-ed18e0ec7820",
        "b03acda3-9fbb-4872-96da-255e6f93b1a0"
      ]
    },
    {
      "id": "398fe792-e87f-4437-bb47-6b1dd2822236",
      "name": "frequency thresholding",
      "definition": "Frequency thresholding is a technique used in data preprocessing and feature selection within AI and machine learning workflows. It involves setting a minimum frequency count or proportion for feature occurrence, such as words in text data or categorical variables in structured data. Features that occur less frequently than this threshold are discarded, under the assumption that infrequent features may contribute noise, cause overfitting, or have limited predictive power. This method helps in reducing dimensionality, improving computational efficiency, and enhancing model performance by focusing on more representative and informative features.",
      "categoryId": "dc763446-344a-45ed-8361-8982b166ce2a",
      "subcategoryIds": [
        "3a6f3425-a127-454e-9e73-6eb08b775df9",
        "38d5065b-6022-4435-bce4-80b7c70346bb",
        "cbf5da38-f5c8-4ac3-b98a-c1a67094bba7",
        "c65bbf65-e7d4-4ea9-b908-c02e8401faa0",
        "fc558910-c3bd-4f43-8326-3106e4acc636",
        "81b9f178-c11a-4ffa-9a26-3a58d4bd12f8"
      ]
    },
    {
      "id": "0c8c1ec3-6f43-40cc-9a63-42409059435b",
      "name": "Frequency-based algorithms",
      "definition": "Frequency-based algorithms are a class of methods in machine learning that analyze the frequency or occurrence patterns of data features, patterns, or events within datasets. These algorithms utilize statistical measures such as counting how often specific data points or patterns appear to make predictions or classifications. They are often employed in areas like natural language processing, anomaly detection, and pattern recognition, where understanding the distribution of data elements is crucial for effective decision-making.",
      "categoryId": "15163f57-df7e-45f9-b10f-4306045ff1c9",
      "subcategoryIds": [
        "3de5616a-3f11-4dd4-871c-6b0cfb866cb0",
        "6ab27f8d-affe-452e-bb38-60720b036731",
        "4b896611-bf6d-4abb-aa10-dc283595681a",
        "88e6218f-9b0b-41e8-a5db-887cd0d02fb4",
        "5d064681-7ebc-4d74-a50a-5f477090244c",
        "8bad2a9b-2f09-40fb-b0cf-24feb5fe0934",
        "7893e239-6271-4437-a190-7b2230ad0ddc",
        "032d2682-9c57-4b53-a462-0c8e2163e555"
      ]
    },
    {
      "id": "de6598cf-b5f6-4d0c-a663-0e9fc05f1ea8",
      "name": "frequency-based sampling",
      "definition": "Frequency-based sampling is a data selection technique in which data points are sampled according to their frequency or occurrence rates within a dataset. This approach emphasizes resampling data based on how often specific events, features, or classes occur, allowing models to better understand and learn from the underlying data distribution. It is often used to address issues such as class imbalance, where certain classes are overrepresented or underrepresented, ensuring more balanced and representative training data.",
      "categoryId": "a16f1228-794f-400e-b347-5b108094d53f",
      "subcategoryIds": [
        "73ae3aae-80c4-46fc-9086-879ea2547b53",
        "17e8d5b9-ae42-4779-940d-b9704ffcb053",
        "89babcf7-de7d-4c7d-9783-a14625d6ac6b",
        "5d053cb1-0742-42cf-8b97-eb6e6c9e349a",
        "de981ef5-702b-4ee8-b7e0-d5d10329db6c",
        "565fb2a8-6836-4516-87df-2d77254ad0c5",
        "50581abd-371c-49c2-a0ff-ecc466e7bb8b",
        "bdfab8ce-c3e2-4f47-bbbc-324407429152"
      ]
    },
    {
      "id": "d94ed885-29ec-493b-87eb-e11690523ea9",
      "name": "Label forcing",
      "definition": "Label forcing is a semi-supervised learning technique used in machine learning to improve model performance by leveraging both labeled and unlabeled data. It involves assigning or 'forcing' label predictions onto unlabeled data points based on certain confidence criteria or auxiliary models, and then retraining the model using this expanded dataset. The process aims to enhance the model\u2019s ability to generalize, especially when labeled data is scarce, by propagating label information from a small set of labeled examples to a larger pool of unlabeled data through iterative refinement.",
      "categoryId": "618807d6-9f71-412e-a016-f6f4377fcc34",
      "subcategoryIds": [
        "4f865ce1-94ba-481f-a230-82824f7f6cf9",
        "30e74c29-92ee-4908-b7d3-2b34b6ba7e34",
        "5d332b3c-a432-4846-8fd3-037897a07a4b",
        "6bd917bd-2e0c-4c37-a591-d38fb2303309",
        "a7ff5a32-0892-4147-b25e-b74e3ac08bcd"
      ]
    },
    {
      "id": "461d7ba1-7c23-4d77-9f44-6ec19c5712f8",
      "name": "Label Noise",
      "definition": "Label noise refers to inaccuracies or errors in the labels assigned to training data in supervised machine learning tasks. Specifically, it occurs when the labels provided for data instances are incorrect, inconsistent, or ambiguous, which can mislead the learning algorithm and impair its ability to model the underlying patterns accurately. This form of noise is a common challenge in real-world datasets where labels are often generated through manual processes, crowdsourcing, or automated labeling techniques that are prone to mistakes.",
      "categoryId": "b4ffc370-1d98-4c88-a8a7-f8ab7121501c",
      "subcategoryIds": [
        "f11093b5-fe24-4ff6-864e-9b60da7044e9",
        "df6b7c8e-e5a4-4523-a5b3-f0305508b21d",
        "2d7713fd-a2f5-427a-8e89-b394f74f8333",
        "62aa6a6c-5957-4013-bdfd-5757da990c41",
        "02102568-f76f-4dd1-a826-511c25f6968f",
        "e5d05512-c226-4b5e-8724-69a39b8f9da0",
        "9632be2a-0517-4196-9d4a-15d2c19e517e",
        "ebebd18e-fbdd-4885-92ce-50c9b70aac58",
        "432dab8f-f3bc-44c7-8939-4cf047905d7d",
        "de17c685-ed9c-4d61-9f1b-5dbe32a55085"
      ]
    },
    {
      "id": "2b6619eb-a0a2-4455-9d57-fc6996c4b13c",
      "name": "Label Propagation",
      "definition": "Label Propagation is a semi-supervised machine learning algorithm used for data classification and clustering, particularly in graph-based data structures. It propagates labels from a small set of labeled data points to unlabeled data points through iterative processes, leveraging the inherent structure of the data to improve labeling accuracy. The core idea is to exploit the similarity between data points, where similar points are likely to share the same label, thereby enabling effective learning even with limited labeled data.",
      "categoryId": "05a932c8-c094-4cc4-a95e-c454d56ad8ca",
      "subcategoryIds": [
        "56a024f0-aad2-4d2d-b2bd-437033676813",
        "d0bf6f4d-bf15-4176-be21-ff4f3c5d629f",
        "c4ffb0d8-7c0b-4c24-b757-64a70354adb3",
        "d26ca7b6-fe4a-40be-8e47-6133bf46d441",
        "dbf6c281-4473-4fb9-9908-3c238faf4158",
        "dcee856f-cfb9-4419-8178-7bcd73c5c251",
        "d0f69dce-f13f-4cb4-afc2-6ece093508e3"
      ]
    },
    {
      "id": "86c0b6cf-f5f8-4549-81f3-0dfeabf9aa69",
      "name": "Label Propagation (Already in your list)",
      "definition": "Label Propagation is a semi-supervised learning algorithm used primarily for graph-based data to assign labels to unlabeled nodes based on the labels of their neighboring nodes. It operates by iteratively updating the labels of data points through the propagation of label information across the graph structure, leveraging the assumption that connected nodes are likely to share similar labels. This technique is especially useful in scenarios where labeled data is scarce but unlabeled data is abundant, enabling the algorithm to infer labels effectively by exploiting the intrinsic structure of the data graph.",
      "categoryId": "3474fe82-93a5-4ccd-96a8-7cf1326920f7",
      "subcategoryIds": [
        "2c42180f-425a-424d-9959-fce8b1877455",
        "a5cedb9d-efc4-4783-aeaf-2b035094d7ef",
        "3469c37d-2ee0-405a-818c-63bc4c22b087",
        "bb28ba08-a605-4cd1-bedf-df54a6f9c896",
        "5745536a-6ef1-4d53-81a7-5f1c2926914e",
        "13b0a9a2-98c1-4514-8e8e-8b1fcb971679",
        "40e2f914-6980-4a0b-bdb7-57e76d72e792",
        "16a97fc0-da88-4082-a6e9-a82088b7b426",
        "c197736d-ccc3-4697-9fda-58cf6fc024e9",
        "f3bf9a46-ddcf-49ef-a7b6-81e277d66658"
      ]
    },
    {
      "id": "709aa27f-6cfa-44fb-8d2e-a4a8d3d2927e",
      "name": "Label Smoothing",
      "definition": "Label smoothing is a regularization technique used in training classification models, particularly neural networks, to prevent the model from becoming overconfident in its predictions. Instead of assigning a probability of 1 to the correct class and 0 to all others, label smoothing distributes a small portion of the probability mass to the incorrect classes. This results in more calibrated and generalizable models by encouraging less confident predictions and reducing overfitting.",
      "categoryId": "369340b8-283b-4b8a-8ad5-723e48cf9fa1",
      "subcategoryIds": [
        "80463c9a-19f1-4769-a383-064780be7c52",
        "28b88087-a55a-407a-84e9-8aa05bdd1621",
        "dcc951e0-9fb6-4d29-9340-de677b996e28",
        "a5e8b6d2-b3c7-4ea1-b2f9-37562aa60413",
        "b3559292-a277-482d-bff3-40089421cd76"
      ]
    },
    {
      "id": "4735598a-4e6c-48b6-878b-c327391fb13f",
      "name": "Label Smoothing Techniques",
      "definition": "Label smoothing is a regularization technique used in training classification models, particularly neural networks, to improve generalization and prevent the model from becoming overly confident in its predictions. Instead of assigning a probability of 1 to the correct class and 0 to all others in the target distribution, label smoothing distributes a small portion of the probability mass uniformly across all classes. This approach effectively softens the target labels, leading to improved model calibration and often enhanced performance on unseen data.",
      "categoryId": "d87737eb-4f8f-4978-a432-d782df021d96",
      "subcategoryIds": [
        "cb334064-b53b-45f2-b498-b16a842fe53b",
        "2608333a-6325-490c-9d8b-cf1cb97bc78d",
        "be80a38f-aa8c-4cc2-8975-d14f78c2a286",
        "6f19e371-2d8c-4130-b53f-6dfc4f087046",
        "a89e8372-9165-46b7-bff2-7919b95f29f6",
        "84c25096-308a-4a55-b581-fe01199dc285",
        "504638c9-89f6-4805-b750-8b7704e43caa",
        "d16a4a1a-c673-412e-a92c-86599e1f0f45"
      ]
    },
    {
      "id": "17fc17ea-6878-467b-9292-e49c34f424a0",
      "name": "Ladder Nets",
      "definition": "Ladder Nets are a type of neural network architecture that combines elements of traditional convolutional neural networks (CNNs) with ladder-style connections. They are designed to facilitate efficient feature extraction and hierarchical information flow by incorporating skip connections that pass features across different layers, thereby improving the network's ability to learn complex patterns and representations in data such as images, speech, or sequential information.",
      "categoryId": "5333e89e-2492-4d6f-b6b1-e72dc32f5208",
      "subcategoryIds": [
        "e2d8a1b0-95db-4ac1-a59f-ddbd491cf1fa",
        "3fdfdc89-8d76-4fd7-8b50-c9367c0be246",
        "74269981-714b-4a07-babd-600df5fa1b0e",
        "36c24874-154d-48a5-acc5-4e9cd5d8a45a",
        "0008b7bc-c3ed-4d59-bd5b-c4be1df8a6aa"
      ]
    },
    {
      "id": "fdddd5b9-16fc-4f06-b5bb-5dc78beaf1c2",
      "name": "Ladder Nets Enhancements",
      "definition": "Ladder Nets Enhancements refer to advanced modifications and improvements applied to Ladder Networks, a semi-supervised learning architecture that integrates supervised and unsupervised learning principles. These enhancements aim to improve feature representation, training efficiency, and robustness of the model by incorporating additional layers, regularization techniques, and optimization strategies to better leverage both labeled and unlabeled data during training.",
      "categoryId": "3cf62c13-b26d-412c-9323-d849e20110c1",
      "subcategoryIds": [
        "79f8e5e3-a18a-4447-b1be-dd202ebab1a1",
        "22fdb3c0-0249-4474-aaec-46bce60c7396",
        "9aa0a9d3-26e5-4dcf-be3e-a0d163c91951",
        "03e5590e-10fc-4cce-8619-47a4d29cd2cd",
        "3bea07f7-bf0f-483f-b373-6b24006c8356",
        "15c03a73-cc50-42bd-8ae0-ec03e7dfd7f9",
        "e8c34369-5fc6-40bf-91ce-c9f95df679fb",
        "e0ef8f21-f430-4453-a8dc-074701b802ab",
        "1665e4bc-20c0-4a33-a148-fa6810769a32"
      ]
    },
    {
      "id": "edf1393d-34fd-47c9-b9cf-19302e6a5ea9",
      "name": "Ladder Nets Enhancements Techniques",
      "definition": "Ladder Nets Enhancements Techniques refer to series of advanced modifications and optimization strategies applied to Ladder Networks, a semi-supervised learning architecture. These techniques aim to improve the network's performance, robustness, and efficiency by refining its layered structure, regularization methods, and training procedures, thereby enabling better exploitation of limited labeled data in various machine learning tasks.",
      "categoryId": "8036fb15-70a5-4cbd-b917-a0846835fd10",
      "subcategoryIds": [
        "7fbbe364-9a9d-4552-8589-c9e056cf1276",
        "3779e4af-5501-47f0-baca-056337b140c8",
        "72a3cd34-2347-4ff9-a8f5-dc947ef2d06a",
        "42e44246-e32f-4921-a81b-0a64e437c199",
        "0757959c-31fe-445f-8d9a-918ff8737781",
        "7c467c66-88f2-4b19-aa7b-3e8ce66ecc23",
        "4a7567d8-8a3f-4223-9da7-91700cdbeca5",
        "8b801bb4-bd0c-4886-af6e-ae4df734297d",
        "1bf2a138-5889-4d12-b72a-f879530c988a",
        "bfd92cde-4097-4ce2-b3ef-1e9e144196a2"
      ]
    },
    {
      "id": "74ad3cb1-9330-4e48-8a5e-b078d9804b56",
      "name": "Ladder Nets Extensions",
      "definition": "Ladder Networks Extensions refer to advanced modifications and augmentations to the original Ladder Networks architecture, which are designed to improve semi-supervised learning capabilities by incorporating additional layers, pathways, or connectivity patterns. These extensions aim to enhance the network\u2019s ability to leverage both labeled and unlabeled data effectively, often resulting in better feature extraction, improved robustness, and increased training efficiency in various machine learning tasks.",
      "categoryId": "b5fd6ba2-5581-4576-b2d8-ca4382e4019b",
      "subcategoryIds": [
        "5d02b05a-b7ba-452e-9689-00e570bc0237",
        "5a3e141b-8073-45d5-9499-275d925edfe3",
        "62f4ad81-d18e-4b42-aeb5-85030b093c11",
        "d870c326-398f-4c10-8f38-04fbaa9a3b0f",
        "fb808508-1478-4f27-a8f5-db877e8adb8d",
        "2edb8faa-7ea8-42e2-9433-4ba0e699c0b8",
        "e0a3206e-30d1-42d0-b4ac-7aeb1bd49181",
        "2b32cddb-0241-48c5-9c9b-ffd7d2186577",
        "178783ad-05a7-4689-8975-87e9d56d2ee6",
        "0f6e8f43-7cec-4c96-89c6-eabccb83b674"
      ]
    },
    {
      "id": "b3990373-4997-4877-986c-2394600204c1",
      "name": "Ladder Nets Extensions Techniques",
      "definition": "Ladder Nets Extensions Techniques refer to advanced methods used to enhance the architecture and functionality of Ladder Networks, a class of semi-supervised learning models. These techniques aim to improve the network's ability to learn from limited labeled data by extending the base Ladder Network with additional layers, connections, or modules, thereby increasing model capacity and representation power while maintaining efficient learning characteristics.",
      "categoryId": "b017525a-0826-4881-9223-ee79ca9969a1",
      "subcategoryIds": [
        "ad8bc4e4-e477-4ad6-973d-42104f0bf5d2",
        "181c70e1-b18e-4698-8ea7-15c40fbefbb6",
        "33f069bc-38cb-4db5-8f89-0c92a53ee9d4",
        "68a3517a-fcbe-44a5-9f8a-09b92ad6fa9d",
        "81185b0b-1132-4091-a77f-e509bc5d7aa1",
        "bbfb0afd-1f7c-44f2-ac94-96beff39dc2f"
      ]
    },
    {
      "id": "c930ba64-9664-4b3e-aa01-0d365541be07",
      "name": "Lambda Architecture",
      "definition": "Lambda Architecture is an architectural design pattern for processing massive quantities of real-time and batch data efficiently and reliably. It aims to provide a comprehensive data processing framework that combines real-time data streams with batch processing workflows to deliver scalable, fault-tolerant, and low-latency data analytics solutions. This architecture integrates different processing models to harness their respective strengths, ensuring accuracy, freshness, and historical context in data analytics and machine learning applications.",
      "categoryId": "1540d631-e09d-4ed0-bbc4-631a933f8ac4",
      "subcategoryIds": [
        "d8dac3d1-8f16-4781-add7-880367f815c5",
        "24594b85-f927-4d02-b043-f5024eebd8c8",
        "3798a8eb-4fcf-4411-ab9d-e1528912bf55",
        "7fad01b9-15da-4bc7-adbe-52ccefbe49dc",
        "a7360818-a468-417f-a86e-e02e7ab68d04",
        "729d9578-0ddd-4c25-85c1-355e9810dabc"
      ]
    },
    {
      "id": "74d75f05-5e6e-4de8-b493-d7c9dd917827",
      "name": "Language Generation Evaluation",
      "definition": "Language Generation Evaluation refers to the process of systematically assessing the quality, accuracy, coherence, and relevance of text generated by language models. It involves using various metrics, benchmarks, and human judgments to determine how well AI-generated language outputs meet desired standards of readability, factual correctness, and contextual appropriateness. This evaluation is crucial for refining models and ensuring their outputs are reliable for practical applications.",
      "categoryId": "a0e248ec-018a-450c-a6ff-024f7fe3a7d7",
      "subcategoryIds": [
        "4d2c5193-23a8-4b7e-823b-3b9f7e7ba0bb",
        "5c7c1cb2-5bf0-42b6-9e6c-c26905b38320",
        "8ba014e0-d5b3-412a-adae-ae8050235e67",
        "84a40f1c-841b-45d2-84ad-1eafba837db2",
        "f8b473cd-7718-4133-8cc3-106c6ca5f547",
        "87c97821-1783-44ef-aae6-81a3e08cb3a9",
        "d986e5ee-b132-428a-bd08-f13b7ea70aa9",
        "a48976a3-6831-46de-a54a-cc1fa55f4c6a",
        "8314fc65-fcb0-42b4-8ef1-c8642ceb9fb6",
        "ffede9e0-2f04-49c0-bdfc-6dcdf0cc7e2b"
      ]
    },
    {
      "id": "4eb75b9d-928d-471c-a0c6-537ba9e31c45",
      "name": "Language Generation in Robotics",
      "definition": "Language Generation in Robotics refers to the application of natural language processing (NLP) and artificial intelligence techniques to enable robots to produce coherent, contextually appropriate, and human-like language responses. This involves not only understanding human language input but also generating meaningful spoken or written language to interact effectively with humans in various contexts, such as service robots, autonomous assistants, or collaborative agents.",
      "categoryId": "dd7ed944-5362-4778-9b2c-00a657481e3f",
      "subcategoryIds": [
        "3943c2f3-7222-4754-bbf6-c64ed8b6dbef",
        "e0e6df6c-f26d-431e-b8bc-8844ef24e1b8",
        "3f29eff2-8294-4079-b1ea-6c902324af6b",
        "0de50da1-f11c-4cc8-817a-0fafc9b6033d",
        "1b6681ff-28cc-45cb-98d3-3a8ab774aacd",
        "befd0722-5119-4590-bc3e-0f8dd21b26c4",
        "265a1629-4564-49b3-b11c-dc7fa7e66328",
        "960fcbfe-ed0f-405f-85c6-97e2d3492791",
        "faf15def-22ed-4cf6-ba64-0b35c23561a9",
        "95352cb8-b213-4d62-b0b6-78bbc13e0e52"
      ]
    },
    {
      "id": "9a99ba97-ca60-4cb3-b7ac-0b264e57ce15",
      "name": "language model adaptation",
      "definition": "Language model adaptation refers to the process of modifying or fine-tuning pre-trained language models to better suit specific tasks, domains, or datasets. This involves adjusting the model's parameters using additional training on targeted data, enabling the model to generate more accurate, relevant, and contextually appropriate outputs within a particular application or domain. The goal of language model adaptation is to enhance the performance and utility of language models in real-world scenarios by making them more aligned with specific linguistic, cultural, or domain-specific nuances.",
      "categoryId": "29861353-f354-406d-b64b-c1255eb0bc79",
      "subcategoryIds": [
        "d3aff5c2-023f-43d5-b502-675fc8b7ce08",
        "e1c09896-2001-4eca-9ec1-555b52b4a325",
        "740b9937-ad92-425d-9c8a-aa7cd2575b23",
        "5712787f-2694-4448-a85e-233ed1f0abc2",
        "4ceb35be-d5f6-42de-b671-c41f2afc2724",
        "c04a9613-b4ca-42be-872e-09a32c31bd68",
        "0835d104-3fca-4502-b7f1-21d63b5d77f7",
        "c2d2c529-bd79-408e-abf7-ee09c99b1402",
        "70b5a382-9235-4a8d-ba9d-8115d1e314d9",
        "cd2b49dd-9983-48ec-8b1a-6aff362fb8c9"
      ]
    },
    {
      "id": "88738192-9e6f-4b02-b5af-23f131dd0479",
      "name": "language model evaluation",
      "definition": "Language model evaluation refers to the systematic process of assessing the performance, accuracy, and quality of language models\u2014such as neural networks trained to understand, generate, and interpret human language. It involves applying various metrics, benchmarks, and testing procedures to determine how well a language model meets specific linguistic, contextual, and task-oriented requirements, thereby guiding model development and deployment in real-world applications.",
      "categoryId": "c7c67f26-e995-4ed5-92a0-6ed12ae458bd",
      "subcategoryIds": [
        "1b3be4f8-3a21-4049-88e8-cd50460b6b87",
        "5d74e2cb-1122-4c76-b281-57c79689d730",
        "160595f2-31c3-4dd8-bbcf-5f07a23d3c70",
        "d968b26a-132a-4966-937d-331ef39f87b8",
        "74dd99aa-a670-4f52-994f-e931ed1cfc1f",
        "32eecac1-6a9c-4856-b23e-2282d342bd69",
        "235de4fb-0d2a-4dab-adbd-97e5a63a84a4",
        "a5948fa0-86e1-4a6a-aadf-cd2d963491f1",
        "702fe3c7-b41d-44a7-b865-37ff1a81513d",
        "bcd24414-956a-4015-8e1a-aefa1d64327c",
        "8ddff22e-3513-48f8-bcad-187de0c09022"
      ]
    },
    {
      "id": "32bf4d5a-898e-44ed-9d89-910aa6f8068b",
      "name": "Language Model Fine-Tuning",
      "definition": "Language Model Fine-Tuning refers to the process of adapting a pre-trained language model to perform well on a specific task or domain by further training it on task-specific data. This technique leverages the general language understanding captured during initial large-scale training and refines it to meet particular application requirements, enhancing accuracy, relevance, and performance in targeted language tasks.",
      "categoryId": "c25cc053-793f-446d-904f-fc6f51f14422",
      "subcategoryIds": [
        "55b38c55-92e3-4f30-9aee-98068b5823d6",
        "87717397-79e8-40aa-bc4f-e9f58cfc5d21",
        "7ce0abc8-19a1-4ed3-8ad2-81d8df8d47e3",
        "2744cbc4-4cba-487a-8f9a-376ed3da10b4",
        "4a13b670-1d49-44d3-90b6-5671c301cc6a",
        "b50a1596-7cc0-44fe-b885-d4d21c7993fd",
        "f4fc5cb1-5b00-4bd0-878a-1354f9fced95",
        "44788346-3c7d-4e03-8ed3-4c9a607e6f3d",
        "d1292fde-7373-490e-a95c-2773594a60d2"
      ]
    },
    {
      "id": "032a6f41-4de8-4108-bb24-ac46440de587",
      "name": "Language Model Pretraining",
      "definition": "Language Model Pretraining refers to the process of training a neural network-based language model on a large corpus of text data before it is fine-tuned for specific downstream tasks. This pretraining enables the model to learn general language representations, understanding syntax, semantics, and contextual relationships, which can be later adapted for tasks such as translation, summarization, question-answering, and more. The core idea is to leverage vast amounts of unlabeled text data to develop a versatile and robust language understanding system that reduces the need for task-specific labeled datasets.",
      "categoryId": "83f17289-a385-485d-a871-d0b2aa12f325",
      "subcategoryIds": [
        "38d3c48d-5ba3-4ce9-8065-63336444ea85",
        "aa5406f7-4617-4b05-8593-f7a4173067c6",
        "9a273478-2f60-4fe8-87ec-9722b4174163",
        "8e8ac3af-2740-438c-a06c-2fe94953a465",
        "451982ed-f707-4a2c-bc07-bfc4e59fc0b4",
        "fd4a717f-0d0c-465a-a3cb-79ec6e4661be",
        "d3625ae6-fbbd-492f-9237-2dd7feb6bd96",
        "729f1863-a474-4567-b29b-64a8e98188d9",
        "54e429d9-a0aa-4c9f-b496-4821ed9caa91",
        "c7813086-f603-46c3-8a7c-456422925112",
        "284367fb-ee2a-4f44-9d76-314f9e370b86"
      ]
    },
    {
      "id": "9568f317-efd3-4788-bed3-f9565460891a",
      "name": "Language Modeling",
      "definition": "Language modeling is a fundamental task in natural language processing (NLP) that involves developing algorithms and systems capable of understanding, generating, and predicting human language. Essentially, a language model assigns probabilities to sequences of words or tokens, enabling applications such as speech recognition, machine translation, text generation, and autocomplete systems. Modern language models, especially those based on deep learning architectures like transformers, have dramatically advanced the capacity to comprehend and produce human-like text with contextual understanding.",
      "categoryId": "68a34110-1aef-4dee-a219-19cac6ec7ed0",
      "subcategoryIds": [
        "9269897c-80af-4b70-a0f4-b1a6d872cb8f",
        "29f2f6fa-d2ae-43b6-a362-0562f41ee368",
        "54358df3-f222-4f3e-9a75-dba846914119",
        "1e1c0a0b-32ff-42f1-8a40-5790eae7c6e0",
        "0e4cf086-293d-4bdc-963a-2333cfa23811",
        "6c5eacab-85bc-4f15-81e0-00ceba6e2156",
        "ea24e375-c2b8-4c74-810a-014c7b807d2b",
        "62dfaf8b-f1d6-4e1c-a9f7-487f9cc53474",
        "c83dd678-cbf8-4fd7-ac2f-c337c95f0c6d",
        "48fdb0b2-ce71-4c4c-a7a6-13623ecbaadf",
        "78fda110-d26b-4f95-9fe9-69af5e5ba240",
        "9817c6de-7c55-4178-8cba-1ff72fe5f8d4"
      ]
    },
    {
      "id": "523ab42b-f149-4b51-9c38-eb2d11cdaca9",
      "name": "Language Models",
      "definition": "Language models are a class of artificial intelligence systems designed to understand, generate, and manipulate human language. They are trained on large corpora of text data to learn statistical patterns, syntax, semantics, and contextual relationships among words and phrases. These models can perform a variety of language-related tasks such as translation, summarization, question-answering, and text generation, making them fundamental tools in natural language processing (NLP).",
      "categoryId": "1b39fd05-f939-483a-97b7-76ac4fac7094",
      "subcategoryIds": [
        "ce4d42b1-22cb-425f-aee1-cf49f839929f",
        "2b222c12-9bb7-4aee-8a0e-d9a94fe7ef67",
        "9cc5a5c6-535d-43dc-91d8-68b6de77e325",
        "e65eb1a6-80bf-4042-9a56-dd76c80ea31d",
        "f6a1ca23-a974-4801-9442-67b956f13f62",
        "85373010-a744-4b2f-83a2-9b10a7257f47",
        "64921dbf-55c3-4b54-9fd6-94dc3061747b",
        "f696ba94-2463-4db1-b43a-2ac60844e907",
        "624274a8-3316-446e-814a-b4dfdb83b926",
        "14295711-3367-4466-a27a-7c5e07e3f232",
        "e8970752-77d2-4086-b835-f1541bf3a3cd",
        "72677967-aa1e-4177-a7c4-95f95913125b",
        "cd68ecaf-3351-4db4-9fc7-cc26d869967c",
        "0e60dd62-7aef-4ae5-8008-bf10bc215e2f",
        "091f8001-d8a9-4048-a1ff-0f88cfd54b67"
      ]
    },
    {
      "id": "ff6b7dcf-57c1-46a0-8ca0-a5c54f90f38a",
      "name": "Language Models (e.g., BERT, GPT)",
      "definition": "Language models are a class of artificial intelligence models designed to understand, generate, and manipulate human language. They process large amounts of text data to learn the statistical and contextual patterns of language, enabling tasks such as translation, summarization, question answering, and conversation simulation. Examples include models like BERT (Bidirectional Encoder Representations from Transformers) and GPT (Generative Pre-trained Transformer), which are built on transformer architectures and have significantly advanced natural language processing (NLP).",
      "categoryId": "7ce04689-9d02-4038-9353-68d11c54b9fd",
      "subcategoryIds": [
        "a1e2e98c-6f3f-421c-b271-63dd0524c1a1",
        "7c8ea90d-47a6-4c81-8a03-d24cd54fc98e",
        "99382cf2-d423-4567-84fe-2140376d0da6",
        "adb149f4-a664-48fb-8080-083487cf54d7",
        "2f956404-7972-4735-b999-e3882098ee69",
        "1664c83d-9068-474d-b526-41ec1e068c68",
        "2de3ac0e-e833-4e24-bb73-7213fd767236",
        "6fc375d5-66bc-4db3-85f9-9309695616d0",
        "abd9a3ab-bb10-40e2-be06-a5fead2225a7",
        "1e3d39a1-5a2c-4c35-85a3-de56114c4889"
      ]
    },
    {
      "id": "dd17f9ff-ca5f-4c8f-ad64-d882acc804e7",
      "name": "Laplacian Distribution",
      "definition": "The Laplacian distribution, also known as the double exponential distribution, is a continuous probability distribution characterized by a sharp peak at its mean and symmetric exponential tails on either side. It is defined by two parameters: the location parameter (which indicates the distribution's central point) and the scale parameter (which influences the spread or dispersion). The probability density function (PDF) of the Laplacian distribution embodies a sharp peak at the mean with exponential decay in both directions, making it useful for modeling data with frequent small deviations and outliers.",
      "categoryId": "d40eb624-31ec-434b-9e62-1aff69486ca6",
      "subcategoryIds": [
        "fdc72108-767e-41cf-9679-ef615fb25368",
        "7b821f7e-6bff-4e0e-9ef0-5ee043adfc58",
        "b20ca6a9-8f66-4c1f-b213-f692e97027ef",
        "6400d38b-cc6b-4ab0-94c8-ef756d2dac09",
        "afc19ceb-498d-4ad2-9566-2126c63eb37f",
        "50f2b226-359f-44cd-9fe2-6bc66e3c2cbc",
        "a6f31dc3-5846-41e3-a467-28068d18a7b8",
        "f4c5f149-7ee4-4628-a671-79d17b89e924"
      ]
    },
    {
      "id": "c6d12f56-9b22-411c-a916-f8b239d2bfa3",
      "name": "Laplacian Regularization",
      "definition": "Laplacian Regularization is a technique used in machine learning and graph-based learning algorithms that leverages the Laplacian matrix of a graph to impose smoothness constraints on functions defined over data points. It encourages the learned function to vary smoothly across the data manifold, thereby improving generalization especially in semi-supervised learning scenarios. This regularization term incorporates the graph structure to penalize models for significant variations across neighboring data points, ensuring consistency and coherence in the learned representations.",
      "categoryId": "e5f197c3-e00a-4c39-8e04-cb47c529ef8b",
      "subcategoryIds": [
        "cae56b97-edf9-4733-b330-1c68064259fa",
        "47f52594-9878-4e81-aedd-eb9981b81370",
        "01c81f1a-ed03-4cf6-af2b-6b2dcd066aa8",
        "4b9acf9f-9517-477c-ab12-202a3435ad78",
        "70a8188b-7bd3-4786-8b07-924711a0bcc6",
        "c71f8903-e046-4133-86e3-41ebeed36982",
        "0efc4073-0197-4798-972a-9712efe39fe7"
      ]
    },
    {
      "id": "61fd8683-6ff0-4bad-ba30-ab12c155c6ea",
      "name": "Large Foundation Models",
      "definition": "Large Foundation Models are extensive pre-trained machine learning models that serve as the groundwork for a wide range of downstream AI tasks. These models are characterized by their massive size, often containing billions or even trillions of parameters, enabling them to understand and generate complex data like language, images, or multimodal content. They are typically trained on vast and diverse datasets, allowing them to capture broad contextual understanding which can then be fine-tuned for specific applications.",
      "categoryId": "8ba0c392-1499-48d0-9d26-b9db4d846921",
      "subcategoryIds": [
        "df86cd67-188a-4769-80f1-b05c50eef10c",
        "6d859d5b-81de-4463-b731-b52192a82dbb",
        "7496f13d-9c88-47bb-8eed-26b8c233130e",
        "ff5f1bc3-d526-4f7f-9bdf-642fbb17b57f",
        "9632d11b-25a3-4a55-8c26-4eaee8521b98",
        "81478beb-a449-4a5d-9f46-6291783d019a",
        "0e58bd5f-4d52-4848-8cdc-8ccae5b6c203",
        "3a316f1b-f93c-43bc-b533-2130f87feba1",
        "135ad075-3367-45bd-8f0c-d50d84199693",
        "5fab44c7-16c8-4567-8c44-fe09b1ee93a5",
        "f828c06c-80b2-47d5-a1ce-da0d7cb23690"
      ]
    },
    {
      "id": "14db1926-9ffa-4b2c-8f38-f18c29b1590c",
      "name": "Large Language Models (LLMs)",
      "definition": "Large Language Models (LLMs) are advanced artificial intelligence systems designed to understand, generate, and manipulate human language at a high level of complexity. These models are built using deep learning techniques, particularly transformer architectures, and are trained on vast amounts of text data to learn linguistic patterns, semantics, and contextual relationships. LLMs can perform a wide range of language tasks, including translation, summarization, question-answering, and text generation, often achieving human-like performance.",
      "categoryId": "3ee61d83-32ba-4e14-a555-571c40195b78",
      "subcategoryIds": [
        "4097aa23-60f0-465e-8a09-836e7711031b",
        "5d6f99c6-7f70-4613-85ff-2698a82673b5",
        "f838c6e0-7293-4d2f-a02b-f0625fef22f5",
        "bf01810b-7c16-48c9-b1e2-8aebf4b0890e",
        "438fca87-c5f9-4156-b7ad-2b7374756cb4",
        "0e22bc22-2e66-41ca-9b71-03c8d5982f98",
        "36a72913-257f-4ad4-b1bc-49c3cc578287",
        "9e889e7c-a869-4246-aaf0-3f96aab36c4a",
        "34071fe7-a1bf-4894-bf74-5ea116207ead",
        "4631cc83-e2a2-4c79-a626-124933d39224"
      ]
    },
    {
      "id": "1d3e2ddd-0a2f-47a9-adb6-d703287bf7cb",
      "name": "Large Model Architecture",
      "definition": "A Large Model Architecture refers to a type of neural network design characterized by having a vast number of parameters, often ranging from hundreds of millions to trillions. These models are built to process and learn from massive datasets, enabling them to perform complex tasks such as natural language understanding, image recognition, and decision-making with high accuracy. Examples include transformer-based models like GPT-3 and large-scale convolutional neural networks used in computer vision. The primary goal of large model architectures is to leverage extensive capacity to capture intricate patterns and relationships within data, resulting in more powerful and versatile AI systems.",
      "categoryId": "081dd52e-9610-43a8-9200-f32b30349251",
      "subcategoryIds": [
        "10b697ef-3f8e-4f84-8421-4f79831482b2",
        "27b3fc49-0b7e-4bd7-a64f-0d7641851ea4",
        "08d96cb9-6cca-4f79-be1c-88ed7eb25dba",
        "1ce8297d-5347-4d66-af1b-d6ec52a302c4",
        "e91e0d3d-391a-4423-a27f-28e914c9a65b",
        "3c3bb2aa-1c26-46f0-8cb6-ee5d23463a7c"
      ]
    },
    {
      "id": "ad0b4591-0bf5-42c9-b1c2-fcf681c308ff",
      "name": "Lasso",
      "definition": "Lasso, short for Least Absolute Shrinkage and Selection Operator, is a regression analysis method that performs both variable selection and regularization to enhance the prediction accuracy and interpretability of statistical models. It introduces a penalty equivalent to the absolute value of the magnitude of coefficients to constrain or shrink some coefficients to zero, effectively selecting a simpler model by excluding less important features.",
      "categoryId": "b70b98c0-09e1-4cb5-b0f2-a3b03b850e7e",
      "subcategoryIds": [
        "b5ec2fa5-6e85-4eaf-b53e-b54052401177",
        "98c1b6f6-b38b-4928-bed3-2c1b50e81c45",
        "dc7817a5-f2b5-4b35-97ae-4a946cd47a4c",
        "5b7b2228-0583-4d94-b95d-f86170e7442b",
        "bb69979a-d26f-4c47-8d62-a627338a4f10",
        "db6991de-f9c7-4a6c-a1eb-f1d2001371e6",
        "354a2992-6f0f-4575-9395-aa94d4c0e1ca",
        "0c9eb019-b17b-4a88-92ba-d15a9907964c"
      ]
    },
    {
      "id": "bc1fe13c-1433-4aa3-b4fb-2c6924359688",
      "name": "Lasso Regression",
      "definition": "Lasso Regression, also known as Least Absolute Shrinkage and Selection Operator (Lasso), is a statistical method used in linear regression models to perform both variable selection and regularization. It introduces a penalty equal to the absolute value of the magnitude of coefficients, which encourages sparsity in the model by shrinking some coefficients exactly to zero. This enhances the model's interpretability and helps prevent overfitting, especially when dealing with high-dimensional data.",
      "categoryId": "738a6bae-54b8-4fff-98c8-b9f6bf96477f",
      "subcategoryIds": [
        "026abae5-2d75-4c9b-8413-06903161d8e0",
        "ea6404f7-079a-4ee7-a456-3d6da333d10a",
        "1a1b899e-cfcc-4394-8449-b135873336f0",
        "4ad89322-443d-49f4-9c9c-4b181dc93147",
        "1d3c458a-7ab1-4440-8429-900e4013bc14",
        "578760c2-9063-4a81-9f66-4774b653ec6e",
        "e37c1f0a-fc1b-4607-b749-2e3f71ef2533",
        "dd91eac9-aad4-4d88-9af2-74e6c975eec1"
      ]
    },
    {
      "id": "18a8b498-68b3-4db7-9b27-cbb1b4836985",
      "name": "Lasso/Ridge",
      "definition": "Lasso (Least Absolute Shrinkage and Selection Operator) and Ridge regression are regularization techniques used in linear regression models to prevent overfitting and improve model generalization. Both methods modify the ordinary least squares objective by adding a penalty term based on the magnitude of the coefficients, encouraging simpler models. Lasso adds an L1 penalty, promoting sparsity and feature selection, whereas Ridge adds an L2 penalty, shrinking coefficients towards zero but not necessarily eliminating them.",
      "categoryId": "293d145e-3b41-4bd3-bdf8-d8aae6a49633",
      "subcategoryIds": [
        "673afa9a-d1b0-4560-84d6-b825e61c0276",
        "2043f240-a15e-4f9f-b3cd-3c801c4118f9",
        "19431ae8-f9e4-42b0-be3d-dafe61608648",
        "129f6042-1c00-4829-8361-0dc39be0a170",
        "5ba4e7e1-6ece-4f13-b5d3-040b3f397af4",
        "498d971a-4368-4133-8e04-0c59fb5d1ffe",
        "2bcecdec-c877-4fb9-969a-e9f31eb1b5fa",
        "b89b3652-cb86-4b2f-a488-db9bd5d7f4ec",
        "1d467281-2399-454d-bc7e-7fb24534d384",
        "2ee531a1-e8b5-4b01-ac03-c764a41ecf47",
        "09279ba5-438c-4ff9-999b-13f216f991cf"
      ]
    },
    {
      "id": "b0ff2161-cafc-46bf-bb1c-b60ea70791c9",
      "name": "Lasso/Ridge Regression",
      "definition": "Lasso (Least Absolute Shrinkage and Selection Operator) and Ridge Regression are regularization techniques used in linear regression models to prevent overfitting and enhance model generalization. Both methods modify the ordinary least squares (OLS) loss function by adding penalty terms based on the magnitude of the coefficients, encouraging simpler, more robust models. While Ridge Regression applies an L2 penalty that shrinks coefficients towards zero, Lasso uses an L1 penalty that can set some coefficients exactly to zero, enabling feature selection.",
      "categoryId": "623343fe-a47b-418b-9c99-4f89338c2e57",
      "subcategoryIds": [
        "f79890f1-32be-45c4-a683-af746b58cc1d",
        "7d03e886-fb78-4c21-ad0d-bf23972c1d93",
        "6387cdfc-f94f-4cc2-af20-e0cb89e5a1c9",
        "0129eea1-6556-4db1-baa9-be3480a05574",
        "7d4c4a17-e5fa-487e-98a5-6d3526faa1e2",
        "848b1da7-2d33-40a4-a9e3-3700a128e201",
        "bfb00585-6f02-4ec8-b143-c5a925da63de",
        "6b4d5de6-7f2a-410a-af9e-c15103df8cb8"
      ]
    },
    {
      "id": "8ed98095-d6a2-4b20-b0d3-5484efa4ff95",
      "name": "Latency Optimization",
      "definition": "Latency Optimization in AI/ML refers to the process of reducing the delay between a user's request or input and the system's response. It aims to make AI/ML systems more responsive and efficient by minimizing the time taken for data processing, model inference, and communication across different system components. Effective latency optimization ensures real-time performance, enhances user experience, and is crucial in applications where prompt responses are critical, such as autonomous vehicles, real-time analytics, and interactive AI interfaces.",
      "categoryId": "be926310-7863-4039-80de-38cdc305d7a7",
      "subcategoryIds": [
        "a777227d-68d4-4b97-8bf6-3828756c1e99",
        "db03d65b-3f49-4728-9224-9d294af0c004",
        "e6e54b78-4a64-45c7-9901-5ff99d2fb15c",
        "5e8d78f3-e53a-4ede-a8ad-36592f7a5097",
        "69a8daf4-d5d7-4837-96d8-480aeabc086a",
        "4b4ae1da-f813-4be5-9260-282e1871e16c",
        "a1335708-6610-48ae-92b0-feca945b6df5",
        "5fdd1e76-c851-4922-8f1c-439a73fce913",
        "68dcf394-d61e-46ca-8608-6d826068de76",
        "465860a6-f2e3-4129-ba8d-3a7a4c84947d"
      ]
    },
    {
      "id": "f6953526-9e86-4aa1-b52b-c47641ce9f32",
      "name": "latency-aware training",
      "definition": "Latency-aware training refers to a set of techniques and methodologies in machine learning where the training process is optimized by accounting for the latency or response time constraints of deployment environments. This approach aims to modify learning algorithms, model architectures, or training procedures to ensure models can deliver predictions within acceptable latency bounds, especially crucial for real-time or near-real-time applications. It involves balancing model accuracy with inference speed, often through model simplification, optimization, or specialized training procedures that consider the latency requirements during the learning phase.",
      "categoryId": "13d6cfbf-6802-4c47-ad77-d9e42552b977",
      "subcategoryIds": [
        "c4665ca8-c990-494c-bd1e-65e73f6fd37a",
        "fd7e3aa0-02db-4efa-a33a-250365f89bcc",
        "44e767ff-9e9d-42a7-b950-e45af8e4d58f",
        "c7b32ceb-2614-46ff-8fad-ffa32d1fb217",
        "22dbcda5-9904-4ba8-8816-7a25a1d76c5d",
        "c2030b59-7411-4598-927c-b507aa3bbff1",
        "d34dd36b-7fe3-47fc-87d2-ccaeaab96a75",
        "1984b619-0d01-4278-a9d4-6f912cb3541d",
        "104a54e4-9947-49b2-9d1b-a17c56168868"
      ]
    },
    {
      "id": "588fed23-f836-4196-8796-be5fa3958d2c",
      "name": "Latent Bottlenecks",
      "definition": "Latent Bottlenecks refer to hidden or subtle limitations within a neural network's architecture or training process that restrict the model's capacity to learn or generalize effectively. These bottlenecks are not always immediately obvious but can significantly hinder model performance by constraining information flow, reducing the richness of learned representations, or causing overfitting or underfitting. Detecting and alleviating latent bottlenecks is crucial for optimizing deep learning models, especially in large-scale or complex tasks.",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd",
      "subcategoryIds": [
        "ba2398df-38aa-435d-beb1-85551c9a10fd",
        "ca240c55-bc42-4383-945e-86fabb9ef8ed",
        "4337f19e-e95a-4f76-9890-32101d01df2f",
        "ed832016-911a-46ff-9a89-fb2394e1cb23",
        "c9e8fee6-39f6-4548-80a6-c0810d6b602f"
      ]
    },
    {
      "id": "55bedceb-d7ad-498d-aa1d-47551c0342ba",
      "name": "Latent Diffusion Model",
      "definition": "A Latent Diffusion Model (LDM) is a type of generative model in the field of artificial intelligence that utilizes the concept of diffusion processes operating within a compressed, lower-dimensional latent space to generate high-quality data, such as images or audio. It combines the principles of variational autoencoders and diffusion probabilistic models to produce detailed and coherent outputs while maintaining computational efficiency. Unlike traditional generative models that work directly in the high-dimensional data space, LDMs perform their operations in a learned latent space, enabling more scalable and faster training and inference.",
      "categoryId": "3e8a0f67-698b-4ccf-9438-e31ac1cd3ab5",
      "subcategoryIds": [
        "2b793608-43d7-4ad0-b43c-cc825dd4a4d6",
        "8c905b18-e2ac-447a-a49c-c72fbfb4d9aa",
        "ddd7c3de-7b06-4e04-b13e-5fb18eeeffce",
        "42712bcc-47bf-4947-b9da-38b5550afd57",
        "d8a64297-0160-4973-b085-91ae3d7ada31",
        "cfaeff11-77b9-4f37-b3e9-01060bf0eac2",
        "41f23cca-fb80-4155-aa39-b614255c951c",
        "fae435c7-11e1-4d33-83b5-5cb99f7f3f08",
        "1e5cc1cd-24ec-46fa-9658-6cdb344c8873",
        "65f76f4c-08af-4587-87b8-678593e46051"
      ]
    },
    {
      "id": "b2927916-d412-4386-84d1-6c56b922a999",
      "name": "Latent diffusion models",
      "definition": "Latent diffusion models are a class of generative models in machine learning that utilize the concept of diffusion processes in a latent space to generate high-quality data, such as images, audio, or other complex modalities. These models work by progressively transforming noise into coherent data through a learned reverse diffusion process, operating efficiently within a compressed latent representation rather than directly in pixel or raw data space. This approach enables scalable, flexible, and high-fidelity data generation, making them a powerful tool in artificial intelligence applications.",
      "categoryId": "3211afce-2d2a-4bd7-8220-ed642e49b2b5",
      "subcategoryIds": [
        "4cad352f-52a1-4ac3-96b3-d1a2aa1b4c06",
        "12723ca4-58ef-4ad9-8a60-ad3df2732233",
        "6208d6c7-20da-4a9f-814c-b2c27e49a3ce",
        "2918d598-59e1-4040-9847-8677d8cfe1e8",
        "1567b1da-9eda-44ec-9d6c-2323062140d1",
        "2ce56870-336b-47b0-aaa5-8a368dcdf724",
        "6f1a7223-6b53-4c13-b223-865b1cd4aa64",
        "81d49c76-aeb3-41f6-89eb-a4cfb679a9a8"
      ]
    },
    {
      "id": "82366f3a-0bba-41f6-ba35-18af19b12073",
      "name": "Latent Dirichlet Allocation (LDA)",
      "definition": "Latent Dirichlet Allocation (LDA) is a generative probabilistic model widely used in natural language processing and machine learning for discovering abstract topics within a large corpus of text data. It assumes that each document is a mixture of multiple topics, and each topic is characterized by a distribution over words. By analyzing the patterns of word co-occurrence across documents, LDA uncovers hidden thematic structures and assigns probabilities to different topics within individual documents, enabling tasks such as topic modeling, document classification, and information retrieval.",
      "categoryId": "6bd59b84-978b-4ae6-a812-c596d49a29aa",
      "subcategoryIds": [
        "5226325b-b454-4a92-bbe7-900acd0c13a2",
        "310cee59-2880-40f7-80cf-58069ef14df6",
        "69c8b09a-bf06-497f-bbd4-f09f7864d8a2",
        "492450b9-9f79-4cf8-9773-f7b803136f33",
        "91cd6c7d-fbdf-45f4-bee3-48ca089d9f2e",
        "544b2b90-fc4f-44f8-99c3-1743e63b23ef",
        "33bad4fa-0796-4ada-b7a0-ed425f4c3292",
        "de90910c-4d88-48a4-960f-9c923f0e0362"
      ]
    },
    {
      "id": "24ce7282-8353-4d37-af26-0f4e10b99efc",
      "name": "Latent Dirichlet Allocation (LDA) Techniques",
      "definition": "Latent Dirichlet Allocation (LDA) is a generative probabilistic model used for discovering abstract topics within large collections of text data. It assumes that each document is a mixture of various topics, and each topic is characterized by a distribution over words. LDA aims to identify these hidden (latent) topical structures by analyzing word co-occurrence patterns across documents, enabling automated topic discovery and text summarization in a scalable manner.",
      "categoryId": "07424377-51ad-489f-a046-e4e860551930",
      "subcategoryIds": [
        "fa79fb6d-f3bc-4178-994b-527e8a66fc59",
        "8e5ac8a4-7c5d-4ea3-ae47-ee6eefe7707f",
        "c1b2dcaf-c9fa-44d2-8b95-8765f4e5086b",
        "9fd88dbe-4661-44d8-a74e-73db50851a11",
        "733311a9-68c5-4464-b21e-f7924abb5a66",
        "ea3bc011-e364-4962-ab73-f4cba2ceb265",
        "ad903595-cf80-466a-a25e-00e59d08049e",
        "5b6cbe7d-a0d3-472b-96b9-38b7f11e32d1",
        "6a24c4ad-7590-4c42-9b41-a58dcc8865f2",
        "ea1ce754-7684-49b6-bfb7-090513d047e8"
      ]
    },
    {
      "id": "5aad9303-571f-4257-aba9-4d7a434f0d80",
      "name": "Latent Information Bottleneck",
      "definition": "The Latent Information Bottleneck (LIB) is an extension of the Information Bottleneck (IB) framework, which aims to extract the most relevant information from input data while compressing irrelevant details. LIB introduces the concept of a latent space\u2014an intermediary representation\u2014that serves as a bottleneck for information flow, enabling models to learn compact, meaningful representations of data by balancing compression with predictive power. This approach is particularly useful in deep learning architectures where understanding and controlling the flow of information through layers can improve interpretability and generalization.",
      "categoryId": "2ed7b5c6-e7ef-4b58-aafa-176349399b9b",
      "subcategoryIds": [
        "1d8aa901-ad0b-4071-a933-35effa5ff2ee",
        "37050455-9e27-4aab-9a83-005969b3338c",
        "5519d86e-d38f-41f7-957a-ad02a1d12307",
        "08a8f894-d63e-483b-9d5a-7778f95f6284",
        "599107e9-3e09-466f-a3d4-ce8c38965f5d",
        "56779133-9b64-4146-9e32-74e84acf84f7",
        "152a5702-dd90-4354-ad82-cbae6adea2e2",
        "02effe67-d23c-486e-83a1-76a10a799c27",
        "14e761d8-bcae-472c-824a-08563e89e661",
        "756690f1-caa9-4e99-9288-1079758e22a8",
        "8bd0f4cc-0f18-4982-9c0a-6dd03403b46e"
      ]
    },
    {
      "id": "d7ec4a16-680e-47e5-bd10-40ba11ff5c9a",
      "name": "Latent Semantic Analysis (LSA)",
      "definition": "Latent Semantic Analysis (LSA) is a natural language processing technique that aims to analyze relationships between a set of documents and the terms they contain by producing a set of concepts related to the underlying structure of the data. It is primarily used to identify patterns in the relationships between terms and documents, capturing the latent (hidden) semantic structure within large text corpora. By transforming text data into a lower-dimensional semantic space, LSA facilitates tasks such as document similarity, information retrieval, and text clustering, enabling more meaningful understanding of textual data beyond superficial keyword matching.",
      "categoryId": "14867a94-bcae-4075-8ee4-7154def1ed01",
      "subcategoryIds": [
        "5da7a85d-2787-4ab8-b6f0-5e4887aaf317",
        "30852a50-c99a-4a09-a6cb-f8d086665cf0",
        "673ea721-093b-44ff-a9b8-c4859fc2aaa5",
        "397d5ac1-4ba6-43bd-8037-9a39c697ebe7",
        "620b8ff1-7e6b-4e74-83c3-e03a2f432cbb",
        "175d8644-c31f-452f-a340-24a96223b428"
      ]
    },
    {
      "id": "74f9addc-ef9b-4a5b-961b-d63fbd3d7ad8",
      "name": "Latent Semantic Indexing",
      "definition": "Latent Semantic Indexing (LSI) is a mathematical technique used in natural language processing and information retrieval that analyzes relationships between a set of documents and the terms they contain. By uncovering underlying, or 'latent', semantic structures in large text corpora, LSI helps in capturing the meaning and contextual associations of words, enabling more effective search and content analysis beyond simple keyword matching.",
      "categoryId": "e439aa10-143d-4c8d-bc4f-0f87e833d241",
      "subcategoryIds": [
        "5f6a999b-6d7c-4acb-9102-14cb4bd2c9db",
        "a4ba1ccd-97f4-4576-b521-3ccc3475bf62",
        "5980d75f-4a66-4197-8b5c-0a623a4329d4",
        "97073224-fa20-4e88-a6fe-c3b4941068cc",
        "53e907cc-dbac-4806-9b71-b96471288699"
      ]
    },
    {
      "id": "87102ba2-c07d-4993-8dbf-04c5e9a9a077",
      "name": "Latent Semantic Indexing (LSI)",
      "definition": "Latent Semantic Indexing (LSI) is a mathematical technique used in natural language processing and information retrieval to analyze relationships between a set of documents and the terms they contain. By uncovering the underlying latent relationships (semantics) between terms and documents, LSI facilitates improved information retrieval by capturing conceptual associations beyond mere keyword matching. It transforms textual data into a reduced-dimensional semantic space, enabling more accurate search results and document similarity assessments.",
      "categoryId": "b1839f82-076b-4d1e-a2a0-824fe015be59",
      "subcategoryIds": [
        "2d01f7df-9b23-496f-a0f8-bc9edcfb22df",
        "2be5315b-d861-4b71-b20e-76ba9f398bb1",
        "7377c36e-2d46-4384-8b51-211991f62f62",
        "31763187-8798-458e-b4f2-43efffffbf1e",
        "02d2613b-308b-41d2-8bc0-dea379f62922",
        "ea45528a-38ca-49f9-9558-9b8161eb899f",
        "b1fc3410-f2a3-4cf2-ad6d-b8e9e3090198",
        "34bb40bd-83c9-44fa-8ece-9e358bb241f3"
      ]
    },
    {
      "id": "4ff43944-bff8-4deb-bdd8-61b940899e34",
      "name": "latent semantic similarity",
      "definition": "Latent semantic similarity refers to a measure of resemblance between two pieces of text based on their underlying semantic meaning, as inferred from their representations in a reduced or latent feature space. It involves analyzing the semantic content of text rather than just surface-level lexical matches, enabling the comparison of documents, sentences, or concepts based on their conceptual relatedness, even if they do not share common words or exact phrasing.",
      "categoryId": "6fdaf690-f56b-4be7-9530-8c1a06b84b99",
      "subcategoryIds": [
        "6fb4e403-d906-4292-ac41-4d907d381ce4",
        "9d2b7f5f-e2eb-4b03-941a-36c6c273bec9",
        "ddcdf5a2-f1d3-4336-bbe1-a6d715dcfc96",
        "a308a31c-f925-4dc2-9a90-36bc7cb40724",
        "059f0206-ac04-4547-b5ee-5d73bb5b9e02",
        "8171eb4b-1097-42cb-8fc1-c7c7203b849d"
      ]
    },
    {
      "id": "1881279e-4200-45aa-995a-137466328756",
      "name": "Latent Space Exploration",
      "definition": "Latent Space Exploration refers to the process of analyzing and navigating the hidden, lower-dimensional representations within machine learning models, particularly generative models like autoencoders and variational autoencoders (VAEs). These latent spaces encode complex data distributions into compact, meaningful features, enabling the exploration, manipulation, and understanding of the underlying structure of the data. By traversing this latent space, researchers can generate new data instances, understand variations within data, and perform tasks like interpolation, attribute manipulation, and concept discovery.",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd",
      "subcategoryIds": [
        "ba2398df-38aa-435d-beb1-85551c9a10fd",
        "40d97c83-d07b-42af-9e4e-053a5ff80214",
        "6d293309-2195-4276-bf97-d590f2c292b0",
        "f97f7c36-2b0d-4421-84e6-d7f1edab33c7",
        "92f3d039-c7b8-4044-ad3b-6bc29f9488db",
        "8a46cf6a-1442-41bb-855f-eb6e19cda79e",
        "ba8bd8ee-5dac-4843-9c87-fd7f89ed3c75",
        "af1647ba-b09a-4b5a-9cb3-c72a50ed6cdf",
        "0c624556-cc0d-4be5-a2aa-67781444b8be",
        "c92b47b7-d911-46a9-ba16-bb29e2671691"
      ]
    },
    {
      "id": "c86f03ab-a488-4cad-8101-104c7e1bcd5d",
      "name": "Latent Space Exploration Enhancements",
      "definition": "Latent Space Exploration Enhancements refer to advanced techniques and methodologies aimed at improving the analysis, manipulation, and understanding of latent spaces in generative models such as Variational Autoencoders (VAEs), Generative Adversarial Networks (GANs), and other deep learning architectures. These enhancements seek to facilitate more precise, efficient, and meaningful navigation within the latent representations, enabling better control over generated outputs and deeper insights into the underlying data structures.",
      "categoryId": "f626050b-7b3e-4633-bd6b-c4e7583cd021",
      "subcategoryIds": [
        "17f34c8a-731e-41fa-aeaa-8d8a8601a68c",
        "db59544c-b20d-4fbd-9152-48c31945792e",
        "3b88edbb-5799-45cf-8408-7622f151fd12",
        "99b1d70f-0b14-4703-9a4a-6f88c6817e04",
        "a138768b-e773-4038-acef-71e2a68f34f5",
        "eb29f43b-a8b3-45f7-b4f9-01d0b72ff298"
      ]
    },
    {
      "id": "4ea277fc-75da-4d7e-9b8c-fc4b60a189d6",
      "name": "Latent Space Exploration Extensions",
      "definition": "Latent Space Exploration Extensions refer to advanced techniques and methodologies that expand the capabilities of exploring, interpreting, and manipulating latent spaces within generative models such as Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs). These extensions aim to enhance our understanding of the learned representations, improve the controllability of generated outputs, and facilitate applications like image editing, data augmentation, and feature disentanglement by providing more sophisticated tools for navigating and exploiting the latent representations.",
      "categoryId": "42ca4030-93f8-49f7-9508-9dc5f2cc3cb5",
      "subcategoryIds": [
        "c725d351-7e5c-44ee-8e6b-5fee31e20a90",
        "573badb4-945d-4b10-ab89-d336785807ba",
        "f4dbdef4-71bd-493e-a71b-57554e95195e",
        "d77c2899-6cdc-40d0-ae91-53dddded2740",
        "88098ed8-ec7f-4587-9786-3c81af9be6e3",
        "43dbaeb6-debf-4ec1-883c-871b75a86075",
        "e9cbb760-6fc6-49e4-8897-7c729b36523d",
        "be60f579-3859-4ac9-8019-ff7435f7e431",
        "e3add5ee-8d6e-458f-b5d4-0f425d393cfc",
        "6ae5dbe0-6b98-40eb-be72-5e3bd096f478"
      ]
    },
    {
      "id": "38bf88df-207c-493a-ab52-1739492aea8f",
      "name": "Latent Space Exploration Extensions Extensions",
      "definition": "Latent Space Exploration Extensions refer to advanced methodologies and tools developed to analyze, manipulate, and understand the latent spaces within generative models, particularly in the context of deep learning frameworks such as Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs). These extensions aim to enhance the interpretability, controllability, and diversity of generated data by probing and traversing the latent representations that encode complex data distributions, including images, text, and audio. They often include techniques for discovering meaningful directions, interpolating between features, and editing latent vectors to achieve desired outputs.",
      "categoryId": "4b3b6d86-b112-4598-91bb-97ba6c587215",
      "subcategoryIds": [
        "b053fe74-00e1-40ae-9f38-6864e322f36f",
        "c84cff55-4045-4e89-a09f-ae08240044a6",
        "b0b23a18-2c46-43c8-b342-3e955e092049",
        "a9f0d2fe-f188-4c8b-bc39-8ef6a5464c89",
        "b65c1197-b5f7-484f-88c4-b0e16f1faf76",
        "f6c9e8bd-c74b-46be-bc2f-6613f1a750fb",
        "7f8f751a-7600-445e-9ac9-cff63801ecb6",
        "74665b88-a6cb-4ea7-8e32-fcea06932d6c",
        "b249a22c-dfda-4f02-8e81-8efd2e80e5c1",
        "43c2e9bd-ef49-4b41-9ad1-4a497c51c2f1"
      ]
    },
    {
      "id": "35301e22-b956-44cd-b986-27d191f64efb",
      "name": "Latent Space Exploration Extensions Extensions Techniques",
      "definition": "Latent Space Exploration Extensions Techniques refer to advanced methods and tools used to analyze, interpret, and manipulate the latent representations learned by generative models such as Variational Autoencoders (VAEs), Generative Adversarial Networks (GANs), and other neural network architectures. These techniques aim to enhance our ability to navigate and understand the complex, high-dimensional latent spaces where meaningful features and data variations are encoded, enabling more controlled and meaningful generation, interpolation, and discovery of underlying data structures.",
      "categoryId": "132a1d10-78d6-47e0-aaed-db18d4661196",
      "subcategoryIds": [
        "82a7890a-840b-40fe-a721-f766756a5ac6",
        "b8de55d6-d962-4c9f-aba1-f52e6c931c93",
        "7c131a44-2490-4727-a1b2-1f5c83320ac5",
        "4c72c862-7103-4c43-9b55-3007bd3f76dc",
        "4876aaab-b503-42ae-b4d6-dd0dcffe7b14",
        "8162017c-c926-4407-8209-65664723febf",
        "073bb664-6466-485e-b8ef-e5c061f60fa7",
        "1c1e4c7a-7b2a-4e27-97ea-4e598ca9757d",
        "cdfe76cc-a632-427b-be5d-cf808fbac4e2",
        "37056d27-6a0e-4ee4-bc06-0ab7a519a4cb",
        "df088d0a-0ad6-4a03-a3b7-c675dcf2a461"
      ]
    },
    {
      "id": "1eb7bdd3-2637-4f6b-a925-f17aed8d4d92",
      "name": "Latent Space Exploration Extensions Extensions Techniques Enhancements Techniques",
      "definition": "Latent Space Exploration Extensions Techniques Enhancements Techniques refer to specialized methods and tools designed to investigate, manipulate, and improve the latent representations within generative models, such as Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs). These techniques aim to better understand the structure of the latent space, facilitate the generation of more diverse and controlled outputs, and enhance the model's capabilities in tasks like image synthesis, style transfer, and data augmentation. Extensions and enhancements often involve developing algorithms that enable more intuitive navigation of the latent space, improved mapping functions, and robust means to interpret latent variables.",
      "categoryId": "fdb982a0-2ecb-4ab2-995e-ff18122d816d",
      "subcategoryIds": [
        "68facd19-3d17-43ac-95ba-3bcda5258f14",
        "51603cef-f0f7-47c6-bfd4-7b95598f9219",
        "47a8b536-2bf2-4b29-8fdc-39945e43e841",
        "b4f20394-be40-4d48-9fac-c94d1979be27",
        "96b0bea4-3171-47bc-be29-f0724e8921ae",
        "4b333df4-27e6-4fdb-b831-7a1d7c396c81",
        "f3c528c2-7c78-470c-bf4e-96aacfadfbe8",
        "62d429cb-a2ce-4116-a1e6-ed68a6732ae9"
      ]
    },
    {
      "id": "d0d2df0b-e331-4cfa-bd1c-8e5b4d1e5433",
      "name": "Latent Space Exploration Techniques",
      "definition": "Latent Space Exploration Techniques refer to methods used to investigate, interpret, and manipulate the representations within the latent space of generative models, such as Variational Autoencoders (VAEs), Generative Adversarial Networks (GANs), and other deep learning frameworks. The latent space is a compressed, often high-dimensional, representation where complex data distributions are encoded in a way that captures underlying features and variations. Exploring this space allows researchers and practitioners to understand the learned features, generate new data samples, and perform meaningful transformations by traversing or manipulating points within this space.",
      "categoryId": "14b2607b-fd5f-4c2d-be29-eaf24b185168",
      "subcategoryIds": [
        "0ee7c5e1-6b55-4712-9664-3f25c02ca6a9",
        "17523c97-d182-4581-80e1-b889bbd1d4d1",
        "cb2df7e1-5ad7-4115-938b-7df7c6da91e3",
        "239f5146-04cf-4207-b096-85bb1bf6bfc7",
        "bd38f0c5-5194-40e4-a691-240395bba823",
        "83ead385-a24f-4a4c-8db7-ceef453c6aa2",
        "a9ef9724-3761-4e41-9e21-0a847bf7ca02",
        "f44692c9-41b3-43d3-86c6-191586c2a57b",
        "7abe19a8-ad1c-42d6-8b6a-7e294bacc656",
        "fc76255c-a8b7-4790-b16a-2bb734f18137"
      ]
    },
    {
      "id": "6ad0a89e-b0e1-4c9a-bc82-82ff0d41a52f",
      "name": "Latent Space Manipulation",
      "definition": "Latent Space Manipulation refers to the process of modifying or navigating within the latent space representations of generative models, such as Variational Autoencoders (VAEs) or Generative Adversarial Networks (GANs), to achieve desired changes in the generated outputs. This technique involves understanding the structure of the latent space\u2014a compressed, high-dimensional representation of data\u2014and applying transformations that alter specific attributes of the generated content, such as facial features, styles, or other semantic attributes, while maintaining realism and coherence.",
      "categoryId": "0b980795-0e8c-4a88-9558-3dc165b50901",
      "subcategoryIds": [
        "431d1080-b667-4dc0-b2e0-92ee54443c8e",
        "4bdb2b95-45dc-4144-b171-76d78efdf444",
        "5ac0ac31-8902-4b9f-a0f7-de3b9b8fbd6e",
        "3ee2cf19-ff30-4042-b43e-c140a3cca21c",
        "54db5441-2f4a-4b9f-a6bd-eb018b451c84",
        "bc3799b0-c315-4b40-8187-403b281331a2"
      ]
    },
    {
      "id": "6b5defb1-08d9-41b5-8002-a32448d4c052",
      "name": "Latent Space Manipulation Methods",
      "definition": "Latent Space Manipulation Methods refer to techniques used to alter or explore the latent representations learned by generative models, such as autoencoders or Generative Adversarial Networks (GANs). These methods enable controlled modifications of generated data (e.g., images, audio) by navigating or manipulating the underlying latent space, which encodes high-level semantic features in a compressed form. The primary goal is to achieve interpretable and targeted changes in output data, such as changing facial expressions, ages, or styles in images, by operating within the latent representations rather than directly on the raw data.",
      "categoryId": "220f5104-cf02-4b0b-a4b6-d9a319f1a437",
      "subcategoryIds": [
        "77510841-aa35-4c90-9b60-5afebd3dd279",
        "80bf16c3-cc31-4c0b-9086-575d76c82f76",
        "c0af7c36-e082-4b50-895e-53aef9984a7d",
        "7b9c11f0-06c9-441b-b40a-8a6681604964",
        "f5811827-7762-4d6c-90e4-91c6c0a1278b",
        "a1e8db92-845f-4405-81cb-ec59cf5bebcd",
        "6fa303dd-6709-471a-90d6-2c8f0533e91a",
        "93e3e227-02bd-44d8-bb4f-f831f6d1fcbe"
      ]
    },
    {
      "id": "97fb60dd-870b-4f29-8dbc-9076e205bc08",
      "name": "Latent Space Manipulation Techniques",
      "definition": "Latent Space Manipulation Techniques refer to a set of methods used to alter and control the representations of data within the latent space of generative models, such as Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs). These techniques enable precise modifications of generated outputs\u2014such as changing facial expressions, ages, or styles\u2014by manipulating the features embedded in the latent vectors. Essentially, they provide a means to understand and steer the generative process by adjusting the underlying latent variables without retraining the model.",
      "categoryId": "aa173205-a10d-488d-b501-8f87aa6d6681",
      "subcategoryIds": [
        "ad4a3356-26ad-44b1-a9f5-3429db65fe90",
        "f7674b89-6971-41f3-91f9-6f4de2d3487e",
        "552921e9-850a-49e3-8448-e50d1967518d",
        "d149b123-59da-42ee-801f-a73e386b7b9a",
        "513dd76c-8e7a-485c-a1b9-5ea02d7e9c3c",
        "9d830fb0-d346-452b-9a23-efac656cd8cd",
        "49a9f46d-3172-4cd8-8e1a-7d7ea563ec5b",
        "bd42eda2-130c-47f6-afbc-25c16f6e049d",
        "360156bf-4074-484e-bda4-2e32da0d19a9",
        "e97c9bc1-67a9-4e6f-923d-ab079b4d81ed"
      ]
    },
    {
      "id": "2247eaa9-804f-440b-919c-ce5767662c84",
      "name": "Latent Space Models",
      "definition": "Latent Space Models are a class of generative models that learn a compressed, low-dimensional representation\u2014known as the latent space\u2014of high-dimensional data. These models encode data into latent variables which capture the underlying factors of variation, enabling the generation, interpolation, and understanding of complex data structures such as images, text, and audio. By mapping data to and from this latent space, they facilitate tasks like data generation, reconstruction, and feature extraction with greater efficiency and interpretability.",
      "categoryId": "c8a1736a-8549-4e98-ab91-480924788bd1",
      "subcategoryIds": [
        "e0db6e19-1b4b-451c-9db7-c4d99dca8ee8",
        "05b58676-4089-49a7-a95b-6d242c579c1a",
        "537ef966-9a2a-41f1-a78f-666ed492bf9f",
        "a4b2b571-ba2a-4e04-8611-c5753f3ea6c1",
        "b0396b1e-37df-4192-ab32-9b319316f6da",
        "63418a55-1c83-492c-b924-6a5ee43832f6",
        "1b2ab2c7-f191-412f-ba9a-7b284a97fc86",
        "63721b08-e317-4106-908b-b5835f796193",
        "caa37c41-5294-4097-83ae-f0aca2a5392a",
        "9f80f28a-852c-463b-8ffb-de5f6dce3eec"
      ]
    },
    {
      "id": "2367daff-16e4-49a7-86be-d708eb91dbc3",
      "name": "Latent Space Navigation Maps",
      "definition": "Latent Space Navigation Maps are representations that visualize and facilitate movement within the high-dimensional latent spaces learned by generative models, such as Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs). These maps serve as navigational tools, allowing users to explore, interpolate, and manipulate the generated data by understanding the structure and relationships within the latent space, enabling controlled generation of images, videos, or other data forms.",
      "categoryId": "90759216-9938-4255-ae89-97f048035020",
      "subcategoryIds": [
        "63cb321b-0890-4fd1-baa5-3055da06f777",
        "9900f54c-f703-45d4-b8b7-9fa7b18a81f1",
        "83f984cb-660a-42dd-9793-941d61bb79f9",
        "e3cca1f5-fa98-4a36-b5a0-03b79bdc1a4d",
        "524918ed-cf3d-415c-baee-4af078d007b0",
        "d5756767-7d4e-4833-bcff-37f817c3f75a",
        "91a53752-83b0-421c-a88b-62ff74accd62",
        "3c499d14-8b60-499b-9499-18c18b9b9998",
        "c7d2c9bc-912e-4dfc-a20c-d547ad306071",
        "fd52dd71-70ef-4e38-bbd1-b63e38f28d52"
      ]
    },
    {
      "id": "e0b7f717-f526-4905-a987-cb55ee3cdeb6",
      "name": "Latent Space Network Models",
      "definition": "Latent Space Network Models are a class of probabilistic models that combine network (graph) analysis with latent space representations to understand and visualize complex relational data. These models embed nodes of a network into a latent (usually low-dimensional) space, where the probability of edges between nodes depends on their positions in this space. By doing so, they facilitate the modeling of network structure, community detection, and link prediction while capturing underlying latent features that influence connectivity patterns.",
      "categoryId": "6361e606-eaca-45f3-a223-7115c8e9e752",
      "subcategoryIds": [
        "6a29373c-bd69-4a20-9d0f-e6eda7bb86c4",
        "d2249c66-71d7-4cbd-b928-d7dd00e1288c",
        "ec2cb002-59d7-42a7-b49a-d955f92a9d7b",
        "e1075808-56e3-434d-a20d-16a4f10eb466",
        "8cb1207a-6e7e-4e71-9e26-40bed790a014",
        "f70099bd-3eba-46dc-971a-0cd2b41749a9",
        "29b9ef70-903a-48e8-8f27-00d7788f9215",
        "2a9625c8-1639-4344-89c7-216c687e27db",
        "60852749-8e72-425d-bc7d-1764a6ee17d5",
        "237cbf64-5f8e-494b-bc2c-5d5050075014"
      ]
    },
    {
      "id": "7fd30ada-b2ed-4f9b-bd62-6b17cbe79450",
      "name": "Policy gradient for text generation",
      "definition": "Policy gradient methods for text generation are a class of reinforcement learning techniques that optimize the parameters of a probabilistic model (often a neural network) directly to maximize a reward signal, such as fluency, relevance, or specific stylistic qualities in generated text. Instead of using explicit likelihood-based training, these methods learn to generate sequences by adjusting model parameters in a way that increases the expected reward, enabling more flexible, goal-oriented text generation.",
      "categoryId": "c340d5b2-b41f-47f7-a9d5-31290268f9e6",
      "subcategoryIds": [
        "cddebbe6-2b71-42f4-9e73-c2196bdeadf3",
        "a377bac3-7468-437f-9419-1c33b041a092",
        "9879733e-0909-46ae-81b2-ca9683181094",
        "afd0cacf-19e4-43b7-b7e3-dc49d679671e",
        "68bc8d4b-02c5-4082-95c9-73e15393d691",
        "775d4119-8d9d-4756-a576-77a42f914747",
        "764aed64-4626-4557-a62e-6c7102490d7b"
      ]
    },
    {
      "id": "2e482526-b5e2-4139-bf5b-d076b90c46ff",
      "name": "Policy Gradient Methods",
      "definition": "Policy Gradient Methods are a class of reinforcement learning algorithms that optimize policies directly by estimating the gradient of expected rewards with respect to policy parameters. Unlike value-based methods that focus on estimating value functions, policy gradients adjust the parameters of a stochastic policy to maximize cumulative rewards, enabling the agent to learn complex behaviors and continuous action spaces effectively.",
      "categoryId": "f6e32c03-e555-47c2-9c98-da6ea9354710",
      "subcategoryIds": [
        "19483483-feca-43ca-899e-0d5e13435057",
        "f5749793-07c9-44e8-8d4d-324d0f01d233",
        "c74c6aee-343a-411e-accf-fceff413db0b",
        "ab540c4a-45c4-4937-ae19-ca1cd013db05",
        "b9b62bb4-d7f7-4e57-9a0b-5524fdcb778e",
        "06221ae0-db1e-4d9b-9d5c-54c27bccebfe",
        "e693e887-4c64-4fca-8463-1da66d9a1538",
        "d9b9c5c5-ee82-4bc4-9e58-3d098219a820",
        "9c862cab-1402-4216-a64a-f25b5d184f01",
        "34fca6e3-fa0e-4933-aea1-d8d7bb0277ab"
      ]
    },
    {
      "id": "59775276-08b6-4eef-86f9-ff3a8fc5829b",
      "name": "Policy Gradient Methods and Variants",
      "definition": "Policy Gradient Methods and Variants are a class of reinforcement learning algorithms that optimize policies directly by estimating the gradient of expected rewards with respect to policy parameters. Unlike value-based methods, which focus on estimating value functions, policy gradient techniques parameterize the policy explicitly and enhance it by ascending the gradient toward higher expected returns. These methods are crucial for solving complex control tasks, especially where the action space is continuous or high-dimensional, and they form the foundation for various advanced reinforcement learning algorithms.",
      "categoryId": "f88d4ab8-8049-4580-a679-1194e7da77ab",
      "subcategoryIds": [
        "39702f80-32d0-4a7e-b8f3-4af08b324afa",
        "855bd9d4-bb4f-4340-a720-6a8e3e681a2a",
        "d67c44b4-945a-4160-a905-aa86c3abada6",
        "21200647-f10d-4890-9caf-aa9cabe7101b",
        "119a285d-53f1-4893-90a8-8b43e4229d6f",
        "01945edb-bab4-42c5-89df-33e431fc3636"
      ]
    },
    {
      "id": "4aa068d8-81a9-423c-a4c8-6551f6ef34c0",
      "name": "Policy Gradients",
      "definition": "Policy gradients are a class of reinforcement learning algorithms that optimize the policy directly by adjusting its parameters to maximize expected cumulative rewards. Unlike value-based methods, which estimate the value function and derive policies indirectly, policy gradient methods explicitly parameterize the policy and use gradient ascent to improve it. These algorithms are particularly useful in environments with continuous or high-dimensional action spaces, where traditional value-based methods may struggle.",
      "categoryId": "99457e6b-e884-42ed-ba3d-a7395d94a4c2",
      "subcategoryIds": [
        "1a1bc431-1319-4d6d-b92c-1146acc30a52",
        "4bb622f4-ff9d-4795-9018-764da9c469ca",
        "7656e394-c1c4-4ff2-b57b-312375a0d072",
        "b3c56d61-d88d-47ff-9b44-5bfe94a0bdb2",
        "e5fe715d-206e-4195-a96d-f1b69f335931",
        "119b7a2d-a783-4ae0-b3e3-15958dd4a136",
        "9053a7bf-8027-4397-9ce3-06e7c05b9ca3"
      ]
    },
    {
      "id": "e5a8b2c8-0bd9-4a0b-b523-c2d9161f30a8",
      "name": "Policy Iteration",
      "definition": "Policy Iteration is a fundamental algorithm in the field of Reinforcement Learning, used to compute the optimal policy for a Markov Decision Process (MDP). It alternates between evaluating a policy\u2014estimating the value function for a given policy\u2014and improving the policy by making it greedy with respect to the current value function. This iterative process continues until convergence, resulting in an optimal policy that maximizes the expected cumulative reward over time.",
      "categoryId": "02ce6114-e7b2-4852-95d4-20b9efa8c190",
      "subcategoryIds": [
        "e39f3663-7eac-4636-b3dd-84e898a8e4b7",
        "5fd6fd94-172f-4306-880c-b62af8668a17",
        "e79a1e9b-9275-4794-bf63-75dc2f9739c2",
        "18d7c531-b134-414a-9707-d6508b942879",
        "b40b770b-865b-4642-8317-43bd8a8f81e0",
        "7619cdda-7b34-4353-9bb2-77f4109cdf95",
        "26ea70a2-d289-4202-940b-b0a38736d11a",
        "204e6ac3-5477-47b1-b557-ba663207c7db",
        "d05a4f0d-77c5-4349-8928-7da326664107"
      ]
    },
    {
      "id": "6c78a05a-1490-40f4-8668-fde53a0e6e4c",
      "name": "Policy Networks",
      "definition": "Policy Networks are a class of neural network architectures used in reinforcement learning that directly parameterize the policy function, which maps states to actions. Unlike value-based methods, policy networks generate probabilities or distributions over actions, enabling agents to make decisions in complex, high-dimensional environments. They are often employed in policy gradient methods, where the goal is to optimize the policy parameters to maximize expected rewards.",
      "categoryId": "99457e6b-e884-42ed-ba3d-a7395d94a4c2",
      "subcategoryIds": [
        "1a1bc431-1319-4d6d-b92c-1146acc30a52",
        "4bb622f4-ff9d-4795-9018-764da9c469ca",
        "119b7a2d-a783-4ae0-b3e3-15958dd4a136",
        "e5fe715d-206e-4195-a96d-f1b69f335931",
        "55327e82-da79-42f3-a9bc-bcfef13f739c",
        "9f6ad194-c982-423d-96b3-470e3d077342",
        "0c7cc971-0004-45cb-9230-d6e52e9d558c",
        "2f7a582c-9b70-4232-8a14-670e1dc1c4d1",
        "9528b57d-2e47-4236-a08f-fccf91a8b2b0",
        "3a5ab249-3a48-44c6-933d-693d2ebe3809"
      ]
    },
    {
      "id": "e6743d65-3dcb-4533-8fba-5b8b79350022",
      "name": "Policy Networks (Already in your list)",
      "definition": "Policy networks are a type of neural network architecture used within reinforcement learning frameworks to directly parameterize the policy function, which maps states or observations to actions. Unlike value-based methods that estimate the value of actions, policy networks focus on learning the policy distribution itself, enabling agents to make decisions by sampling from this distribution. They are fundamental components in policy gradient methods, allowing for flexible and expressive policy representations that can handle complex environments and high-dimensional action spaces.",
      "categoryId": "99457e6b-e884-42ed-ba3d-a7395d94a4c2",
      "subcategoryIds": [
        "492f9272-ac86-4f6b-9aa6-5cb71432fef3",
        "72449936-6c97-49a4-b697-753eb4e20d67",
        "e5fe715d-206e-4195-a96d-f1b69f335931",
        "1329dd2d-1cb7-4cd5-8ffc-142e818de909",
        "6f6b7278-c878-48d3-a56c-b320659934d0"
      ]
    },
    {
      "id": "4316ece0-1bb5-4f21-bc66-123ff99c5292",
      "name": "Policy Networks Techniques",
      "definition": "Policy Networks Techniques refer to a class of methods in reinforcement learning where neural networks are employed to directly parameterize and learn policy functions. These techniques enable an agent to decide on actions based on its current state by learning a policy network that maps observations to actions, allowing for complex, high-dimensional decision-making processes. Policy networks are often optimized through gradient-based methods to maximize expected rewards, and they form the core of many modern reinforcement learning algorithms, including Policy Gradient methods and Actor-Critic architectures.",
      "categoryId": "11a5291c-c524-452b-b523-37508ff2092a",
      "subcategoryIds": [
        "f6b2caa5-b3d0-47ae-862c-b27d5a8a8436",
        "dd017202-5563-4718-b862-06d9b2112238",
        "1c930b08-b76e-4b6b-aac8-65b737d6b81c",
        "15912023-4ee2-406c-bdbd-d0e5dad62a0c",
        "3870a24b-cd23-46aa-95c2-3b83d2e6e036",
        "20c0fbc5-0540-4231-a944-720ac9f2b56b",
        "93e10ad7-ade6-47aa-941c-9091b735ab24",
        "96cc67ea-451a-418e-a3bf-408038232eba",
        "6aced27f-6fd8-4bb0-88b9-df76f1204b76",
        "92c8123c-e278-423f-b13d-05cf5ca2ef06",
        "182ea949-c24f-4cb2-a55b-4e865742181a"
      ]
    },
    {
      "id": "c8e6d6ae-d958-4055-9e7c-31b176079a23",
      "name": "Polyak Averaging",
      "definition": "Polyak Averaging, also known as Polyak-Ruppert averaging, is a technique used in optimization and stochastic approximation to improve the convergence properties of iterative algorithms. It involves maintaining an average of the sequence of parameter estimates obtained during the training process, rather than relying solely on the final parameter values. This averaging smooths out fluctuations caused by stochasticity and can lead to more stable and accurate estimations in various machine learning models, especially in the context of stochastic gradient descent (SGD).",
      "categoryId": "6b97ea5d-cfff-4435-a8fd-4940a2594e0a",
      "subcategoryIds": [
        "14ed6c20-6a91-4fa4-8538-7a28cbcccc8b",
        "f9feb119-aa45-4eff-940f-a2584e4956c6",
        "6ad1cabf-32ee-4429-a413-149445c50e94",
        "a06712d7-c58e-4981-a309-2588221bc42c",
        "a05ae7e2-6950-4574-8795-911cccb85c26"
      ]
    },
    {
      "id": "5f788f1d-eb5b-4095-a680-d78b82eb971d",
      "name": "Polyak Averaging Enhancements",
      "definition": "Polyak Averaging Enhancements refer to advanced techniques that utilize Polyak averaging\u2014a method where iterates of an optimization algorithm are averaged over time\u2014to improve the convergence properties and stability of stochastic gradient methods in machine learning. These enhancements involve modifications or extensions to the basic Polyak averaging approach, aiming to achieve faster convergence rates, reduce variance, and improve the generalization performance of models during training.",
      "categoryId": "4e4487a8-5959-4646-802e-980132212f3f",
      "subcategoryIds": [
        "90798469-58d6-4134-8939-a94fdd26038f",
        "fd3e405d-be50-466f-add4-1ea157f0b7e9",
        "07f76d6a-872e-4b5d-bd5e-59e25024cf13",
        "9dc3beea-bc58-48e8-9433-b19ed107a24d",
        "1cedfeaf-cf0a-4b54-b7f7-6ba64ca39c9c",
        "c4fdd880-d24c-4540-a76a-02c09cece631",
        "64ec915b-47bd-4e8f-a889-270f3e098676",
        "bfc39cb8-72ba-4b8d-a5ad-a4cc96af4f06"
      ]
    },
    {
      "id": "4d1fbf61-4343-44ad-885a-f6fea849ca8e",
      "name": "Polyak Averaging Extensions",
      "definition": "Polyak Averaging Extensions refer to advanced techniques in stochastic optimization that build upon the traditional Polyak averaging method. These extensions involve modifications and enhancements aimed at improving convergence properties, stability, and performance of algorithms like stochastic gradient descent (SGD). By averaging iterates or incorporating adaptive strategies, Polyak Averaging Extensions seek to produce more accurate parameter estimates, especially in the context of noisy or high-variance data environments in machine learning models.",
      "categoryId": "8758d7ed-9b34-4580-a3e9-6baabc5d4782",
      "subcategoryIds": [
        "33a5e797-655e-45ac-b94c-2848484938f1",
        "53f48c79-d6ce-4060-b133-f651fa9700a9",
        "8bbc4293-3532-42de-967e-8cb0e58b35a3",
        "d2836f48-1dad-4e82-bb86-1026dc38d1fd",
        "e7d09658-ed44-4072-82ed-0d1b594f91df",
        "55ecad47-8076-4765-b9fd-5b45cb606a6f"
      ]
    },
    {
      "id": "13509b16-d5c5-42d2-959e-6eb77450e034",
      "name": "Polyak Averaging Extensions Extensions",
      "definition": "Polyak averaging extensions refer to advanced methodologies that build upon the original Polyak averaging technique, aiming to improve the convergence and stability of iterative optimization algorithms in machine learning. These extensions incorporate modifications such as adaptive averaging schemes, weighted averages, and hybrid approaches to address limitations of the basic Polyak averaging, thereby enhancing model training and performance, especially in stochastic or non-convex settings.",
      "categoryId": "36a05ba2-b50b-49c6-a989-56e398faf855",
      "subcategoryIds": [
        "3925d81f-ce44-44ab-add9-49c838cea2f1",
        "a4ee90f8-f040-4123-abcc-e90015332e50",
        "b467994e-14b5-4bb2-815b-0e36c6e803f3",
        "ee022723-90c9-43b2-af96-7ad719276cb5",
        "c7683149-bfd1-44ea-bf0c-2fcec031d89d",
        "c62bacc4-c234-4d2d-8db2-b219e6ee0c5f",
        "fc9661e6-8f85-41a1-96f1-56a4091524b1",
        "a0af42cb-ecd6-4604-86f0-5d56d3015f1a"
      ]
    },
    {
      "id": "63bf15d6-8bf5-4de3-af63-892b95638e43",
      "name": "Polyak Averaging Extensions Techniques Extensions",
      "definition": "Polyak Averaging Extensions Techniques refer to a set of optimization methods in machine learning that build upon the basic Polyak averaging principle. Originally proposed by Boris Polyak, these techniques involve averaging iterates of stochastic or deterministic processes during training to enhance convergence properties, stability, and generalization ability of algorithms. Extensions to the original method adapt, modify, or enhance the core averaging concept to accommodate various learning scenarios, including high-dimensional models, non-convex loss landscapes, and stochastic gradient-based methods.",
      "categoryId": "fedc536b-aff8-46b7-97b4-1a665d485f50",
      "subcategoryIds": [
        "5c1f3bed-2645-4dc9-82a1-323f06f70ec4",
        "169f006c-2b5d-4464-b1e5-3e168374b7ec",
        "65464f29-539e-44db-a577-6f001f2896ae",
        "4580d336-7fbb-4a11-8fff-a42eb894d872",
        "f5011d3c-85c0-4697-ac0f-83c4bb9c9958",
        "5abc81b8-9d7b-43a0-ba14-7ce1f99dd17a",
        "f97f9592-83b9-449b-9a55-9d8454f77f90",
        "34dee0f7-f01c-4891-b44d-01520762c922",
        "3d55233e-e314-4368-b35a-cdd87cec5bd1",
        "e9c29299-a5ac-4844-963f-645e79339351",
        "4ff56b3a-2762-45f7-aab9-967ea3ea2870"
      ]
    },
    {
      "id": "fd0a84f2-013f-4a2d-85fb-ae9c0e929eaf",
      "name": "Polyak Averaging Extensions Techniques Extensions Enhancements",
      "definition": "Polyak averaging extensions techniques enhancements refer to a set of advanced methodologies used to improve convergence, stability, and performance in iterative optimization algorithms within machine learning. These techniques build upon the original Polyak averaging approach, which involves averaging the parameters or weights of a model over iterations to achieve better generalization and reduced variance. Extensions and enhancements in this context include various modifications, adaptive schemes, and hybrid methods designed to optimize the averaging process, adapt to different learning scenarios, and enhance the efficiency of training algorithms.",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd",
      "subcategoryIds": [
        "f76f9fa9-944e-4293-9af1-88d649a7e0f9",
        "74f47f09-1750-4cc1-9e68-df2fe65352b4",
        "042ce2f7-9a3d-4b64-adca-e4fe2a8e1f6e",
        "b8981166-59d8-4107-b816-100d4347f703",
        "1799266f-eb1d-4032-b51b-905892713105",
        "db47f73b-7d04-479c-aceb-d3d544c2147b",
        "4f980b11-0cde-4ebc-84d3-bee36a06210f",
        "93e9232e-2805-4661-b8d3-b1e4c2b1ac13",
        "1ad83791-d4d3-40a8-bf14-b04c4542fbe8",
        "34351bd0-d725-438d-be5c-4fa21b05ec74"
      ]
    },
    {
      "id": "4fc5b76f-ca70-4e8d-91e2-9ffc537efa46",
      "name": "Polyak Averaging Extensions Techniques Extensions Enhancements Techniques",
      "definition": "Polyak averaging extensions techniques refer to advanced methods that build upon the original Polyak averaging strategy in optimization algorithms. Polyak averaging involves taking the average of parameter iterates during stochastic or deterministic optimization to enhance convergence properties and stability. Extensions and enhancements often include various modifications such as adaptive averaging schedules, variance reduction techniques, and integration with other optimization strategies to improve learning efficiency, robustness, and convergence speed in AI and machine learning applications.",
      "categoryId": "40fe59b1-0726-4e49-b792-04394279af82",
      "subcategoryIds": [
        "d642616e-70c3-45a2-8714-146bd57e3b29",
        "8ed49d6e-0f7d-4023-9da3-ce73e85b7ac7",
        "c3d8dc56-3cb0-42d7-a225-c6a17b3eedce",
        "af6046fa-4bf2-4e9c-b550-1ddbcd8227ba",
        "fe816bc3-ad54-46fc-a352-358076c9e86c",
        "8c2ccb9c-b046-47a6-bae6-3661ba47a6e1",
        "28fa835a-e199-461a-bf57-6d9a2655bf8e",
        "c58465f9-4c72-4ba1-89e1-faf9fd6e9c68",
        "7209a5c6-1f10-4130-a30a-8a8414b2dec0",
        "602cb98e-0376-4780-8b9c-4231af35ebd4",
        "44129250-ad61-4ff0-8d7a-3eadf8af393f"
      ]
    },
    {
      "id": "680afc97-bedc-40eb-99ee-ec64fc1d7630",
      "name": "Polyak Averaging Techniques",
      "definition": "Polyak averaging techniques refer to a set of optimization methods in machine learning that involve averaging parameters or iterates during the training process to improve convergence properties. Named after Boris Polyak, these techniques aim to stabilize training, reduce variance, and achieve more accurate and robust parameter estimates by combining multiple solutions obtained at different training steps through averaging, often leading to better convergence behavior compared to standard stochastic gradient descent (SGD).",
      "categoryId": "193c441c-0d53-488d-b730-5029bdfdd470",
      "subcategoryIds": [
        "755f6a38-f441-4634-b1a3-194d0ad19aa4",
        "c970c2b5-e675-441f-89e8-ca82eab9ead6",
        "4b73b8a0-459f-4232-be57-697d5a222e3a",
        "0003674e-c03d-422c-a3ad-1a21728f2bbe",
        "1c3c75eb-fb17-4178-ad29-d38ae6ec24a7",
        "0d081765-8298-4470-a833-087df98ef1c0",
        "4aedd598-609a-4e04-885b-6267533f665c"
      ]
    },
    {
      "id": "e6a12811-fbca-44d2-b261-f47b9c6aecad",
      "name": "Polyak Averaging Techniques Extensions",
      "definition": "Polyak Averaging Techniques Extensions refer to advanced methods that build upon the standard Polyak averaging concept to improve the convergence and stability properties of optimization algorithms, particularly in training neural networks. These extensions often incorporate modifications such as weighted averaging schemes, adaptive averaging strategies, or probabilistic adjustments to enhance the efficiency and robustness of the original techniques, facilitating better generalization and faster convergence during model training.",
      "categoryId": "eb60f725-cd3b-42fb-8264-a708ee582c93",
      "subcategoryIds": [
        "0cdc2bde-ca47-407b-84c1-ee28eacf6b39",
        "74963b27-f8fd-4ea0-bdfa-e6bfc40d5ded",
        "f63dea55-800c-4165-8198-6eb287ddb413",
        "e16da5cb-24f0-4b10-9e1d-b672af0395ac",
        "466d79d1-dfd0-4757-a1b8-539398e8d540",
        "b83b333a-4d7b-4647-8698-d0153f1c47e0",
        "91ee2aaa-b10c-46a0-b65f-d2220d7673bf",
        "56ad7cff-fecd-484f-bdc0-2755eab6c7c6",
        "c399233d-e478-40dd-95c2-0ee69fb80799"
      ]
    },
    {
      "id": "313fa635-49e7-4493-ae18-ea5795f515dd",
      "name": "Polyak Averaging Techniques Extensions Extensions",
      "definition": "Polyak Averaging Techniques Extensions refer to advanced methods built upon the fundamental Polyak averaging principle, which aims to improve the convergence and stability of stochastic optimization algorithms used in machine learning. These extensions incorporate additional strategies such as adaptive averaging schedules, variance reduction, and robustness enhancements to further refine model training processes, leading to more reliable and efficient learning outcomes across various neural network architectures and large-scale data scenarios.",
      "categoryId": "1516c0ec-8acc-4d4d-b3ab-bd75ba42392a",
      "subcategoryIds": [
        "fc348056-a459-42a0-acca-de64d7f7050e",
        "4fd42899-fe0e-470b-8649-289caafb4782",
        "82741cee-174c-43e9-86cf-19d18d0a39ea",
        "d2024473-7480-44d5-8a00-117f2ca3e80f",
        "78ab53aa-d4bf-41d6-9e20-ce79dc29e328",
        "274cbc0c-1a13-4cac-9160-cdd626df7241",
        "44330b53-d6f3-47dc-883f-c2786c7454c9",
        "7034221d-d64e-4954-b372-42e86df49ceb",
        "69db4b43-013a-468f-9af2-16c15d20902a",
        "b43f240a-e8a4-4f49-b930-a8085b464f9e"
      ]
    },
    {
      "id": "79e64b49-9f3f-4a63-987c-930a836da9b9",
      "name": "Polyak Averaging Techniques Extensions Extensions Extensions",
      "definition": "Polyak Averaging Techniques Extensions Extensions Extensions refer to advanced methodologies that build upon the classical Polyak averaging approach in stochastic optimization. Polyak averaging is a technique used to improve the convergence properties and stability of iterative algorithms by averaging the parameter estimates over iterations. Extensions to this technique aim to enhance its performance, adapt it to different contexts, and incorporate additional mechanisms such as momentum, adaptive learning rates, or higher-order averaging schemes, thereby broadening its applicability in modern machine learning models.",
      "categoryId": "d82a717a-5aed-483a-985c-31daec95cb81",
      "subcategoryIds": [
        "26019a02-ccfb-4661-96b6-318865ff56f4",
        "88326218-3c3a-4b20-82f4-975f1923a17a",
        "7ee0561a-b820-4641-bf51-8f79f994f0cb",
        "25da901a-89a1-4a43-92fa-59c64e79daf5",
        "3422c7bd-672f-4cb4-abb5-a36586948235",
        "3656cfc0-af2b-4b4f-9cb5-58f165646b22"
      ]
    },
    {
      "id": "90eac69b-2340-45a8-b72a-7b71f846dd53",
      "name": "Polyak Averaging Techniques Extensions Extensions Extensions Enhancements Techniques",
      "definition": "Polyak Averaging Techniques Extensions Extensions Extensions Enhancements Techniques refer to a set of advanced methods that build upon the fundamental Polyak averaging concept in stochastic optimization. These techniques aim to improve the convergence speed, stability, and robustness of iterative algorithms such as stochastic gradient descent (SGD) by incorporating various extension and enhancement strategies. They often involve sophisticated averaging schemes, adaptive mechanisms, or hybrid models designed to optimize the learning process in neural networks and other machine learning models.",
      "categoryId": "3f72f147-f36e-4a6b-ba3d-8be862ab91b3",
      "subcategoryIds": [
        "dbee770b-75b6-4bf5-ad80-af7b9ba749a0",
        "8bdfe8e0-0e52-484f-90bd-6c3d5680ad71",
        "406807cd-8a62-432a-811d-5f1b59e4c781",
        "1e0f90f8-65fe-469e-93cd-c25e89438d78",
        "ba173515-a4d7-4444-bc03-8a5bb6ad93dc",
        "711203c1-d3f6-4311-b8dd-cfd97499b9a0",
        "191193e6-03c0-418e-be21-752f9254ff23",
        "655dfd10-45d4-41b1-bdd5-ac550616d6fc",
        "573e9e01-baaf-4aa3-acd7-5fb6682445f4",
        "4786674c-5365-468f-a504-b8b5f5fbacc1",
        "c7789e1c-e870-4098-8363-10963f7bf1a5"
      ]
    },
    {
      "id": "efbe1b78-7672-4849-9397-58da560a1755",
      "name": "Polynomial Features",
      "definition": "Polynomial features refer to new features generated by raising existing features to various powers and combining them through polynomial terms. In machine learning, polynomial features are used to transform original input features into a higher-dimensional space to enable models to capture non-linear relationships between features and the target variable. This transformation involves creating polynomial combinations of the original features up to a specified degree, thereby allowing linear models to fit complex, non-linear patterns in the data.",
      "categoryId": "0238721b-3693-4f2c-81a2-ddaa11fad71d",
      "subcategoryIds": [
        "b2d1102e-d9ec-4c86-839e-608473ccb8e0",
        "af893db8-0142-42e8-a319-d302436637b3",
        "98e45552-dc2d-4169-a1f6-b75e371fff7f",
        "680c653a-87b6-438d-9d3e-be9d1e264203",
        "97f568af-f22d-433c-9a3e-49e658be2098",
        "7f8d2b3e-0d95-42be-b691-1d93bc99360d",
        "fad176a4-85fd-4cbe-aa65-44673b31a614",
        "81f9d698-43e4-43a8-afbb-bd62a90c83f0"
      ]
    },
    {
      "id": "e10e9673-b1a3-4bb5-98e8-68f506a656ae",
      "name": "Polynomial Networks",
      "definition": "Polynomial Networks are a class of neural network architectures that explicitly incorporate polynomial functions into their structure to model complex, non-linear relationships within data. These networks leverage polynomial expansions to approximate highly nonlinear functions, offering a structured approach to capturing intricate data patterns. Unlike traditional neural networks that learn non-linearities through layered compositions of simple activation functions, polynomial networks directly encode polynomial relationships, enabling efficient modeling of specific types of data dependencies.",
      "categoryId": "25fb22cf-839b-4373-afe3-14b1b7f75e55",
      "subcategoryIds": [
        "901ce0ab-210c-482f-b638-be06ffb06885",
        "a27e10f2-9fde-4438-9ee9-cf7e69448f3e",
        "df55e05b-c856-466c-8b86-b5ad67624ec3",
        "af6b981c-ded0-4fbd-b0d7-3943fa80df30",
        "f73c8497-f295-4120-a113-e7c181324e58",
        "818bec1d-d80a-4c58-bc3e-495e7660eca0",
        "90b176b7-ac40-4536-a0d6-b28770a48011",
        "319c100c-2c16-41dd-896d-d80365d8a504",
        "89e0c031-cd9c-491f-84ce-c567d5ec5bc8"
      ]
    },
    {
      "id": "635c6f6c-fb5b-4289-8f7a-3ed071a7f956",
      "name": "Polynomial Regression",
      "definition": "Polynomial Regression is a form of regression analysis that models the relationship between a dependent variable and one or more independent variables by fitting a polynomial equation to the observed data. Unlike linear regression, which models a straight-line relationship, polynomial regression can capture nonlinear patterns by introducing polynomial terms (such as squared or cubic terms) of the predictors, allowing for more flexible modeling of complex data relationships.",
      "categoryId": "54457308-8214-4333-868f-259d5bed7d25",
      "subcategoryIds": [
        "0dc099a6-f049-4e25-99c3-c54cad421858",
        "d7689b69-09e7-46db-b60c-ac193e5d9ea2",
        "ca2cd0c3-e0db-4b10-92d1-5588bfd1d121",
        "bf057190-ec98-4446-b63e-d9949cd4a2fe",
        "05df759d-4da8-40b0-a1a2-8e5a74e74f1f",
        "7be59a04-646b-48b4-a523-87e2646bcc8f",
        "30bdb166-d533-458f-96c8-9b4c952907a8",
        "b8c090d2-6acc-44df-ab3e-1052eeae54ce"
      ]
    },
    {
      "id": "c5ab6fc7-d5e4-4ed9-856d-62aa7e922f12",
      "name": "Pooling Layer",
      "definition": "A pooling layer in neural networks is a component that reduces the spatial dimensions (width and height) of the input feature maps while retaining the most important information. It operates by applying a specific operation, such as maximum or average, over a defined window or region of the input, effectively summarizing the features within that region. Pooling layers are typically used in convolutional neural networks (CNNs) to decrease computational load, control overfitting, and achieve spatial invariance to input transformations.",
      "categoryId": "b398ed36-5c3f-4aad-aafd-21421e6c3a30",
      "subcategoryIds": [
        "9a31f17d-695b-43d7-adbf-94da65ca1e4f",
        "9dea828d-8519-417f-b8f2-6f1a00291699",
        "873a4d64-872f-4623-8b13-b96b52a2bf12",
        "35672103-c691-428c-a40c-bd489dfc8746",
        "da389c07-393b-46ae-a02d-eadcb263c29a",
        "71046d65-0ffc-407e-9dd3-c94149a8c917",
        "b548b9e4-d118-496a-8338-cdb96ddf15a6",
        "6d584a6f-35b3-4dda-abc4-0b29410e04d2",
        "b8a59693-fe9a-41db-8512-289b01c4e464",
        "4be76067-1efc-4d49-97a9-1173051a855b",
        "28f6acbc-f3a6-419d-8855-988beb4cf23d"
      ]
    },
    {
      "id": "da641cb0-d8c4-4070-b708-160e2405a533",
      "name": "Pooling Layers",
      "definition": "Pooling layers are a fundamental component of Convolutional Neural Networks (CNNs) used for image and signal processing tasks. They perform a downsampling operation on the feature maps generated by convolutional layers. The primary purpose of pooling layers is to reduce the spatial dimensions (height and width) of the input, thereby decreasing the computational load, reducing overfitting, and capturing dominant features that are invariant to small translations and distortions in the input data. Common types of pooling include max pooling, which selects the maximum value in a pooling window, and average pooling, which computes the average of the values within the window.",
      "categoryId": "a14cfc34-aca7-4cfd-9482-2b1d5b5559d5",
      "subcategoryIds": [
        "31823a6d-6fd8-4603-92c6-1e3fdad3392b",
        "5f4a735a-fa6d-41e0-a2f2-9dddcf034555",
        "95df7ed5-b5bc-4a19-9d73-dcfc7f1af217",
        "5748ff4b-6f08-48b0-9fd5-8fe56060d7e8",
        "895aaec3-4d56-413d-875a-b1825a178d07",
        "eaaf8457-f0d6-401a-94d1-5ceb9e7bbc6a",
        "5e5e16e9-634e-48b3-96ae-e0e413bb9b68",
        "4a5005c1-d97c-4594-8644-ffb81beafb59",
        "3c954567-5d0c-434c-bf63-771a20c2ca83",
        "b07966f5-3cc5-49fd-9f3c-cb131d8b7b34"
      ]
    },
    {
      "id": "187d8063-957b-4641-9ebc-3b6ae6f2816f",
      "name": "Population",
      "definition": "In the context of AI and machine learning, a \"Population\" refers to the entire set of individuals, items, or data points that meet specific criteria within a study or analysis. It embodies the complete group from which a sample may be drawn or analyzed, representing the total universe of interest for a particular problem or research question. For example, in a medical study, the population could be all adults in a city; in a machine learning task, it might be all possible data points that satisfy certain features or conditions relevant to the model.",
      "categoryId": "254cf1d5-ad68-42ea-8f45-76e4372a7117",
      "subcategoryIds": [
        "d723bd8c-a7ca-4160-a9be-34147177e1a4",
        "11a46b8d-5737-4cf7-ab76-c9f410478beb",
        "48093e74-fece-4b4b-8c26-7bc1876889f3",
        "ebabe900-e1a3-4187-9ee6-265e1e19230e",
        "53e4dad2-ea68-427a-af63-572ce59dd52c",
        "e1ed9cb7-bdb0-47e7-87a1-32a2750742b1",
        "0e317222-3384-42c7-8af9-96f483fd59c0",
        "28825bec-e862-4e7d-98dc-8cf0e114c6b9",
        "41e39f4b-94fc-4f8b-b92a-a06cb2cbedd5"
      ]
    },
    {
      "id": "33e71a77-bc0a-45ca-a56a-08ceb4527f17",
      "name": "Population-Based Training",
      "definition": "Population-Based Training (PBT) is an advanced optimization technique in machine learning that jointly tunes hyperparameters and model parameters by maintaining a population of models. These models are trained in parallel, periodically evaluated, and the best-performing models influence the hyperparameter configurations of the less-performing models within the population. This dynamic process allows for continuous and adaptive hyperparameter optimization during training, leading to improved model performance and efficiency compared to traditional static hyperparameter tuning methods.",
      "categoryId": "342ac1a3-a364-4416-a936-860e0936c195",
      "subcategoryIds": [
        "9e90a341-a0c6-41d2-8d70-a43e6737ae4d",
        "fbd9b1da-3315-4b04-8c2e-57f0a61f6d80",
        "ac36ee5e-f010-4102-80ef-dcf0a16e372a",
        "c5826e65-ad06-4a9a-9d81-feb8c38e2df0",
        "9da1ac1c-89d5-442c-a9b4-ae1142dd303a",
        "0a71ed44-7266-4361-b323-469c8bfebac4",
        "5af0913f-1c26-4ab5-886a-d360ceaf3fe4",
        "6ff85f7a-c173-49bc-895c-4b7e1d1b524b",
        "8d62edd2-395a-4870-94ae-28d756e52b16",
        "cd69ed2e-a524-4d79-b2f3-32516bcb9b08"
      ]
    },
    {
      "id": "83ab20fb-a72f-4026-8666-41984461466e",
      "name": "Population-Based Training (PBT)",
      "definition": "Population-Based Training (PBT) is an advanced optimization technique used in machine learning to simultaneously train a population of models or agents by dynamically adjusting hyperparameters and architectures during training. Unlike traditional methods that fix hyperparameters beforehand, PBT involves periodically evaluating the models' performance, selecting the best performers, and propagating their configurations to other models in the population. This approach enables continuous adaptation, leading to improved model performance and robustness across diverse tasks or datasets.",
      "categoryId": "602c83f9-44b1-40ec-b3fa-ec4a0eefb9e1",
      "subcategoryIds": [
        "e03f2718-6157-4f54-bedb-fec77b374420",
        "3143752e-f16e-4cf5-b275-be517dc35f15",
        "36bbf046-4e78-4afa-be84-4aa491bd127e",
        "33b04518-36b2-49fb-9b5f-2478ede69d20",
        "d3424255-2cbc-42fa-b89c-5fccaf9e9b6a",
        "928e453d-dc80-4f97-bda6-07e47fcde63f",
        "6d524857-3fa6-4301-842b-7febcbb2c98c",
        "93e1073f-47a1-4668-b8ac-0fb2fe38c794"
      ]
    },
    {
      "id": "03e1d26e-ed2c-43aa-91df-769749b00c44",
      "name": "Pose Detection",
      "definition": "Pose detection is a computer vision technique that involves identifying and locating human body joints and keypoints within images or videos. It enables the understanding of human poses by detecting the spatial positions of various body parts, such as the head, shoulders, elbows, hips, knees, and ankles. This technology is used to interpret human motion and posture, often serving as a foundational component in applications like activity recognition, motion analysis, and virtual try-on systems.",
      "categoryId": "ffdb9d1f-02d8-4c6c-b49b-6e3343d4b51d",
      "subcategoryIds": [
        "b97fa65f-a67b-4f5f-898b-b4ee38e35380",
        "f628b3ab-ea1c-4015-84a4-5c572e46eb31",
        "1f53386c-7058-48e9-b0a6-b8795735f26e",
        "113c789a-9aa4-4f9d-860f-632cff2d5c9a",
        "3cb3be1d-471d-4e7d-9afb-96642caf79e4",
        "5d12514f-6f80-445e-a26a-3ef1564c6319"
      ]
    },
    {
      "id": "41032eb0-eb11-488b-a4a6-924ae2bc40a5",
      "name": "Pose Estimation",
      "definition": "Pose Estimation is a computer vision technique that aims to determine the spatial positions and orientations of human bodies or objects within an image or video sequence. It involves identifying specific keypoints or landmarks (such as joints or object features) and inferring their three-dimensional configurations. The process enables a system to understand human posture, gestures, or object positioning, which is essential for applications like human-computer interaction, sports analytics, and augmented reality.",
      "categoryId": "8a721960-fff7-4813-a4f2-8f77e254e8db",
      "subcategoryIds": [
        "3a987b5b-53d2-4ea8-9bb6-05f4a05b0ceb",
        "815234fa-ad9e-4f85-845c-6712aa72dc04",
        "6b06b2af-5a67-4543-a01a-7d3bb55b2d96",
        "268a4dce-dc9c-4668-97eb-837fe7713fcb",
        "25dff3f1-2655-45ee-931c-477cd2671a10",
        "a9aa86ef-6ad3-424d-a6e7-88e523b9fdf7",
        "9e15c927-91dc-4bbe-959a-8d48890c7ef9",
        "0e395b53-0f9c-4123-a69e-3b020e42888b",
        "2b6b2e60-a48f-43f7-9ac1-e8f974a1bb7e"
      ]
    },
    {
      "id": "ef7d7122-bf08-4585-b252-4dd6991005c1",
      "name": "Positional Encoding",
      "definition": "Positional encoding is a technique used in neural network architectures, particularly in the transformer model, to inject information about the position of tokens within a sequence. Since transformers lack inherent recurrence or convolution to process sequence order, positional encodings provide the necessary positional context, enabling the model to understand the order and relative positioning of elements in the input data, such as words in a sentence or frames in a video.",
      "categoryId": "f34d19d0-a386-44a1-8827-fdbb79251700",
      "subcategoryIds": [
        "5ecd11d6-6168-48e4-aef3-1ab194542975",
        "3a3dd668-4f14-4ec4-a7b7-648765116ac7",
        "12fbe8ad-5182-41e6-b046-3347b2454961",
        "3c1b9dd0-fbf8-4b53-8518-6ec43fccead8",
        "ed6b3594-ce58-443f-98ee-02ed64e14a65",
        "6d30db0a-086a-43c8-9219-922dd01fc332",
        "616869d0-ea84-4376-a1de-3e11e9dfac26",
        "20d3deb7-428f-4760-ab27-91ae289c4ab4",
        "fe9f9e50-bc0b-4788-ace0-2fdb69d3223f"
      ]
    },
    {
      "id": "a79221b7-d0f6-4db2-be14-be30c826f077",
      "name": "Positional Encoding Techniques",
      "definition": "Positional Encoding Techniques are methods used in neural networks, particularly in transformer architectures, to incorporate information about the position or order of elements within a sequence. Since models like transformers process data in a non-sequential manner, they require a way to understand the relative or absolute positions of tokens or features in input data such as text, speech, or time series. Positional encodings are vectors added to or integrated with input embeddings to provide this positional context, enabling the model to capture sequence order-dependent information effectively.",
      "categoryId": "23715765-4079-4d61-b87a-247d3c78c7a9",
      "subcategoryIds": [
        "bb0e36a6-a68d-47af-b7b7-bc622fa5bc82",
        "df3f9ecf-ae54-4cee-9b2b-b70160464ad6",
        "31bf8c83-2924-4d93-82f9-573b3f07f19e",
        "07e17e99-cf6d-4c33-a658-a9a23c852d9c",
        "e79b0741-0f79-49d4-95cf-9ace48f1e5e2",
        "6a690ec7-4d00-4ef6-9a36-ebef43c03078",
        "e206467b-9668-4220-b9a1-b90efd443a88",
        "a78f0e72-34fc-4104-81e5-599ada87f031",
        "39ee87d0-0518-4aa5-9183-f5dec07885d8",
        "a58d2887-72e2-4364-8907-247b7e47df79"
      ]
    },
    {
      "id": "16c3a085-2f98-4459-8dca-9b23f2382781",
      "name": "Positive Predictive Value (PPV)",
      "definition": "Positive Predictive Value (PPV) is a statistical metric used to evaluate the performance of a classification model, particularly in binary classification tasks. It measures the proportion of true positive results among all positive predictions made by the model. In other words, PPV indicates how many of the instances predicted as positive are actually positive, reflecting the accuracy of positive predictions. Mathematically, PPV is calculated as the number of true positives divided by the sum of true positives and false positives (PPV = TP / (TP + FP)).",
      "categoryId": "3b2fdf5c-5393-45ad-90a7-ad7f56f591d1",
      "subcategoryIds": [
        "52edbded-bcc9-4848-9486-81a2e0c20933",
        "25fca681-cd9f-4e52-a42b-87980c4beca9",
        "88335458-10b7-4762-8992-9c5cf97fee97",
        "c68b177f-1874-41b8-a418-62ef70f64975",
        "71387ace-389c-4be8-b2bf-45729e6a9fc0",
        "b2463f9c-a1e5-43bf-852b-cfe8428c37d5",
        "693e85ae-9d66-420f-bf18-423068458241",
        "70681450-65cb-4823-b39f-7349ed0a593b"
      ]
    },
    {
      "id": "10e7032a-5772-4e8a-af4a-b0c7d747184f",
      "name": "positive-unlabeled sampling",
      "definition": "Positive-unlabeled sampling is a semi-supervised learning technique used in scenarios where only positive examples are labeled, and the rest of the data remains unlabeled. Instead of relying on both positive and negative labeled data, this approach focuses on utilizing the limited positive samples in conjunction with the unlabeled data to build models that can distinguish positive instances from the rest. It is particularly useful when obtaining negative labels is costly or impractical, and aims to leverage the positive and unlabeled data effectively for training classifiers.",
      "categoryId": "e6628bfb-ee12-497e-b253-1a3f8b959dcf",
      "subcategoryIds": [
        "100c227d-d01c-4c85-bfee-147cb2d3de7d",
        "3ced3a46-285a-4004-b2d8-5cba8258c8a4",
        "6fed4e08-6232-4be5-8371-3754ac3e6b6c",
        "1923be93-9659-44ce-8e40-faeab0f2fd5f",
        "c06ccfbb-e42b-4cd4-a5ec-bc16549de513",
        "0d1812ba-c3a0-4211-94a3-56aac79e1e53",
        "f208499f-5bef-4177-917d-57fb0b9a09e0"
      ]
    },
    {
      "id": "e1aaf25c-4988-4bf5-8d6e-f8cca906fbd5",
      "name": "Post-hoc Interpretability",
      "definition": "Post-hoc interpretability refers to techniques and methods used to interpret, explain, and understand the decisions made by a trained machine learning model after it has been developed and deployed. Unlike intrinsic interpretability, which involves designing inherently transparent models, post-hoc methods analyze a trained model's behavior without modifying its structure. These techniques aim to provide insights into the model's decision-making process, increase transparency, and build trust with users, especially in high-stakes applications such as healthcare, finance, and legal systems.",
      "categoryId": "b2f02031-5e66-4570-b8da-ba3f0443f1e3",
      "subcategoryIds": [
        "5b9b0ee7-b58a-4d38-b480-0739c8b838c3",
        "0c3d69f0-e7aa-406f-9c7a-7173a619db40",
        "aef02fb1-b207-46f1-8dc0-8219cf0a24c5",
        "b3a02038-d317-4185-b7f6-48817d710251",
        "9bee2039-75f7-4d30-bd37-8d708fd6dc41",
        "d31b9070-a415-485b-948c-cde62dc9afe4",
        "29503f15-cd97-44d2-a9ac-31ee9aeea1ee",
        "8749f113-5af0-49dd-a1be-86d40b286eff",
        "53ded6dc-593c-4611-bbca-9e440bd1614f",
        "5b278721-516b-4846-b45a-65ead30bd6ba"
      ]
    },
    {
      "id": "f02712fc-4684-4593-9142-3f93c43cb532",
      "name": "Post-Training Quantization",
      "definition": "Post-Training Quantization (PTQ) is a technique used in machine learning to reduce the size, memory footprint, and computational requirements of a trained neural network model. It involves transforming the floating-point weights and activations of a pre-trained model into lower-bit representations, such as 8-bit integers, after the model has been fully trained. This process helps in deploying models on resource-constrained devices like edge devices and mobile phones without significantly compromising accuracy.",
      "categoryId": "0caf7b8c-8da8-4375-b22f-895c516668cc",
      "subcategoryIds": [
        "33eecbc5-6987-4e33-84d2-cb69dde8a5a9",
        "e016c8fc-c951-4658-abd2-17015c7172e4",
        "7e1454c6-6b03-4de1-83cd-9fca88fe496a",
        "e63659fb-8a2e-4e3d-8fed-441f08e9997c",
        "f9ea7ceb-3634-43bf-bfab-fd0021a2b4d0",
        "1498c648-bb83-47f5-a971-59e63404035f",
        "891cc3f2-c4f9-4082-907f-16ef9be4addb"
      ]
    },
    {
      "id": "bc690a21-54fd-43f1-aaa7-9622d6918569",
      "name": "Post-Training Quantization Techniques",
      "definition": "Post-Training Quantization Techniques refer to a set of methods applied to trained neural network models to reduce their size, improve inference speed, and decrease computational requirements without significantly sacrificing accuracy. These techniques involve converting the high-precision floating-point weights and activations of a model into lower-precision formats, such as int8 or int16, after the training process has been completed. The primary goal is to optimize models for deployment in resource-constrained environments like mobile devices, embedded systems, and edge devices while maintaining acceptable performance levels.",
      "categoryId": "0c4cce23-7ea5-44bc-beda-411af30e330b",
      "subcategoryIds": [
        "bc0cf7ac-6c63-46a8-9b0d-db8b646219be",
        "6e8b660e-cd3f-421c-9df9-ca74da798267",
        "b5e183a2-e777-43e8-a4d8-0a8eaafd596d",
        "f7c32a16-fdf8-485b-9ad3-71074aa9c82e",
        "3cd0b0f3-54ae-4a1e-98a8-2c77ec999bee",
        "0126a3c9-d31b-459a-b844-79f1c08e4e58",
        "e1ea4160-941c-4970-9f0d-c866969fd358",
        "950b3d10-761a-47d5-af83-eae8b4ba7729",
        "37321d91-600a-4180-95ca-2f83572a3d60",
        "d23db6b2-bb38-4a7f-9bc0-f6cd60ec7e77"
      ]
    },
    {
      "id": "a1e09950-b5c2-46d3-8195-b89fc1a3ce2a",
      "name": "Posterior Probability",
      "definition": "Posterior Probability is the probability that a hypothesis or model parameter is true given observed data. It is a fundamental concept in Bayesian inference, representing the updated belief about a hypothesis after considering new evidence. Mathematically, it is expressed as P(H|D), where H is the hypothesis and D is the observed data.",
      "categoryId": "0ea3390d-96ff-42b2-bef7-c0076524920a",
      "subcategoryIds": [
        "fcd0f858-e1a9-4f54-b8d0-1b9538703f31",
        "684db5ba-8377-4d02-b69e-d055f23440d6",
        "f4a39b39-690f-4d51-981a-a89e6e6f7b69",
        "5cf0a57f-19eb-40f1-822b-e284345bf91e"
      ]
    },
    {
      "id": "8629baef-ef50-4246-b233-a78ed07e7536",
      "name": "Power Analysis",
      "definition": "Power analysis, also known as statistical power analysis, is a methodological process used to determine the likelihood that a statistical test will correctly reject a false null hypothesis. It quantifies the test\u2019s ability to detect an effect or difference when it truly exists, thus helping researchers assess the adequacy of their study design before data collection. By calculating the required sample size, effect size, significance level, and statistical power, researchers can ensure their study has sufficient sensitivity to identify meaningful effects in data analysis, ultimately improving the validity and reliability of the findings.",
      "categoryId": "44b99a4d-6562-472e-abca-2c13e9503d1f",
      "subcategoryIds": [
        "61474cc6-070b-4d4e-81bd-ed5eeec07286",
        "f790fe7c-a2be-448f-ae8d-578870d27275",
        "ddade37d-79ba-4824-9b98-b9cdec3eaac4",
        "947faa73-10fc-4210-a281-bea5e1fb11e1",
        "b3ee45e9-60d9-4f85-8c02-17484d441987",
        "4f7335ab-0f81-4bbd-bbd1-158f4db0269b",
        "af5e34b9-5884-4ab7-90fb-26fe82f968df",
        "8d81715a-2555-4e23-9e08-53f17c9f2e1e",
        "643b37f3-7311-491f-901c-595a4046cb7a"
      ]
    },
    {
      "id": "ee61d393-1150-472a-8da4-32d3a90f7a49",
      "name": "Power Iteration",
      "definition": "Power Iteration is an iterative algorithm used to approximate the dominant eigenvalue and corresponding eigenvector of a matrix. It is a simple yet powerful method primarily employed in numerical linear algebra to identify the most significant eigenpair, especially in large-scale problems where direct methods are computationally expensive. The process involves repeatedly multiplying a vector by the matrix and normalizing the result to converge toward the eigenvector associated with the largest eigenvalue in magnitude.",
      "categoryId": "fdccc823-9f42-4e83-8af3-614834277df4",
      "subcategoryIds": [
        "0be1e202-22b1-497b-aafd-e6671e90599d",
        "70fd474c-c860-4cae-9b0b-92f15cad2f07",
        "476bf1a2-a7ca-4bd4-9089-8233887380e0",
        "fb6b85ea-1b35-4dfa-b9e5-67361d77e45d",
        "bd1365b9-190e-4ddb-b464-0edaf46fba71",
        "8c40edd3-cbb8-4d1d-a0af-5b7631e5f079",
        "fedb6bba-ae78-4b4f-8f76-37b12f966b32",
        "1ab5d623-1760-4680-862a-1c3fff200f5a",
        "018ec202-7510-4eae-b3ec-2f18c04923e5",
        "b47581ee-f92d-42ba-88f3-9650c2686383"
      ]
    },
    {
      "id": "820c0d47-345a-425f-98b1-016eea37855b",
      "name": "Power Normalization",
      "definition": "Power normalization is a data preprocessing technique commonly used in machine learning and signal processing to adjust the scale of features or signals based on their power levels. It involves normalizing data such that the total power or energy of the signal or feature set is consistent across different samples or instances. This process helps to mitigate the effect of varying signal amplitudes or feature magnitudes, promoting stability and improving the performance of learning algorithms.",
      "categoryId": "0f61dbd9-d17b-4dc4-afe8-50e26577fae3",
      "subcategoryIds": [
        "324eb9c8-bd2a-4deb-8a2f-c7e6d0196718",
        "174e63c3-fccf-4042-ab4f-0618eed5cc9b",
        "ca754288-c1c0-4843-90d0-e62ca812db29",
        "5349647f-6037-4a19-9fe3-f2ed6a0053f3",
        "75f1f33e-7df4-48e0-83f7-9aed42088e57",
        "2cdee3fd-8c66-480c-b047-25662f7b9e68"
      ]
    },
    {
      "id": "6d9bce37-9e41-4773-a30f-288cff35237c",
      "name": "Power of a Test",
      "definition": "The 'Power of a Test' in statistical hypothesis testing refers to the probability that a test correctly rejects the null hypothesis when the alternative hypothesis is true. It is a measure of a test's ability to detect an effect or difference when one genuinely exists. Mathematically, it is expressed as 1 minus the probability of a Type II error (\u03b2), indicating the test's sensitivity and effectiveness in identifying true positives, especially relevant in various applications within AI and ML where decision-making under uncertainty is critical.",
      "categoryId": "5e878ac9-6c86-4cd7-a5ae-8f2817780720",
      "subcategoryIds": [
        "018eae7b-cb77-4699-be1e-497e11fc1b84",
        "8575cab6-f992-4f8a-ae22-1d59ad76bf20",
        "8a63c893-0374-43ee-acb4-57ad9010854e",
        "7d465b30-db4d-43d0-9365-a8a06c581de3",
        "6757b87a-6876-4bb5-bb78-f449c4726dd3",
        "143f47b8-0601-4b3f-a071-0368af1b57b0",
        "65c3404e-9065-4557-9f2d-0fa6d6abda9a",
        "f235d2a2-2a26-49e4-8288-b9a2e1a97b31",
        "36e67317-f8b1-48f1-9f69-bd4a0e40ed4e",
        "2e2bf9b5-c168-455b-b126-092cb708a81c",
        "933277a5-e2cf-4199-90bc-40207a6e3247"
      ]
    },
    {
      "id": "1e900707-d20d-4091-85bd-8be2785ea335",
      "name": "Power-Law Cluster Graph",
      "definition": "A Power-Law Cluster Graph is a type of network structure characterized by a hierarchical clustering pattern where the degree distribution of nodes follows a power-law distribution. In such graphs, a small number of nodes (hubs) possess a very high number of connections, while the majority of nodes have relatively few links. This structure often emerges in systems where connectivity is unevenly distributed, leading to clustered communities or modules that follow a power-law pattern, reflecting the scale-free nature of the network.",
      "categoryId": "a21ebbb6-559b-4556-bf43-82f68c6ffd5c",
      "subcategoryIds": [
        "a35c2188-6396-422c-9a69-92a9053c97e0",
        "421e91f8-6603-4220-9184-e6d903b1ec33",
        "3759b95c-9ecd-494d-8f9b-ced7d566eaf9",
        "781b3271-065a-43bc-a193-bcb64a39ec5f",
        "f9cd6d3f-25f7-4d0d-96ca-144b847ad43e",
        "38a2bbe7-bd3c-43ac-8ed8-986189ffeca5",
        "1aa17cae-ffd5-44b7-9527-31011858deb0",
        "34cc2969-1797-412b-98d7-af703e9972b7",
        "6ef7451b-7f4c-406a-879a-0788d11e0ce2",
        "b00c09cd-1c15-4a5d-b2e0-e39637acfabc"
      ]
    },
    {
      "id": "8afe4f97-c16e-439f-8ecd-d2f0c14fba05",
      "name": "Power-Law Graphs",
      "definition": "Power-law graphs are a type of network graph in which the degree distribution follows a power-law distribution. This means that a small number of nodes (hubs) have a very high degree (many connections), while the vast majority of nodes have relatively few connections. These graphs are characterized by their heavy-tailed degree distributions, which decay polynomially rather than exponentially. Power-law graphs are commonly used to model many real-world complex systems, such as social networks, biological networks, and the internet topology, where the presence of influential hubs significantly impacts the network's structure and dynamics.",
      "categoryId": "e5dbd346-fd12-437c-9370-43110d575dbb",
      "subcategoryIds": [
        "29b69913-6a58-4d72-999f-0ea4a37b14f3",
        "39d9961a-e8c4-4b91-824a-8fe14a752af3",
        "e089b54d-fb8c-472d-9254-df86eaf9fa4d",
        "a5668c0a-94fd-4d6a-9760-d299b2f8c205",
        "3d8f5cd4-2b73-4d61-af76-5f7e0541203b",
        "7b447127-a2ce-4cf0-b22f-5173bf3153c0",
        "c165b34e-2e9d-4a40-a04a-3ad505b404c6",
        "60de5f1b-b554-4b14-938a-d94d7de8a359"
      ]
    },
    {
      "id": "98d916b4-771f-4343-8cd9-f17790d5d9a4",
      "name": "PR curve (Precision-Recall curve)",
      "definition": "The Precision-Recall (PR) curve is a graphical tool used to evaluate the performance of binary classification models, particularly in scenarios where class imbalance is significant. It plots the trade-off between precision (the proportion of true positive predictions among all positive predictions) and recall (the proportion of actual positives correctly identified) across different threshold settings. The curve provides insights into how well a model can distinguish between positive and negative classes, especially in cases where positive instances are rare. The area under the PR curve (AUPRC) serves as a summary metric reflecting the overall effectiveness of the classifier in retrieving relevant instances.",
      "categoryId": "af8462e9-347c-4046-97e4-10c6a5dd0262",
      "subcategoryIds": [
        "55e88973-ed64-414e-b6ae-53132b31809e",
        "0bf1d026-fcc6-4f58-a475-b56b75a9badb",
        "15b28734-7297-4e38-a15e-d82fe3764b6f",
        "ef790c04-b1c0-4f6e-a90a-6267ae2ff4df",
        "ce76156c-ab7c-487a-a91a-19f1cd7ebcf9",
        "e9255ef4-401d-4d57-9680-3f324524ae6c",
        "cf20ca1a-04d6-49f8-84cc-e470d354421d",
        "26086ecd-dca5-4ed9-bd23-c450b7040047",
        "f7a47b2a-3d22-4ef9-9b89-8fb17a40669c",
        "b177ab2f-fe43-47b9-9f98-522fee06dca3",
        "2fa1756b-7401-4135-b272-47a5d24dec2c"
      ]
    },
    {
      "id": "9a9ee98c-6eaa-407a-8632-16b135fc231a",
      "name": "Practical Significance",
      "definition": "Practical Significance in AI/ML refers to the real-world applicability and importance of a model, metric, or result beyond theoretical or statistical validity. It assesses whether the findings or predictions made by an AI/ML system have meaningful and tangible benefits in real-life scenarios, such as improving user experience, increasing efficiency, or providing actionable insights. Unlike statistical significance, which measures whether an effect is likely not due to chance, practical significance focuses on the magnitude and impact of that effect in practical terms, guiding practitioners to prioritize solutions that deliver substantial value.",
      "categoryId": "fbc93b19-5a13-47da-a46d-5c870b28f358",
      "subcategoryIds": [
        "d3ab7827-8992-4523-9ead-e991087a388f",
        "21755801-166d-483a-a604-8ab9b0600355",
        "558d40b4-b152-4f90-98b1-ec6e6a9a7fc9",
        "205dd129-b8fb-4251-889c-d97491b6c52b",
        "a78dedea-607d-4bab-93f4-20d141d53d2c",
        "20cbafd2-30ba-45f2-83a5-abde1b87480a",
        "92a9e6af-b6fb-4a1c-b935-6b5bd715a06b",
        "fce93d46-ac5a-4153-b776-fe3fb5eb1407",
        "79c50b58-c501-41bc-ada1-419900047ca3",
        "de80747f-8375-42be-915f-ffb4b69ce4e3",
        "70155a2a-017d-49a1-9d29-e14adc8d2fb9"
      ]
    },
    {
      "id": "50ca2d54-6776-4be2-b638-aa4b1c967f33",
      "name": "pre-trained embeddings",
      "definition": "Pre-trained embeddings are dense vector representations of data, typically words, phrases, or other units, generated by models trained on large-scale datasets. These embeddings capture semantic and syntactic relationships within the data, enabling more efficient and effective processing in various Natural Language Processing (NLP) and machine learning tasks. By leveraging pre-trained embeddings, models can utilize rich contextual information without requiring training from scratch for each new task.",
      "categoryId": "0e7685d9-3956-4b90-85d5-c9dcddadfbe2",
      "subcategoryIds": [
        "01bd95da-1e24-4a50-a6f4-96cd63589cc6",
        "3163d03c-c6ea-409f-be53-478b405b03a9",
        "a5fdf74e-7e67-4709-b3a4-3f423afcb7cc",
        "a73fead9-ad01-4a5b-b97a-530485dff66a",
        "51e71297-6517-4295-8351-d517cafb9b64",
        "4177dfb7-43c0-4330-a420-ff83c29d3861"
      ]
    },
    {
      "id": "4b51f01d-7063-4076-b762-536e55b25da5",
      "name": "Pre-trained Language Models",
      "definition": "Pre-trained Language Models (PLMs) are advanced artificial intelligence models designed to understand, generate, and contextualize human language. They are trained on vast corpora of text data beforehand (pre-trained) to grasp the complexities of language, including syntax, semantics, and contextual nuances. Once pre-trained, these models can be fine-tuned for specific tasks such as translation, sentiment analysis, question answering, and text summarization, enabling efficient performance across various natural language processing (NLP) applications.",
      "categoryId": "01d46999-1f9b-49e8-a572-2fbf2e928780",
      "subcategoryIds": [
        "1d8becb5-3da1-4264-8d8b-440fed584300",
        "2ec69354-4805-4387-9aa8-5e209020285e",
        "b4b52667-a14d-404f-80c5-9c935c9d6ca3",
        "2c63f09d-7f3c-4d5e-bd8a-86ed89bc85da",
        "1adf760f-3e1a-475b-a3f9-108a32034d4f"
      ]
    },
    {
      "id": "f5d4179f-09ed-479b-a8d6-ca53df66b8b5",
      "name": "Pre-trained Models (e.g., BERT, GPT, ResNet)",
      "definition": "Pre-trained models are neural network models that have been initially trained on large-scale datasets to learn rich feature representations, which can then be fine-tuned or adapted for specific downstream tasks. Examples such as BERT, GPT, and ResNet exemplify models that have been trained on extensive corpora or datasets and are capable of generalizing across various applications, reducing the time and computational resources needed for training from scratch. These models serve as foundational building blocks in modern AI/ML workflows, enabling developers and researchers to leverage their learned knowledge for tasks like language understanding, image classification, and more.",
      "categoryId": "897c2c2e-937b-4766-86c1-76802d7edaa8",
      "subcategoryIds": [
        "2cb45e3d-477f-449c-b600-e640371077e2",
        "46cfc955-687b-4859-9e63-2bc06fe8deaf",
        "b1205d03-ba5e-4d42-a1af-612b97fa4467",
        "77ca9097-c9d4-4399-bc6d-11fcea87a575",
        "3a516efc-2d63-4698-8c1b-a45a0ab09170",
        "b6c3637c-cf0b-4040-8b7d-a7fe13f3d28a",
        "ba90eeff-6dd7-4073-9b2d-7f627dbe9394",
        "0f293f2c-2250-48d3-b666-07332000443e",
        "05daecb0-77bb-42d7-8582-f91d0ff22351",
        "dcb81dbd-6450-4ee6-a1f4-257365d3448f"
      ]
    },
    {
      "id": "b077a22b-8dbc-493b-aec7-05a7e80d2f05",
      "name": "Pre-training",
      "definition": "Pre-training in machine learning refers to the process of training a model on a large, generic dataset before fine-tuning it on a specific, task-related dataset. This initial phase helps the model learn broad features and representations that are transferable across various tasks, significantly reducing the amount of labeled data and training time required for the final task-specific model.",
      "categoryId": "a1e1de27-1094-4660-88be-3b3e14f6996a",
      "subcategoryIds": [
        "671cf91d-29a8-496a-b47f-947533c0e0af",
        "93e73ce3-9aad-4cb5-a0c8-e861caac3868",
        "592beb45-f9af-4752-b498-b4cea9110825",
        "a158642a-6620-4b6b-9f15-e9325c93baaa",
        "736db009-3be4-4a74-a9a2-0a133345ebc3",
        "59c02a9b-aef5-4d39-94d3-db4427aef92a"
      ]
    },
    {
      "id": "b3b4c719-ded9-4056-aa05-09f51bece1eb",
      "name": "Precedent Cases",
      "definition": "Precedent Cases refer to previously decided legal cases that serve as a guiding or authoritative reference for resolving current legal disputes. In an AI/ML context, the term is metaphorically used to describe historical data, prior models, or case studies that inform or influence current decision-making processes, model training, or system development. They encapsulate established patterns, outcomes, or rules derived from past instances, providing a foundation for designing, evaluating, and improving AI/ML systems.",
      "categoryId": "92657e19-1bbe-499b-ad86-900e5df98be5",
      "subcategoryIds": [
        "e62e8647-16ed-4ffc-be78-cecf74fad76d",
        "f1734613-9809-4011-a746-45cbb9b7e6e8",
        "39d657ce-0b00-4d0a-b3ac-b11e16cfc70b",
        "a3d3eb97-42c9-41fe-8c6e-ac0e995bb1c4",
        "6e5ddd02-ba34-4cd2-a3f1-9ac7692407a8",
        "2aaab042-daf0-4edc-88e2-5b0d9b25a041",
        "f84dda41-27b8-4e99-8f30-c67c1e472d92",
        "e10c4b8f-50be-49cd-a365-d126db98a981"
      ]
    },
    {
      "id": "8f2228e2-044c-4c11-b96e-e8fbf99a9a28",
      "name": "Precision",
      "definition": "Precision, also known as positive predictive value, is a statistical measure used in classification models to evaluate the accuracy of positive predictions. It is defined as the ratio of true positive predictions to the total number of positive predictions made by the model (sum of true positives and false positives). In essence, precision indicates how many of the predicted positive instances are actually positive. It is a critical metric in scenarios where minimizing false positives is important.",
      "categoryId": "593c069f-2068-41c7-a64d-ca30ca5d4bb9",
      "subcategoryIds": [
        "ef4fed92-e191-4b55-81dd-799f787e68ce",
        "20d72691-100d-4b5e-81cd-9263d892db50",
        "d8f0d30e-c9bc-49e2-8de8-a4b909dd0f05",
        "8961df50-9fad-44c7-bd6b-5c41d2df5a85",
        "e9b3dcae-d129-434c-9817-f9c323597507",
        "745fec49-db64-4d76-9f0f-21602c576b9c",
        "f4d08776-7b18-48ec-81bb-4311659d1453"
      ]
    },
    {
      "id": "6568da16-425b-4e46-842f-2069d92cf3f8",
      "name": "Precision and Recall",
      "definition": "Precision and recall are fundamental metrics used to evaluate the performance of classification models in machine learning. Precision measures the proportion of true positive predictions among all positive predictions made by the model, indicating how reliable positive predictions are. Recall, also known as sensitivity or true positive rate, measures the proportion of actual positive cases correctly identified by the model, reflecting its ability to detect positive instances. Both metrics provide insights into the model's performance, especially in scenarios with imbalanced classes or when the cost of false positives and false negatives varies significantly.",
      "categoryId": "04764e46-ed48-4cfb-a223-c4c9f52888fc",
      "subcategoryIds": [
        "09c2c3b9-e382-4f83-b917-745d53ac5b09",
        "62eda610-e776-4709-97ca-b5fc875bb713",
        "322e39d1-d134-4968-a62a-b1aa47fd726e",
        "80e5ba09-4062-456f-8e16-fdccdac4f06f",
        "71e94bdd-6507-4cdc-96d3-bca3f1b415a5",
        "aa5caec0-afc8-4c8d-82e8-36379e8f8c35",
        "5945052a-ad02-469b-b844-0c18b92e9f82",
        "ad8c3a41-75b7-461e-b281-6fc8d475d52f",
        "e3badd49-40ef-4929-afec-ff7dee1b9942",
        "23c6f9ea-5e61-46f6-b497-aa38536f637c",
        "dcca43af-5890-46b8-9157-baf4b340911a"
      ]
    },
    {
      "id": "9298af74-ecaa-431d-a485-1e320ea71ec8",
      "name": "precision reduction",
      "definition": "Precision reduction in AI/ML refers to techniques employed to decrease the numerical precision of data representations, such as weights, activations, or gradients, within neural networks and other models. This process involves converting high-precision floating-point numbers (e.g., 32-bit or 64-bit) into lower-precision formats (e.g., 16-bit, 8-bit, or even binary), aiming to optimize computational efficiency, reduce memory usage, and accelerate training and inference processes while maintaining acceptable model accuracy.",
      "categoryId": "40f4817f-5014-4bf7-9918-d6ee35b5476b",
      "subcategoryIds": [
        "a8023855-d302-4703-bd92-bfb8d8a1ceb6",
        "111eb156-f022-4419-8387-3a3314dfe7da",
        "3dd2ce40-e899-4cf8-bc85-5b23f76e670d",
        "3e8351fc-3a37-455a-bdec-5bc41f84990e",
        "015932d4-061c-483b-9693-0be4224e092f",
        "6d266e64-07e2-4c19-889c-0085c60f7b37",
        "43f64583-30d0-4b40-a908-f57bb4cd8200",
        "67584a4d-bb40-4783-bc51-0caa617faa28",
        "f592f895-b3e2-47ed-bf18-057c3e717186",
        "a4016c4e-430f-4291-9840-e48ad3e5fe5f"
      ]
    },
    {
      "id": "d950033a-8433-4385-ad4a-40e8657b8445",
      "name": "Precision-Recall Curve",
      "definition": "The Precision-Recall (PR) Curve is a graphical tool used to evaluate the performance of binary classification models, especially in scenarios with imbalanced datasets. It plots the precision (the fraction of true positive predictions among all positive predictions) against recall (the fraction of true positives identified out of all actual positives) at various threshold levels, providing insights into the trade-offs between these two metrics across different decision thresholds.",
      "categoryId": "54144812-b5c6-47e9-a2b9-c1b4eaece433",
      "subcategoryIds": [
        "a3e13acc-050a-4d20-82f9-aeac9ab633d1",
        "b36e9bf1-9245-4f36-a456-9cbd2244042e",
        "bc243726-b5df-4117-891a-0246346fac19",
        "4440d631-5482-45f9-b626-1f7fa995ab5a",
        "3b4f6a10-324b-4ecc-9381-972fd95f6392",
        "fc6e0f35-2f49-48b8-aaea-f19352c2a5fc",
        "1d021052-4709-4714-b968-a4d780ec7640"
      ]
    },
    {
      "id": "10f0c611-bc25-4271-b035-e5a1f35bd65a",
      "name": "Precision-Recall Tradeoff",
      "definition": "The Precision-Recall Tradeoff refers to the inverse relationship between precision and recall metrics in classification tasks, particularly in scenarios with imbalanced datasets. It highlights that improving one metric often results in a decrease in the other, necessitating a balanced approach depending on the specific application requirements. Precision measures the proportion of true positive predictions among all positive predictions, indicating the accuracy of positive classifications. Recall, also known as sensitivity, measures the proportion of actual positives correctly identified by the model. The tradeoff is typically visualized using precision-recall curves, which help in selecting appropriate thresholds for optimal performance.",
      "categoryId": "869423ad-aa97-4e5e-a138-35a40720da9d",
      "subcategoryIds": [
        "af7e000c-8c08-4669-ba92-ff063bd2b2b1",
        "b014f11b-e936-4503-8d31-0483979a086b",
        "7812005d-e57d-4763-963c-b618a3d9b7ac",
        "d1af6e0b-2808-4560-8946-026cb692812c",
        "a54bd3a9-58bc-444e-a2cc-f65f50263e9d",
        "0d51e4c0-270f-46ca-98f4-51393a141dd6",
        "ad63cdf7-2403-4619-a01a-7e738d629153",
        "35aeeb52-25b8-413e-af36-9873bd54fa32",
        "66673cf2-2738-4ad7-be58-336e0c16f70d",
        "d8bc35ce-0b8f-4967-ae07-bb8021c6374c"
      ]
    },
    {
      "id": "7052baf6-16a1-4fdf-847b-49c22060ce1f",
      "name": "Predictive Coding",
      "definition": "Predictive Coding is a theoretical framework and computational model in neuroscience and machine learning that posits the brain continuously generates and updates predictions about sensory input based on prior knowledge, and then compares these predictions to actual sensory data. Discrepancies, or prediction errors, are used to refine future predictions. In AI and ML, predictive coding algorithms harness this principle to enable systems to efficiently process, interpret, and learn from complex data by prioritizing prediction accuracy and minimizing error signals.",
      "categoryId": "d35134fe-74d5-4c52-8a55-b846c7dfb9e6",
      "subcategoryIds": [
        "702501d5-0b30-47b1-b7ff-22f54d3e041c",
        "70d9c123-089c-4eec-92f5-c5aba24cc5e1",
        "0e0cdc5b-3a25-4a0a-af6f-4bc482ba3e77",
        "6bf95e45-f690-4edb-b823-7b928fa2ebc6",
        "9d86451e-26d1-4bf4-9a4d-8ba27044b1d9",
        "92ba6d48-9284-4569-af61-aa3027b30a58",
        "c6519c9a-996b-46c8-9438-82d02dfefbc3",
        "33c56e72-c1f3-41be-8442-eb3395fe1caf",
        "3f6bce7b-97d6-432e-b9c9-589ee1ead3a6"
      ]
    },
    {
      "id": "6b013143-f8b5-4fbb-afdb-528f6be46a82",
      "name": "Predictive Data Mining",
      "definition": "Predictive Data Mining is a branch of data analysis that focuses on extracting patterns and predictive models from large datasets to forecast future outcomes or behaviors. It involves using statistical techniques, machine learning algorithms, and data mining methods to analyze historical data, identify relevant features, and construct models that can predict unknown or future data points with high accuracy. This process is integral to transforming raw data into actionable insights, enabling businesses and organizations to make informed decisions based on anticipated trends and behaviors.",
      "categoryId": "3c0d64d6-9e10-475e-8d53-bf7f060921de",
      "subcategoryIds": [
        "c423cd52-1881-4411-ace3-c3edc86cc665",
        "8fc2d1c4-b929-4afa-883a-57cacfc97659",
        "d1236303-8de4-41f4-940c-9c5c4088ccc2",
        "210576ab-d2c4-4d43-be0e-afd5f218d0f1",
        "314c7a6c-f1c5-4948-b84b-88bd0c0d6323",
        "33d153c8-5beb-4121-bea5-4846c4645a82",
        "39dbed63-6df8-4bb0-bf21-77e6e142231f",
        "60c427da-7735-4385-9f86-c057737b4cbe",
        "62a3d9fa-1dda-4554-a625-d4123bf9c751",
        "6bcf7e2e-f618-467c-a9d2-3d041ad5738d"
      ]
    },
    {
      "id": "bdf09d59-7e9f-41b6-9404-8ee39363b219",
      "name": "Predictive Modeling",
      "definition": "Predictive modeling is a branch of statistical analysis and machine learning focused on creating models that can forecast future outcomes based on historical data. It involves using algorithms to identify patterns and relationships within data, enabling the prediction of unknown or future data points. These models are widely applied across industries for tasks such as sales forecasting, risk assessment, and customer behavior analysis, making them integral to decision-making processes in data-driven environments.",
      "categoryId": "92ab1c3c-a858-434f-80fc-338a184c3d67",
      "subcategoryIds": [
        "d8ee5b13-81fe-4002-854b-8713c4d99de8",
        "0dfa356e-de91-41a4-8e7d-57314f559aa7",
        "af0e1f5e-aa70-4c1e-9525-62ba1633eb62",
        "572f09bc-d71b-40c1-b2a4-a86f96373915",
        "173a0b85-f3df-4a7f-8125-d016e77012fd",
        "c4042c44-4e51-4518-a6dd-39a241a2c177",
        "164122dd-5a87-45ad-ae4a-ac3c2d9cb01c",
        "ccbb15e5-4057-4c2f-89e3-2588e0b66c73",
        "fbd3802c-7853-46e1-bf2a-95d77bb2b0cd",
        "11a50e18-7d15-4bcd-b9c1-d5c3db577177",
        "d6c81df0-24c8-4c7e-8408-ecaf0d814f3e"
      ]
    },
    {
      "id": "f9f52eb5-3d8b-4025-af58-9eb870dec7ca",
      "name": "predictive probability",
      "definition": "Predictive probability refers to the likelihood of a specific outcome occurring, as estimated by a probabilistic model based on existing data. In AI and machine learning, it signifies the probability assigned by a model to a particular event or prediction, often used to quantify the certainty associated with a classification, regression, or other predictive task. It provides a measure of confidence in the model's forecasts, enabling more informed decision-making processes.",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd",
      "subcategoryIds": [
        "f308d66f-0f63-423d-b9e7-a04f51d43c05",
        "43233124-ce42-4faa-be02-6ad2fb674979",
        "678768b0-4c88-48db-ac0d-562634927521",
        "a79b027d-9eff-46ca-baf5-30007831dc2a",
        "ee15ff7f-ef5e-4708-976c-3b6b9c4b902e",
        "134de141-a38a-4768-be2d-1130edf8abab",
        "ab442b5c-adbb-419d-aae9-459b61d83797",
        "167a31e8-7370-4fd5-9eb5-0454d5f66d98",
        "62f61e14-0c23-4951-afb9-0fce9a944330",
        "0cc9a447-55cc-4f80-8101-2aee1be8ad2f"
      ]
    },
    {
      "id": "fffb2a1f-5187-42aa-b6f7-e3ad44201845",
      "name": "Predictive Validity",
      "definition": "Predictive validity is a measure used to evaluate the effectiveness of a test, model, or instrument in predicting future outcomes or behaviors. In the context of AI and Machine Learning, it refers to how well a predictive model's outputs correspond to actual future data or events. Essentially, it assesses the extent to which the model's predictions are accurate and reliable when applied to new, unseen data, ensuring that the model provides meaningful and useful forecasts in real-world applications.",
      "categoryId": "c2e50132-7174-4331-a50e-bed60c0dbe0c",
      "subcategoryIds": [
        "5ff395ce-bd7c-4f13-a7cf-112e66f21a65",
        "ef9522ee-9c33-4a7c-8d39-ffb9eae7d796",
        "9030a9cb-d2ff-4cd7-90ca-1890fef59651",
        "f3b1b057-074c-4dae-b975-2e7a22ac23d1",
        "1365f06f-20b7-4680-abc7-baf84a4320d2"
      ]
    },
    {
      "id": "650e22b2-87fa-4e6d-b1ff-a41b817fa7cc",
      "name": "Predictor Variable",
      "definition": "A predictor variable, also known as an independent variable or feature, is a measurable factor or attribute used in a statistical or machine learning model to predict or explain the variation in a response or target variable. It serves as input information that influences the outcome of interest, allowing models to learn relationships and make forecasts based on observed data.",
      "categoryId": "d90c8e4d-13d2-43fb-9e31-b459a14372de",
      "subcategoryIds": [
        "a779de61-b413-4c49-b101-ea237ec176c5",
        "9ba30c0c-2f0f-419f-b646-0cbd1d4a50a9",
        "be4eb4e6-4599-4a43-b5c1-1ed3a13dde7f",
        "b6f9c34e-f668-4d1b-888f-cea40214dc32",
        "0d50d199-ca66-44f8-bc20-3a09faa939cb",
        "5bdfee17-8e2e-4a40-b9e1-2276ce104fad",
        "4fc6fd7d-5798-4d45-9a34-13f0bdcf5382",
        "01e3e714-dc5b-4703-ae6f-8ef06c612379"
      ]
    },
    {
      "id": "33738a4e-3d88-464f-80ce-635bb3bb4567",
      "name": "Preferential Attachment Model",
      "definition": "The Preferential Attachment Model is a network growth mechanism that explains how networks such as social, biological, and information networks tend to develop highly connected nodes, or hubs. In this model, new nodes are more likely to connect to existing nodes that already have a high degree of connections, leading to a scale-free network characterized by a power-law degree distribution. This phenomenon captures the 'rich-get-richer' effect, where popular nodes become even more popular over time.",
      "categoryId": "47aadffe-07c5-4d14-a9af-f735545fdd0c",
      "subcategoryIds": [
        "dbe6b24d-7ee6-454e-8d1e-e44df4085f54",
        "0456b013-176f-4b8d-9cb4-a3189eec22ef",
        "b73fff3a-d1c8-4c03-8430-bc7eca018894",
        "9759c440-968c-48f3-a2f0-11c8525915e1",
        "87654db0-928a-4af5-87de-27b4deaea3b0",
        "6e4074e6-2456-420d-8910-0f21172ef6ee",
        "88478724-d772-4c2d-a562-2958ed307467",
        "88df9959-1e4f-4af2-a675-3325a0d2ce31"
      ]
    },
    {
      "id": "c76e9d96-b23b-465b-95df-6a69a88ef267",
      "name": "Preferential Attachment Networks",
      "definition": "Preferential Attachment Networks are a class of network models where new nodes are more likely to connect to existing nodes that already have a high degree of connectivity. This mechanism results in networks with a few highly connected hubs and many nodes with fewer links, exhibiting a scale-free degree distribution. These networks are used to model real-world systems such as social networks, citation networks, and the internet, where new entities tend to attach to popular or well-connected nodes, reinforcing existing connectivity patterns.",
      "categoryId": "05f2a543-5a39-4f64-a14c-0d93475106c6",
      "subcategoryIds": [
        "869f129c-4da2-4b0a-baf7-703a7d70caee",
        "a5b78030-a90f-45c3-9266-a306b62fc462",
        "336f4e59-902a-4f7e-8556-770b7c0ec281",
        "d59db091-d404-4b5e-8a54-8f330cc5a7dd",
        "96b4de4c-6bc0-4ea0-a90c-d2a40caa0130",
        "6a8069a4-f9b8-47bf-a494-c05a7b8fa15a",
        "3dbf65fb-cb3c-4b5a-968c-bf64faf22537",
        "d60002d3-d8c3-45d8-8760-0bfac4a8a3fb",
        "53794895-66b1-440a-ace9-70c14916b488",
        "b1e4e9e9-560c-4bc7-b12a-a6410dbac93a"
      ]
    },
    {
      "id": "380f1bd0-b1b1-4d28-9044-87cf88c1445c",
      "name": "Prefix Tuning",
      "definition": "Prefix tuning is a parameter-efficient fine-tuning technique used in natural language processing (NLP) models. It involves training a small set of continuous vectors, called prefix prompts, which are prepended to the input embeddings during model inference. This approach enables the adaptation of large pre-trained language models (PLMs) to specific tasks without updating the core model weights, thereby reducing computational costs and storage requirements. Essentially, prefix tuning leverages prompts as a way to steer the language model's output towards desired behaviors while maintaining the general knowledge encoded in the full model.",
      "categoryId": "92e8f341-0ee0-43e7-8fd4-090d9642bff0",
      "subcategoryIds": [
        "cfe5362c-c179-4ea2-b217-bad21319fd2d",
        "57114b63-6182-4db5-8278-158f2f7b003b",
        "6a870e15-0867-4466-95d8-4703e5b70ec4",
        "2324b054-c845-48c5-9ba2-38b9258a74f0",
        "cd9daa61-c4db-49f2-b037-da116a94da3e",
        "921bb85b-ed27-49de-b4cd-94a24e5df0b5",
        "185bcff1-c253-4f72-afad-6cd9214d331a",
        "2edf31cb-ef85-48b6-a45f-17fc9c03894d",
        "6230ebd2-34c7-4c6f-a134-08fd1766a810"
      ]
    },
    {
      "id": "c7362531-ffa4-4761-a7dc-0cf3020eb683",
      "name": "Presence Penalty",
      "definition": "Presence Penalty is a parameter used in natural language generation models, such as GPT, to influence the diversity of the generated text. It penalizes the model for repeatedly selecting tokens or words that have already been used, thereby encouraging more varied and less repetitive outputs. By adjusting the presence penalty, developers can control how much the model avoids reusing previously mentioned concepts or tokens within a given context.",
      "categoryId": "c1b289fc-1fcb-4d24-a770-fc528e43d6ee",
      "subcategoryIds": [
        "eeccb48f-9579-4f9f-82e8-14af1a9ccba2",
        "bdf70940-9958-4054-8f0c-3baf493184bb",
        "16cf3fbb-4e93-484a-8a8a-afb2e5fd937f",
        "a9aa7eec-f25f-4ecd-8968-767d11cce947",
        "88c5e7b2-ddf9-4ef0-895f-005344c6d8e9",
        "da24262b-0a9a-4de1-b63d-55452a05ed4b",
        "681a036e-504a-4b3d-9c94-35de6bcfdde3"
      ]
    },
    {
      "id": "864ce1bd-c56f-46f3-953b-39d293cbddea",
      "name": "Pretext Task",
      "definition": "A Pretext Task, also known as a pretraining objective, is an auxiliary task designed to help a machine learning model learn useful representations of data before being fine-tuned on the specific target task. It involves training the model on a self-supervised or unsupervised task where the correct answers are derived from the input data itself, allowing the model to learn underlying patterns without requiring labeled datasets. These tasks are crucial in modern AI development, especially in natural language processing and computer vision, enabling models to develop rich feature representations that improve downstream task performance.",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd",
      "subcategoryIds": [
        "0838fc9f-83a4-4eeb-8134-24dfdd39b682",
        "aa0d171f-ee5d-4474-a9c2-f419c730ebfd",
        "ba8bd8ee-5dac-4843-9c87-fd7f89ed3c75",
        "abe8f879-91ad-4677-b6db-9a7dad85c00b",
        "6ace9e41-867f-4bf0-8913-291ff79e4751",
        "39df3cf2-2c77-419f-98c8-6cef33d78ef1",
        "fd7942cd-f442-49ff-a8db-9105ef604ee7",
        "4337f19e-e95a-4f76-9890-32101d01df2f",
        "4446a74b-8197-4c40-a261-de889d713d6b",
        "b8678472-1f76-4d11-915d-18259a178d26"
      ]
    },
    {
      "id": "22fe5d1e-ebcb-4e92-9c5b-bf6debb858d8",
      "name": "Pretrained Weights from Transfer Learning",
      "definition": "Pretrained weights from transfer learning refer to the initial parameters or internal representations of a neural network model that have been trained on a large, possibly generic dataset and are subsequently used as a starting point for a related but different task. Instead of training a model from scratch, practitioners leverage these pretrained weights to accelerate training, improve performance, and reduce computational resources. This approach allows models to benefit from features learned during the initial training, which often capture fundamental patterns in data such as edges, textures, or higher-level concepts, making them highly valuable in various machine learning applications.",
      "categoryId": "9492d189-a19a-49cc-a1e6-46cc2e992fbd",
      "subcategoryIds": [
        "cfec4b5c-827c-4fa2-9935-71b01bf3efe4",
        "c7c29bde-a318-45d7-b2be-28fa7509619b",
        "4446a74b-8197-4c40-a261-de889d713d6b",
        "b8678472-1f76-4d11-915d-18259a178d26",
        "4337f19e-e95a-4f76-9890-32101d01df2f",
        "6cdcc7f2-c55d-4a9a-bea5-76b975bf59a0",
        "fd7942cd-f442-49ff-a8db-9105ef604ee7",
        "3b4f328d-7af4-4300-8787-93860575ae8f",
        "a902820a-d431-41de-8f15-f9407fc129c9",
        "745fd042-f078-438c-aa6b-783cee37be91"
      ]
    },
    {
      "id": "5a36f9a7-7233-4618-82ef-9e7dbc1a1862",
      "name": "Pretraining",
      "definition": "Pretraining in machine learning refers to the process of training a model on a large, general dataset before fine-tuning it on a specific task or domain. This approach helps the model learn general features and representations that can be adapted to various downstream tasks, often resulting in improved performance and reduced training time. Pretraining is a foundational step in many state-of-the-art models, particularly in natural language processing (NLP) and computer vision, enabling models to leverage vast amounts of unlabeled or partially labeled data to build robust initial representations.",
      "categoryId": "8954a6e5-05c9-4f6c-98c8-a9f60179badc",
      "subcategoryIds": [
        "0c6f0ec0-471f-4995-a61f-9b02dd352875",
        "15add49e-ff72-4f4a-b3db-810cf5515649",
        "c809d250-40b0-4744-9365-a96306d5cbcb",
        "43321d03-0b9d-481b-9f3d-9eebb4a1a283",
        "a64b8567-61ee-4774-9b78-1fde14fad2c3",
        "3a0c0996-1710-4f20-a961-acd0f724ed42",
        "ab242f39-6dfa-4a33-965d-10f7d2324258",
        "635048a3-99a1-44fb-b10a-005c7e75f242",
        "f20b4176-451c-4991-bba2-68b0b95a71cf",
        "106a25b9-48e0-4a36-8281-2d470a2ff9c4"
      ]
    },
    {
      "id": "e75a0e55-6d4c-4eb8-a1e1-2d5ddf376981",
      "name": "Pretraining and Fine-Tuning Paradigm",
      "definition": "The 'Pretraining and Fine-Tuning Paradigm' refers to a methodological approach in machine learning where a model is first trained on a large, general dataset (pretraining) to learn broad patterns and representations, and subsequently adapted to specific tasks through additional training on smaller, task-specific datasets (fine-tuning). This paradigm allows for leveraging vast amounts of unlabeled or minimally labeled data to develop foundational models that can be efficiently specialized for particular applications, thus improving performance and reducing training time compared to training models from scratch.",
      "categoryId": "064f4ae6-0b6b-4972-b926-5577e8ba4472",
      "subcategoryIds": [
        "813524e0-0b8b-4616-9d54-803b1ed66326",
        "835d2e52-3552-4303-b704-d41fffb76476",
        "29403518-6d44-45b1-9679-bdb4ca997cc2",
        "ab6e83ec-00ee-47d4-abf5-cb6a26d8ab0b",
        "81104903-ab4b-4293-8ef5-596cc7ecc1f8",
        "c4e7fca1-6726-4ab0-be08-a834c21cbcbe",
        "928d2560-26f1-4378-a70a-1fa500cbbacc",
        "ec51d067-ad85-42e3-8d2c-42929245a7c5",
        "43183b13-148c-4f8e-8a9d-fc0a306d2f06",
        "d85c9870-9ce3-4465-869a-930d7c471571"
      ]
    },
    {
      "id": "7444ff78-3b4d-437a-948c-b228e2f37dca",
      "name": "Principal Component Analysis (PCA)",
      "definition": "Principal Component Analysis (PCA) is a statistical technique used in machine learning and data analysis to reduce the dimensionality of a dataset while preserving as much variability as possible. It transforms the original variables into a new set of uncorrelated variables called principal components, ordered by the amount of variance they capture. This process simplifies complex data, making it easier to visualize, interpret, and use for subsequent modeling tasks.",
      "categoryId": "73064999-8c6b-46d0-9348-504e41976f45",
      "subcategoryIds": [
        "aa165982-6a88-4de7-91a6-eb1e74e2b293",
        "05259814-08d0-4447-8494-9e24a4fb3890",
        "dff6f0b5-215e-4bcc-a622-d73e4383f3d1",
        "3e4b61c0-4800-4ee5-871d-b56930578b96",
        "3bf530ac-c7b9-4624-b1aa-3ed82c6d88b2"
      ]
    },
    {
      "id": "8f0bd448-1c5d-4f19-82b9-52cc6a2062e4",
      "name": "principal component analysis (PCA) for embeddings",
      "definition": "Principal Component Analysis (PCA) for embeddings is a dimensionality reduction technique used to transform high-dimensional embedding vectors into a lower-dimensional space. By identifying the directions (principal components) along which the data varies the most, PCA simplifies the structure of embeddings\u2014such as word, sentence, or image embeddings\u2014while preserving as much informational variance as possible. This process facilitates visualization, noise reduction, and improved computational efficiency in subsequent tasks.",
      "categoryId": "2433bd03-6d3a-4bd2-8695-cbc38078bf91",
      "subcategoryIds": [
        "514106a7-e8c6-4135-acb5-277c5b27e602",
        "c443f0b9-07d4-4095-9e7a-a243be883038",
        "ae5504be-81b9-495d-8096-09cc4cf9483e",
        "615a6cd5-2b3c-4827-9dc4-c4fae2809a06",
        "dd3297f0-3337-4f57-abd9-79433659d381",
        "8a266f8f-d5c0-41a4-849e-202a2fd35116"
      ]
    },
    {
      "id": "40ceaad5-3b7d-4224-bcba-ddc1ebbe7d21",
      "name": "Principal Component Analysis (PCA) in Regression",
      "definition": "Principal Component Analysis (PCA) in Regression is a dimensionality reduction technique that leverages PCA to identify the most significant features or components in the data before applying regression models. It involves transforming the original correlated variables into a smaller set of uncorrelated variables called principal components, which capture the maximum variance within the data. When integrated into regression, PCA helps address issues like multicollinearity, improves model stability, and reduces overfitting by simplifying the feature space and emphasizing the most informative features.",
      "categoryId": "659f680a-5d62-4775-b990-ede10c2b51e2",
      "subcategoryIds": [
        "e22ce3c5-5660-4b0b-9378-90cfd2b2c084",
        "71beb96c-91c0-4a92-aae8-b6c8dd94efd0",
        "48d6712c-0586-4f49-8016-05c11ec9e795",
        "2dceabd8-8671-401b-b32e-a57b4f7abcb5",
        "569e8e7c-9aa4-4d8c-b1af-fd70efb8ed89",
        "b2e2f71c-cf34-421f-a43b-955976873efa",
        "9a9df14b-0070-4b6b-b387-43cbc0dd34fb",
        "728083c0-4922-4f8c-b873-ae1ae54f9124"
      ]
    }
  ]
}