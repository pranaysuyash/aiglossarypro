{
  "categories": [
    {
      "id": "ab2b4a90-f0cf-402d-a798-fafcc2dd2ca7",
      "name": "Probability Theory"
    },
    {
      "id": "8dc40527-6f46-4a1b-9ab1-5905adcdcc6d",
      "name": "Distance Metrics"
    },
    {
      "id": "2bd8b40c-79f5-4b84-813f-a70ebe2d5360",
      "name": "Neural Networks"
    },
    {
      "id": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "name": "Machine Learning"
    },
    {
      "id": "f001a980-b036-4a8b-a7b0-290e7b1c9a77",
      "name": "Deep Learning"
    },
    {
      "id": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38",
      "name": "Artificial Intelligence"
    },
    {
      "id": "a08d705b-8994-4bcf-9c82-17c75c3bc367",
      "name": "Statistics"
    },
    {
      "id": "306fd1ff-712c-4027-a13a-5f560c4b6b72",
      "name": "Linear Algebra"
    },
    {
      "id": "c2c2f0d1-ca4f-4b23-9086-ee7ab14ad5a6",
      "name": "Matrix Factorization"
    },
    {
      "id": "f697ffdc-db4e-4058-938b-63083e5204a2",
      "name": "Computer Vision"
    },
    {
      "id": "0f9a17f6-01ac-468e-a0ce-db0dbd086923",
      "name": "Graph Theory"
    },
    {
      "id": "954025b2-e0af-4d2f-b77a-ddca1b88361e",
      "name": "Natural Language Processing (Nlp)"
    },
    {
      "id": "8e501b08-14ea-4c6c-bbe8-0e8a0c7dfa17",
      "name": "Ai/Ml"
    },
    {
      "id": "32ecb9c6-c9a0-4b57-b94e-d5e703a0388d",
      "name": "Electrical Engineering"
    },
    {
      "id": "88458ea2-7ad9-4440-b6c6-dd20ed5c727c",
      "name": "Computational Complexity"
    },
    {
      "id": "f59f920d-a73a-4a03-89d5-b1fbef1c4b96",
      "name": "Circuit Analysis"
    },
    {
      "id": "da0a70ec-2846-4a5b-96d2-41f9070d7d56",
      "name": "Signal Processing"
    },
    {
      "id": "8d35f4cf-19b3-4944-a323-473abaa3eb92",
      "name": "Convolutional Neural Networks"
    },
    {
      "id": "970cc6d8-f2a1-4be1-b044-4044a17fc1dc",
      "name": "Supervised Learning"
    },
    {
      "id": "a1c2ec89-ddcf-4fff-ad43-622a5b33df97",
      "name": "Multi-Label Classification"
    },
    {
      "id": "62590c8a-eeee-4408-b5ec-71614f20da3d",
      "name": "Generative Models"
    },
    {
      "id": "f3b96f41-4969-4c65-adc2-feb6e1ab6e95",
      "name": "Ai Security"
    },
    {
      "id": "908d0be6-c964-4196-a519-24e707e1f1b1",
      "name": "Ai"
    },
    {
      "id": "f4a166e4-92f8-4e53-bbd2-66c352a23c5e",
      "name": "Data Mining"
    },
    {
      "id": "45dc2762-eb9a-41a3-b001-b823adcbf3a4",
      "name": "Time-Series Analysis"
    },
    {
      "id": "b1801e0d-e24b-4ad2-9e47-20e042487137",
      "name": "Semi-Supervised Learning"
    },
    {
      "id": "de8842d5-eb45-4c4d-b8f3-15f9a39657f4",
      "name": "Clustering"
    },
    {
      "id": "9c2d686b-dc1c-4ed7-bf77-2cbe83efde08",
      "name": "Natural Language Processing"
    },
    {
      "id": "9bc4b2cf-9af5-40c7-b6e8-302cd9ba549c",
      "name": "Bayesian Regression"
    },
    {
      "id": "673c9312-a3b8-46cb-b61a-e25b3c7f30a1",
      "name": "Probability"
    },
    {
      "id": "bd264002-0726-4dd7-bb5e-134c5fc6e63e",
      "name": "Generative Adversarial Networks"
    },
    {
      "id": "d05f2a80-334c-41d4-b0db-02c71638e9d8",
      "name": "Energy-Based Models (Ebms) Are A Class Of Probabilistic Models That Assign An Energy Score To Eac..."
    },
    {
      "id": "90081538-133d-4daa-842e-dd866ccc294a",
      "name": "Ensemble Methods"
    },
    {
      "id": "568523b2-fa1a-4a9e-b2e7-c894832e26e2",
      "name": "Ensemble Learning"
    },
    {
      "id": "93b6daed-ada5-467e-bb57-c4b278896740",
      "name": "Statistical Estimation"
    },
    {
      "id": "f3cc5848-17f6-4279-a475-458a184ce408",
      "name": "Chemical Engineering"
    },
    {
      "id": "3e4c5e60-7266-4d25-8242-b6f3b9a4b190",
      "name": "Formal Concept Analysis"
    },
    {
      "id": "68a5cba0-fded-4081-b8ab-4e9e975b8706",
      "name": "Reinforcement Learning"
    },
    {
      "id": "2b22b5bb-853f-4223-b261-3529a749faa5",
      "name": "Fourier Features"
    },
    {
      "id": "b8efc3ce-ee01-45f6-98b1-b4f2f8403af6",
      "name": "Ai Hardware"
    },
    {
      "id": "0bf30cf3-9e76-4a60-bafa-42b77b5eb474",
      "name": "Fractional Calculus"
    },
    {
      "id": "316ca6bb-f333-42fa-bb20-ddc3944c0961",
      "name": "Feature Engineering"
    },
    {
      "id": "7e3a5556-560d-464a-a3d5-60eeb033a538",
      "name": "Probability Distributions"
    },
    {
      "id": "691a0b1e-82ca-49f5-a362-e61040cc378e",
      "name": "Regression"
    }
  ],
  "subcategories": [
    {
      "id": "d2e4b2d4-caef-43da-af6a-2c16ac20ea09",
      "name": "Probability Theory",
      "categoryId": "ab2b4a90-f0cf-402d-a798-fafcc2dd2ca7"
    },
    {
      "id": "545516f1-70dc-4138-87e5-16978ca55d25",
      "name": "Characteristic Function",
      "categoryId": "ab2b4a90-f0cf-402d-a798-fafcc2dd2ca7"
    },
    {
      "id": "4cb739f5-85c2-4cc3-b297-2cdb62ffd854",
      "name": "Distribution Functions",
      "categoryId": "ab2b4a90-f0cf-402d-a798-fafcc2dd2ca7"
    },
    {
      "id": "219a9ecc-6d6f-40c9-9e09-d72995f513af",
      "name": "Random Variables",
      "categoryId": "ab2b4a90-f0cf-402d-a798-fafcc2dd2ca7"
    },
    {
      "id": "4c724cc5-801c-4952-a403-b3d96d59fcf3",
      "name": "Fourier Analysis",
      "categoryId": "ab2b4a90-f0cf-402d-a798-fafcc2dd2ca7"
    },
    {
      "id": "ab975c15-7fa1-4454-ab17-bf34be3bb416",
      "name": "Distance Metrics",
      "categoryId": "8dc40527-6f46-4a1b-9ab1-5905adcdcc6d"
    },
    {
      "id": "d36ed93d-5b22-4586-88d3-7226607de7cc",
      "name": "Geometric Measures",
      "categoryId": "8dc40527-6f46-4a1b-9ab1-5905adcdcc6d"
    },
    {
      "id": "a87e80c0-f57d-49a3-832f-8c6b4ca0ec96",
      "name": "Mathematical Foundations",
      "categoryId": "8dc40527-6f46-4a1b-9ab1-5905adcdcc6d"
    },
    {
      "id": "4c77a526-7edd-4fcf-b9e6-e185c35746f0",
      "name": "High-Dimensional Spaces",
      "categoryId": "8dc40527-6f46-4a1b-9ab1-5905adcdcc6d"
    },
    {
      "id": "e6a1815f-8e1e-4703-84f1-9f4ed81b4fe1",
      "name": "Quantitative Analysis",
      "categoryId": "8dc40527-6f46-4a1b-9ab1-5905adcdcc6d"
    },
    {
      "id": "cd922b08-7af3-40f6-b0c5-b94541a988ce",
      "name": "Neural Networks",
      "categoryId": "2bd8b40c-79f5-4b84-813f-a70ebe2d5360"
    },
    {
      "id": "bc7c410c-09fd-4a31-8490-8c24f32c7f59",
      "name": "Approximation Theory",
      "categoryId": "2bd8b40c-79f5-4b84-813f-a70ebe2d5360"
    },
    {
      "id": "dbd3d0e0-9f23-4c24-b9bf-066a56da4879",
      "name": "Learning Algorithms",
      "categoryId": "2bd8b40c-79f5-4b84-813f-a70ebe2d5360"
    },
    {
      "id": "11dde0a2-af7f-49bb-b929-0c96731170e7",
      "name": "Function Approximation",
      "categoryId": "2bd8b40c-79f5-4b84-813f-a70ebe2d5360"
    },
    {
      "id": "92f91748-6064-4387-97ad-0db5f17a2327",
      "name": "Polynomial Approximation",
      "categoryId": "2bd8b40c-79f5-4b84-813f-a70ebe2d5360"
    },
    {
      "id": "fd1b802d-75aa-4296-ae3a-45c2aa62fbd7",
      "name": "Spectral Methods",
      "categoryId": "2bd8b40c-79f5-4b84-813f-a70ebe2d5360"
    },
    {
      "id": "a1bbc4a4-1eba-48e0-a1b6-f88a22c8b336",
      "name": "Neural Network Architectures",
      "categoryId": "2bd8b40c-79f5-4b84-813f-a70ebe2d5360"
    },
    {
      "id": "fd0c198f-cb24-4cd1-8807-3629dc3127ae",
      "name": "Polynomial Approximation",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "47b6ebd7-6eb8-43ee-8d6d-9db29b9b2cc8",
      "name": "Spectral Neural Networks",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "570304bd-837d-4b58-9ca2-01a0bcbe652a",
      "name": "Orthogonal Polynomials",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "c49cb07f-1341-4d2c-b56f-0545a1d35140",
      "name": "Activation Functions",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "7f19d104-aea0-49bb-a63e-fb2280c13428",
      "name": "Function Approximation",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "334ac660-3840-49c3-a8c9-bfd498fe2e4e",
      "name": "Ai",
      "categoryId": "f001a980-b036-4a8b-a7b0-290e7b1c9a77"
    },
    {
      "id": "7e64c981-2bac-4a23-8c33-a0696ddc1c4d",
      "name": "Model Optimization",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "5636aaea-61fe-415d-abd2-87b5e9b7b655",
      "name": "Training Techniques",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "dbc0fbd3-b1d5-4468-a0e3-b2bd499baf83",
      "name": "Neural Network Training",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "2707ad97-58b5-4ccd-abf8-7de989844ea6",
      "name": "Model Ensemble Methods",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "8613a5cc-2f99-4c6c-90a3-0be00fedc16d",
      "name": "Quality Model Selection",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "5bb0e07d-d7f8-4723-91d3-d25afacf1e32",
      "name": "Cheminformatics",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "8a64fc1b-e9a1-45b6-884c-ae7f670e7ac1",
      "name": "Chemical Data Analysis",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "b27afe7e-daf6-41ea-bf97-d19f73568fb7",
      "name": "Molecular Modeling",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "8a0d95d8-a5d0-4eb9-b8d3-638f2d80174c",
      "name": "Quantitative Structure-Activity Relationship (Qsar)",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "e3528470-778f-45e7-9166-4c1b816fc72c",
      "name": "Chemoinformatics",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "6f8d5f15-84b9-45c5-a679-7114d6449648",
      "name": "Statistical Hypothesis Testing",
      "categoryId": "a08d705b-8994-4bcf-9c82-17c75c3bc367"
    },
    {
      "id": "6bea9bda-1081-474f-8dde-bea4765f6faf",
      "name": "Categorical Data Analysis",
      "categoryId": "a08d705b-8994-4bcf-9c82-17c75c3bc367"
    },
    {
      "id": "f2a9c10a-7cff-4ec5-8e8e-eb853e32cd0f",
      "name": "Contingency Tables",
      "categoryId": "a08d705b-8994-4bcf-9c82-17c75c3bc367"
    },
    {
      "id": "b1f01590-aefa-4cf6-bab3-66ac3bc5e7bb",
      "name": "Independence Testing",
      "categoryId": "a08d705b-8994-4bcf-9c82-17c75c3bc367"
    },
    {
      "id": "b4455a4f-62b9-4e97-b12b-00e957d0958f",
      "name": "Goodness-Of-Fit Tests",
      "categoryId": "a08d705b-8994-4bcf-9c82-17c75c3bc367"
    },
    {
      "id": "ee69739a-e5c4-4f72-bf51-fbe3f796d401",
      "name": "Independence Tests",
      "categoryId": "a08d705b-8994-4bcf-9c82-17c75c3bc367"
    },
    {
      "id": "8f27857e-4e35-4e6b-b821-80c06195bc79",
      "name": "Chi-Square Distribution",
      "categoryId": "a08d705b-8994-4bcf-9c82-17c75c3bc367"
    },
    {
      "id": "0b1e8e79-9477-4dd3-b1c4-51e198f356a1",
      "name": "Linear Algebra",
      "categoryId": "306fd1ff-712c-4027-a13a-5f560c4b6b72"
    },
    {
      "id": "5c322266-7234-40aa-a99d-fd98d83573f7",
      "name": "Matrix Decomposition",
      "categoryId": "306fd1ff-712c-4027-a13a-5f560c4b6b72"
    },
    {
      "id": "6ba00efa-1dec-4590-82bc-dfa2c7ae1ec4",
      "name": "Numerical Methods",
      "categoryId": "306fd1ff-712c-4027-a13a-5f560c4b6b72"
    },
    {
      "id": "787bb9f6-964e-4697-9344-96fd4a0c491f",
      "name": "Matrix Factorization",
      "categoryId": "306fd1ff-712c-4027-a13a-5f560c4b6b72"
    },
    {
      "id": "082f60c7-b476-4711-8bf9-5f9d6a9cb637",
      "name": "Numerical Linear Algebra",
      "categoryId": "306fd1ff-712c-4027-a13a-5f560c4b6b72"
    },
    {
      "id": "8a1e5bef-f7c8-4ec0-ab82-d05a41e9bd35",
      "name": "Optimization Techniques",
      "categoryId": "c2c2f0d1-ca4f-4b23-9086-ee7ab14ad5a6"
    },
    {
      "id": "66a76614-5d7f-43e9-ab91-f6875ef6de6c",
      "name": "Numerical Methods",
      "categoryId": "c2c2f0d1-ca4f-4b23-9086-ee7ab14ad5a6"
    },
    {
      "id": "2e7f8b58-c388-4057-8a6c-5700530365f5",
      "name": "Matrix Decomposition",
      "categoryId": "c2c2f0d1-ca4f-4b23-9086-ee7ab14ad5a6"
    },
    {
      "id": "07656591-0f7f-4666-98c3-d1369af777df",
      "name": "Linear Algebra",
      "categoryId": "c2c2f0d1-ca4f-4b23-9086-ee7ab14ad5a6"
    },
    {
      "id": "3fc3ed66-56e5-42f2-860c-f2e8a8175286",
      "name": "Convex Optimization",
      "categoryId": "c2c2f0d1-ca4f-4b23-9086-ee7ab14ad5a6"
    },
    {
      "id": "9c4da778-1438-4568-aa80-e1d203b4542b",
      "name": "Image Processing",
      "categoryId": "f697ffdc-db4e-4058-938b-63083e5204a2"
    },
    {
      "id": "85d9a1e3-b1dc-44ca-aed6-0998d68289ac",
      "name": "Computational Photography",
      "categoryId": "f697ffdc-db4e-4058-938b-63083e5204a2"
    },
    {
      "id": "adf52a76-db88-4513-a594-2151e2b0f481",
      "name": "Optical Corrections",
      "categoryId": "f697ffdc-db4e-4058-938b-63083e5204a2"
    },
    {
      "id": "1f816b49-16d2-4073-9574-77afe5e81035",
      "name": "Digital Imaging",
      "categoryId": "f697ffdc-db4e-4058-938b-63083e5204a2"
    },
    {
      "id": "4b2595be-12c0-4967-a852-4c0c5fc573cf",
      "name": "Image Enhancement",
      "categoryId": "f697ffdc-db4e-4058-938b-63083e5204a2"
    },
    {
      "id": "55349f35-ebc0-4f80-b37c-a1e0d31e563d",
      "name": "Graph Theory",
      "categoryId": "0f9a17f6-01ac-468e-a0ce-db0dbd086923"
    },
    {
      "id": "a3ffa0fa-b300-46f4-8e0e-dadcce99d935",
      "name": "Random Graph Models",
      "categoryId": "0f9a17f6-01ac-468e-a0ce-db0dbd086923"
    },
    {
      "id": "00bf7964-56cd-4075-bc76-de676f6b1fa2",
      "name": "Network Science",
      "categoryId": "0f9a17f6-01ac-468e-a0ce-db0dbd086923"
    },
    {
      "id": "b7d1bbe8-5e67-47de-b733-bef11905fdcd",
      "name": "Probability Theory",
      "categoryId": "0f9a17f6-01ac-468e-a0ce-db0dbd086923"
    },
    {
      "id": "c5b77f86-9585-4cfa-9ad1-594612dd3436",
      "name": "Complex Networks",
      "categoryId": "0f9a17f6-01ac-468e-a0ce-db0dbd086923"
    },
    {
      "id": "ea7f2084-465d-48fc-b419-f08939b79149",
      "name": "Natural Language Processing (Nlp)",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "c74120e9-9918-40c5-abc5-d5059bb9634d",
      "name": "Data Preprocessing",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "34480a2f-e650-4d03-ab95-87e1819c36e9",
      "name": "Sequence Modeling",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "7d5f3585-5e59-4a8c-94e7-2ae0201dcf85",
      "name": "Embedding Techniques",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "e9978dd2-7ae2-48a8-b89c-c2b1f5676564",
      "name": "Hierarchical Clustering",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "6c8d7ad9-f087-46d8-835e-2df926b775ca",
      "name": "Tokenization",
      "categoryId": "954025b2-e0af-4d2f-b77a-ddca1b88361e"
    },
    {
      "id": "fe86b3a7-a8f1-4bb3-8c20-6b365e8c8adc",
      "name": "Text Segmentation",
      "categoryId": "954025b2-e0af-4d2f-b77a-ddca1b88361e"
    },
    {
      "id": "443cb00f-9681-4c30-ab33-48301f10e597",
      "name": "Sequence Modeling",
      "categoryId": "954025b2-e0af-4d2f-b77a-ddca1b88361e"
    },
    {
      "id": "b1e7f526-326e-4bf5-89b5-966a147b55b2",
      "name": "Linguistic Features",
      "categoryId": "954025b2-e0af-4d2f-b77a-ddca1b88361e"
    },
    {
      "id": "a4501694-a7d0-4006-a8fa-67bf0cd8389d",
      "name": "Contextual Embedding",
      "categoryId": "954025b2-e0af-4d2f-b77a-ddca1b88361e"
    },
    {
      "id": "5b0fafa8-c248-4991-b985-36b42b620c0b",
      "name": "Natural Language Processing (Nlp)",
      "categoryId": "8e501b08-14ea-4c6c-bbe8-0e8a0c7dfa17"
    },
    {
      "id": "2264027b-1e9d-4a5f-bc65-9d2c9c3bbdae",
      "name": "Automatic Image Captioning",
      "categoryId": "8e501b08-14ea-4c6c-bbe8-0e8a0c7dfa17"
    },
    {
      "id": "d3d6ec39-86f5-4d77-b039-39485984ffe0",
      "name": "Image Caption Evaluation",
      "categoryId": "8e501b08-14ea-4c6c-bbe8-0e8a0c7dfa17"
    },
    {
      "id": "2844ae80-cb7b-40d7-82e7-27ed39196f34",
      "name": "Text Similarity Metrics",
      "categoryId": "8e501b08-14ea-4c6c-bbe8-0e8a0c7dfa17"
    },
    {
      "id": "23719b2a-fec2-493d-8d34-8b14bc18c2d9",
      "name": "Evaluation Criteria For Generated Content",
      "categoryId": "8e501b08-14ea-4c6c-bbe8-0e8a0c7dfa17"
    },
    {
      "id": "251eea71-c9d3-4ee5-8f66-953f9788fd1d",
      "name": "Image Classification",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "4ed40284-5364-4874-bb2d-3818aa4963dc",
      "name": "Computer Vision",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "9dc72b70-4fa6-46fa-a602-347ddb342454",
      "name": "Dataset",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "216f146d-1fe6-4ac0-8732-9833861d5a57",
      "name": "Cifar-10",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "e20ed8d3-19c3-46a2-ade6-a3dc8924b5d0",
      "name": "Deep Learning",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "43d73341-07fe-428e-bace-0583976863ea",
      "name": "Image Classification",
      "categoryId": "f697ffdc-db4e-4058-938b-63083e5204a2"
    },
    {
      "id": "d9109fbb-bc7b-4cca-ae56-d7551579fb83",
      "name": "Dataset",
      "categoryId": "f697ffdc-db4e-4058-938b-63083e5204a2"
    },
    {
      "id": "a25b29f5-3ad4-429a-ad2e-3de3dacd73e0",
      "name": "Computer Vision",
      "categoryId": "f697ffdc-db4e-4058-938b-63083e5204a2"
    },
    {
      "id": "fb0eadef-30cc-44fc-a68c-0f2561ce08eb",
      "name": "Multiclass Classification",
      "categoryId": "f697ffdc-db4e-4058-938b-63083e5204a2"
    },
    {
      "id": "1328d458-382c-413d-b08a-16b2e211ca8b",
      "name": "Benchmark Dataset",
      "categoryId": "f697ffdc-db4e-4058-938b-63083e5204a2"
    },
    {
      "id": "692a8fa6-39cc-4756-a76f-b7840702c715",
      "name": "Class Incremental Learning (Cil) Falls Under The Broader Categories Of Continual Learning",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "9d42691b-51f6-4ca9-96e1-d7ed612ed2ff",
      "name": "Lifelong Learning",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "4b36b619-eb41-481d-8e96-3f6b602bd338",
      "name": "And Incremental Learning. It Is A Subfield Dedicated To Enabling Models To Learn From New Data St...",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "18ca3eb3-091e-420e-af0d-819e0f08abd4",
      "name": "Thus Addressing Issues Like Catastrophic Forgetting. Related Sub-Category Tags Include Online Lea...",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "8b1a6ba6-c3c7-4571-8cd6-a7434ef9708e",
      "name": "Adaptive Learning",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "2f835b4c-b0b0-4725-a22b-93965b2b6c92",
      "name": "Circuit Analysis",
      "categoryId": "32ecb9c6-c9a0-4b57-b94e-d5e703a0388d"
    },
    {
      "id": "d7d8cf2a-7e5e-456a-bf49-2e032c437b04",
      "name": "Electrical Engineering",
      "categoryId": "32ecb9c6-c9a0-4b57-b94e-d5e703a0388d"
    },
    {
      "id": "16550a10-b8be-4cd8-ad36-860db478ebfc",
      "name": "Electronics",
      "categoryId": "32ecb9c6-c9a0-4b57-b94e-d5e703a0388d"
    },
    {
      "id": "1e14f82f-0700-4a6f-93e2-13b6b0241f80",
      "name": "Circuit Theory",
      "categoryId": "32ecb9c6-c9a0-4b57-b94e-d5e703a0388d"
    },
    {
      "id": "4c19c1da-282e-4037-877e-633fecf8a631",
      "name": "Circuit Simulation",
      "categoryId": "32ecb9c6-c9a0-4b57-b94e-d5e703a0388d"
    },
    {
      "id": "08eb122f-501e-421b-b074-88dda5edde1b",
      "name": "Complexity Theory",
      "categoryId": "88458ea2-7ad9-4440-b6c6-dd20ed5c727c"
    },
    {
      "id": "20bc67df-e417-437d-8c90-a1b3d4706d8f",
      "name": "Computational Complexity",
      "categoryId": "88458ea2-7ad9-4440-b6c6-dd20ed5c727c"
    },
    {
      "id": "316279ca-160b-4e6c-b25a-0547e6b28d10",
      "name": "Boolean Circuits",
      "categoryId": "88458ea2-7ad9-4440-b6c6-dd20ed5c727c"
    },
    {
      "id": "98abc211-6969-4e96-9aac-00eb4ab958f0",
      "name": "Logical Circuits",
      "categoryId": "88458ea2-7ad9-4440-b6c6-dd20ed5c727c"
    },
    {
      "id": "2af70efa-76de-4ed0-8ccd-84bf6278934e",
      "name": "Algorithm Analysis",
      "categoryId": "88458ea2-7ad9-4440-b6c6-dd20ed5c727c"
    },
    {
      "id": "b0f7e4e6-c3fc-40be-8db2-dbc1eec31a5e",
      "name": "Circuit-Level Analysis",
      "categoryId": "f59f920d-a73a-4a03-89d5-b1fbef1c4b96"
    },
    {
      "id": "286772ee-2957-46ed-95b7-16852f2429e9",
      "name": "Digital Circuits",
      "categoryId": "f59f920d-a73a-4a03-89d5-b1fbef1c4b96"
    },
    {
      "id": "35338fc8-4898-4386-8524-ac01bc663dfd",
      "name": "Analog Circuits",
      "categoryId": "f59f920d-a73a-4a03-89d5-b1fbef1c4b96"
    },
    {
      "id": "18fd68fc-7d03-400c-a8dd-b1aa1a6b0aff",
      "name": "Circuit Simulation",
      "categoryId": "f59f920d-a73a-4a03-89d5-b1fbef1c4b96"
    },
    {
      "id": "49e08617-c41f-49dc-a089-be8b555acddb",
      "name": "Electrical Engineering",
      "categoryId": "f59f920d-a73a-4a03-89d5-b1fbef1c4b96"
    },
    {
      "id": "5ae781b4-c2b4-4956-ae4d-d32b00da73f4",
      "name": "Signal Processing",
      "categoryId": "da0a70ec-2846-4a5b-96d2-41f9070d7d56"
    },
    {
      "id": "a180f2df-b653-43fb-b6dc-dccd0eb6bd54",
      "name": "Digital Signal Processing (Dsp)",
      "categoryId": "da0a70ec-2846-4a5b-96d2-41f9070d7d56"
    },
    {
      "id": "d010c5d1-8e0d-43a1-aeee-fc055adfd97f",
      "name": "Discrete Mathematics",
      "categoryId": "da0a70ec-2846-4a5b-96d2-41f9070d7d56"
    },
    {
      "id": "104f6f71-2444-4a5d-b82a-3b1f01bf591f",
      "name": "Fourier Transform",
      "categoryId": "da0a70ec-2846-4a5b-96d2-41f9070d7d56"
    },
    {
      "id": "d7a45f53-2016-4d8e-91d3-12267589de84",
      "name": "Time Series Analysis",
      "categoryId": "da0a70ec-2846-4a5b-96d2-41f9070d7d56"
    },
    {
      "id": "9cf61226-99e7-4f7e-ab55-8de6878d22b8",
      "name": "Convolutional Neural Networks (Cnns)",
      "categoryId": "8d35f4cf-19b3-4944-a323-473abaa3eb92"
    },
    {
      "id": "0afcc4cb-d3b3-4f6b-97bd-5fc65c20a472",
      "name": "Padding Techniques",
      "categoryId": "8d35f4cf-19b3-4944-a323-473abaa3eb92"
    },
    {
      "id": "a32537db-0dbe-4a01-ac00-1b49aba9a009",
      "name": "Zero Padding",
      "categoryId": "8d35f4cf-19b3-4944-a323-473abaa3eb92"
    },
    {
      "id": "91df24de-c9ef-4757-8bc2-62a7e91b70d2",
      "name": "Spatial Padding",
      "categoryId": "8d35f4cf-19b3-4944-a323-473abaa3eb92"
    },
    {
      "id": "5c2d6fb8-cea9-4780-b55b-5799aa573569",
      "name": "Edge Handling",
      "categoryId": "8d35f4cf-19b3-4944-a323-473abaa3eb92"
    },
    {
      "id": "e45e0e74-efcc-4174-942b-072f702387e3",
      "name": "Convolutional Neural Networks",
      "categoryId": "8d35f4cf-19b3-4944-a323-473abaa3eb92"
    },
    {
      "id": "820087aa-779b-4dd9-9189-5ee55ebc05d0",
      "name": "Circular Padding",
      "categoryId": "8d35f4cf-19b3-4944-a323-473abaa3eb92"
    },
    {
      "id": "ec87e0b9-0abe-4590-a1c4-2ae216bd27d0",
      "name": "Image Processing",
      "categoryId": "8d35f4cf-19b3-4944-a323-473abaa3eb92"
    },
    {
      "id": "1d7e05e7-bafc-4d76-9b49-7399e7682d0e",
      "name": "Deep Learning Architectures",
      "categoryId": "8d35f4cf-19b3-4944-a323-473abaa3eb92"
    },
    {
      "id": "cae1b750-f2ad-4c75-a518-8d3a436f02be",
      "name": "Model Interpretability",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "ea3cb06c-3503-47c9-9c61-95eb5031b5ba",
      "name": "Convolutional Neural Networks (Cnns)",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "264662e6-620c-480f-b678-d94764d291ce",
      "name": "Visualization Techniques",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "7636d23d-181c-4c10-9dd9-65e0781c4cd2",
      "name": "Class Activation Maps (Cam)",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "d244fcef-53f6-4a98-846a-d555018d0a1a",
      "name": "Visualization",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "084ac074-a369-44e5-ab57-2f74bc28eb09",
      "name": "Cnn Interpretability",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "7ad9c81f-c128-4d79-ace1-c4d071d3937b",
      "name": "Deep Learning Explainability",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "3ffd7102-687d-4707-a2b6-74461b12c371",
      "name": "Class Imbalance",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "b753368c-4ba7-4b7e-8a2e-699872c32076",
      "name": "Data Imbalance",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "18bb6fe6-7aa0-44fd-9970-dec1163c6533",
      "name": "Skewed Data",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "11044d60-0243-4f56-85c9-a4d5b5edc1da",
      "name": "Imbalanced Datasets",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "256ff9ec-dd7d-452b-856f-ec895fdda9a9",
      "name": "Classification Challenges",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "717e5f5f-d1ec-47fe-ba34-0face182e973",
      "name": "Supervised Learning",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "b06e68ad-6a06-4f80-b0ea-65be6b75265e",
      "name": "Cost-Sensitive Learning",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "d9f0fa65-c0ec-40a4-a414-fa8bcca8b81f",
      "name": "Loss Function Customization",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "c1864dd9-1cf1-4124-81cf-55ceb25b72fa",
      "name": "Class-Balanced Loss",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "c89f17ea-9f53-4364-8224-740b4849dbbc",
      "name": "Loss Functions",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "07d2d46f-f247-4cc5-80e3-aea381e010b8",
      "name": "Imbalanced Data",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "9d2e9b86-37a6-4f53-afc7-2c22f2d00ab6",
      "name": "Machine Learning",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "08856b83-5c02-471d-8709-ed1895cee178",
      "name": "Data Sampling",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "b50f5366-8da8-4b3a-ab76-48a0514acc87",
      "name": "Data Balancing Techniques",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "5d38820d-77b5-4989-bb38-b887e8eb7007",
      "name": "Classification",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "817e217f-cbaa-4096-8740-bcddc032fcab",
      "name": "Binary Classification",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "5f27f14b-8e7a-475d-99d7-6628cdcde180",
      "name": "Multiclass Classification",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "d825ceb3-ee90-40b9-8e37-ca716f279c3d",
      "name": "Multi-Label Classification",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "3dbf1efc-9922-4389-8c81-c099b7201134",
      "name": "Decision Trees",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "d8a0f87a-5f11-4af7-876a-b64f3cba6ba7",
      "name": "Predictive Modeling",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "1298f14e-a65f-4f0b-8d3e-ca29048786a3",
      "name": "Machine Learning Algorithms",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "b0f89030-4291-47f6-89b7-454435c911e4",
      "name": "Model Evaluation",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "34d750d7-f98f-40b2-8d52-cb8ef8635175",
      "name": "Model Performance Metrics",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "6c0debb8-acc8-4744-929e-575ccfa004b7",
      "name": "Confusion Matrix",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "5b90f45e-faff-404e-8571-e25ae87e686e",
      "name": "Precision",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "668c1527-07f0-472b-bccc-ac93e24556d4",
      "name": "Classification Problems",
      "categoryId": "970cc6d8-f2a1-4be1-b044-4044a17fc1dc"
    },
    {
      "id": "90bc9c42-5130-4e4e-b885-a6a4ce1491a0",
      "name": "Supervised Learning",
      "categoryId": "970cc6d8-f2a1-4be1-b044-4044a17fc1dc"
    },
    {
      "id": "0b7ac157-8b35-4fe8-b408-eb9ea2348185",
      "name": "Pattern Recognition",
      "categoryId": "970cc6d8-f2a1-4be1-b044-4044a17fc1dc"
    },
    {
      "id": "709f19cc-b12b-48f6-89c3-d19c43458c1b",
      "name": "Discrete Labels",
      "categoryId": "970cc6d8-f2a1-4be1-b044-4044a17fc1dc"
    },
    {
      "id": "b7c9b09d-a3d1-4a1e-819e-cee9245fd6ff",
      "name": "Binary Classification",
      "categoryId": "970cc6d8-f2a1-4be1-b044-4044a17fc1dc"
    },
    {
      "id": "72a3d8b2-e0f5-4122-9e9b-8fb9ea5d9225",
      "name": "Classification Report",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "2705f271-43ae-48b3-9eaf-1f213cf8b96b",
      "name": "Performance Metrics",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "6c9380ab-67fe-4fff-afe2-9a4119cf52c0",
      "name": "Recall",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "3e4a915d-b8ae-494f-8150-aeb6da71a240",
      "name": "Multi-Label Classification",
      "categoryId": "a1c2ec89-ddcf-4fff-ad43-622a5b33df97"
    },
    {
      "id": "d174ebfd-143e-4419-94f6-11d9983b0713",
      "name": "Chain-Based Methods",
      "categoryId": "a1c2ec89-ddcf-4fff-ad43-622a5b33df97"
    },
    {
      "id": "83fa04ef-a1d1-4c8f-b25b-bf0be370022b",
      "name": "Sequential Modeling",
      "categoryId": "a1c2ec89-ddcf-4fff-ad43-622a5b33df97"
    },
    {
      "id": "6ed5771f-dbf7-4364-9a30-d582a7785ecc",
      "name": "Ensemble Techniques",
      "categoryId": "a1c2ec89-ddcf-4fff-ad43-622a5b33df97"
    },
    {
      "id": "77544135-c878-45eb-899d-7473fe6459f1",
      "name": "Multi-Output Classification",
      "categoryId": "a1c2ec89-ddcf-4fff-ad43-622a5b33df97"
    },
    {
      "id": "6ec3302a-53e8-4535-8793-f506d2deaa77",
      "name": "Machine Learning",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d"
    },
    {
      "id": "2af107aa-a52f-43ff-9ba5-9bf19ee791d0",
      "name": "Deep Learning",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d"
    },
    {
      "id": "0a7b29b7-bbf9-487c-b28c-85f189713da6",
      "name": "Generative Models",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d"
    },
    {
      "id": "6b702b69-beb3-45a1-ae5c-2c1a51d7565b",
      "name": "Diffusion Models",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d"
    },
    {
      "id": "695f5f16-f48f-492e-9185-cc52e11794cc",
      "name": "Text-To-Image Synthesis",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d"
    },
    {
      "id": "914761b2-8b8a-4562-b5ea-e8cd9edde26b",
      "name": "Sentiment Analysis",
      "categoryId": "f3b96f41-4969-4c65-adc2-feb6e1ab6e95"
    },
    {
      "id": "310eead7-8775-44fe-85d8-15b1b2e0034f",
      "name": "Ai Security",
      "categoryId": "f3b96f41-4969-4c65-adc2-feb6e1ab6e95"
    },
    {
      "id": "99b0b1cb-6ae6-4304-a466-42f2b80bbc25",
      "name": "Model Robustness",
      "categoryId": "f3b96f41-4969-4c65-adc2-feb6e1ab6e95"
    },
    {
      "id": "73b4cf3b-943c-41f6-b9d0-51abe43f31ea",
      "name": "Privacy Risks",
      "categoryId": "f3b96f41-4969-4c65-adc2-feb6e1ab6e95"
    },
    {
      "id": "b3d7c694-3f74-4088-9ca6-fadd9b89b8f4",
      "name": "Adversarial Attacks",
      "categoryId": "f3b96f41-4969-4c65-adc2-feb6e1ab6e95"
    },
    {
      "id": "9106d622-1204-44d8-9fa5-d7cb1cf38140",
      "name": "Thermodynamics",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "383b4cee-7c07-44f4-997f-7f7b156e17e4",
      "name": "Climate Modeling",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "b1152ef6-31f6-45d3-aab4-37596b34a65e",
      "name": "Data-Driven Simulations",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "a1342359-391e-49cb-8beb-2b141fcff21b",
      "name": "Fluid Mechanics",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "e4b350b5-97b8-4e17-ba0e-08dda1cef0e1",
      "name": "Phase Transitions",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "c436de57-4333-47b6-bfee-02aa25d7fbb7",
      "name": "Artificial Intelligence",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "fc36f5e7-1074-4d81-a41b-f5b8f3522221",
      "name": "Machine Learning",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "923d8dcd-ccdf-4e8e-8225-da3538ae2371",
      "name": "Automated Machine Learning",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "d1f6602b-5034-4f4c-acff-7bf5016d4671",
      "name": "Mlops",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "5c42aa78-e1ea-4584-80e5-c4eb1c03ea27",
      "name": "Experiment Management",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "25bd4f43-ad8c-4ef1-b0d7-d328e7ec949f",
      "name": "Computer Vision",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "89854309-3160-47ce-8cae-070aa916fdc1",
      "name": "Natural Language Processing",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "d1171b2e-d29b-4445-869e-93b0fc69f8f4",
      "name": "Multimodal Learning",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "d2ee9f2d-d5ab-4736-8403-0d3b26b68a77",
      "name": "Representation Learning",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "3c126fe9-8e68-416c-a7c3-89cfe38f4759",
      "name": "Contrastive Learning",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "970b0f00-da14-4036-ba1d-94a59f04fc15",
      "name": "Optimization Techniques",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "22cc01b6-d2d3-4451-9a7d-f63ddbfd3250",
      "name": "Gradient Clipping",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "4aae74d6-aee2-4aae-994c-39e98b6bf2ad",
      "name": "Regularization Methods",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "4f75aab2-6a09-4264-827e-0f3a7d0a0541",
      "name": "Deep Learning Optimization",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "e39f7c36-5cbf-4f68-b805-068f6b3d602d",
      "name": "Gradient Management",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "4d6b4a0c-8506-4bc4-a598-d397d1d1cb74",
      "name": "Gradient Descent",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "3aa6b1ce-f5cc-48db-b9a9-780b6c1a1c82",
      "name": "Regularization",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "9292a572-b0d0-4fbd-b142-28c591b4863f",
      "name": "Norm Clipping",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "b99f3671-be24-4a68-bbc0-dba07cbd7d11",
      "name": "Value Clipping",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "92da754b-5fdd-436e-91af-374a3c681eaa",
      "name": "Training Stability",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "f4482f3e-44c1-492c-9df4-13c294cc0c2c",
      "name": "Gradient Regularization",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "4f73b730-6944-4ecd-811a-d66430e84165",
      "name": "Community Detection",
      "categoryId": "0f9a17f6-01ac-468e-a0ce-db0dbd086923"
    },
    {
      "id": "4a975ee8-9a2e-4f4c-bff7-bfbb645d8486",
      "name": "Network Analysis",
      "categoryId": "0f9a17f6-01ac-468e-a0ce-db0dbd086923"
    },
    {
      "id": "afd1bf86-575d-4a84-983e-7d08a6a48994",
      "name": "Clustering",
      "categoryId": "0f9a17f6-01ac-468e-a0ce-db0dbd086923"
    },
    {
      "id": "520f0016-03d5-4fba-a567-a23c3192ce46",
      "name": "Subgraphs",
      "categoryId": "0f9a17f6-01ac-468e-a0ce-db0dbd086923"
    },
    {
      "id": "c2ea442e-e554-4e3d-a8ee-4788e283f06e",
      "name": "Data Mining",
      "categoryId": "f4a166e4-92f8-4e53-bbd2-66c352a23c5e"
    },
    {
      "id": "fe37749c-3829-4fb1-98e5-e7a6e4ff7299",
      "name": "Frequent Itemset Mining",
      "categoryId": "f4a166e4-92f8-4e53-bbd2-66c352a23c5e"
    },
    {
      "id": "dd551b09-d032-4ce4-948a-38bdb0469149",
      "name": "Association Rule Learning",
      "categoryId": "f4a166e4-92f8-4e53-bbd2-66c352a23c5e"
    },
    {
      "id": "37a7534b-d752-42d2-860a-ede59da67447",
      "name": "Pattern Discovery",
      "categoryId": "f4a166e4-92f8-4e53-bbd2-66c352a23c5e"
    },
    {
      "id": "564f2293-eded-43b7-8422-d772a579b47a",
      "name": "Market Basket Analysis",
      "categoryId": "f4a166e4-92f8-4e53-bbd2-66c352a23c5e"
    },
    {
      "id": "4eebb21a-3fca-403b-979d-d556dc60e726",
      "name": "Centrality Measures",
      "categoryId": "0f9a17f6-01ac-468e-a0ce-db0dbd086923"
    },
    {
      "id": "e29e0224-e5bd-4f5d-8600-d3fd20908d36",
      "name": "Data Science",
      "categoryId": "0f9a17f6-01ac-468e-a0ce-db0dbd086923"
    },
    {
      "id": "f67956a4-d648-40a9-95aa-50dff205b07f",
      "name": "Social Network Analysis",
      "categoryId": "0f9a17f6-01ac-468e-a0ce-db0dbd086923"
    },
    {
      "id": "f212d3fe-bffc-48cc-be70-b5229325fcf7",
      "name": "Structural Time-Series",
      "categoryId": "45dc2762-eb9a-41a3-b001-b823adcbf3a4"
    },
    {
      "id": "00f49fe5-04b5-4a82-9e39-df24d1b587b6",
      "name": "Temporal Data Mining",
      "categoryId": "45dc2762-eb9a-41a3-b001-b823adcbf3a4"
    },
    {
      "id": "55cb78d3-873c-4e9a-8d57-d732cdd87a9c",
      "name": "Dynamic Clustering",
      "categoryId": "45dc2762-eb9a-41a3-b001-b823adcbf3a4"
    },
    {
      "id": "d3a80b78-9182-4c8f-a8c6-7cd7d1f08013",
      "name": "Structural Pattern Recognition",
      "categoryId": "45dc2762-eb9a-41a3-b001-b823adcbf3a4"
    },
    {
      "id": "690879e6-03f4-461c-a964-7323930588a7",
      "name": "Time-Series Segmentation",
      "categoryId": "45dc2762-eb9a-41a3-b001-b823adcbf3a4"
    },
    {
      "id": "6277a764-6509-44a1-9888-3da4f33b0949",
      "name": "Semi-Supervised Learning",
      "categoryId": "b1801e0d-e24b-4ad2-9e47-20e042487137"
    },
    {
      "id": "85abdbff-4fa9-4802-9a55-94d4a4942e64",
      "name": "Unsupervised Learning",
      "categoryId": "b1801e0d-e24b-4ad2-9e47-20e042487137"
    },
    {
      "id": "f54ea56c-97ca-4539-a8bb-e80ff810d8d0",
      "name": "Representation Learning",
      "categoryId": "b1801e0d-e24b-4ad2-9e47-20e042487137"
    },
    {
      "id": "1bc402c1-c1cd-4a27-b397-6457d209a79e",
      "name": "Data Clustering",
      "categoryId": "b1801e0d-e24b-4ad2-9e47-20e042487137"
    },
    {
      "id": "9ad10329-3eee-4282-9378-0784a59766f6",
      "name": "Manifold Assumption",
      "categoryId": "b1801e0d-e24b-4ad2-9e47-20e042487137"
    },
    {
      "id": "14d1ffd3-60c1-4792-b2fc-034df96de84b",
      "name": "Clustering",
      "categoryId": "de8842d5-eb45-4c4d-b8f3-15f9a39657f4"
    },
    {
      "id": "9e2a63d4-4859-4523-b7fb-5f050b533191",
      "name": "Unsupervised Learning",
      "categoryId": "de8842d5-eb45-4c4d-b8f3-15f9a39657f4"
    },
    {
      "id": "8e226485-354c-48bb-a4f4-85db71af9034",
      "name": "Data Validation",
      "categoryId": "de8842d5-eb45-4c4d-b8f3-15f9a39657f4"
    },
    {
      "id": "5bb76676-b0eb-437f-89bf-17520ced1f62",
      "name": "Model Evaluation",
      "categoryId": "de8842d5-eb45-4c4d-b8f3-15f9a39657f4"
    },
    {
      "id": "96c2c13d-4e8e-4bce-b7ff-aaa1522445e5",
      "name": "Data Quality",
      "categoryId": "de8842d5-eb45-4c4d-b8f3-15f9a39657f4"
    },
    {
      "id": "f7fbd271-aa14-4525-b7f5-8dd2ed6e3ab3",
      "name": "Sampling Techniques",
      "categoryId": "a08d705b-8994-4bcf-9c82-17c75c3bc367"
    },
    {
      "id": "8e42e36c-af7c-48ad-a60a-3a15dd3efdea",
      "name": "Probability Sampling",
      "categoryId": "a08d705b-8994-4bcf-9c82-17c75c3bc367"
    },
    {
      "id": "43bb7476-160b-4df6-a8d6-27349ebc0193",
      "name": "Data Collection Methods",
      "categoryId": "a08d705b-8994-4bcf-9c82-17c75c3bc367"
    },
    {
      "id": "b8169f76-041b-454a-a266-fa66cbcc0597",
      "name": "Statistical Sampling",
      "categoryId": "a08d705b-8994-4bcf-9c82-17c75c3bc367"
    },
    {
      "id": "6508d06c-0367-4c18-87f1-d4042ee06edd",
      "name": "Data Sampling",
      "categoryId": "a08d705b-8994-4bcf-9c82-17c75c3bc367"
    },
    {
      "id": "65ed1888-c776-4246-ab44-c86291e632ea",
      "name": "Clustering",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "872bc9d2-f120-4ad5-a406-1b1ca7bf595a",
      "name": "Unsupervised Learning",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "cf92c8a4-a9db-4e72-9f65-9f1ad88c1d3d",
      "name": "Data Segmentation",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "7e9ccbae-8f93-4817-83a0-17ae7ce46465",
      "name": "Pattern Recognition",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "05d4e37f-78ad-4c32-ad2f-ceb141f15292",
      "name": "Grouping",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "f554b946-f76b-4cd3-a6f2-8db098eddd84",
      "name": "Data Clustering",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "502909de-6a6d-43d2-93d7-8c58d1680728",
      "name": "Similarity Measures",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "cddbf0ee-82f0-4115-9283-062f8d41dc98",
      "name": "Clustering Algorithms",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "0978ed21-e721-43dd-8b81-4c0f5116355a",
      "name": "K-Means",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "09b54e72-5d26-4bb4-becd-05f7da000519",
      "name": "Clustering Metrics",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "ccbbee09-ead6-4cdf-8721-28cc5dc04e9c",
      "name": "Silhouette Score",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "035c51e0-edb7-42cb-9d01-379a5779b628",
      "name": "Davies-Bouldin Index",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "97d07028-f14a-46b5-8974-54b6b3d960f0",
      "name": "Cluster Validation",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "ce344a7b-649e-44be-b0cc-2452ab9ef3e3",
      "name": "Cluster Quality Metrics",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "33dfcddf-1428-44c2-87df-b83a244538ee",
      "name": "Pattern Recognition",
      "categoryId": "de8842d5-eb45-4c4d-b8f3-15f9a39657f4"
    },
    {
      "id": "fd4f4ddb-749f-4ca0-9842-7e52b3f13459",
      "name": "Data Clustering",
      "categoryId": "de8842d5-eb45-4c4d-b8f3-15f9a39657f4"
    },
    {
      "id": "c588d31d-cf4a-4c86-8757-f5aa31fbb286",
      "name": "Stability Analysis",
      "categoryId": "de8842d5-eb45-4c4d-b8f3-15f9a39657f4"
    },
    {
      "id": "3cca23ce-f46e-41a9-ba62-ee8c6ba695c0",
      "name": "Validation Techniques",
      "categoryId": "de8842d5-eb45-4c4d-b8f3-15f9a39657f4"
    },
    {
      "id": "bbe9e149-7005-45b7-bf79-81c097de42d4",
      "name": "Emotion Modeling",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "e583927d-bcde-452b-83e8-0bb99d5a9045",
      "name": "Affective Computing",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "ae192cae-c5b2-49e1-b082-991d4a3c0d04",
      "name": "Sentiment Analysis",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "7d1ba3c0-cd77-4bcd-b37b-dda4e83bab2f",
      "name": "Mood Detection",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "6557773a-68af-4416-960e-30d522a461c6",
      "name": "Affect Recognition",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "bee1fd9c-1cdb-4259-9ff9-10f37b7ad14c",
      "name": "Emotion Recognition",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "61108606-142d-427d-88a2-aa27a682bf52",
      "name": "Facial Expression Analysis",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "0c7e833d-c171-43ed-8d11-85cf72f9d329",
      "name": "Voice Emotion Detection",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "c0aa1b0a-2b17-4327-b9c1-f8825a6e1c52",
      "name": "Multimodal Data",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "db0b5d8c-554c-4ad1-8e82-2d7495d80e92",
      "name": "Data Collection",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "cc6b5431-9933-4e06-9c27-87ca695dcec6",
      "name": "Feature Extraction",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "4fd5b85e-4dde-4a7f-938b-34bdbaa3ca29",
      "name": "Emotion-Aware Text Generation",
      "categoryId": "9c2d686b-dc1c-4ed7-bf77-2cbe83efde08"
    },
    {
      "id": "ae951205-1cad-4747-9bf1-6f24671575ea",
      "name": "Sentiment-Driven Nlp",
      "categoryId": "9c2d686b-dc1c-4ed7-bf77-2cbe83efde08"
    },
    {
      "id": "2b03e362-2b77-462d-8600-96f5c7d39295",
      "name": "Affective Computing",
      "categoryId": "9c2d686b-dc1c-4ed7-bf77-2cbe83efde08"
    },
    {
      "id": "7c9bfb66-c614-44e0-a977-d848bc9faaa5",
      "name": "Emotion Recognition",
      "categoryId": "9c2d686b-dc1c-4ed7-bf77-2cbe83efde08"
    },
    {
      "id": "50bd8a1c-913b-4223-81f5-6795b0037810",
      "name": "Emotional Language Modeling",
      "categoryId": "9c2d686b-dc1c-4ed7-bf77-2cbe83efde08"
    },
    {
      "id": "0d5fae95-5c7a-4248-b22c-ede62114b761",
      "name": "Emotion Ai Frameworks",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "6d04aa07-2701-4a8e-a7c7-56969dc7f022",
      "name": "Human-Computer Interaction",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "4068740d-1036-42d3-8933-728856a0fd09",
      "name": "Emotion Detection",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "781c2318-3909-4911-8289-b210b6010d28",
      "name": "Bayesian Statistics",
      "categoryId": "9bc4b2cf-9af5-40c7-b6e8-302cd9ba549c"
    },
    {
      "id": "69f19b5f-c935-4c04-a6ad-1e5e37cd1190",
      "name": "Empirical Bayes",
      "categoryId": "9bc4b2cf-9af5-40c7-b6e8-302cd9ba549c"
    },
    {
      "id": "af89c9a5-7c7c-49f2-87f5-5a97493a33b0",
      "name": "Regression Analysis",
      "categoryId": "9bc4b2cf-9af5-40c7-b6e8-302cd9ba549c"
    },
    {
      "id": "d75abfa1-91a7-4ffd-b42d-8722a67deca7",
      "name": "Hierarchical Models",
      "categoryId": "9bc4b2cf-9af5-40c7-b6e8-302cd9ba549c"
    },
    {
      "id": "a207c01b-039b-4c9b-827d-e45eeafe0555",
      "name": "Statistical Estimation",
      "categoryId": "9bc4b2cf-9af5-40c7-b6e8-302cd9ba549c"
    },
    {
      "id": "4f7ea125-f38d-419f-aa78-826d3c32d422",
      "name": "Statistics",
      "categoryId": "673c9312-a3b8-46cb-b61a-e25b3c7f30a1"
    },
    {
      "id": "b61ace1a-0538-4081-a3c5-8905fc965e51",
      "name": "Probability Theory",
      "categoryId": "673c9312-a3b8-46cb-b61a-e25b3c7f30a1"
    },
    {
      "id": "8bd7f04f-76d6-47dc-8c89-e0c57a9d2738",
      "name": "Data Analysis",
      "categoryId": "673c9312-a3b8-46cb-b61a-e25b3c7f30a1"
    },
    {
      "id": "58bb0353-6ab0-4b5a-a2e4-f55ac4b145fa",
      "name": "Empirical Methods",
      "categoryId": "673c9312-a3b8-46cb-b61a-e25b3c7f30a1"
    },
    {
      "id": "e605015b-0c75-4543-aa74-57adcef7875f",
      "name": "Probabilistic Modeling",
      "categoryId": "673c9312-a3b8-46cb-b61a-e25b3c7f30a1"
    },
    {
      "id": "312fd869-e3ed-46c1-93d6-d6761c829ccf",
      "name": "Ai/Ml Sub-Category Tags: Reinforcement Learning",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "7d4f1423-1555-48d6-9aa7-29c85ec1d520",
      "name": "Autonomous Agents",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "9aed8f86-0fb0-4e56-a61c-d8e5e442c2bc",
      "name": "Decision-Making Systems",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "3156632e-6629-44f9-b8ba-32d788c6b3d6",
      "name": "Policy Optimization",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "d3057f5e-d4ce-43e4-97c8-9c7915b05a35",
      "name": "Reward Functions",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "945b606f-5af9-48f3-864b-89cf8d2fd5f4",
      "name": "Dimensionality Reduction",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "a1ad0275-7b39-4d7c-bf6c-9143f49e7bb7",
      "name": "Feature Extraction",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "21abdc69-e38c-419b-8070-3c0ad92a9258",
      "name": "Neural Networks",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "f1c99574-6493-4a66-9244-3a0c84edfa16",
      "name": "Attention Mechanisms",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "702021a8-49b4-4664-9381-0594cc8680ca",
      "name": "Sequence-To-Sequence Models",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "cc6d0720-ed03-4530-9b41-81823876a9fa",
      "name": "Encoder-Decoder Architecture",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "85ba73ef-ca0e-4f6e-9bc9-96582428e0cb",
      "name": "Sequence-To-Sequence Models",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "be38ddb2-4455-40c0-be30-125a8c3604b2",
      "name": "Recurrent Neural Networks (Rnn)",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "04d05267-99cb-415b-88de-bfb14654d9f4",
      "name": "Long Short-Term Memory (Lstm)",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "812a495a-5398-41bb-b5c8-a3f2713ba5c3",
      "name": "Gated Recurrent Units (Gru)",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "5dd5b4e1-a00c-4c40-aa79-39bdcb4916be",
      "name": "Encoder-Decoder Models",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "538bbc62-0fdd-4df5-ac69-016ab17ef045",
      "name": "Neural Network Architectures",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "ab3d8b86-fc58-4835-a55c-fa17e6cc1a6c",
      "name": "Recurrent Neural Networks",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "07fc4e41-a36e-4d10-ac4a-a23e24d2d7be",
      "name": "Transformers",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "f2d3270a-18fc-43bc-9019-db70d6973cfb",
      "name": "Encoder-Decoder Models Extensions",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "eb388d8c-7fd9-4af0-ab54-b599ab540ec5",
      "name": "Sequence-To-Sequence Models",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "654f0bca-f93a-48be-8f13-f4590c4ca9f2",
      "name": "Transformers",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "1e882a33-9eca-476e-8bfc-655f2dcd1b11",
      "name": "Attention Mechanisms",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "6259c3f6-f0b6-4479-94e1-9bcc8d3af8b8",
      "name": "Multi-Head Attention",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "795330db-42d4-48bc-88eb-92de8c9b35aa",
      "name": "Encoder-Decoder Models Extensions",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "61dd55c5-cbc7-4cee-a058-e73e9e1345ca",
      "name": "Transformer Architectures",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "1e2f3665-4317-44fc-8c05-ed100a588d97",
      "name": "Variants Of Encoder-Decoder",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "22ba3caa-de7c-4cd0-a272-96999e8c8e78",
      "name": "Encoder-Decoder Models Extensions",
      "categoryId": "2bd8b40c-79f5-4b84-813f-a70ebe2d5360"
    },
    {
      "id": "3f9e7fa3-5cdd-434f-88e5-0944273dc4e2",
      "name": "Transformer Variants",
      "categoryId": "2bd8b40c-79f5-4b84-813f-a70ebe2d5360"
    },
    {
      "id": "9c005c56-ec1b-4765-90ac-2b42b097f917",
      "name": "Sequence-To-Sequence Architectures",
      "categoryId": "2bd8b40c-79f5-4b84-813f-a70ebe2d5360"
    },
    {
      "id": "e0f82f78-f607-4f7b-865d-782d5c62f7aa",
      "name": "Attention Mechanisms",
      "categoryId": "2bd8b40c-79f5-4b84-813f-a70ebe2d5360"
    },
    {
      "id": "94917cf7-dfed-4f37-a4ae-4ca87d4f4062",
      "name": "Residual Connections",
      "categoryId": "2bd8b40c-79f5-4b84-813f-a70ebe2d5360"
    },
    {
      "id": "da44e261-7de1-46cc-b5c6-c00b8903e76c",
      "name": "Encoder-Decoder Models Extensions Techniques",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "adb64517-8b11-42ee-863e-cf9a7bc2a4c5",
      "name": "Sequence-To-Sequence Learning",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "62bf1743-5bb2-435e-8466-17c39705a66b",
      "name": "Attention Mechanisms",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "b6a56d63-07c4-496e-9257-9a038cba90ef",
      "name": "Transformer Architectures",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "acdef06d-c098-43c1-bb71-0e2faf4b97df",
      "name": "Model Optimization",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "44fbdd23-5eec-422c-b223-f6bf0493d6fa",
      "name": "Deep Learning",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "408ea5ef-f392-4c02-a5a4-ad6208a6bf9b",
      "name": "Self-Supervised Learning",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "268a42b0-d97e-4d93-99f3-b47412dea076",
      "name": "Encoding",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "43098ab8-779d-4b6d-86be-349782fdda68",
      "name": "Textual",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "525126fd-68df-4056-84ab-f7759e0a8ef3",
      "name": "Or Complex Data Formats Into Numerical Representations Suitable For Model Ingestion. Common Sub-C...",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "327ada80-d125-4dca-9328-e57a9361cfcb",
      "name": "'Label Encoding'",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "fb826642-4af8-46da-8b0d-65c22e6f42de",
      "name": "'Ordinal Encoding'",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "c8151e87-b5a8-4540-8065-9fdb92af2e4d",
      "name": "Natural Language Processing",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "3ae39cd7-45ba-40ea-aced-bae77e81a765",
      "name": "Dialogue Management",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "9aa9ac36-d8c5-4227-85cd-ea97af4a59b3",
      "name": "Speech Recognition",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "564b7828-ca8c-4f24-85d0-a87e2b10076e",
      "name": "Language Understanding",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "76b5b7ad-769b-4d75-ac58-7ae46f96c240",
      "name": "Model Distillation",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "ed3069ae-de26-4e99-a4ce-b2d7d3d4969c",
      "name": "Energy-Based Models",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "e90fb9b7-fc2b-491f-a0be-c0c4f638721f",
      "name": "Energy Functions",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "b3490d1e-e8ad-4c2d-b580-a5b92e034990",
      "name": "Probabilistic Frameworks",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "e9a51db2-b9fb-43f5-bf57-d5b2e97d45c6",
      "name": "Energy-Based Gans (Ebgans)",
      "categoryId": "bd264002-0726-4dd7-bb5e-134c5fc6e63e"
    },
    {
      "id": "5669e852-298e-409b-8a71-a0d4385db693",
      "name": "Generative Adversarial Networks",
      "categoryId": "bd264002-0726-4dd7-bb5e-134c5fc6e63e"
    },
    {
      "id": "88495f62-49a5-4e2f-b66a-197feb34994d",
      "name": "Energy-Based Models",
      "categoryId": "bd264002-0726-4dd7-bb5e-134c5fc6e63e"
    },
    {
      "id": "1d95d6f5-d42d-46a7-90fb-b14616491680",
      "name": "Deep Learning",
      "categoryId": "bd264002-0726-4dd7-bb5e-134c5fc6e63e"
    },
    {
      "id": "01820fa2-95ad-417a-98c0-740374cbb26e",
      "name": "Unsupervised Learning",
      "categoryId": "bd264002-0726-4dd7-bb5e-134c5fc6e63e"
    },
    {
      "id": "b1eec4d6-cc4c-49e7-b264-0ef204a7f021",
      "name": "Energy-Based Models (Ebms)",
      "categoryId": "d05f2a80-334c-41d4-b0db-02c71638e9d8"
    },
    {
      "id": "8e8f3042-73bc-4826-b826-217fc2504594",
      "name": "Probabilistic Graphical Models",
      "categoryId": "d05f2a80-334c-41d4-b0db-02c71638e9d8"
    },
    {
      "id": "1af7a20e-5dce-48f9-a5e1-38cb3ea6b2ae",
      "name": "Generative Models",
      "categoryId": "d05f2a80-334c-41d4-b0db-02c71638e9d8"
    },
    {
      "id": "b92801d9-2eed-4ae9-927d-f94e54f841a9",
      "name": "Energy Functions",
      "categoryId": "d05f2a80-334c-41d4-b0db-02c71638e9d8"
    },
    {
      "id": "79bdfa3a-0d5a-46ed-82b8-85447cdfdf75",
      "name": "Markov Random Fields",
      "categoryId": "d05f2a80-334c-41d4-b0db-02c71638e9d8"
    },
    {
      "id": "2fd23381-1b6b-41b7-adf6-f797dcff53d2",
      "name": "Energy-Based Models (Ebms)",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "4304b376-e2dd-4475-a205-53d4b839e50c",
      "name": "Probabilistic Models",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "e51eda89-e791-4ae7-a017-f7d9145e9dfb",
      "name": "Energy Functions",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "a7d03bed-7235-4bc5-8daa-af6514c7320d",
      "name": "Energy Landscape",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "2a95f5b4-98c6-4efc-8406-edf5bca000c9",
      "name": "Generative Models",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "8ecd6bb2-5a15-4c29-b707-72721e1d0a36",
      "name": "Energy-Based Models",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "dd33f637-8b74-499c-9229-96b369533b0b",
      "name": "Deep Energy Models",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "dd204a62-5692-406d-9a21-d228e04bc020",
      "name": "Markov Random Fields",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "e08561ed-178a-4ecd-956b-9317d5630cd3",
      "name": "Ensemble Averaging",
      "categoryId": "90081538-133d-4daa-842e-dd866ccc294a"
    },
    {
      "id": "37b54e2c-13bd-4c4d-a859-c39e2fb8eea0",
      "name": "Ensemble Methods",
      "categoryId": "90081538-133d-4daa-842e-dd866ccc294a"
    },
    {
      "id": "30044e99-ef6e-43d5-bab9-da162bfd09ba",
      "name": "Aggregation Techniques",
      "categoryId": "90081538-133d-4daa-842e-dd866ccc294a"
    },
    {
      "id": "d888959d-8582-4494-8cc9-eb5ce56ea839",
      "name": "Voting",
      "categoryId": "90081538-133d-4daa-842e-dd866ccc294a"
    },
    {
      "id": "28f9280c-f44a-45ba-98f5-40e6a1724b0c",
      "name": "Bagging",
      "categoryId": "90081538-133d-4daa-842e-dd866ccc294a"
    },
    {
      "id": "4b8e54fb-8712-49ee-bec9-6909266fd348",
      "name": "Ensemble Distillation",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "a5ff2600-aa41-4762-8ba7-80fc7cee4e6b",
      "name": "Model Compression",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "25ef6ff2-d15f-4fb4-af32-9108ceb6f659",
      "name": "Knowledge Distillation",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "dc3002a2-4a77-414c-b527-67a4997447db",
      "name": "Neural Network Compression",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "2df47eec-dc34-4850-b588-665760e8d581",
      "name": "Ensemble Learning",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "a6d0c0c3-c6b8-4dec-a63b-5bbf0ae315f5",
      "name": "Ensemble Diversity",
      "categoryId": "568523b2-fa1a-4a9e-b2e7-c894832e26e2"
    },
    {
      "id": "e1bdc998-7073-40c7-b5f6-933bab821d14",
      "name": "Model Diversity",
      "categoryId": "568523b2-fa1a-4a9e-b2e7-c894832e26e2"
    },
    {
      "id": "3378b567-5cde-40e8-91c2-365cd90546fe",
      "name": "Ensemble Learning",
      "categoryId": "568523b2-fa1a-4a9e-b2e7-c894832e26e2"
    },
    {
      "id": "eeb723d2-6147-4b24-b400-0a154b358997",
      "name": "Bagging",
      "categoryId": "568523b2-fa1a-4a9e-b2e7-c894832e26e2"
    },
    {
      "id": "0b6d87ab-60ce-4d2a-8418-66d14c664673",
      "name": "Boosting",
      "categoryId": "568523b2-fa1a-4a9e-b2e7-c894832e26e2"
    },
    {
      "id": "4e5fdbcf-9c3b-44aa-8577-e93f45f8c4e0",
      "name": "Ensemble Diversity Techniques",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "f5d30122-fb5b-4b5e-ab91-45f368d7ad83",
      "name": "Bagging",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "fab5b3fe-3d21-4bdc-8855-b88e657d9216",
      "name": "Boosting",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "94104f48-0061-432c-9ed6-9018ece61755",
      "name": "Stacking",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "417ae609-09df-4130-9e2b-36155b382e8a",
      "name": "Random Forests",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "1e35ffee-05a9-4571-94d4-77756456debf",
      "name": "Ensemble Diversity Techniques Extensions",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "8f31e2cc-de02-479e-acb9-d6001be355e4",
      "name": "Ensemble Methods",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "878c1b31-e88c-4c56-b12e-8259eb312ce3",
      "name": "Diversity Strategies",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "9c77f0de-3d59-417e-9572-316a26ce9e27",
      "name": "Gradient Boosting",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "1e35ed9a-a95a-4693-bb98-1e56a49dbfcb",
      "name": "Ensemble Learning",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "192eba82-dbd6-4f91-a211-a4121d7b775c",
      "name": "Supervised Learning",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "acf8482e-f0e5-41d7-b96f-56b976868802",
      "name": "Decision Trees",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "4c21c4d7-8d93-4a2c-9ea4-03cd90621694",
      "name": "Boosting Algorithms",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "48c4499f-7cc2-4d7a-b0e0-20f42a8077ba",
      "name": "Fisher Information",
      "categoryId": "93b6daed-ada5-467e-bb57-c4b278896740"
    },
    {
      "id": "b49154e7-159b-484b-859d-685e2cc54831",
      "name": "Statistical Estimation",
      "categoryId": "93b6daed-ada5-467e-bb57-c4b278896740"
    },
    {
      "id": "19548fe5-ee17-479b-b5f5-0f2205bc2f4b",
      "name": "Information Theory",
      "categoryId": "93b6daed-ada5-467e-bb57-c4b278896740"
    },
    {
      "id": "80893482-da3f-43ff-a237-ea803d0b39e8",
      "name": "Parameter Estimation",
      "categoryId": "93b6daed-ada5-467e-bb57-c4b278896740"
    },
    {
      "id": "81615611-76b6-4a86-bd77-8c3ed6c85e5e",
      "name": "Variance Bound",
      "categoryId": "93b6daed-ada5-467e-bb57-c4b278896740"
    },
    {
      "id": "d3812fad-73c3-4d68-ae08-75426c127c98",
      "name": "Statistical Estimation",
      "categoryId": "a08d705b-8994-4bcf-9c82-17c75c3bc367"
    },
    {
      "id": "5329233d-e893-4511-8d75-49b3f382c2af",
      "name": "Information Theory",
      "categoryId": "a08d705b-8994-4bcf-9c82-17c75c3bc367"
    },
    {
      "id": "39742e93-589a-4e30-83ab-a6a90ceea6ce",
      "name": "Parameter Estimation",
      "categoryId": "a08d705b-8994-4bcf-9c82-17c75c3bc367"
    },
    {
      "id": "2bdfe829-326f-4dda-a399-2ef3268ed16c",
      "name": "Fisher Information",
      "categoryId": "a08d705b-8994-4bcf-9c82-17c75c3bc367"
    },
    {
      "id": "e90d7b50-b12c-4944-b395-85fc32d1fc0d",
      "name": "Covariance Matrices",
      "categoryId": "a08d705b-8994-4bcf-9c82-17c75c3bc367"
    },
    {
      "id": "3abc130f-c77a-4ced-87cc-77c5c70ca310",
      "name": "Feature Extraction",
      "categoryId": "f697ffdc-db4e-4058-938b-63083e5204a2"
    },
    {
      "id": "9d9af0b9-4bd1-431d-832f-78f88a05422a",
      "name": "Pattern Recognition",
      "categoryId": "f697ffdc-db4e-4058-938b-63083e5204a2"
    },
    {
      "id": "c9bea7f4-145d-451c-977e-4a5aa52409b6",
      "name": "Machine Learning",
      "categoryId": "f697ffdc-db4e-4058-938b-63083e5204a2"
    },
    {
      "id": "96ac26e6-28ae-4409-b9e8-a88401724e80",
      "name": "Feature Encoding",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "cebe5f85-a68c-4dc9-a2f3-623cc085cb33",
      "name": "Visual Recognition",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "3a35cb2a-392b-41f5-8720-5d772f18bd83",
      "name": "Image Processing",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "f814aadf-073b-40cf-81c7-6e83763ff62a",
      "name": "High-Dimensional Descriptors",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "21f9f1a2-3abb-4825-8de8-0f060fadac18",
      "name": "Bag-Of-Features",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "0ac77f84-cc43-4a63-98d0-3055e399e5be",
      "name": "Statistical Tests",
      "categoryId": "a08d705b-8994-4bcf-9c82-17c75c3bc367"
    },
    {
      "id": "4acce7cb-063a-4740-a1a7-48422eda355b",
      "name": "Hypothesis Testing",
      "categoryId": "a08d705b-8994-4bcf-9c82-17c75c3bc367"
    },
    {
      "id": "b000ce27-ad7f-42ee-8e9b-47155d14646b",
      "name": "Non-Parametric Tests",
      "categoryId": "a08d705b-8994-4bcf-9c82-17c75c3bc367"
    },
    {
      "id": "c39b0e3d-9a44-4cf4-8a10-7174855c7d95",
      "name": "Optimization",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "e5f2339d-b008-4ed8-96a8-a8adadae1aa7",
      "name": "Evolutionary Algorithms",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "b2d78c8f-42fc-4292-acad-0bad865e2ec8",
      "name": "Genetic Algorithms",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "5a6248c0-b39e-4ed2-9ea3-09d7ee1af6e5",
      "name": "Search",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "6cc2794b-837e-4697-a617-ac5554db873f",
      "name": "Evaluation Metrics",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "278f0946-f5d6-4b81-83f7-be95908fc244",
      "name": "Transformer Architectures",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "df2d4561-41c3-44b8-a4c1-fa3f6f25a44c",
      "name": "Model Optimization",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "26d10b88-6142-48ea-bea1-a58b4cc44073",
      "name": "Efficient Neural Networks",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "adc35ee6-b920-4ff5-ab44-61123c70ceb5",
      "name": "Sequence Modeling",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "50f7fdbd-8abd-45c6-a55a-8212cb798125",
      "name": "Separation Processes",
      "categoryId": "f3cc5848-17f6-4279-a475-458a184ce408"
    },
    {
      "id": "49ab17c3-3b0b-4741-a01f-7f1afc388ec8",
      "name": "Distillation",
      "categoryId": "f3cc5848-17f6-4279-a475-458a184ce408"
    },
    {
      "id": "4e510063-8b04-404d-8dad-aa8cf0378080",
      "name": "Chemical Engineering",
      "categoryId": "f3cc5848-17f6-4279-a475-458a184ce408"
    },
    {
      "id": "44b7164f-5080-4d12-b8af-18d23e85f32b",
      "name": "Fluid Dynamics",
      "categoryId": "f3cc5848-17f6-4279-a475-458a184ce408"
    },
    {
      "id": "02ff7687-c3ff-47e3-bf40-8e3d9777a7eb",
      "name": "Separation Techniques",
      "categoryId": "f3cc5848-17f6-4279-a475-458a184ce408"
    },
    {
      "id": "d7c9fd52-3854-4713-9e2d-fd73a703a05c",
      "name": "Neural Network Architecture",
      "categoryId": "2bd8b40c-79f5-4b84-813f-a70ebe2d5360"
    },
    {
      "id": "7ad310ec-2721-493c-9ab9-eeeb27f30bf9",
      "name": "Model Flexibility",
      "categoryId": "2bd8b40c-79f5-4b84-813f-a70ebe2d5360"
    },
    {
      "id": "768d0f71-5e12-4f4a-b735-756718b5900f",
      "name": "Adaptive Neural Networks",
      "categoryId": "2bd8b40c-79f5-4b84-813f-a70ebe2d5360"
    },
    {
      "id": "c20300a0-ab48-4681-8aba-1de0f2205fa5",
      "name": "Dynamic Network Structures",
      "categoryId": "2bd8b40c-79f5-4b84-813f-a70ebe2d5360"
    },
    {
      "id": "317dbdcd-6ce3-491f-af9e-437cb402feb9",
      "name": "Parameter Efficiency",
      "categoryId": "2bd8b40c-79f5-4b84-813f-a70ebe2d5360"
    },
    {
      "id": "df565de2-ff54-4edb-8dbe-5d0a811c60eb",
      "name": "Flow-Based Generative Models",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d"
    },
    {
      "id": "1b5fd874-a8af-4c95-bcbe-f6732b54fe6b",
      "name": "Normalizing Flows",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d"
    },
    {
      "id": "b07870e9-caba-4d1f-9dfd-5004b9df06f3",
      "name": "Variational Flows",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d"
    },
    {
      "id": "cad6b1fd-dd50-40b7-95c4-6e2f5eedccad",
      "name": "Continuous Latent Variable Models",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d"
    },
    {
      "id": "909ad962-b285-4960-aba1-33c85b72b991",
      "name": "Bijective Transformations",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d"
    },
    {
      "id": "8b703eee-4941-4c4c-a1a7-96a5885e8609",
      "name": "Flow-Based Generative Models Enhancements",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d"
    },
    {
      "id": "c0a0666b-5f5e-4280-b5da-ca71af519ab5",
      "name": "Autoregressive Flows",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d"
    },
    {
      "id": "8db1dc80-adf1-41bd-9313-022e2f74284b",
      "name": "Residual Flows",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d"
    },
    {
      "id": "df0d439d-1192-485d-8e29-3e50ddf8924a",
      "name": "Flow-Based Generative Models Extensions",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d"
    },
    {
      "id": "3c945745-4bb3-420f-8ebb-f58a85baca20",
      "name": "Continuous Flows",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d"
    },
    {
      "id": "d307b6bf-89b1-4920-9335-ee24f127a383",
      "name": "Discrete Flows",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d"
    },
    {
      "id": "2d58e1bb-bb7b-4562-98e3-b00e2e69b8e8",
      "name": "Neural Autoregressive Flows",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d"
    },
    {
      "id": "49ef5038-6b0e-4828-89ce-2c6fceaef501",
      "name": "Flow-Based Generative Models Techniques",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d"
    },
    {
      "id": "df8b7d5d-70c0-4286-9c03-00922f9642d2",
      "name": "Continuous Flow Models",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d"
    },
    {
      "id": "944d40cf-53e5-4605-93d4-63805c4d88c8",
      "name": "Invertible Neural Networks",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d"
    },
    {
      "id": "72a731b6-ee71-438f-b1c3-cf90989f54a7",
      "name": "Flow-Based Models",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d"
    },
    {
      "id": "6d3e3289-f175-4e7b-9abf-8333f4291fe3",
      "name": "Probabilistic Models",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d"
    },
    {
      "id": "94bedad1-22da-46cb-bc55-255af3613ccc",
      "name": "Density Estimation",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d"
    },
    {
      "id": "85e91bde-a240-40a7-b83a-854b2198d817",
      "name": "Flow-Based Models Enhancement",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d"
    },
    {
      "id": "9766ddbd-f435-4f1d-bb81-7868645385f4",
      "name": "Probabilistic Flow Models",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d"
    },
    {
      "id": "66f78ac6-0fad-46e3-a004-5edc16eb8aae",
      "name": "Flow-Based Models Enhancements",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "ed753c26-3e2c-447a-9bed-98ac6e603f9f",
      "name": "Normalizing Flows",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "b047564a-b5c0-44aa-b377-fadf885dd4ca",
      "name": "Variational Flows",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "76e717f5-395f-4351-b0d4-52ad90da22e9",
      "name": "Invertible Neural Networks",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "ec0d1aac-fa0c-4225-a525-3833ac77b0bd",
      "name": "Conditional Flows",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "4f16e4b7-8c7c-4f39-a04b-b70b6888dfa7",
      "name": "Flow-Based Models Techniques Enhancements",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d"
    },
    {
      "id": "4e8787b3-8a70-49a1-b8c2-83ea320e99fe",
      "name": "Generative Flows",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d"
    },
    {
      "id": "42f7a74d-b0fa-49a6-8844-b24ec328c41c",
      "name": "Variational Inference",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d"
    },
    {
      "id": "4ffa2658-c00f-42b8-a3ae-a76a9a2e5262",
      "name": "Flow-Based Models Variants",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d"
    },
    {
      "id": "a48f5302-7c7f-493a-a7a0-e648af878063",
      "name": "Flow-Based Neural Networks",
      "categoryId": "8e501b08-14ea-4c6c-bbe8-0e8a0c7dfa17"
    },
    {
      "id": "57202a5b-09b0-4d88-afb6-3cf302f52828",
      "name": "Normalizing Flows",
      "categoryId": "8e501b08-14ea-4c6c-bbe8-0e8a0c7dfa17"
    },
    {
      "id": "94cd104c-0afb-4c96-bddc-2052ea685696",
      "name": "Probabilistic Models",
      "categoryId": "8e501b08-14ea-4c6c-bbe8-0e8a0c7dfa17"
    },
    {
      "id": "cdd23d8e-f7b9-4902-9b50-ece12463c342",
      "name": "Deep Generative Models",
      "categoryId": "8e501b08-14ea-4c6c-bbe8-0e8a0c7dfa17"
    },
    {
      "id": "69b08c53-32ad-4a3f-aff3-72d6efb68476",
      "name": "Continuous Density Estimation",
      "categoryId": "8e501b08-14ea-4c6c-bbe8-0e8a0c7dfa17"
    },
    {
      "id": "7520fdf2-df96-4f39-b4c3-53f2d8919655",
      "name": "Fluency Metrics",
      "categoryId": "9c2d686b-dc1c-4ed7-bf77-2cbe83efde08"
    },
    {
      "id": "14579579-5636-464c-91dd-3ff3c541cb08",
      "name": "Language Quality Metrics",
      "categoryId": "9c2d686b-dc1c-4ed7-bf77-2cbe83efde08"
    },
    {
      "id": "23243f43-8bcb-41d3-acd0-03c4cf700d51",
      "name": "Speech",
      "categoryId": "9c2d686b-dc1c-4ed7-bf77-2cbe83efde08"
    },
    {
      "id": "adf28be7-79e6-4ef1-b8a7-eaf424779252",
      "name": "Natural Language Processing (Nlp)",
      "categoryId": "9c2d686b-dc1c-4ed7-bf77-2cbe83efde08"
    },
    {
      "id": "a41a087e-25f5-4fd6-964f-5ab8427600ba",
      "name": "Language Proficiency Measurement",
      "categoryId": "9c2d686b-dc1c-4ed7-bf77-2cbe83efde08"
    },
    {
      "id": "399f0b5d-4aa1-47f3-a9b7-220ca272aefc",
      "name": "Focal Loss",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "3e4888cd-add3-444d-a04c-f2ca8ee8063a",
      "name": "Object Detection",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "68fa65d9-3fdc-41d2-b6e6-5baf963c89db",
      "name": "Image Segmentation",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "2b8346c2-5f83-49ca-8b92-114caa5cb2d7",
      "name": "Softmax",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "34eba7dc-2b03-445d-be2b-589be710be82",
      "name": "Focal Loss Extensions",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "520db4ac-b075-4e9d-9b71-7184c1db5909",
      "name": "Loss Function Variants",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "fa46bd2f-67e3-4d01-8bb7-90fe85d43d7d",
      "name": "Class Imbalance Handling",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "531d40b1-9a34-44ac-8f35-2a2b78cc39d1",
      "name": "Focal Loss Extensions Enhancements",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "8a7866e7-6068-48e0-b00f-3c19cb05aa4d",
      "name": "Loss Function Improvements",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "3282f8e2-17d2-4b30-9e68-db713e61334a",
      "name": "Hard Example Mining",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "5e7cd7f6-5446-423b-af52-d1564d03cd6a",
      "name": "Adaptive Loss Functions",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "440d1e4e-4cb7-405a-82b4-39a4cdd8a65c",
      "name": "Focal Loss Extensions",
      "categoryId": "8e501b08-14ea-4c6c-bbe8-0e8a0c7dfa17"
    },
    {
      "id": "156f3f97-b8d5-48e4-a3b7-77bc5967f6c5",
      "name": "Class Imbalance Handling",
      "categoryId": "8e501b08-14ea-4c6c-bbe8-0e8a0c7dfa17"
    },
    {
      "id": "8f9aae04-365a-4241-99fc-2b4e1210c2b9",
      "name": "Loss Function Improvements",
      "categoryId": "8e501b08-14ea-4c6c-bbe8-0e8a0c7dfa17"
    },
    {
      "id": "48d53dcf-075b-4885-9ff9-d803894b688e",
      "name": "Adaptive Loss Functions",
      "categoryId": "8e501b08-14ea-4c6c-bbe8-0e8a0c7dfa17"
    },
    {
      "id": "ffbee2d8-552f-4002-bc75-b2ad4b1a10d5",
      "name": "Hard Example Mining",
      "categoryId": "8e501b08-14ea-4c6c-bbe8-0e8a0c7dfa17"
    },
    {
      "id": "46f7b48d-f7cb-442f-be7e-28d47e50574e",
      "name": "Focal Loss Variants",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "973965bc-bef9-48ec-8034-0fc7704fe422",
      "name": "Loss Function Modifications",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "d7c020f4-fb99-4f6c-9ebc-cc68f0a2fa34",
      "name": "Deep Learning Techniques",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "9417273e-477f-46a4-88f5-bb5e6e35944e",
      "name": "Focal Loss Variants",
      "categoryId": "f001a980-b036-4a8b-a7b0-290e7b1c9a77"
    },
    {
      "id": "e2dcaf9e-35e3-43fb-8030-57691881a1c0",
      "name": "Loss Functions",
      "categoryId": "f001a980-b036-4a8b-a7b0-290e7b1c9a77"
    },
    {
      "id": "87df4289-9bc5-4f6b-8459-fae13dc80623",
      "name": "Class Imbalance",
      "categoryId": "f001a980-b036-4a8b-a7b0-290e7b1c9a77"
    },
    {
      "id": "bb127a8f-0f65-4ef1-a809-b8dfe100c002",
      "name": "Hard Example Mining",
      "categoryId": "f001a980-b036-4a8b-a7b0-290e7b1c9a77"
    },
    {
      "id": "7078f677-44ff-42da-a6a5-9a452029e658",
      "name": "Focal Loss",
      "categoryId": "f001a980-b036-4a8b-a7b0-290e7b1c9a77"
    },
    {
      "id": "2e9ca9e9-4b4d-48d9-8a81-85d2832c4624",
      "name": "Class Imbalance Techniques",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "7d03feca-5798-49a9-8721-a33b35c5170a",
      "name": "Sequence-To-Sequence Models",
      "categoryId": "9c2d686b-dc1c-4ed7-bf77-2cbe83efde08"
    },
    {
      "id": "bff2de96-3d19-4cce-ab9c-4e6858489471",
      "name": "Decoding Strategies",
      "categoryId": "9c2d686b-dc1c-4ed7-bf77-2cbe83efde08"
    },
    {
      "id": "05517f8c-44d8-443e-81e6-047173397cd8",
      "name": "Teacher Forcing",
      "categoryId": "9c2d686b-dc1c-4ed7-bf77-2cbe83efde08"
    },
    {
      "id": "bacded76-f6e7-44d3-874c-a2e42ba23ec0",
      "name": "Model Debugging",
      "categoryId": "9c2d686b-dc1c-4ed7-bf77-2cbe83efde08"
    },
    {
      "id": "da33ba6d-243b-432f-9d65-54c0cb1059f2",
      "name": "Nlp Training Methods",
      "categoryId": "9c2d686b-dc1c-4ed7-bf77-2cbe83efde08"
    },
    {
      "id": "0dac0fc4-3a0b-4015-8cb2-76db144a0970",
      "name": "Forecasting Falls Under The Sub-Category Tags Such As Time Series Analysis",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "d7b2af52-d528-43e6-a17f-d59cbbeabebe",
      "name": "Predictive Analytics",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "a19c9ec7-daa8-4402-a3b1-df9a55f4246b",
      "name": "Quantitative Analysis",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "8b1416d4-5e3b-4bf1-9388-57fb3e629843",
      "name": "And Statistical Modeling. It Involves Techniques That Analyze Temporal Data To Make Future Predic...",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "a565f81c-6ebe-4b7b-abe0-4ed6ad9abefb",
      "name": "Emphasizing Patterns",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "720cae1b-2d91-4570-a3a6-137918aaf756",
      "name": "Cellular Automata",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "bab81fff-07a6-463f-9b7c-dd33496cac8f",
      "name": "Percolation Theory",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "403f5211-7e0f-476b-a598-44320a0bd409",
      "name": "Modeling",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "8ad22e67-0f72-40d2-9cab-16be05d66a53",
      "name": "Stochastic Processes",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "61eabdb8-0e94-4c81-bfc8-c77fbab77b2d",
      "name": "Spatial Dynamics",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "33e748fe-6f4e-403f-8a61-6ca9b9ed13c7",
      "name": "Natural Disasters",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "e1e8a3b5-9acf-4878-be2c-72759231f580",
      "name": "Simulation",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "68a8448f-cf78-4840-bfce-e437ec7ec034",
      "name": "Wildfire Spread",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "9c503921-3a2e-4d43-8c3d-1b4e613d2f3f",
      "name": "Complex Systems",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "cb75937e-b06c-4697-9e03-e9f0241a32e3",
      "name": "Environmental Modeling",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "0edf077b-d37f-4a83-b98e-c5cee88589a6",
      "name": "Formal Concept Analysis (Fca)",
      "categoryId": "3e4c5e60-7266-4d25-8242-b6f3b9a4b190"
    },
    {
      "id": "043be617-2cbb-4fac-9cc9-d6415fbc4ebd",
      "name": "Lattice Theory",
      "categoryId": "3e4c5e60-7266-4d25-8242-b6f3b9a4b190"
    },
    {
      "id": "68257faa-dc39-4603-aed4-a72a6a9b00ad",
      "name": "Formal Contexts",
      "categoryId": "3e4c5e60-7266-4d25-8242-b6f3b9a4b190"
    },
    {
      "id": "9feb9273-4eee-47e9-a0d1-e266cca8dd42",
      "name": "Galois Connections",
      "categoryId": "3e4c5e60-7266-4d25-8242-b6f3b9a4b190"
    },
    {
      "id": "b7450a52-e083-4b4c-9c38-7380357662d0",
      "name": "Concept Hierarchies",
      "categoryId": "3e4c5e60-7266-4d25-8242-b6f3b9a4b190"
    },
    {
      "id": "b204675e-95df-41a1-9b31-b7d94221f09b",
      "name": "Reinforcement Learning",
      "categoryId": "68a5cba0-fded-4081-b8ab-4e9e975b8706"
    },
    {
      "id": "ec22789c-c449-4f07-9b1b-e61730384fcb",
      "name": "Inverse Reinforcement Learning",
      "categoryId": "68a5cba0-fded-4081-b8ab-4e9e975b8706"
    },
    {
      "id": "54e7121c-bc11-48ad-88b6-8654c6248c52",
      "name": "Forward Reinforcement Learning",
      "categoryId": "68a5cba0-fded-4081-b8ab-4e9e975b8706"
    },
    {
      "id": "f82407aa-1b01-4d0b-9b8b-1ea2df162606",
      "name": "Imitation Learning",
      "categoryId": "68a5cba0-fded-4081-b8ab-4e9e975b8706"
    },
    {
      "id": "4ae29e50-6a1a-4e9e-863b-1c5a3522f039",
      "name": "Machine Learning Paradigms",
      "categoryId": "68a5cba0-fded-4081-b8ab-4e9e975b8706"
    },
    {
      "id": "0452d4bc-5397-4db2-a43a-f0afb34a9688",
      "name": "Knowledge Inference",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "0f2a13a9-0897-4218-8339-70906555f9da",
      "name": "Rule-Based Systems",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "7c1a240f-6619-465d-9833-615eb952fb20",
      "name": "Logical Reasoning",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "e50bb273-c8d7-4cbf-a3ae-e9e08e9106d6",
      "name": "Expert Systems",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "a2e12fc1-02bf-48f7-bda8-a9e9d2b97827",
      "name": "Inference Engine",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "eeebe374-3802-491d-8dd5-7b73067d7a4e",
      "name": "Diffusion Processes",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d"
    },
    {
      "id": "2f20476b-92ce-4f6b-9938-86be90b6f2f8",
      "name": "Generative Modeling",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d"
    },
    {
      "id": "b7d3db7f-b813-4456-9525-0f5a00afde39",
      "name": "Markov Processes",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d"
    },
    {
      "id": "fcabc1dc-b655-49bd-9710-22b714f6ae97",
      "name": "Stochastic Differential Equations",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d"
    },
    {
      "id": "eaf47bb2-e211-49c6-ab68-17da87ccc419",
      "name": "Neural Networks",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "c71a3022-4886-4a54-851a-17e5325b3a1b",
      "name": "Model Evaluation",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "a62f0a0a-208b-478b-a998-5c37057322e3",
      "name": "Computational Graphs",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "0edb723a-8aee-46c6-a8fb-22b5b3a82365",
      "name": "Activation Functions",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "b5bbbd59-7e62-4168-b005-4c3985d2778a",
      "name": "Foundation Model",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "4aff76ce-31cf-4101-8dd1-aeedbd2f522a",
      "name": "Large Language Model",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "dd4ea1a2-f336-48e4-8f8b-b60450a7b109",
      "name": "Pretrained Model",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "96d4d033-f428-4ea7-9c34-2a01daa28884",
      "name": "Foundation Models",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "0b3ae715-d1c5-4233-b3a3-e26d930adc87",
      "name": "Large-Scale Pretrained Models",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "7c1443d7-de0c-4e96-a1b8-e19a6a92f234",
      "name": "Transfer Learning",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "ebe00f5f-aee9-4961-988e-bb52d0f73448",
      "name": "Sub-Category Tags For 'Foundational Ai Model' Include Terms Such As 'Large Language Model'",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "351ad74d-b16f-435f-b61e-c0b145807c8b",
      "name": "'Pretraining'",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "48969b49-e42f-453e-824b-2046d5a236a8",
      "name": "'Transformer Architecture'",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "7b582048-fc5f-4ff3-82c0-2c9acf397c14",
      "name": "'Neural Network Foundations'",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "60904928-3e0f-43c1-a1d1-f7c2e8d5eb3c",
      "name": "'Model Scaling'",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "7029cf5d-a3c4-46a8-a789-a486607ca1ca",
      "name": "Fourier Features",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "8d9e8ad8-efa0-47ad-b762-57153d72955c",
      "name": "Feature Mapping",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "eb2703ff-cc93-4895-9569-0b8e54742696",
      "name": "Random Fourier Features",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "d24dd52f-003b-4df5-8e30-e1ac8ad0b850",
      "name": "Kernel Approximation",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "608b3750-2570-4c52-906f-c01cf20e05fc",
      "name": "Positional Encoding",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "ff30c244-b37e-4030-a75c-2e7e5346d98d",
      "name": "Neural Networks",
      "categoryId": "2b22b5bb-853f-4223-b261-3529a749faa5"
    },
    {
      "id": "2a6095cf-35c8-43de-85ae-030eeb712f8d",
      "name": "Feature Engineering",
      "categoryId": "2b22b5bb-853f-4223-b261-3529a749faa5"
    },
    {
      "id": "084037c6-aefe-47e6-8a4c-e09f298f0bfb",
      "name": "Kernel Methods",
      "categoryId": "2b22b5bb-853f-4223-b261-3529a749faa5"
    },
    {
      "id": "ad0ad4f3-d588-4337-8d09-6d0f15c89400",
      "name": "Positional Encoding",
      "categoryId": "2b22b5bb-853f-4223-b261-3529a749faa5"
    },
    {
      "id": "e4c6bde1-e37d-4a37-984a-b172ef6ffd41",
      "name": "Machine Learning Foundations",
      "categoryId": "2b22b5bb-853f-4223-b261-3529a749faa5"
    },
    {
      "id": "9effa62d-67f4-444d-a608-939315cf3b51",
      "name": "Fourier Neural Operator",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "77427602-fb3e-4eb1-961f-85228fcd2332",
      "name": "Fno",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "97036176-e7b0-4d87-b532-6c503bcf02dd",
      "name": "Operator Learning",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "bdeb1ffa-765e-476d-848b-cc2f59e15dda",
      "name": "Neural Operator",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "09c41ca5-5d87-4619-a486-9ff5c7ebb456",
      "name": "Spectral Methods",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "7c85f82c-279b-4279-b456-e15bb86eda5d",
      "name": "Fourier Neural Operators",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "a770b0dc-c167-42c4-988e-9b7495563d24",
      "name": "Infinite-Dimensional Problems",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "e6634ca6-dc2d-405e-a61d-f98139c02001",
      "name": "Fourier Neural Operators Enhancements",
      "categoryId": "2bd8b40c-79f5-4b84-813f-a70ebe2d5360"
    },
    {
      "id": "8a14aefa-dbf5-4440-a223-98b8109dea21",
      "name": "Neural Operators",
      "categoryId": "2bd8b40c-79f5-4b84-813f-a70ebe2d5360"
    },
    {
      "id": "2ea66079-7712-44cb-a9c3-46d11d25b60b",
      "name": "Fourier Transform",
      "categoryId": "2bd8b40c-79f5-4b84-813f-a70ebe2d5360"
    },
    {
      "id": "5df44f83-2802-4dca-ab3a-0f5f4e52a37a",
      "name": "High-Dimensional Pdes",
      "categoryId": "2bd8b40c-79f5-4b84-813f-a70ebe2d5360"
    },
    {
      "id": "53ffc314-2de5-46ab-9a7d-56b70ba1ddd6",
      "name": "Operator Learning",
      "categoryId": "2bd8b40c-79f5-4b84-813f-a70ebe2d5360"
    },
    {
      "id": "a3c00a97-9243-49dd-9d58-a32bcc82802b",
      "name": "Fourier Transforms",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "edffd131-fd6a-4398-b0fb-f86572de4957",
      "name": "Pde Solvers",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "cd9577ab-2712-4bc2-a1ec-3bdbc0be4155",
      "name": "Neural Operator Extensions",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "328c7b33-a1fb-49bd-a2a8-baad831edaef",
      "name": "Fourier Neural Operators Techniques Enhancements",
      "categoryId": "2bd8b40c-79f5-4b84-813f-a70ebe2d5360"
    },
    {
      "id": "6116a152-90c1-43b7-a9a2-b2d0fcd2c4a2",
      "name": "Deep Learning",
      "categoryId": "2bd8b40c-79f5-4b84-813f-a70ebe2d5360"
    },
    {
      "id": "805dbf01-b8eb-4462-a124-5bd7d364ad7f",
      "name": "Fourier Neural Operators Techniques Extensions",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "27000128-d1d6-4c84-9bb9-9990b1d3a64a",
      "name": "Spectral Methods",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "1166af08-8173-4e62-8f38-f7c011a34fcb",
      "name": "Operator Learning",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "26b605fd-3f04-421d-8b55-0578f03c4c45",
      "name": "Deep Approximate Operators",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "818f8a69-cdd3-46a0-84e5-7317034d9010",
      "name": "Function Space Regression",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "a7f02e9a-cca5-42f5-91a7-b035f8794474",
      "name": "Fourier Neural Operators",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "cfb6b232-af70-4e94-89cb-fbc2132140fe",
      "name": "Operator Learning",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "e4f1a9de-654c-45fb-8972-5ddf9739c13f",
      "name": "Numerical Pde Solvers",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "f41ab917-9023-4063-870c-b1cfbc8aedb8",
      "name": "Deep Learning",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "69804a22-5ab0-4944-8e12-d26a5e0ad0e4",
      "name": "Neural Operator Methods",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "90020ff5-1a88-4179-8184-3f946cc0282d",
      "name": "Neural Operators",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "831812cd-b79a-4496-b8d3-48c3157e6640",
      "name": "Fourier Transforms",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "1f5c1df3-1e8e-4a13-b2f4-b6e0b24069a4",
      "name": "Deep Learning Extensions",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "ccc1a144-fe67-4a0e-8228-638f629a9a9e",
      "name": "Model Enhancements",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "25e9c249-de44-43c7-a877-3090643e7bf8",
      "name": "Numerical Methods",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "288adc51-8347-43e4-ae30-bba27a20a6b5",
      "name": "Fourier Transform",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "f1a3b404-894e-41b4-9d5d-509b4c3cc1dd",
      "name": "Convolutional Neural Networks (Cnns)",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "da9e7ef5-f58d-4f0d-938c-dc16898c4127",
      "name": "Frequency Domain Analysis",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "e3c9d0a0-6022-4992-a349-da41e1ff7af7",
      "name": "Spectral Methods",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "770e5216-f145-4a60-93f5-95a554af63b6",
      "name": "Signal Processing",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "434a6b76-d87b-436e-a9e6-7d3c804dd4af",
      "name": "Clustering Validation",
      "categoryId": "de8842d5-eb45-4c4d-b8f3-15f9a39657f4"
    },
    {
      "id": "97d5a2aa-f632-4799-8547-3a189b8aa0cd",
      "name": "Internal Validation Metrics",
      "categoryId": "de8842d5-eb45-4c4d-b8f3-15f9a39657f4"
    },
    {
      "id": "4cd7e9f5-808d-4006-945c-561fae84f308",
      "name": "Similarity Measures",
      "categoryId": "de8842d5-eb45-4c4d-b8f3-15f9a39657f4"
    },
    {
      "id": "91d18692-e830-4291-a4e4-8783780e78a0",
      "name": "Cluster Similarity Indices",
      "categoryId": "de8842d5-eb45-4c4d-b8f3-15f9a39657f4"
    },
    {
      "id": "59e42d62-4e5d-452c-895f-b5bd6e6c2c2b",
      "name": "Clustering Validation Metrics",
      "categoryId": "de8842d5-eb45-4c4d-b8f3-15f9a39657f4"
    },
    {
      "id": "e40d54c8-695c-497d-8f93-287e4d502e95",
      "name": "Pattern Mining",
      "categoryId": "f4a166e4-92f8-4e53-bbd2-66c352a23c5e"
    },
    {
      "id": "3606be39-a025-4128-a7b8-0d4f126a17b4",
      "name": "Association Rule Mining",
      "categoryId": "f4a166e4-92f8-4e53-bbd2-66c352a23c5e"
    },
    {
      "id": "6c227fc9-f93d-43cc-a2c0-e3429bf64047",
      "name": "Frequent Pattern Mining",
      "categoryId": "f4a166e4-92f8-4e53-bbd2-66c352a23c5e"
    },
    {
      "id": "c803e3cd-c958-4c72-aa47-c307993ae423",
      "name": "Commercial Data Analysis",
      "categoryId": "f4a166e4-92f8-4e53-bbd2-66c352a23c5e"
    },
    {
      "id": "2bd5cd9a-4544-4bb1-973e-4df22959431b",
      "name": "Quantization",
      "categoryId": "8e501b08-14ea-4c6c-bbe8-0e8a0c7dfa17"
    },
    {
      "id": "3234b5b7-ec8d-4442-90b5-3dbce7c7ec56",
      "name": "Low-Precision Computation",
      "categoryId": "8e501b08-14ea-4c6c-bbe8-0e8a0c7dfa17"
    },
    {
      "id": "f2e979ac-0e96-4314-8779-9d30593e7ec0",
      "name": "Model Compression",
      "categoryId": "8e501b08-14ea-4c6c-bbe8-0e8a0c7dfa17"
    },
    {
      "id": "c1f0a55e-645c-485b-a51d-49803323d374",
      "name": "Fp16",
      "categoryId": "8e501b08-14ea-4c6c-bbe8-0e8a0c7dfa17"
    },
    {
      "id": "cc1fe632-a197-464c-ae0c-fc42334681cd",
      "name": "Half-Precision Floating Point",
      "categoryId": "8e501b08-14ea-4c6c-bbe8-0e8a0c7dfa17"
    },
    {
      "id": "7a5d363f-ed0f-4f99-9d18-154aaa91a6e3",
      "name": "Fpga",
      "categoryId": "b8efc3ce-ee01-45f6-98b1-b4f2f8403af6"
    },
    {
      "id": "cafdc916-4de3-428a-aa0f-167414fc6ba9",
      "name": "Field Programmable Gate Arrays",
      "categoryId": "b8efc3ce-ee01-45f6-98b1-b4f2f8403af6"
    },
    {
      "id": "e022f1be-e09e-4a41-935a-1d21d0174ef0",
      "name": "Hardware Acceleration",
      "categoryId": "b8efc3ce-ee01-45f6-98b1-b4f2f8403af6"
    },
    {
      "id": "7d23c6fa-5c6e-454b-90b3-88fdd52d32e9",
      "name": "Reconfigurable Computing",
      "categoryId": "b8efc3ce-ee01-45f6-98b1-b4f2f8403af6"
    },
    {
      "id": "1c5fd97e-ae20-46e7-a91d-41b302a2793a",
      "name": "Custom Hardware For Ai",
      "categoryId": "b8efc3ce-ee01-45f6-98b1-b4f2f8403af6"
    },
    {
      "id": "5fcd55f1-942a-4d0f-b2f2-3bbdf92c5ecd",
      "name": "Fractional Calculus",
      "categoryId": "0bf30cf3-9e76-4a60-bafa-42b77b5eb474"
    },
    {
      "id": "cbdbee02-b615-42b7-9b4c-bcd64ef6ad72",
      "name": "Non-Integer Order Derivatives",
      "categoryId": "0bf30cf3-9e76-4a60-bafa-42b77b5eb474"
    },
    {
      "id": "766b7b97-0eca-4ccb-a081-cdd5b26b8490",
      "name": "Generalized Differentiation",
      "categoryId": "0bf30cf3-9e76-4a60-bafa-42b77b5eb474"
    },
    {
      "id": "f0521863-8a1b-486f-bb24-cf9f2697665a",
      "name": "Nonlocal Operators",
      "categoryId": "0bf30cf3-9e76-4a60-bafa-42b77b5eb474"
    },
    {
      "id": "531212b9-f73a-4ac4-9bc8-bf05305424ee",
      "name": "Fractional Integrals",
      "categoryId": "0bf30cf3-9e76-4a60-bafa-42b77b5eb474"
    },
    {
      "id": "01d1df87-6e06-45e1-8443-d4fe95ab67b0",
      "name": "Audio Preprocessing",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "3bcad920-efbc-4dbf-a3e5-e47f74e7e24d",
      "name": "Spectrogram Analysis",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "6150643a-e0ed-4b9d-95d9-5f4ab0e69a78",
      "name": "Signal Processing",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "79c1dcd8-1d8e-4e3f-a192-f910a9c72bb4",
      "name": "Time-Series Data",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "e4af570a-2b16-49e1-a7ea-476fbb20d910",
      "name": "Knowledge Representation",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "4dd88458-186a-4127-a208-9c243598b4d4",
      "name": "Image Quality Assessment",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "62ea1f24-abc5-46d9-842b-d41ff25ac1dc",
      "name": "Gans",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "14a74e59-9fd1-412d-a29d-34a5123cf7ed",
      "name": "Statistical Distances",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "d30519ae-b610-4ac6-a7b6-d9e9689071d8",
      "name": "Numerical Encoding",
      "categoryId": "316ca6bb-f333-42fa-bb20-ddc3944c0961"
    },
    {
      "id": "ef6d3977-585b-4c1b-9d39-ae9e99d16b18",
      "name": "Categorical Data",
      "categoryId": "316ca6bb-f333-42fa-bb20-ddc3944c0961"
    },
    {
      "id": "1cc08efe-13c7-46e6-819b-72c37291c7d9",
      "name": "Feature Engineering",
      "categoryId": "316ca6bb-f333-42fa-bb20-ddc3944c0961"
    },
    {
      "id": "f1d0d618-9704-4200-b7da-7ef7e5272a41",
      "name": "Data Preprocessing",
      "categoryId": "316ca6bb-f333-42fa-bb20-ddc3944c0961"
    },
    {
      "id": "f5b07a84-7532-4bdc-84ad-ff3456f8fc55",
      "name": "Data Transformation",
      "categoryId": "316ca6bb-f333-42fa-bb20-ddc3944c0961"
    },
    {
      "id": "c7661545-2da5-4cf7-83dc-655f04f7e13a",
      "name": "Nlp",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "4795d07c-f55a-44a7-abe6-6c281cf87a6b",
      "name": "Text Generation",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "66a4a8f8-1249-4238-af3c-4cbb6fbda9d0",
      "name": "Language Modeling",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "5fd6193c-74a7-4df4-9f17-8a2e3aa4cbf9",
      "name": "Prompt Engineering",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "55808d82-17ad-411b-bfcc-c4e6455f52bc",
      "name": "Ai Text Tools",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "ea42938b-ab43-47ba-bad6-91e3de58e614",
      "name": "Natural Language Processing",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "197947bc-33d7-4715-9931-619ddd440adb",
      "name": "Text Mining",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "3cdb3439-4c9a-41eb-bc61-b1f36b6377c2",
      "name": "Feature Selection",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "3af56afe-d2ba-4494-bc0b-69a128dc6dfe",
      "name": "Frequency-Based Algorithms Fall Under The Sub-Category Of Statistical",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "94b5ea03-112f-491b-ba53-c5b2ad79f47b",
      "name": "Time-Series Analysis",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "ab7a09cb-1f32-44f2-987d-c4a9c7ab5601",
      "name": "And Probabilistic Modeling. These Algorithms Leverage Frequency Components",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "f7c48efe-f107-47a7-a979-d74bdd1de57b",
      "name": "Anomalies",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "90d735e5-b431-4a61-bd38-f16c249914d1",
      "name": "Or Features",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "6d461300-3bd8-4048-9ddb-02ec66a0e5ca",
      "name": "Sampling Techniques",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "7ff5f124-db54-44e8-83b1-c5800bcf11a9",
      "name": "Frequency-Based Sampling",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "dcf95069-65d9-4bf8-a79e-0a941b0068f2",
      "name": "Data Sampling Methods",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "f57e7def-3aeb-40b8-a5a5-959995b80afc",
      "name": "Data Subsetting",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "c7df8c85-dc92-40fd-89a4-ad12ae1af2c4",
      "name": "Data Frequency Analysis",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "5841cf9e-1f53-41e7-92f8-95b347c672d2",
      "name": "Semi-Supervised Learning",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "38ef180c-a426-4866-8265-2dc47c4ce628",
      "name": "Self-Training",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "65e4360d-ff4f-4b22-93de-cd656c61adcc",
      "name": "Confidence Calibration",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "fd5086b8-26c9-41ac-b709-5f76d0e137d4",
      "name": "Pseudo-Labeling",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "ab1f5577-046e-4bbc-a593-e9a22a353e40",
      "name": "Weak Labels",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "7eff4991-c335-4116-a2ec-3bb4069c26bd",
      "name": "Data Quality",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "80ad2c65-5896-4d9a-9a08-425982837266",
      "name": "Noise Robustness",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "829d8301-e6e8-4195-bc9a-f69f5f4c2f37",
      "name": "Noise Handling",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "61d3b748-2f4b-47b2-a940-6584e7353f64",
      "name": "Graph-Based Algorithms",
      "categoryId": "b1801e0d-e24b-4ad2-9e47-20e042487137"
    },
    {
      "id": "6c6c89a2-c827-4583-8a72-f54397e14772",
      "name": "Machine Learning",
      "categoryId": "b1801e0d-e24b-4ad2-9e47-20e042487137"
    },
    {
      "id": "e3fe0460-00c1-46ff-a9eb-bc6f61fc92d4",
      "name": "Data Labeling",
      "categoryId": "b1801e0d-e24b-4ad2-9e47-20e042487137"
    },
    {
      "id": "b307fcf0-bfb7-4250-97ec-b0504e397d1a",
      "name": "Classification",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "269d48b7-c2ee-4489-8220-09cc6676736e",
      "name": "Loss Functions",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "500feb9c-2bee-4206-a708-b2e0574a07a6",
      "name": "Model Regularization",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "6c11893c-3708-41f2-8988-0a621ded3ff4",
      "name": "Ladder Nets Enhancements",
      "categoryId": "2bd8b40c-79f5-4b84-813f-a70ebe2d5360"
    },
    {
      "id": "6825c0f6-bd3f-4e2b-b32e-dc1d7aa93d62",
      "name": "Skip Connections",
      "categoryId": "2bd8b40c-79f5-4b84-813f-a70ebe2d5360"
    },
    {
      "id": "8aa51cd4-a40f-45cc-9b59-082c9c89fe5f",
      "name": "Network Regularization",
      "categoryId": "2bd8b40c-79f5-4b84-813f-a70ebe2d5360"
    },
    {
      "id": "d0c315ba-d0fc-45d2-a7a1-fa3806ed0f5f",
      "name": "Ladder Nets Enhancements Techniques",
      "categoryId": "f001a980-b036-4a8b-a7b0-290e7b1c9a77"
    },
    {
      "id": "e0af036b-97b7-47c6-8b71-bb0b8eac7e32",
      "name": "Deep Learning",
      "categoryId": "f001a980-b036-4a8b-a7b0-290e7b1c9a77"
    },
    {
      "id": "b698f681-8035-42cd-8aa4-d4c89d8b7596",
      "name": "Neural Network Optimization",
      "categoryId": "f001a980-b036-4a8b-a7b0-290e7b1c9a77"
    },
    {
      "id": "71548cd6-c850-4fb4-bf69-9d6966472ae8",
      "name": "Convolutional Networks",
      "categoryId": "f001a980-b036-4a8b-a7b0-290e7b1c9a77"
    },
    {
      "id": "e2582031-e34a-4191-88c9-baa5bb85a0bc",
      "name": "Feature Extraction",
      "categoryId": "f001a980-b036-4a8b-a7b0-290e7b1c9a77"
    },
    {
      "id": "23947227-bebd-470c-a41f-2a70e9dcbc61",
      "name": "Ladder Nets Extensions",
      "categoryId": "f001a980-b036-4a8b-a7b0-290e7b1c9a77"
    },
    {
      "id": "a5a622f0-5c23-49f9-a770-5261071c0021",
      "name": "Neural Network Architectures",
      "categoryId": "f001a980-b036-4a8b-a7b0-290e7b1c9a77"
    },
    {
      "id": "537ad2e9-dcd6-45e6-990f-924314c64bd4",
      "name": "Deep Learning Modules",
      "categoryId": "f001a980-b036-4a8b-a7b0-290e7b1c9a77"
    },
    {
      "id": "1b9ec128-1abc-4495-93cb-26e5580bd282",
      "name": "Hierarchical Neural Networks",
      "categoryId": "f001a980-b036-4a8b-a7b0-290e7b1c9a77"
    },
    {
      "id": "0feffada-0883-4b17-8059-95e09534b06c",
      "name": "Multi-Layer Neural Networks",
      "categoryId": "f001a980-b036-4a8b-a7b0-290e7b1c9a77"
    },
    {
      "id": "43336c9d-a92f-48d4-97ed-281d3231c1f9",
      "name": "Batch Processing",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "29d9b6be-0418-46e6-8391-464125537f9f",
      "name": "Real-Time Streaming",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "f1342943-3e53-4710-8570-2f0a6e1c8972",
      "name": "Data Pipeline",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "bfa33835-6e46-4a2c-97d9-d87a5742f95c",
      "name": "Data Storage",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "4592f465-e47b-4c0e-b5b5-4ba1b514d250",
      "name": "Fault Tolerance",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "145e60d6-3340-462d-8e7c-d5571b984d0b",
      "name": "Natural Language Processing (Nlp)",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "ef558e5f-113f-470a-8e6b-350323ccf65a",
      "name": "Robotics",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "17e9a6cd-6875-4cb6-8111-e9ccf61db5e8",
      "name": "Text Generation",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "0fa7d136-1535-4501-b511-3e50188ea504",
      "name": "Human-Robot Interaction",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "8d03c94f-6d92-483c-bcc8-74270975585e",
      "name": "Dialogue Systems",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "82e15f41-5ca8-4ec1-940d-deee20b46632",
      "name": "Language Model Evaluation Involves Sub-Category Tags Such As Perplexity",
      "categoryId": "9c2d686b-dc1c-4ed7-bf77-2cbe83efde08"
    },
    {
      "id": "cfd77b58-be64-41ec-85f9-aa5c0375c076",
      "name": "Bleu Score",
      "categoryId": "9c2d686b-dc1c-4ed7-bf77-2cbe83efde08"
    },
    {
      "id": "bd935dd5-a1bd-4be4-a49d-76362395b483",
      "name": "Rouge",
      "categoryId": "9c2d686b-dc1c-4ed7-bf77-2cbe83efde08"
    },
    {
      "id": "3d5c7536-0a87-4246-8f10-0b20dce40339",
      "name": "Accuracy",
      "categoryId": "9c2d686b-dc1c-4ed7-bf77-2cbe83efde08"
    },
    {
      "id": "1116b6a3-f459-40fc-a258-6f29b8895020",
      "name": "F1 Score",
      "categoryId": "9c2d686b-dc1c-4ed7-bf77-2cbe83efde08"
    },
    {
      "id": "e825b76d-32d0-4cd9-9395-06960c0f93ca",
      "name": "Machine Learning",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "f2b57728-ae40-40b5-bb47-aa27643c0eff",
      "name": "Model Adaptation",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "a7e16ba8-97bf-43c9-94aa-d6edcbb6fe15",
      "name": "Transfer Learning",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1"
    },
    {
      "id": "8c1a451e-cdcb-49cd-8e3d-5d8e8449ef4f",
      "name": "Fine-Tuning",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "6cbc1861-8494-4cb5-a387-28977b54ce35",
      "name": "Language Modeling",
      "categoryId": "9c2d686b-dc1c-4ed7-bf77-2cbe83efde08"
    },
    {
      "id": "b2dd0de1-08a9-4fca-9c15-37669eec1a5b",
      "name": "Text Generation",
      "categoryId": "9c2d686b-dc1c-4ed7-bf77-2cbe83efde08"
    },
    {
      "id": "a86b4cf2-835a-4943-b679-5a50bf9a3995",
      "name": "Sequence Modeling",
      "categoryId": "9c2d686b-dc1c-4ed7-bf77-2cbe83efde08"
    },
    {
      "id": "94865aec-f25c-43f8-8022-eebd19226f47",
      "name": "Probabilistic Models",
      "categoryId": "9c2d686b-dc1c-4ed7-bf77-2cbe83efde08"
    },
    {
      "id": "e012e44e-75ae-4dbb-821f-25f15131ae75",
      "name": "Language Models",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "c65f8e28-b4d5-4bb2-a26d-b64709d6ca8e",
      "name": "Nlp Models",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "54a55b8b-1947-43e0-986e-6aec946c36b8",
      "name": "Probabilistic Language Models",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "015d982c-366d-4823-af3a-a9d61dc60eb3",
      "name": "Neural Language Models",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "189800e6-acc9-4249-be49-8161680e9981",
      "name": "Generative Models",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "1512fdbc-58e5-413a-85fe-886cf0f5eae9",
      "name": "Probability Distributions",
      "categoryId": "7e3a5556-560d-464a-a3d5-60eeb033a538"
    },
    {
      "id": "67558f98-8ff3-4162-8609-ffed526dfd6f",
      "name": "Continuous Distributions",
      "categoryId": "7e3a5556-560d-464a-a3d5-60eeb033a538"
    },
    {
      "id": "34e3aaf0-7bd1-416d-8c73-91ad7c1654e4",
      "name": "Symmetric Distributions",
      "categoryId": "7e3a5556-560d-464a-a3d5-60eeb033a538"
    },
    {
      "id": "6d66a85d-6d8b-487a-beae-8316a3102775",
      "name": "Central Limit Theorem",
      "categoryId": "7e3a5556-560d-464a-a3d5-60eeb033a538"
    },
    {
      "id": "6da3b7ee-074e-449b-bb59-9f0c5c4127e5",
      "name": "Statistical Modeling",
      "categoryId": "7e3a5556-560d-464a-a3d5-60eeb033a538"
    },
    {
      "id": "65943156-2a6a-4551-9ffa-dc798daa465b",
      "name": "Laplacian Regularization",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "12cd9e10-302e-45d2-bbcc-e24d0b28f761",
      "name": "Manifold Learning",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "84bfe21f-cb18-46df-8d4e-2aff6c652856",
      "name": "Graph-Based Regularization",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "c6eab35e-4b2c-4acd-859d-432c9eaf7564",
      "name": "Smoothness Constraints",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "934c9604-f4b6-451a-bea9-4820e2e73f89",
      "name": "Multimodal Models",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "eb3eae56-6459-4acb-93f1-4c1f5d9bb860",
      "name": "Large Language Models (Llms)",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "b37a3aa3-242c-4a60-9b65-49ab3fa73cf6",
      "name": "Transformer Models",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "4bdd3ae4-6f87-41b3-96d3-c40779279200",
      "name": "Model Scaling",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38"
    },
    {
      "id": "e323ff31-f033-4fcb-8441-720a7d9f7c4d",
      "name": "Regression",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "6ddd0fc7-f1ea-44ab-85ee-e0daeeab88d9",
      "name": "Regularization Techniques",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "8b0e734d-7d86-40a9-a344-394899bfe536",
      "name": "Linear Models",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5"
    },
    {
      "id": "e534835e-3fee-4d3d-9282-ce4e3b7ef22a",
      "name": "Supervised Learning",
      "categoryId": "691a0b1e-82ca-49f5-a362-e61040cc378e"
    },
    {
      "id": "e856a97c-6285-4dd0-9275-f7f25905a46a",
      "name": "Regression Analysis",
      "categoryId": "691a0b1e-82ca-49f5-a362-e61040cc378e"
    },
    {
      "id": "a6ea097c-8df3-4242-bf53-efe27e7a4d94",
      "name": "Regularization Techniques",
      "categoryId": "691a0b1e-82ca-49f5-a362-e61040cc378e"
    },
    {
      "id": "69726424-68c4-496a-979f-cf339a985d59",
      "name": "Linear Models",
      "categoryId": "691a0b1e-82ca-49f5-a362-e61040cc378e"
    },
    {
      "id": "6ff59bfc-0a38-484f-a5c3-bee728be2c5d",
      "name": "Penalized Regression",
      "categoryId": "691a0b1e-82ca-49f5-a362-e61040cc378e"
    }
  ],
  "terms": [
    {
      "id": "f23d2c79-8d37-4d79-a5ae-f254ec17fe10",
      "name": "Characteristic Function",
      "definition": "A characteristic function is a fundamental concept in probability theory and statistics that uniquely characterizes the probability distribution of a random variable. Formally, it is defined as the expected value of e^{itX}, where X is a random variable, t is a real number, and i is the imaginary unit. The characteristic function encapsulates all the information about the distribution of X and serves as a powerful tool for analyzing probability distributions, deriving properties, and proving limit theorems.",
      "categoryId": "ab2b4a90-f0cf-402d-a798-fafcc2dd2ca7",
      "subcategoryIds": [
        "d2e4b2d4-caef-43da-af6a-2c16ac20ea09",
        "545516f1-70dc-4138-87e5-16978ca55d25",
        "4cb739f5-85c2-4cc3-b297-2cdb62ffd854",
        "219a9ecc-6d6f-40c9-9e09-d72995f513af",
        "4c724cc5-801c-4952-a403-b3d96d59fcf3"
      ]
    },
    {
      "id": "812f6ad9-3382-4993-822f-780b3735f10c",
      "name": "Chebyshev Distance",
      "definition": "Chebyshev Distance, also known as L-infinity norm or maximum metric, is a measure of distance between two points in a multidimensional space. It calculates the greatest difference across any single coordinate dimension between the two points, effectively capturing the maximum deviation. Mathematically, for two points p and q in n-dimensional space, Chebyshev distance is defined as the maximum absolute difference among their corresponding components: D(p, q) = max(|p_i - q_i|) for i in 1 to n.",
      "categoryId": "8dc40527-6f46-4a1b-9ab1-5905adcdcc6d",
      "subcategoryIds": [
        "ab975c15-7fa1-4454-ab17-bf34be3bb416",
        "d36ed93d-5b22-4586-88d3-7226607de7cc",
        "a87e80c0-f57d-49a3-832f-8c6b4ca0ec96",
        "4c77a526-7edd-4fcf-b9e6-e185c35746f0",
        "e6a1815f-8e1e-4703-84f1-9f4ed81b4fe1"
      ]
    },
    {
      "id": "f9ef3f78-2e6e-45db-b5c6-4549885b6194",
      "name": "Chebyshev Networks",
      "definition": "Chebyshev Networks are a class of neural network architectures that utilize Chebyshev polynomials as activation functions or basis functions. These networks leverage properties of Chebyshev polynomials to approximate complex functions efficiently, offering advantages in spectral approximation, stability, and convergence. They are often employed in scenarios requiring high-precision function approximation and can be adapted for various regression and classification tasks within the field of machine learning.",
      "categoryId": "2bd8b40c-79f5-4b84-813f-a70ebe2d5360",
      "subcategoryIds": [
        "cd922b08-7af3-40f6-b0c5-b94541a988ce",
        "bc7c410c-09fd-4a31-8490-8c24f32c7f59",
        "dbd3d0e0-9f23-4c24-b9bf-066a56da4879",
        "11dde0a2-af7f-49bb-b929-0c96731170e7",
        "92f91748-6064-4387-97ad-0db5f17a2327"
      ]
    },
    {
      "id": "6727878b-dbca-4bde-af97-d3cc24639d83",
      "name": "Chebyshev Polynomial Networks",
      "definition": "Chebyshev Polynomial Networks are a class of neural network architectures that leverage Chebyshev polynomials to perform function approximation and spectral filtering within the network. They are designed to efficiently approximate complex functions by exploiting the mathematical properties of Chebyshev polynomials, which are a sequence of orthogonal polynomials with remarkable approximation capabilities. These networks incorporate polynomial expansions directly into their architecture, allowing for effective modeling of non-linear relationships while maintaining computational efficiency and stability.",
      "categoryId": "2bd8b40c-79f5-4b84-813f-a70ebe2d5360",
      "subcategoryIds": [
        "bc7c410c-09fd-4a31-8490-8c24f32c7f59",
        "92f91748-6064-4387-97ad-0db5f17a2327",
        "fd1b802d-75aa-4296-ae3a-45c2aa62fbd7",
        "a1bbc4a4-1eba-48e0-a1b6-f88a22c8b336",
        "11dde0a2-af7f-49bb-b929-0c96731170e7"
      ]
    },
    {
      "id": "77673d91-576b-42ad-9102-cc6a3cd04877",
      "name": "Chebyshev Polynomials in Neural Networks",
      "definition": "Chebyshev polynomials are a sequence of orthogonal polynomials that arise in approximation theory and numerical analysis. In the context of neural networks, Chebyshev polynomials are used as activation functions or as basis functions within neural network architectures to improve approximation capabilities, enhance numerical stability, and facilitate spectral methods. Their properties allow neural networks to approximate complex functions efficiently by leveraging the polynomials' recurrence relations and orthogonality properties.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "fd0c198f-cb24-4cd1-8807-3629dc3127ae",
        "47b6ebd7-6eb8-43ee-8d6d-9db29b9b2cc8",
        "570304bd-837d-4b58-9ca2-01a0bcbe652a",
        "c49cb07f-1341-4d2c-b56f-0545a1d35140",
        "7f19d104-aea0-49bb-a63e-fb2280c13428"
      ]
    },
    {
      "id": "0905fb68-2eee-4132-934d-037c83d825c0",
      "name": "Check-pointing in Training",
      "definition": "Check-pointing in training refers to the process of saving the current state of a machine learning model during the training process. This typically involves storing the model's parameters, optimizer states, and other relevant information at specific intervals or after significant events. These saved states, known as checkpoints, can be used to resume training from that point in case of interruptions, or for later evaluation and model deployment. Check-pointing is an essential technique to prevent loss of progress, enable experimentation with different training strategies, and facilitate model versioning.",
      "categoryId": null,
      "subcategoryIds": []
    },
    {
      "id": "534acde1-cb60-48ef-9fcd-5487a8fc1338",
      "name": "Checkerboard Artifacts",
      "definition": "Checkerboard artifacts are visual distortions observed in images generated or processed by certain AI and machine learning models, especially in the context of image synthesis, super-resolution, and generative adversarial networks (GANs). These artifacts manifest as a regular grid-like pattern resembling a checkerboard, often leading to undesirable visual irregularities such as blockiness, uneven textures, or unnatural repetitive patterns that detract from the realism and quality of the generated images.",
      "categoryId": "f001a980-b036-4a8b-a7b0-290e7b1c9a77",
      "subcategoryIds": [
        "334ac660-3840-49c3-a8c9-bfd498fe2e4e"
      ]
    },
    {
      "id": "4ef79d67-cb26-4391-8ea1-558cbfef7af8",
      "name": "checkpoint averaging",
      "definition": "Checkpoint averaging is a technique used during the training of machine learning models, particularly neural networks, where multiple model checkpoints (saved states at different training iterations) are combined, typically by averaging their parameters. This process helps produce a more generalized and stable model by smoothing out fluctuations that occur during the stochastic optimization process. Instead of relying solely on the final checkpoint, checkpoint averaging leverages the collective information from several intermediate models to improve performance and robustness.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "7e64c981-2bac-4a23-8c33-a0696ddc1c4d",
        "5636aaea-61fe-415d-abd2-87b5e9b7b655",
        "dbc0fbd3-b1d5-4468-a0e3-b2bd499baf83",
        "2707ad97-58b5-4ccd-abf8-7de989844ea6",
        "8613a5cc-2f99-4c6c-90a3-0be00fedc16d"
      ]
    },
    {
      "id": "9e9bac64-a495-4aed-a674-de1235dc0e32",
      "name": "Checkpoints",
      "definition": "In the context of AI and machine learning, 'checkpoints' refer to saved states of a model during training, allowing practitioners to pause and resume training, evaluate model performance at different stages, or recover from interruptions. These snapshots capture the model's learned parameters such as weights and biases, enabling continuity and efficient experimentation.",
      "categoryId": null,
      "subcategoryIds": []
    },
    {
      "id": "36715066-666b-4ab5-a2da-06acd7314ada",
      "name": "Cheminformatics",
      "definition": "Cheminformatics, also known as chemoinformatics, is an interdisciplinary field that combines principles of chemistry, computer science, and information technology to store, analyze, model, and visualize chemical data. It involves the application of computational techniques to solve chemical problems, facilitate chemical data management, and accelerate the discovery and development of new compounds, drugs, and materials.",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38",
      "subcategoryIds": [
        "5bb0e07d-d7f8-4723-91d3-d25afacf1e32",
        "8a64fc1b-e9a1-45b6-884c-ae7f670e7ac1",
        "b27afe7e-daf6-41ea-bf97-d19f73568fb7",
        "8a0d95d8-a5d0-4eb9-b8d3-638f2d80174c",
        "e3528470-778f-45e7-9166-4c1b816fc72c"
      ]
    },
    {
      "id": "b3dfce9a-c37a-42f4-b73c-578b3acdebc5",
      "name": "Chi-Square Test",
      "definition": "The Chi-Square Test is a statistical method used to determine whether there is a significant association between two categorical variables. It assesses how well observed data fit the expected distribution under the assumption of independence. Essentially, it compares the observed frequencies in each category with the frequencies expected if there were no association, helping to identify relationships or dependencies within data sets.",
      "categoryId": "a08d705b-8994-4bcf-9c82-17c75c3bc367",
      "subcategoryIds": [
        "6f8d5f15-84b9-45c5-a679-7114d6449648",
        "6bea9bda-1081-474f-8dde-bea4765f6faf",
        "f2a9c10a-7cff-4ec5-8e8e-eb853e32cd0f",
        "b1f01590-aefa-4cf6-bab3-66ac3bc5e7bb",
        "b4455a4f-62b9-4e97-b12b-00e957d0958f"
      ]
    },
    {
      "id": "7592afee-f880-4b12-801a-d8da85d6ddf2",
      "name": "Chi-Square Tests",
      "definition": "Chi-Square Tests are statistical tools used to determine whether there is a significant association between categorical variables or to assess how well an observed distribution fits an expected distribution. These tests evaluate the independence of variables in contingency tables or the goodness-of-fit of an observed frequency distribution against a theoretical model. They are widely used in data analysis to identify relationships and to validate hypotheses involving categorical data.",
      "categoryId": "a08d705b-8994-4bcf-9c82-17c75c3bc367",
      "subcategoryIds": [
        "6f8d5f15-84b9-45c5-a679-7114d6449648",
        "6bea9bda-1081-474f-8dde-bea4765f6faf",
        "b4455a4f-62b9-4e97-b12b-00e957d0958f",
        "ee69739a-e5c4-4f72-bf51-fbe3f796d401",
        "8f27857e-4e35-4e6b-b821-80c06195bc79"
      ]
    },
    {
      "id": "5af555f2-bc4f-4082-8287-838bd827d2f4",
      "name": "Cholesky Decomposition",
      "definition": "Cholesky Decomposition is a numerical method used in linear algebra for decomposing a symmetric, positive-definite matrix into the product of a lower triangular matrix and its conjugate transpose. Specifically, for a given matrix A, the Cholesky decomposition finds a lower triangular matrix L such that A = LL\u1d57. This technique simplifies solving systems of linear equations, matrix inversion, and covariance matrix operations in various scientific and engineering computations.",
      "categoryId": "306fd1ff-712c-4027-a13a-5f560c4b6b72",
      "subcategoryIds": [
        "0b1e8e79-9477-4dd3-b1c4-51e198f356a1",
        "5c322266-7234-40aa-a99d-fd98d83573f7",
        "6ba00efa-1dec-4590-82bc-dfa2c7ae1ec4",
        "787bb9f6-964e-4697-9344-96fd4a0c491f",
        "082f60c7-b476-4711-8bf9-5f9d6a9cb637"
      ]
    },
    {
      "id": "0345d2ce-8a40-4ed8-a660-edff7f290bb2",
      "name": "Cholesky Decomposition in Optimization",
      "definition": "Cholesky Decomposition is a numerical method used to factorize a symmetric, positive-definite matrix into the product of a lower triangular matrix and its transpose. In the context of optimization, it is often employed to efficiently solve systems of linear equations, perform matrix inversions, and compute covariance matrices, thereby facilitating many algorithms in machine learning and statistical modeling.",
      "categoryId": "c2c2f0d1-ca4f-4b23-9086-ee7ab14ad5a6",
      "subcategoryIds": [
        "8a1e5bef-f7c8-4ec0-ab82-d05a41e9bd35",
        "66a76614-5d7f-43e9-ab91-f6875ef6de6c",
        "2e7f8b58-c388-4057-8a6c-5700530365f5",
        "07656591-0f7f-4666-98c3-d1369af777df",
        "3fc3ed66-56e5-42f2-860c-f2e8a8175286"
      ]
    },
    {
      "id": "2edbcde3-7468-4d87-9e55-ec11d8eecc27",
      "name": "Chromatic Aberration Correction",
      "definition": "Chromatic Aberration Correction refers to the process of identifying and mitigating color fringing and blurring artifacts in digital images and optical systems caused by the dispersion of light through lenses. This correction aims to enhance image clarity, color fidelity, and overall visual quality by compensating for the chromatic aberration that occurs when different wavelengths of light focus at different points in the optical path.",
      "categoryId": "f697ffdc-db4e-4058-938b-63083e5204a2",
      "subcategoryIds": [
        "9c4da778-1438-4568-aa80-e1d203b4542b",
        "85d9a1e3-b1dc-44ca-aed6-0998d68289ac",
        "adf52a76-db88-4513-a594-2151e2b0f481",
        "1f816b49-16d2-4073-9574-77afe5e81035",
        "4b2595be-12c0-4967-a852-4c0c5fc573cf"
      ]
    },
    {
      "id": "34c86e10-5380-42ea-a792-0f38718512b7",
      "name": "Chung\u2013Lu Model",
      "definition": "The Chung\u2013Lu Model is a random graph generation model used in network science to produce networks with a specified degree distribution. It falls under the category of inhomogeneous random graphs, where the probability of an edge existing between two nodes depends on assigned weights or propensities related to each node. This model is particularly useful for modeling complex networks such as social networks, biological networks, and information networks that exhibit heterogeneous degree distributions.",
      "categoryId": "0f9a17f6-01ac-468e-a0ce-db0dbd086923",
      "subcategoryIds": [
        "55349f35-ebc0-4f80-b37c-a1e0d31e563d",
        "a3ffa0fa-b300-46f4-8e0e-dadcce99d935",
        "00bf7964-56cd-4075-bc76-de676f6b1fa2",
        "b7d1bbe8-5e67-47de-b733-bef11905fdcd",
        "c5b77f86-9585-4cfa-9ad1-594612dd3436"
      ]
    },
    {
      "id": "f1a5ac36-161a-4bc7-958e-ac6a1839b586",
      "name": "Chunking",
      "definition": "Chunking in the context of AI and machine learning refers to the process of dividing data, sequences, or information into smaller, manageable, and meaningful segments called 'chunks.' This technique is used to simplify complex data, improve learning efficiency, and enhance the interpretability of models. In neural networks, especially in natural language processing (NLP) and speech recognition, chunking often involves segmenting continuous data streams into discrete units for better processing.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "ea7f2084-465d-48fc-b419-f08939b79149",
        "c74120e9-9918-40c5-abc5-d5059bb9634d",
        "34480a2f-e650-4d03-ab95-87e1819c36e9",
        "7d5f3585-5e59-4a8c-94e7-2ae0201dcf85",
        "e9978dd2-7ae2-48a8-b89c-c2b1f5676564"
      ]
    },
    {
      "id": "a8ab2a11-5a4d-471e-abc1-4ef8235d953a",
      "name": "Chunking in NLP",
      "definition": "Chunking in NLP (Natural Language Processing) is a technique used to segment and group words or tokens in a sentence into meaningful units called 'chunks.' These chunks typically represent syntactic constituents such as noun phrases, verb phrases, or other grammatical components. The process involves dividing text into these manageable segments to facilitate further analysis, understanding, or processing tasks like parsing, information extraction, and question answering. Unlike sentence-level parsing, chunking focuses on identifying and labeling these non-overlapping segments without necessarily constructing a complete hierarchical syntactic structure.",
      "categoryId": "954025b2-e0af-4d2f-b77a-ddca1b88361e",
      "subcategoryIds": [
        "6c8d7ad9-f087-46d8-835e-2df926b775ca",
        "fe86b3a7-a8f1-4bb3-8c20-6b365e8c8adc",
        "443cb00f-9681-4c30-ab33-48301f10e597",
        "b1e7f526-326e-4bf5-89b5-966a147b55b2",
        "a4501694-a7d0-4006-a8fa-67bf0cd8389d"
      ]
    },
    {
      "id": "91e3df38-761f-4d6f-93b1-77a1d7612164",
      "name": "CIDEr Score",
      "definition": "The CIDEr (Consensus-based Image Description Evaluation) score is an automated metric used to evaluate the quality of image captions generated by machine learning models. It measures how closely a machine-generated caption aligns with human reference captions by analyzing the consensus among multiple references based on n-gram overlap, emphasizing the relevance and descriptiveness of the language used. CIDEr is designed to address the limitations of earlier metrics such as BLEU and ROUGE, by incorporating semantic importance and human consensus, making it particularly useful in tasks like image captioning and multimodal content description.",
      "categoryId": "8e501b08-14ea-4c6c-bbe8-0e8a0c7dfa17",
      "subcategoryIds": [
        "5b0fafa8-c248-4991-b985-36b42b620c0b",
        "2264027b-1e9d-4a5f-bc65-9d2c9c3bbdae",
        "d3d6ec39-86f5-4d77-b039-39485984ffe0",
        "2844ae80-cb7b-40d7-82e7-27ed39196f34",
        "23719b2a-fec2-493d-8d34-8b14bc18c2d9"
      ]
    },
    {
      "id": "5db6d47f-231b-4296-8500-81e1e512ee69",
      "name": "CIFAR-10 Dataset",
      "definition": "The CIFAR-10 dataset is a widely used benchmark dataset in the field of machine learning and computer vision. It consists of 60,000 32x32 color images divided into 10 distinct classes, with 6,000 images per class. The dataset is split into 50,000 training images and 10,000 test images, providing a foundation for developing and evaluating image classification algorithms. CIFAR-10 is designed to challenge models with its variety and complexity of images, making it a popular choice for assessing the performance of neural networks and other image recognition methods.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "251eea71-c9d3-4ee5-8f66-953f9788fd1d",
        "4ed40284-5364-4874-bb2d-3818aa4963dc",
        "9dc72b70-4fa6-46fa-a602-347ddb342454",
        "216f146d-1fe6-4ac0-8732-9833861d5a57",
        "e20ed8d3-19c3-46a2-ade6-a3dc8924b5d0"
      ]
    },
    {
      "id": "b738057a-eade-4f42-b8a9-c0b87d93a26c",
      "name": "CIFAR-100 Dataset",
      "definition": "The CIFAR-100 Dataset is a widely used benchmark dataset in the field of machine learning and computer vision research. It consists of 60,000 color images divided into 100 different classes, with 600 images per class. The dataset is split into 50,000 training images and 10,000 test images. Each image is of size 32x32 pixels and has a corresponding label indicating its class. The dataset is designed to facilitate the development and evaluation of image classification algorithms, providing a challenging yet manageable dataset due to its diversity and complexity.",
      "categoryId": "f697ffdc-db4e-4058-938b-63083e5204a2",
      "subcategoryIds": [
        "43d73341-07fe-428e-bace-0583976863ea",
        "d9109fbb-bc7b-4cca-ae56-d7551579fb83",
        "a25b29f5-3ad4-429a-ad2e-3de3dacd73e0",
        "fb0eadef-30cc-44fc-a68c-0f2561ce08eb",
        "1328d458-382c-413d-b08a-16b2e211ca8b"
      ]
    },
    {
      "id": "c6214a8c-4142-40fc-967f-66e989b59fcf",
      "name": "CIL (Class Incremental Learning)",
      "definition": "Class Incremental Learning (CIL) is a subset of continual learning where a model learns to recognize new classes over time without forgetting previously learned classes. It involves sequentially updating a classifier with new class data while maintaining high accuracy on earlier classes, effectively mimicking human-like learning abilities. CIL aims to address the challenges of dynamic environments where data and class distributions evolve, enabling AI systems to adapt incrementally rather than requiring retraining from scratch.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "692a8fa6-39cc-4756-a76f-b7840702c715",
        "9d42691b-51f6-4ca9-96e1-d7ed612ed2ff",
        "4b36b619-eb41-481d-8e96-3f6b602bd338",
        "18ca3eb3-091e-420e-af0d-819e0f08abd4",
        "8b1a6ba6-c3c7-4571-8cd6-a7434ef9708e"
      ]
    },
    {
      "id": "df452d66-e8dc-4118-9bc9-4d2a95917a7e",
      "name": "Circuit Analysis",
      "definition": "Circuit Analysis refers to the process of systematically understanding and evaluating electrical circuits to determine the behavior of current, voltage, and power within the network. It involves applying fundamental electrical principles and mathematical techniques to analyze how circuits respond under various conditions, enabling engineers and scientists to design, troubleshoot, and optimize electronic systems and devices.",
      "categoryId": "32ecb9c6-c9a0-4b57-b94e-d5e703a0388d",
      "subcategoryIds": [
        "2f835b4c-b0b0-4725-a22b-93965b2b6c92",
        "d7d8cf2a-7e5e-456a-bf49-2e032c437b04",
        "16550a10-b8be-4cd8-ad36-860db478ebfc",
        "1e14f82f-0700-4a6f-93e2-13b6b0241f80",
        "4c19c1da-282e-4037-877e-633fecf8a631"
      ]
    },
    {
      "id": "e34ba517-c7d6-46bb-846b-389dd48cc18e",
      "name": "Circuit Complexity",
      "definition": "Circuit complexity is a branch of computational complexity theory that focuses on quantifying the minimum resources required to compute a boolean function or perform a computation using logical circuits. It involves analyzing the size, depth, and gate count of combinational and sequential circuits necessary to implement specific functions, providing a measure of the computational difficulty and efficiency of implementing boolean functions in hardware or logical systems.",
      "categoryId": "88458ea2-7ad9-4440-b6c6-dd20ed5c727c",
      "subcategoryIds": [
        "08eb122f-501e-421b-b074-88dda5edde1b",
        "20bc67df-e417-437d-8c90-a1b3d4706d8f",
        "316279ca-160b-4e6c-b25a-0547e6b28d10",
        "98abc211-6969-4e96-9aac-00eb4ab958f0",
        "2af70efa-76de-4ed0-8ccd-84bf6278934e"
      ]
    },
    {
      "id": "50345589-1bdf-4f07-94db-1d00bf4afdc6",
      "name": "Circuit-level Analysis",
      "definition": "Circuit-level Analysis is a fundamental technique used in electronic engineering and computing to examine and understand the behavior of circuits at the individual component and connection level. In the context of AI/ML, it involves analyzing the hardware implementation of AI models, particularly neural networks, by studying the electrical and logical operations within the circuitry that execute these algorithms. This approach allows engineers and researchers to optimize hardware performance, detect faults, improve energy efficiency, and enhance the overall reliability of AI systems.",
      "categoryId": "f59f920d-a73a-4a03-89d5-b1fbef1c4b96",
      "subcategoryIds": [
        "b0f7e4e6-c3fc-40be-8db2-dbc1eec31a5e",
        "286772ee-2957-46ed-95b7-16852f2429e9",
        "35338fc8-4898-4386-8524-ac01bc663dfd",
        "18fd68fc-7d03-400c-a8dd-b1aa1a6b0aff",
        "49e08617-c41f-49dc-a089-be8b555acddb"
      ]
    },
    {
      "id": "a5911c86-d31a-463e-9bdc-31cba0e33b81",
      "name": "Circular Convolution",
      "definition": "Circular convolution is a mathematical operation used to combine two finite sequences (or signals) to produce a third sequence, representing their combined effect under periodic or cyclic conditions. Unlike linear convolution, which considers signals to be of infinite length or zero-padded outside their original domain, circular convolution assumes the signals are periodic with a fixed period, effectively wrapping around at the boundaries. This operation is fundamental in digital signal processing, especially in contexts involving discrete Fourier transforms (DFT) and fast Fourier transforms (FFT), where it enables efficient computation of convolutions through frequency domain multiplication.",
      "categoryId": "da0a70ec-2846-4a5b-96d2-41f9070d7d56",
      "subcategoryIds": [
        "5ae781b4-c2b4-4956-ae4d-d32b00da73f4",
        "a180f2df-b653-43fb-b6dc-dccd0eb6bd54",
        "d010c5d1-8e0d-43a1-aeee-fc055adfd97f",
        "104f6f71-2444-4a5d-b82a-3b1f01bf591f",
        "d7a45f53-2016-4d8e-91d3-12267589de84"
      ]
    },
    {
      "id": "d6bb0b69-e7eb-4ac9-84c9-28195aad7aae",
      "name": "Circular Padding",
      "definition": "Circular padding is a padding technique used in convolutional neural networks (CNNs) where the input data is padded by wrapping around its own boundary elements, creating a seamless, circular extension of the original data. This method ensures that the convolutional kernels can process all regions of the input without losing information at the edges, effectively treating the data as if it were on a continuous loop.",
      "categoryId": "8d35f4cf-19b3-4944-a323-473abaa3eb92",
      "subcategoryIds": [
        "9cf61226-99e7-4f7e-ab55-8de6878d22b8",
        "0afcc4cb-d3b3-4f6b-97bd-5fc65c20a472",
        "a32537db-0dbe-4a01-ac00-1b49aba9a009",
        "91df24de-c9ef-4757-8bc2-62a7e91b70d2",
        "5c2d6fb8-cea9-4780-b55b-5799aa573569"
      ]
    },
    {
      "id": "56ef022b-6a39-44ae-b748-b0b588cdf408",
      "name": "Circular Padding in CNNs",
      "definition": "Circular Padding in Convolutional Neural Networks (CNNs) is a padding technique where the input feature map is extended by wrapping around its edges, allowing the values from one edge to be used to pad the opposite edge. Unlike zero-padding, which adds zeros around the borders, circular padding treats the input as if it is connected in a loop, creating a seamless wrap-around effect. This approach helps preserve the continuity of features at the borders, which can be particularly beneficial for tasks requiring seamless edge handling, such as in signal processing or image analysis where boundary artifacts need to be minimized.",
      "categoryId": "8d35f4cf-19b3-4944-a323-473abaa3eb92",
      "subcategoryIds": [
        "e45e0e74-efcc-4174-942b-072f702387e3",
        "0afcc4cb-d3b3-4f6b-97bd-5fc65c20a472",
        "820087aa-779b-4dd9-9189-5ee55ebc05d0",
        "ec87e0b9-0abe-4590-a1c4-2ae216bd27d0",
        "1d7e05e7-bafc-4d76-9b49-7399e7682d0e"
      ]
    },
    {
      "id": "31d0620e-a898-4c20-9392-12c5e36cf836",
      "name": "Class Activation Mapping (CAM)",
      "definition": "Class Activation Mapping (CAM) is a visualization technique used in convolutional neural networks (CNNs) to identify the regions of an input image that are most influential in the model's decision-making process. CAM generates heatmaps indicating the areas within an image that contribute significantly to the predicted class, thereby providing interpretability and insight into the model's focus during classification tasks.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "4ed40284-5364-4874-bb2d-3818aa4963dc",
        "e20ed8d3-19c3-46a2-ade6-a3dc8924b5d0",
        "cae1b750-f2ad-4c75-a518-8d3a436f02be",
        "ea3cb06c-3503-47c9-9c61-95eb5031b5ba",
        "264662e6-620c-480f-b678-d94764d291ce"
      ]
    },
    {
      "id": "e997393c-05e9-419c-a967-6de531260f76",
      "name": "Class Activation Maps (CAM)",
      "definition": "Class Activation Maps (CAM) are visualization techniques used in convolutional neural networks (CNNs) to identify the regions in an input image that are most relevant for a specific class prediction. CAMs generate heatmaps that highlight these discriminative areas, providing insights into how the model interprets visual data and making it easier to understand model decisions at a localized level.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "7636d23d-181c-4c10-9dd9-65e0781c4cd2",
        "d244fcef-53f6-4a98-846a-d555018d0a1a",
        "084ac074-a369-44e5-ab57-2f74bc28eb09",
        "251eea71-c9d3-4ee5-8f66-953f9788fd1d",
        "7ad9c81f-c128-4d79-ace1-c4d071d3937b"
      ]
    },
    {
      "id": "1f19b2dd-9b1f-4a53-aa89-c9a06fef11a1",
      "name": "Class Balanced Sampling",
      "definition": "Class Balanced Sampling is a data sampling technique used in machine learning to address class imbalance within a dataset. It involves selecting samples from each class in such a way that each class is equally represented during training, regardless of their original frequencies. This approach helps in reducing bias toward majority classes and improving the model\u2019s ability to learn minority class patterns, ultimately leading to more balanced and fair predictions.",
      "categoryId": null,
      "subcategoryIds": []
    },
    {
      "id": "dc4c1f72-77aa-4fa4-817b-797e3891c7d8",
      "name": "Class Imbalance",
      "definition": "Class imbalance refers to a situation in machine learning classification tasks where the distribution of classes within a dataset is uneven, with some classes significantly underrepresented compared to others. This imbalance can adversely affect the performance of models by causing them to be biased towards the majority classes, often leading to poor recognition or prediction accuracy for the minority classes. Addressing class imbalance is critical for developing robust and reliable AI systems, especially in applications where identifying rare events or minority class instances is vital, such as fraud detection, medical diagnosis, and anomaly detection.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "3ffd7102-687d-4707-a2b6-74461b12c371",
        "b753368c-4ba7-4b7e-8a2e-699872c32076",
        "18bb6fe6-7aa0-44fd-9970-dec1163c6533",
        "11044d60-0243-4f56-85c9-a4d5b5edc1da",
        "256ff9ec-dd7d-452b-856f-ec895fdda9a9"
      ]
    },
    {
      "id": "b8ee45a1-f9e0-4a97-b3e8-d092c7baae00",
      "name": "Class Weighting",
      "definition": "Class weighting is a technique used in machine learning to address class imbalance in classification tasks. It involves assigning different weights to different classes during model training, typically giving higher weights to underrepresented classes and lower weights to overrepresented ones. This approach helps the model pay more attention to minority classes, improving overall performance and fairness in imbalanced datasets.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "717e5f5f-d1ec-47fe-ba34-0face182e973",
        "11044d60-0243-4f56-85c9-a4d5b5edc1da",
        "7e64c981-2bac-4a23-8c33-a0696ddc1c4d",
        "b06e68ad-6a06-4f80-b0ea-65be6b75265e",
        "d9f0fa65-c0ec-40a4-a414-fa8bcca8b81f"
      ]
    },
    {
      "id": "d1051762-b701-4ca5-bdb6-2836d34feaec",
      "name": "Class-balanced Loss",
      "definition": "Class-balanced Loss is a loss function designed to mitigate the challenges posed by imbalanced datasets in machine learning. It emphasizes balancing the contribution of each class to the loss, ensuring that minority classes receive appropriate attention during training. This approach helps models perform better across all classes, especially when certain classes are underrepresented, by adjusting the loss computation to counteract class imbalance effects.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "c1864dd9-1cf1-4124-81cf-55ceb25b72fa",
        "c89f17ea-9f53-4364-8224-740b4849dbbc",
        "07d2d46f-f247-4cc5-80e3-aea381e010b8",
        "9d2e9b86-37a6-4f53-afc7-2c22f2d00ab6",
        "e20ed8d3-19c3-46a2-ade6-a3dc8924b5d0"
      ]
    },
    {
      "id": "15afb21b-17b7-42cb-8a29-dace1e8f4475",
      "name": "class-balanced sampling",
      "definition": "Class-balanced sampling is a technique used in machine learning to address class imbalance within datasets. It involves adjusting the probability of selecting samples from different classes during training to ensure that each class is adequately represented, thereby preventing the model from becoming biased towards the majority class. This can be achieved through methods such as oversampling minority classes, undersampling majority classes, or applying weighted sampling strategies. The goal is to improve model performance, especially in tasks where certain classes are underrepresented, by providing a more balanced training process.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "9d2e9b86-37a6-4f53-afc7-2c22f2d00ab6",
        "08856b83-5c02-471d-8709-ed1895cee178",
        "3ffd7102-687d-4707-a2b6-74461b12c371",
        "b50f5366-8da8-4b3a-ab76-48a0514acc87",
        "717e5f5f-d1ec-47fe-ba34-0face182e973"
      ]
    },
    {
      "id": "39660d4a-820a-4cd5-b09f-2cec3bb4afd3",
      "name": "Class-weighted Loss",
      "definition": "Class-weighted Loss is a technique used in machine learning to address class imbalance during model training. It involves assigning different weights to different classes in the loss function, thereby increasing the penalty for misclassifying minority classes and helping the model pay more attention to less frequent classes. This approach modifies the standard loss function to incorporate class-specific weights, aiming to improve overall model performance, especially when dealing with skewed datasets.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "717e5f5f-d1ec-47fe-ba34-0face182e973",
        "c89f17ea-9f53-4364-8224-740b4849dbbc",
        "3ffd7102-687d-4707-a2b6-74461b12c371",
        "7e64c981-2bac-4a23-8c33-a0696ddc1c4d",
        "b06e68ad-6a06-4f80-b0ea-65be6b75265e"
      ]
    },
    {
      "id": "a58b10fa-d269-4bfb-a758-015b86e3df14",
      "name": "Classification",
      "definition": "Classification is a supervised machine learning technique where an algorithm learns to categorize data points into predefined classes or labels based on input features. It involves training a model on labeled datasets, enabling it to assign new, unseen data to one of the established categories. The primary goal of classification is to accurately predict the class label for each data instance, facilitating decision-making processes across various applications.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "5d38820d-77b5-4989-bb38-b887e8eb7007",
        "717e5f5f-d1ec-47fe-ba34-0face182e973",
        "817e217f-cbaa-4096-8740-bcddc032fcab",
        "5f27f14b-8e7a-475d-99d7-6628cdcde180",
        "d825ceb3-ee90-40b9-8e37-ca716f279c3d"
      ]
    },
    {
      "id": "08c347fa-19e9-4929-abf2-797540658c88",
      "name": "Classification and Regression Trees (CART)",
      "definition": "Classification and Regression Trees (CART) is a decision tree algorithm used for supervised machine learning tasks, primarily classification and regression. It constructs binary trees by splitting data based on feature values, aiming to improve predictive accuracy. The CART algorithm produces a tree structure where internal nodes represent feature-based splits, and leaf nodes represent output predictions, enabling easy interpretation of the model's decision-making process.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "717e5f5f-d1ec-47fe-ba34-0face182e973",
        "3dbf1efc-9922-4389-8c81-c099b7201134",
        "5d38820d-77b5-4989-bb38-b887e8eb7007",
        "d8a0f87a-5f11-4af7-876a-b64f3cba6ba7",
        "1298f14e-a65f-4f0b-8d3e-ca29048786a3"
      ]
    },
    {
      "id": "3d0ed3a0-772b-4aea-b59e-b7dc521b7bc7",
      "name": "classification evaluation",
      "definition": "Classification evaluation refers to the process of assessing the performance of a classification model, which is designed to predict categorical labels for data instances. It involves using various metrics and methods to determine how accurately and efficiently the model assigns inputs to the correct classes, thereby enabling practitioners to understand the model's effectiveness and identify areas for improvement.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "717e5f5f-d1ec-47fe-ba34-0face182e973",
        "b0f89030-4291-47f6-89b7-454435c911e4",
        "34d750d7-f98f-40b2-8d52-cb8ef8635175",
        "6c0debb8-acc8-4744-929e-575ccfa004b7",
        "5b90f45e-faff-404e-8571-e25ae87e686e"
      ]
    },
    {
      "id": "edbe96d2-60cf-498b-a746-6049a34335f2",
      "name": "Classification Problem",
      "definition": "A Classification Problem in machine learning involves categorizing data points into predefined classes or categories based on their features. The goal is for the model to learn patterns from labeled training data so that it can predict the class labels of new, unseen data accurately. This type of problem is fundamental in environments where decision-making is based on categorization, such as spam detection, image recognition, and medical diagnosis.",
      "categoryId": "970cc6d8-f2a1-4be1-b044-4044a17fc1dc",
      "subcategoryIds": [
        "668c1527-07f0-472b-bccc-ac93e24556d4",
        "90bc9c42-5130-4e4e-b885-a6a4ce1491a0",
        "0b7ac157-8b35-4fe8-b408-eb9ea2348185",
        "709f19cc-b12b-48f6-89c3-d19c43458c1b",
        "b7c9b09d-a3d1-4a1e-819e-cee9245fd6ff"
      ]
    },
    {
      "id": "ce3cb10f-a377-4bb0-83b9-bd11aefe2601",
      "name": "classification report",
      "definition": "A classification report is a comprehensive evaluation tool in machine learning that provides detailed metrics to assess the performance of a classification model. It summarizes key performance indicators such as precision, recall, F1-score, and support for each class in a classification task, offering insights into how well the model distinguishes between different categories. Typically generated after predictions are made on test data, the classification report helps practitioners understand the strengths and weaknesses of their models in terms of class-wise performance.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "72a3d8b2-e0f5-4122-9e9b-8fb9ea5d9225",
        "2705f271-43ae-48b3-9eaf-1f213cf8b96b",
        "b0f89030-4291-47f6-89b7-454435c911e4",
        "5b90f45e-faff-404e-8571-e25ae87e686e",
        "6c9380ab-67fe-4fff-afe2-9a4119cf52c0"
      ]
    },
    {
      "id": "2d7fb1e6-fa23-4253-a7ca-f90efebfac1e",
      "name": "Classifier Chains",
      "definition": "Classifier Chains are a method used in multi-label classification tasks where multiple labels are predicted simultaneously for a given instance. This technique involves chaining individual binary classifiers, each responsible for predicting a specific label, with each classifier taking into account the predictions of previous classifiers in the chain. The goal is to exploit label correlations and interdependencies, improving overall classification accuracy in multi-label scenarios.",
      "categoryId": "a1c2ec89-ddcf-4fff-ad43-622a5b33df97",
      "subcategoryIds": [
        "3e4a915d-b8ae-494f-8150-aeb6da71a240",
        "d174ebfd-143e-4419-94f6-11d9983b0713",
        "83fa04ef-a1d1-4c8f-b25b-bf0be370022b",
        "6ed5771f-dbf7-4364-9a30-d582a7785ecc",
        "77544135-c878-45eb-899d-7473fe6459f1"
      ]
    },
    {
      "id": "722e7b10-fa93-4673-bd38-2bdefdb3a1a7",
      "name": "Classifier-Free Guidance",
      "definition": "Classifier-Free Guidance is a technique employed in generative models\u2014particularly in tasks like image synthesis and text generation\u2014that enhances the quality and diversity of generated outputs without relying on explicit classifier models. Instead of using an external classifier to steer the generation process, this approach integrates guidance directly into the model's sampling or inference procedure, allowing the model to produce high-fidelity results that adhere to desired attributes or prompts. It leverages learned, conditional information within the generative model itself, enabling more flexible and efficient control over the output while reducing dependence on separate classification components.",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d",
      "subcategoryIds": [
        "6ec3302a-53e8-4535-8793-f506d2deaa77",
        "2af107aa-a52f-43ff-9ba5-9bf19ee791d0",
        "0a7b29b7-bbf9-487c-b28c-85f189713da6",
        "6b702b69-beb3-45a1-ae5c-2c1a51d7565b",
        "695f5f16-f48f-492e-9185-cc52e11794cc"
      ]
    },
    {
      "id": "466c2531-e491-4024-a686-41c2814baeac",
      "name": "Claude Security Impact in Sentiment Analysis",
      "definition": "Claude security impact in sentiment analysis refers to the potential vulnerabilities, risks, and ethical considerations associated with the use of the Claude AI model (developed by Anthropic) when analyzing and interpreting sentiment data. This impact encompasses how the deployment of Claude can influence user privacy, data security, bias propagation, and the accuracy of sentiment detection, which in turn affects decision-making processes based on sentiment insights.",
      "categoryId": "f3b96f41-4969-4c65-adc2-feb6e1ab6e95",
      "subcategoryIds": [
        "914761b2-8b8a-4562-b5ea-e8cd9edde26b",
        "310eead7-8775-44fe-85d8-15b1b2e0034f",
        "99b0b1cb-6ae6-4304-a466-42f2b80bbc25",
        "73b4cf3b-943c-41f6-b9d0-51abe43f31ea",
        "b3d7c694-3f74-4088-9ca6-fadd9b89b8f4"
      ]
    },
    {
      "id": "8df5ae3f-1638-4297-9d9e-32a7867a43d0",
      "name": "Clausius-Clapeyron Relation in AI Thermodynamics",
      "definition": "The Clausius-Clapeyron relation is a fundamental thermodynamic equation that describes the phase transition between two states of matter, typically relating temperature and pressure during processes such as vaporization, condensation, sublimation, or melting. In the context of AI thermodynamics, this relation provides insights into how energy, entropy, and phase stability interact within models that emulate or simulate thermodynamic behaviors, often in the pursuit of optimizing energy-efficient AI hardware or understanding thermodynamic-inspired training algorithms.",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1",
      "subcategoryIds": [
        "9106d622-1204-44d8-9fa5-d7cb1cf38140",
        "383b4cee-7c07-44f4-997f-7f7b156e17e4",
        "b1152ef6-31f6-45d3-aab4-37596b34a65e",
        "a1342359-391e-49cb-8beb-2b141fcff21b",
        "e4b350b5-97b8-4e17-ba0e-08dda1cef0e1"
      ]
    },
    {
      "id": "5545ec33-ffae-491b-9e3f-33e1d5d7130d",
      "name": "ClearML",
      "definition": "ClearML is an open-source platform designed to facilitate end-to-end machine learning workflows, encompassing experiment management, orchestration, and deployment. It provides tools for tracking, managing, and automating AI/ML projects, enabling data scientists and engineers to streamline development, collaboration, and reproducibility of models within a unified environment. By integrating various components such as experiment tracking, model versioning, and pipeline automation, ClearML aims to enhance efficiency and transparency in machine learning operations.",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38",
      "subcategoryIds": [
        "c436de57-4333-47b6-bfee-02aa25d7fbb7",
        "fc36f5e7-1074-4d81-a41b-f5b8f3522221",
        "923d8dcd-ccdf-4e8e-8225-da3538ae2371",
        "d1f6602b-5034-4f4c-acff-7bf5016d4671",
        "5c42aa78-e1ea-4584-80e5-c4eb1c03ea27"
      ]
    },
    {
      "id": "0c1b9036-4ca1-4ce1-8eff-322e9ece8b08",
      "name": "CLIP (Contrastive Language-Image Pretraining)",
      "definition": "CLIP (Contrastive Language-Image Pretraining) is a neural network model developed by OpenAI that learns to connect visual concepts with their corresponding natural language descriptions. By jointly training on large-scale datasets of images and their associated textual captions, CLIP can recognize and retrieve images based on textual queries and generate descriptive captions, effectively bridging the gap between visual perception and language understanding in AI systems.",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38",
      "subcategoryIds": [
        "25bd4f43-ad8c-4ef1-b0d7-d328e7ec949f",
        "89854309-3160-47ce-8cae-070aa916fdc1",
        "d1171b2e-d29b-4445-869e-93b0fc69f8f4",
        "d2ee9f2d-d5ab-4736-8403-0d3b26b68a77",
        "3c126fe9-8e68-416c-a7c3-89cfe38f4759"
      ]
    },
    {
      "id": "761a4aba-0d6d-4927-a6eb-2ddc1c29a91c",
      "name": "CLIP (Contrastive Language\u2013Image Pretraining)",
      "definition": "CLIP (Contrastive Language\u2013Image Pretraining) is an advanced machine learning model developed by OpenAI that is designed to understand and relate visual and textual data. It is trained to connect images and their accompanying descriptive text by learning a shared embedding space, enabling it to perform tasks such as image classification, retrieval, and zero-shot recognition without specific task-specific training. CLIP's architecture combines natural language processing and computer vision techniques, allowing it to interpret complex visual concepts based on language inputs.",
      "categoryId": null,
      "subcategoryIds": []
    },
    {
      "id": "232ff396-371b-4d12-a910-36e3db4044fb",
      "name": "Clipped Gradient",
      "definition": "A clipped gradient refers to a technique in machine learning where the magnitude of the gradient vector is restricted or limited during training. This process, known as gradient clipping, involves setting a threshold and ensuring that the computed gradients do not exceed this value, effectively 'clipping' the gradient to a specified maximum norm or value. This approach helps prevent excessively large updates to model parameters, which can destabilize the training process, especially in models with deep architectures or recurrent neural networks. The primary goal of gradient clipping is to improve training stability and convergence by controlling the scale of weight updates.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "970b0f00-da14-4036-ba1d-94a59f04fc15",
        "22cc01b6-d2d3-4451-9a7d-f63ddbfd3250",
        "4aae74d6-aee2-4aae-994c-39e98b6bf2ad",
        "4f75aab2-6a09-4264-827e-0f3a7d0a0541",
        "e39f7c36-5cbf-4f68-b805-068f6b3d602d"
      ]
    },
    {
      "id": "1aaff30b-0f8f-400e-9ea6-73750bcefc53",
      "name": "Clipping Gradients",
      "definition": "Clipping gradients is a technique used in training neural networks to prevent the explosion of gradient values, which can destabilize the training process. It involves setting a threshold (clip value) and scaling down the gradients for parameters whose gradients exceed this threshold, ensuring they remain within a manageable range. This process helps maintain stable convergence and improves training efficiency, especially in models with deep or recurrent architectures.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "970b0f00-da14-4036-ba1d-94a59f04fc15",
        "4d6b4a0c-8506-4bc4-a598-d397d1d1cb74",
        "3aa6b1ce-f5cc-48db-b9a9-780b6c1a1c82",
        "dbc0fbd3-b1d5-4468-a0e3-b2bd499baf83",
        "e20ed8d3-19c3-46a2-ade6-a3dc8924b5d0"
      ]
    },
    {
      "id": "f054112f-37d2-472c-b1f9-48084f755aa6",
      "name": "Clipping Gradients Techniques",
      "definition": "Clipping gradients is a technique in machine learning used to prevent the problem of exploding gradients during the training of neural networks. It involves limiting or 'clipping' the magnitude of the gradients to a specified maximum value before updating the model parameters. This process helps stabilize training, especially in deep networks or recurrent neural networks, by ensuring that gradients do not become excessively large, which can cause numerical instability and impede convergence.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "22cc01b6-d2d3-4451-9a7d-f63ddbfd3250",
        "9292a572-b0d0-4fbd-b142-28c591b4863f",
        "b99f3671-be24-4a68-bbc0-dba07cbd7d11",
        "970b0f00-da14-4036-ba1d-94a59f04fc15",
        "92da754b-5fdd-436e-91af-374a3c681eaa"
      ]
    },
    {
      "id": "31ef7393-f2b9-41d7-a9d3-744da4873196",
      "name": "Clipping Gradients Techniques Extensions",
      "definition": "Clipping Gradients Techniques Extensions refer to methods used in deep learning to modify or restrict gradient values during the backpropagation process, aiming to improve training stability and model performance. Gradient clipping involves capping the magnitude of gradients to prevent issues such as exploding gradients, which can cause unstable updates and hinder convergence. Extensions of these techniques encompass various methods that adapt or enhance basic gradient clipping to better suit specific architectures, optimize training efficiency, or address unique challenges encountered in complex neural networks.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "970b0f00-da14-4036-ba1d-94a59f04fc15",
        "22cc01b6-d2d3-4451-9a7d-f63ddbfd3250",
        "dbc0fbd3-b1d5-4468-a0e3-b2bd499baf83",
        "4aae74d6-aee2-4aae-994c-39e98b6bf2ad",
        "4f75aab2-6a09-4264-827e-0f3a7d0a0541"
      ]
    },
    {
      "id": "6bdd9df9-6146-47e2-839d-395c38c264f4",
      "name": "Clipping Norms in Gradient Descent",
      "definition": "Clipping norms in gradient descent refer to a regularization technique used to prevent excessively large gradients during the training process of neural networks. This method involves constraining the magnitude of the gradients by scaling them down whenever they exceed a predefined threshold, known as the clipping norm. The primary goal is to stabilize training, improve convergence, and prevent issues such as exploding gradients, which can hinder model performance and training efficiency.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "22cc01b6-d2d3-4451-9a7d-f63ddbfd3250",
        "9292a572-b0d0-4fbd-b142-28c591b4863f",
        "92da754b-5fdd-436e-91af-374a3c681eaa",
        "970b0f00-da14-4036-ba1d-94a59f04fc15",
        "f4482f3e-44c1-492c-9df4-13c294cc0c2c"
      ]
    },
    {
      "id": "e1aa7b94-d919-4700-a2de-d907299b3268",
      "name": "Clique",
      "definition": "In the context of graph theory and network analysis within AI and machine learning, a 'clique' is defined as a subset of nodes in a graph where every pair of nodes is directly connected by an edge. In other words, a clique forms a complete subgraph, meaning all nodes within the subset are mutually adjacent. This concept is used to identify tightly-knit groups within a network, where each member interacts with every other member, highlighting dense regions of connectivity relevant for various analysis tasks.",
      "categoryId": "0f9a17f6-01ac-468e-a0ce-db0dbd086923",
      "subcategoryIds": [
        "55349f35-ebc0-4f80-b37c-a1e0d31e563d",
        "4f73b730-6944-4ecd-811a-d66430e84165",
        "4a975ee8-9a2e-4f4c-bff7-bfbb645d8486",
        "afd1bf86-575d-4a84-983e-7d08a6a48994",
        "520f0016-03d5-4fba-a567-a23c3192ce46"
      ]
    },
    {
      "id": "93037ff8-6028-4cfc-8161-0f281837c298",
      "name": "Closed Frequent Itemsets",
      "definition": "Closed Frequent Itemsets are a specialized concept in the field of data mining and pattern discovery. They refer to itemsets within transactional datasets that are both frequent\u2014appearing in at least a specified minimum number of transactions (support threshold)\u2014and closed, meaning there is no super-set of the itemset with the same support. This ensures that closed frequent itemsets provide a compact, lossless representation of all frequent itemsets, capturing maximum information without redundancy. They serve as a fundamental component for generating association rules and for understanding the underlying structure of transactional data.",
      "categoryId": "f4a166e4-92f8-4e53-bbd2-66c352a23c5e",
      "subcategoryIds": [
        "c2ea442e-e554-4e3d-a8ee-4788e283f06e",
        "fe37749c-3829-4fb1-98e5-e7a6e4ff7299",
        "dd551b09-d032-4ce4-948a-38bdb0469149",
        "37a7534b-d752-42d2-860a-ede59da67447",
        "564f2293-eded-43b7-8422-d772a579b47a"
      ]
    },
    {
      "id": "fc07e000-791e-4d27-9575-9eb3404d8436",
      "name": "Closeness Centrality",
      "definition": "Closeness Centrality is a measure used in network analysis to determine how close a node is to all other nodes within a graph. It quantifies the average shortest path distance from a given node to all other nodes, with higher closeness centrality values indicating nodes that are strategically positioned to quickly reach all others in the network. This metric is particularly useful for identifying influential or central nodes within social, communication, or transportation networks, facilitating the understanding of network efficiency and information flow.",
      "categoryId": "0f9a17f6-01ac-468e-a0ce-db0dbd086923",
      "subcategoryIds": [
        "4a975ee8-9a2e-4f4c-bff7-bfbb645d8486",
        "4eebb21a-3fca-403b-979d-d556dc60e726",
        "55349f35-ebc0-4f80-b37c-a1e0d31e563d",
        "e29e0224-e5bd-4f5d-8600-d3fd20908d36",
        "f67956a4-d648-40a9-95aa-50dff205b07f"
      ]
    },
    {
      "id": "ad4e50a4-e5c6-4547-8d72-ff50c1390a73",
      "name": "CLUSTER (Clustering with Ubiquitous Structural Time-series)",
      "definition": "Clustering with Ubiquitous Structural Time-series (CLUSTER) is an advanced machine learning technique designed to identify inherent groupings within large-scale time-series data by incorporating structural and contextual information. This approach leverages clustering algorithms tailored to handle the complexities of temporal sequences, emphasizing the preservation of temporal patterns and structural features to reveal meaningful patterns across various domains such as finance, healthcare, and IoT systems.",
      "categoryId": "45dc2762-eb9a-41a3-b001-b823adcbf3a4",
      "subcategoryIds": [
        "f212d3fe-bffc-48cc-be70-b5229325fcf7",
        "00f49fe5-04b5-4a82-9e39-df24d1b587b6",
        "55cb78d3-873c-4e9a-8d57-d732cdd87a9c",
        "d3a80b78-9182-4c8f-a8c6-7cd7d1f08013",
        "690879e6-03f4-461c-a964-7323930588a7"
      ]
    },
    {
      "id": "e711d53f-f856-4e31-ae6d-0eab813dedda",
      "name": "Cluster Assumption",
      "definition": "The 'Cluster Assumption' is a fundamental concept in semi-supervised learning, which posits that data points within the same cluster are likely to share the same class label. It suggests that the decision boundary should lie in a low-density region, effectively separating clusters of different classes, thereby enabling classifiers to leverage unlabeled data by assuming that similar data points form coherent groups.",
      "categoryId": "b1801e0d-e24b-4ad2-9e47-20e042487137",
      "subcategoryIds": [
        "6277a764-6509-44a1-9888-3da4f33b0949",
        "85abdbff-4fa9-4802-9a55-94d4a4942e64",
        "f54ea56c-97ca-4539-a8bb-e80ff810d8d0",
        "1bc402c1-c1cd-4a27-b397-6457d209a79e",
        "9ad10329-3eee-4282-9378-0784a59766f6"
      ]
    },
    {
      "id": "1380d775-51a3-4724-addd-df1e46a76924",
      "name": "cluster purity",
      "definition": "Cluster purity is a metric used to evaluate the quality of clustering algorithms by measuring the extent to which each cluster contains data points belonging predominantly to a single class or category. It quantifies how well the clusters correspond to predefined ground-truth labels, providing insight into the homogeneity of the clusters. A higher cluster purity indicates that the clusters are more homogeneous and that the clustering algorithm has effectively distinguished between different groups in the data.",
      "categoryId": "de8842d5-eb45-4c4d-b8f3-15f9a39657f4",
      "subcategoryIds": [
        "14d1ffd3-60c1-4792-b2fc-034df96de84b",
        "9e2a63d4-4859-4523-b7fb-5f050b533191",
        "8e226485-354c-48bb-a4f4-85db71af9034",
        "5bb76676-b0eb-437f-89bf-17520ced1f62",
        "96c2c13d-4e8e-4bce-b7ff-aaa1522445e5"
      ]
    },
    {
      "id": "a2b6bfc4-715d-42cf-be2f-032f7c4728a3",
      "name": "cluster sampling",
      "definition": "Cluster sampling is a statistical sampling technique used to select a subset of data from a population by dividing the entire population into distinct groups, or clusters, and then randomly selecting entire clusters for analysis. Instead of sampling individual data points, this method focuses on sampling whole groups, which simplifies data collection especially when the population is large or geographically dispersed. It is commonly used in survey research, quality control, and data collection processes within AI/ML workflows to efficiently gather representative data for training, testing, and analysis.",
      "categoryId": "a08d705b-8994-4bcf-9c82-17c75c3bc367",
      "subcategoryIds": [
        "f7fbd271-aa14-4525-b7f5-8dd2ed6e3ab3",
        "8e42e36c-af7c-48ad-a60a-3a15dd3efdea",
        "43bb7476-160b-4df6-a8d6-27349ebc0193",
        "b8169f76-041b-454a-a266-fa66cbcc0597",
        "6508d06c-0367-4c18-87f1-d4042ee06edd"
      ]
    },
    {
      "id": "5ff38f07-ac05-4400-acc1-2804b8fdd66f",
      "name": "Clustering",
      "definition": "Clustering is an unsupervised machine learning technique used to group a set of objects or data points into clusters such that those within each cluster are more similar to each other than to those in other clusters. The primary goal of clustering is to discover natural groupings in data without prior labels or classifications, enabling insights into the underlying structure and patterns within the dataset. It is widely used in various applications, including customer segmentation, image analysis, market research, and pattern recognition.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "65ed1888-c776-4246-ab44-c86291e632ea",
        "872bc9d2-f120-4ad5-a406-1b1ca7bf595a",
        "cf92c8a4-a9db-4e72-9f65-9f1ad88c1d3d",
        "7e9ccbae-8f93-4817-83a0-17ae7ce46465",
        "05d4e37f-78ad-4c32-ad2f-ceb141f15292"
      ]
    },
    {
      "id": "2e42fde6-2d8e-42b8-bb91-9bbdd6336607",
      "name": "Clustering Algorithms",
      "definition": "Clustering Algorithms are a category of unsupervised machine learning techniques used to group a set of objects or data points into clusters such that items within the same cluster are more similar to each other than to those in other clusters. The primary goal is to identify inherent structures or patterns in unlabeled data, facilitating insights, segmentation, and exploration without prior knowledge of class labels.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "872bc9d2-f120-4ad5-a406-1b1ca7bf595a",
        "f554b946-f76b-4cd3-a6f2-8db098eddd84",
        "7e9ccbae-8f93-4817-83a0-17ae7ce46465",
        "502909de-6a6d-43d2-93d7-8c58d1680728",
        "cf92c8a4-a9db-4e72-9f65-9f1ad88c1d3d"
      ]
    },
    {
      "id": "adcdc553-28d0-4389-aede-4142c95aeed8",
      "name": "Clustering Algorithms (e.g., K-means, Hierarchical Clustering)",
      "definition": "Clustering algorithms are a class of unsupervised machine learning techniques used to group a set of objects or data points into clusters based on their features and similarities. The goal is to ensure that data points within the same cluster are more similar to each other than to those in other clusters. Popular examples include K-means clustering, which partitions data into a predefined number of clusters by minimizing intra-cluster variance, and Hierarchical Clustering, which builds a hierarchy of clusters either through agglomerative (bottom-up) or divisive (top-down) methods.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "cddbf0ee-82f0-4115-9283-062f8d41dc98",
        "872bc9d2-f120-4ad5-a406-1b1ca7bf595a",
        "cf92c8a4-a9db-4e72-9f65-9f1ad88c1d3d",
        "0978ed21-e721-43dd-8b81-4c0f5116355a",
        "e9978dd2-7ae2-48a8-b89c-c2b1f5676564"
      ]
    },
    {
      "id": "32632e31-d419-4018-ad2a-9472a7919646",
      "name": "Clustering Evaluation Metrics (e.g., silhouette score, Davies-Bouldin index)",
      "definition": "Clustering evaluation metrics are quantitative measures used to assess the quality and effectiveness of clustering algorithms. They help determine how well the data has been grouped into clusters, especially when true labels are unknown. The silhouette score and Davies-Bouldin index are two widely used metrics that provide insights into the cohesion and separation of clusters, enabling comparison between different clustering results and parameter settings.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "09b54e72-5d26-4bb4-becd-05f7da000519",
        "ccbbee09-ead6-4cdf-8721-28cc5dc04e9c",
        "035c51e0-edb7-42cb-9d01-379a5779b628",
        "97d07028-f14a-46b5-8974-54b6b3d960f0",
        "ce344a7b-649e-44be-b0cc-2452ab9ef3e3"
      ]
    },
    {
      "id": "33d93d5c-a910-475f-9674-d972425b34c8",
      "name": "Clustering Stability",
      "definition": "Clustering Stability refers to the consistency of clustering results when the clustering process is applied multiple times under varying conditions, such as different initializations, data perturbations, or parameter settings. It measures how reliably a clustering algorithm can produce similar groupings, indicating the robustness of the identified clusters to changes in data or algorithmic parameters. High stability suggests that the discovered groups are meaningful and not artifacts of random initialization or noise, while low stability may indicate unreliable or unstable clustering outcomes.",
      "categoryId": "de8842d5-eb45-4c4d-b8f3-15f9a39657f4",
      "subcategoryIds": [
        "9e2a63d4-4859-4523-b7fb-5f050b533191",
        "33dfcddf-1428-44c2-87df-b83a244538ee",
        "fd4f4ddb-749f-4ca0-9842-7e52b3f13459",
        "c588d31d-cf4a-4c86-8757-f5aa31fbb286",
        "3cca23ce-f46e-41a9-ba62-ee8c6ba695c0"
      ]
    },
    {
      "id": "920aee2f-ed67-4665-b15e-d93be1c9c1c9",
      "name": "Emotion Generation",
      "definition": "Emotion Generation refers to the process by which artificial intelligence systems are designed to recognize, simulate, or produce human-like emotional responses. It involves leveraging algorithms and models to generate emotions that can influence interactions, decision-making, or content creation within AI systems. This capability aims to enhance human-AI interactions by making them more natural, empathetic, and engaging.",
      "categoryId": null,
      "subcategoryIds": []
    },
    {
      "id": "8bc4ad8c-3701-4180-a1dc-f24709b18e10",
      "name": "Emotion Modeling",
      "definition": "Emotion Modeling in AI/ML refers to the process of designing systems that can recognize, simulate, interpret, or respond to human emotions. It involves creating computational frameworks that can analyze emotional cues, such as facial expressions, vocal tones, physiological signals, or contextual data, to understand emotional states or generate appropriate emotional responses. This field aims to endow machines with the ability to interact more naturally and empathetically with humans, enhancing user experience and enabling applications across diverse domains.",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38",
      "subcategoryIds": [
        "bbe9e149-7005-45b7-bf79-81c097de42d4",
        "e583927d-bcde-452b-83e8-0bb99d5a9045",
        "ae192cae-c5b2-49e1-b082-991d4a3c0d04",
        "7d1ba3c0-cd77-4bcd-b37b-dda4e83bab2f",
        "6557773a-68af-4416-960e-30d522a461c6"
      ]
    },
    {
      "id": "3b1967ec-d2d2-4155-8a7e-782412762bdb",
      "name": "Emotion Recognition",
      "definition": "Emotion Recognition refers to the process by which AI systems identify, interpret, and classify human emotions from various data sources such as facial expressions, voice intonations, body language, and physiological signals. This technology aims to understand human emotional states in real-time or from recorded data, enabling more natural and effective human-computer interactions. It plays a crucial role in applications ranging from customer service to mental health monitoring, facilitating empathetic and context-aware AI systems.",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38",
      "subcategoryIds": [
        "bee1fd9c-1cdb-4259-9ff9-10f37b7ad14c",
        "e583927d-bcde-452b-83e8-0bb99d5a9045",
        "ae192cae-c5b2-49e1-b082-991d4a3c0d04",
        "61108606-142d-427d-88a2-aa27a682bf52",
        "0c7e833d-c171-43ed-8d11-85cf72f9d329"
      ]
    },
    {
      "id": "4fc22d67-d18a-448f-9445-0adb1a06f551",
      "name": "Emotion-aware Machine Learning",
      "definition": "Emotion-aware Machine Learning refers to a subset of artificial intelligence systems designed to detect, interpret, and respond to human emotions. These systems utilize various data inputs such as facial expressions, voice tone, physiological signals, and textual cues to understand emotional states. The goal is to enhance human-computer interaction by enabling machines to recognize emotional context and adapt their responses accordingly, thereby creating more empathetic and effective communication channels.",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38",
      "subcategoryIds": [
        "bee1fd9c-1cdb-4259-9ff9-10f37b7ad14c",
        "ae192cae-c5b2-49e1-b082-991d4a3c0d04",
        "c0aa1b0a-2b17-4327-b9c1-f8825a6e1c52",
        "db0b5d8c-554c-4ad1-8e82-2d7495d80e92",
        "cc6b5431-9933-4e06-9c27-87ca695dcec6"
      ]
    },
    {
      "id": "a9d1af20-94e2-4cc7-bcd2-b358b95ea15e",
      "name": "Emotion-Aware Text Generation",
      "definition": "Emotion-Aware Text Generation refers to the development of AI systems capable of producing written content that not only conveys factual information but also detects, interprets, and expresses human emotions effectively. These systems analyze emotional cues within input data\u2014such as tone, context, or explicit sentiment indicators\u2014and generate text that aligns with or appropriately responds to these emotional signals, enhancing human-computer interaction through more empathetic and contextually appropriate communication.",
      "categoryId": "9c2d686b-dc1c-4ed7-bf77-2cbe83efde08",
      "subcategoryIds": [
        "4fd5b85e-4dde-4a7f-938b-34bdbaa3ca29",
        "ae951205-1cad-4747-9bf1-6f24671575ea",
        "2b03e362-2b77-462d-8600-96f5c7d39295",
        "7c9bfb66-c614-44e0-a977-d848bc9faaa5",
        "50bd8a1c-913b-4223-81f5-6795b0037810"
      ]
    },
    {
      "id": "53affe11-b0c5-4785-9050-027e1c3f6b00",
      "name": "Emotional AI",
      "definition": "Emotional AI, also known as affective computing, refers to the branch of artificial intelligence focused on recognizing, interpreting, processing, and simulating human emotions. It aims to enable machines to understand and respond to human affective states in a manner that is contextually appropriate, thereby creating more natural and empathetic interactions between humans and technology.",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38",
      "subcategoryIds": [
        "bee1fd9c-1cdb-4259-9ff9-10f37b7ad14c",
        "ae192cae-c5b2-49e1-b082-991d4a3c0d04",
        "e583927d-bcde-452b-83e8-0bb99d5a9045",
        "e583927d-bcde-452b-83e8-0bb99d5a9045",
        "0d5fae95-5c7a-4248-b22c-ede62114b761"
      ]
    },
    {
      "id": "8fa3a657-1f90-4010-ae5b-e80a9a9d91d6",
      "name": "Emotional Intelligence in AI",
      "definition": "Emotional Intelligence in AI refers to the development and integration of systems capable of recognizing, understanding, managing, and responding to human emotions. It involves designing AI models that can interpret emotional cues from speech, text, facial expressions, and physiological signals to facilitate more natural and effective human-AI interactions. Unlike traditional AI systems that operate purely on logical or statistical data, emotionally intelligent AI aims to emulate human-like emotional awareness to improve communication, empathy, and user experience across various applications.",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38",
      "subcategoryIds": [
        "bee1fd9c-1cdb-4259-9ff9-10f37b7ad14c",
        "e583927d-bcde-452b-83e8-0bb99d5a9045",
        "ae192cae-c5b2-49e1-b082-991d4a3c0d04",
        "6d04aa07-2701-4a8e-a7c7-56969dc7f022",
        "4068740d-1036-42d3-8933-728856a0fd09"
      ]
    },
    {
      "id": "840dd8d8-e8b8-4f87-b6b9-483a467ae71b",
      "name": "Empirical Bayes Regression",
      "definition": "Empirical Bayes Regression is an advanced statistical technique that combines elements of Bayesian inference and frequentist estimation to perform regression analysis. It leverages observed data to estimate prior distributions empirically, enabling more adaptive and data-driven modeling, particularly in contexts with multiple related regression problems or high-dimensional data. The approach typically involves estimating hyperparameters from the data and then using these estimates for Bayesian inference in the regression task, resulting in a blending of empirical data insights with Bayesian probabilistic modeling.",
      "categoryId": "9bc4b2cf-9af5-40c7-b6e8-302cd9ba549c",
      "subcategoryIds": [
        "781c2318-3909-4911-8289-b210b6010d28",
        "69f19b5f-c935-4c04-a6ad-1e5e37cd1190",
        "af89c9a5-7c7c-49f2-87f5-5a97493a33b0",
        "d75abfa1-91a7-4ffd-b42d-8722a67deca7",
        "a207c01b-039b-4c9b-827d-e45eeafe0555"
      ]
    },
    {
      "id": "258286be-4d9c-4b62-b13d-aec25634b5fa",
      "name": "empirical probability",
      "definition": "Empirical probability refers to the probability of an event determined by observed data or actual experiments rather than theoretical calculations. It is calculated by dividing the number of times an event occurs by the total number of trials or observations, providing an empirical measure based on real-world evidence. This concept is fundamental in statistics and data analysis, serving as a basis for understanding uncertain phenomena through observed frequencies rather than assumptions or models.",
      "categoryId": "673c9312-a3b8-46cb-b61a-e25b3c7f30a1",
      "subcategoryIds": [
        "4f7ea125-f38d-419f-aa78-826d3c32d422",
        "b61ace1a-0538-4081-a3c5-8905fc965e51",
        "8bd7f04f-76d6-47dc-8c89-e0c57a9d2738",
        "58bb0353-6ab0-4b5a-a2e4-f55ac4b145fa",
        "e605015b-0c75-4543-aa74-57adcef7875f"
      ]
    },
    {
      "id": "f7240d26-714a-4966-b965-2de8712c45b5",
      "name": "Empowerment",
      "definition": "In the context of AI/ML, 'Empowerment' refers to the process of enabling systems, algorithms, or human stakeholders to make informed decisions, exert control, and enhance their capabilities through data, tools, and intelligent automation. It emphasizes augmenting capacity and fostering autonomy, allowing users and AI systems to operate more effectively within complex environments. Empowerment in AI often involves developing models and interfaces that provide users with clear insights and actionable options, thus promoting confidence and independence in decision-making processes.",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1",
      "subcategoryIds": [
        "312fd869-e3ed-46c1-93d6-d6761c829ccf",
        "7d4f1423-1555-48d6-9aa7-29c85ec1d520",
        "9aed8f86-0fb0-4e56-a61c-d8e5e442c2bc",
        "3156632e-6629-44f9-b8ba-32d788c6b3d6",
        "d3057f5e-d4ce-43e4-97c8-9c7915b05a35"
      ]
    },
    {
      "id": "da2a5c0f-f70c-47a2-8316-0667ca8096a6",
      "name": "Encoder",
      "definition": "An encoder in machine learning and deep learning is a component or model responsible for transforming raw data into a more suitable or condensed representation, often capturing the essential features of the input. It maps high-dimensional, complex data into a lower-dimensional space, facilitating easier processing and understanding by subsequent model components. Encoders are fundamental in various architectures, including autoencoders, transformers, and sequence models, serving as the mechanism to extract meaningful features from raw data such as text, images, or signals.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "945b606f-5af9-48f3-864b-89cf8d2fd5f4",
        "a1ad0275-7b39-4d7c-bf6c-9143f49e7bb7",
        "e20ed8d3-19c3-46a2-ade6-a3dc8924b5d0",
        "34480a2f-e650-4d03-ab95-87e1819c36e9",
        "21abdc69-e38c-419b-8070-3c0ad92a9258"
      ]
    },
    {
      "id": "c317c34a-9c06-43a4-9f8c-85d4c0858b08",
      "name": "Encoder Attention",
      "definition": "Encoder Attention refers to a mechanism used within neural network architectures, particularly in sequence-to-sequence models, that allows the model to selectively focus on different parts of the input sequence during processing. It enables the encoder to dynamically weigh the importance of each input token or feature, improving the contextual understanding and feature extraction necessary for tasks such as translation, summarization, and other NLP applications. Essentially, Encoder Attention enhances the encoding process by emphasizing relevant input information, which is then utilized by subsequent decoder modules.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "ea7f2084-465d-48fc-b419-f08939b79149",
        "e20ed8d3-19c3-46a2-ade6-a3dc8924b5d0",
        "21abdc69-e38c-419b-8070-3c0ad92a9258",
        "f1c99574-6493-4a66-9244-3a0c84edfa16",
        "702021a8-49b4-4664-9381-0594cc8680ca"
      ]
    },
    {
      "id": "97d7d45e-12d0-4338-9673-05c89a6f7676",
      "name": "Encoder-Decoder Architecture",
      "definition": "The Encoder-Decoder Architecture is a neural network framework primarily used for sequence-to-sequence tasks, where an input sequence is transformed into an output sequence. This architecture consists of two main components: the encoder, which processes and encodes the input data into a fixed-dimensional context vector or a series of hidden states; and the decoder, which generates the output sequence based on this encoded representation. It is widely used in applications such as machine translation, text summarization, and speech recognition, enabling models to handle variable-length sequences effectively.",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38",
      "subcategoryIds": [
        "cc6d0720-ed03-4530-9b41-81823876a9fa",
        "85ba73ef-ca0e-4f6e-9bc9-96582428e0cb",
        "be38ddb2-4455-40c0-be30-125a8c3604b2",
        "04d05267-99cb-415b-88de-bfb14654d9f4",
        "812a495a-5398-41bb-b5c8-a3f2713ba5c3"
      ]
    },
    {
      "id": "469d126e-36b1-4d95-82a8-ba6fb01c8064",
      "name": "Encoder-Decoder Models",
      "definition": "Encoder-Decoder Models are a specialized class of neural network architectures designed to process input data into a different form or representation, often for tasks involving complex transformations such as language translation, image captioning, and sequence-to-sequence prediction. These models consist of two main components: the encoder, which converts the input into a fixed-length or variable-length internal representation, and the decoder, which generates the output from this representation. This setup enables flexible handling of structured input and output data, especially when the input and output differ in length or format.",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38",
      "subcategoryIds": [
        "5dd5b4e1-a00c-4c40-aa79-39bdcb4916be",
        "85ba73ef-ca0e-4f6e-9bc9-96582428e0cb",
        "538bbc62-0fdd-4df5-ac69-016ab17ef045",
        "ab3d8b86-fc58-4835-a55c-fa17e6cc1a6c",
        "07fc4e41-a36e-4d10-ac4a-a23e24d2d7be"
      ]
    },
    {
      "id": "8c4b8022-6e92-4b25-9a1d-0b9958dd4dea",
      "name": "Encoder-Decoder Models Extensions",
      "definition": "Encoder-Decoder Models Extensions refer to advanced modifications and enhancements of traditional encoder-decoder architectures used in neural networks. These extensions aim to improve the models' ability to handle complex tasks such as sequence-to-sequence learning, language translation, and image captioning by incorporating additional mechanisms like attention, multi-head attention, pointer networks, and hierarchical encoding. They build upon the foundational encoder-decoder framework to address limitations such as fixed context size and to enable more flexible, accurate, and efficient data processing.",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1",
      "subcategoryIds": [
        "f2d3270a-18fc-43bc-9019-db70d6973cfb",
        "eb388d8c-7fd9-4af0-ab54-b599ab540ec5",
        "654f0bca-f93a-48be-8f13-f4590c4ca9f2",
        "1e882a33-9eca-476e-8bfc-655f2dcd1b11",
        "6259c3f6-f0b6-4479-94e1-9bcc8d3af8b8"
      ]
    },
    {
      "id": "49152d6f-663f-43e2-b39c-d563811d37bf",
      "name": "Encoder-Decoder Models Extensions Extensions",
      "definition": "Encoder-Decoder Models Extensions refer to advanced architectures and modifications built upon basic encoder-decoder frameworks used in neural network models. These extensions aim to enhance functionality, efficiency, and performance in various sequence-to-sequence tasks such as machine translation, speech recognition, and image captioning. By integrating techniques like attention mechanisms, multi-head attention, or hierarchical structures, these extensions improve the model's ability to capture complex dependencies and context within data, thereby expanding the capabilities of standard encoder-decoder systems.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "795330db-42d4-48bc-88eb-92de8c9b35aa",
        "702021a8-49b4-4664-9381-0594cc8680ca",
        "f1c99574-6493-4a66-9244-3a0c84edfa16",
        "61dd55c5-cbc7-4cee-a058-e73e9e1345ca",
        "1e2f3665-4317-44fc-8c05-ed100a588d97"
      ]
    },
    {
      "id": "3f1c4a24-9f8a-456f-9d36-a381dc47b660",
      "name": "Encoder-Decoder Models Extensions Extensions Techniques Enhancements Techniques",
      "definition": "Encoder-Decoder Models Extensions Techniques Enhancements Techniques refer to a range of advanced methods and modifications applied to the core encoder-decoder architecture commonly used in sequence-to-sequence tasks. These extensions aim to improve model performance, efficiency, and capability by incorporating additional mechanisms such as attention mechanisms, multi-head attention, transformer architectures, and other optimization strategies. They facilitate better encoding of input data and more effective decoding to generate accurate and contextually relevant outputs across various AI and machine learning applications.",
      "categoryId": "2bd8b40c-79f5-4b84-813f-a70ebe2d5360",
      "subcategoryIds": [
        "22ba3caa-de7c-4cd0-a272-96999e8c8e78",
        "3f9e7fa3-5cdd-434f-88e5-0944273dc4e2",
        "9c005c56-ec1b-4765-90ac-2b42b097f917",
        "e0f82f78-f607-4f7b-865d-782d5c62f7aa",
        "94917cf7-dfed-4f37-a4ae-4ca87d4f4062"
      ]
    },
    {
      "id": "9afc50b4-7917-4026-85cd-474b51079906",
      "name": "Encoder-Decoder Models Extensions Techniques",
      "definition": "Encoder-Decoder Models Extensions Techniques refer to a collection of methods and architectural modifications designed to enhance the capabilities, efficiency, and flexibility of encoder-decoder frameworks in machine learning. These techniques aim to improve the performance of sequence-to-sequence tasks such as machine translation, speech recognition, and image captioning by extending the basic encoder-decoder architecture with mechanisms like attention, residual connections, multi-head attention, and hierarchical encodings. They often address limitations related to handling long sequences, capturing complex dependencies, and improving model interpretability.",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38",
      "subcategoryIds": [
        "da44e261-7de1-46cc-b5c6-c00b8903e76c",
        "adb64517-8b11-42ee-863e-cf9a7bc2a4c5",
        "62bf1743-5bb2-435e-8466-17c39705a66b",
        "b6a56d63-07c4-496e-9257-9a038cba90ef",
        "acdef06d-c098-43c1-bb71-0e2faf4b97df"
      ]
    },
    {
      "id": "469e8532-aea7-4c78-9037-ddaefa8c76e0",
      "name": "Encoder-decoder pretraining",
      "definition": "Encoder-decoder pretraining is a training paradigm in machine learning where models are trained to understand and generate sequential data by first learning to encode input information into a meaningful internal representation and then decode that representation into a desired output. This approach is often used in natural language processing (NLP) and other sequence modeling tasks, enabling models to perform complex transformations such as translation, summarization, and question answering. During pretraining, the model learns general language understanding or feature extraction which can be later fine-tuned for specific tasks.",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38",
      "subcategoryIds": [
        "89854309-3160-47ce-8cae-070aa916fdc1",
        "44fbdd23-5eec-422c-b223-f6bf0493d6fa",
        "d2ee9f2d-d5ab-4736-8403-0d3b26b68a77",
        "85ba73ef-ca0e-4f6e-9bc9-96582428e0cb",
        "408ea5ef-f392-4c02-a5a4-ad6208a6bf9b"
      ]
    },
    {
      "id": "e0ce486c-a489-4820-9aa3-1a9d3970b79b",
      "name": "Encoding",
      "definition": "In the context of AI and machine learning, 'Encoding' refers to the process of converting data, information, or features into a particular format or representation that can be efficiently processed by algorithms. This transformation often involves translating categorical or textual data into numerical formats or compressing data to reduce its complexity while preserving essential information. Encoding is a fundamental step in data preprocessing, enabling models to interpret and learn from diverse types of data effectively.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "268a42b0-d97e-4d93-99f3-b47412dea076",
        "43098ab8-779d-4b6d-86be-349782fdda68",
        "525126fd-68df-4056-84ab-f7759e0a8ef3",
        "327ada80-d125-4dca-9328-e57a9361cfcb",
        "fb826642-4af8-46da-8b0d-65c22e6f42de"
      ]
    },
    {
      "id": "7813ebb0-f92b-4127-bd60-53e74624abad",
      "name": "End-to-End Dialogue Systems",
      "definition": "End-to-End Dialogue Systems are sophisticated artificial intelligence systems designed to facilitate natural, coherent, and contextually relevant conversations with users, typically through natural language processing (NLP). These systems handle the entire dialogue process from user input to response generation within a unified framework, minimizing the need for manual feature engineering or modular pipeline components. They aim to produce human-like interactions by integrating various AI components such as language understanding, context management, and response generation into a seamless, end-to-end trainable model.",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1",
      "subcategoryIds": [
        "c8151e87-b5a8-4540-8065-9fdb92af2e4d",
        "3ae39cd7-45ba-40ea-aced-bae77e81a765",
        "9aa9ac36-d8c5-4227-85cd-ea97af4a59b3",
        "564b7828-ca8c-4f24-85d0-a87e2b10076e",
        "eb388d8c-7fd9-4af0-ab54-b599ab540ec5"
      ]
    },
    {
      "id": "4b63279c-49c8-40b9-b5e4-3c338de9e9d6",
      "name": "energy-based distillation",
      "definition": "Energy-based distillation is a machine learning technique that involves leveraging energy functions or energy landscapes to guide the process of model compression, transfer learning, or knowledge distillation. It derives its name from the concept of using energy metrics to evaluate and optimize the transfer of information from a teacher model to a student model, aiming to improve the efficiency and effectiveness of the distillation process by framing it within an energy minimization paradigm.",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38",
      "subcategoryIds": [
        "76b5b7ad-769b-4d75-ac58-7ae46f96c240",
        "ed3069ae-de26-4e99-a4ce-b2d7d3d4969c",
        "e90fb9b7-fc2b-491f-a0be-c0c4f638721f",
        "b3490d1e-e8ad-4c2d-b580-a5b92e034990",
        "d2ee9f2d-d5ab-4736-8403-0d3b26b68a77"
      ]
    },
    {
      "id": "8b3a5bad-fbae-4502-9e31-95d617e66c19",
      "name": "Energy-Based GANs (EBGANs)",
      "definition": "Energy-Based Generative Adversarial Networks (EBGANs) are a class of generative models that utilize an energy function to guide the training process. Unlike traditional GANs, which rely on a discriminator to classify real versus fake data, EBGANs employ an energy function as a measure of data authenticity, where lower energy indicates closer resemblance to real data. The generator aims to produce samples that minimize the energy, effectively learning the data distribution by training with a simple autoencoder as the energy function.",
      "categoryId": "bd264002-0726-4dd7-bb5e-134c5fc6e63e",
      "subcategoryIds": [
        "e9a51db2-b9fb-43f5-bf57-d5b2e97d45c6",
        "5669e852-298e-409b-8a71-a0d4385db693",
        "88495f62-49a5-4e2f-b66a-197feb34994d",
        "1d95d6f5-d42d-46a7-90fb-b14616491680",
        "01820fa2-95ad-417a-98c0-740374cbb26e"
      ]
    },
    {
      "id": "2ef05bc0-a621-4967-b176-28d524c0a953",
      "name": "Energy-Based Models",
      "definition": "Energy-Based Models (EBMs) are a class of probabilistic models in machine learning that define a scalar energy function over data points or configurations. The core idea is that data points with low energy values are more likely or preferable, while those with high energy are less likely. Unlike traditional probabilistic models that explicitly specify probability distributions, EBMs focus on learning an energy function such that the probability of a data point is proportional to the exponential of the negative energy. EBMs can be used for tasks such as density estimation, generative modeling, classification, and reinforcement learning by leveraging the energy landscape to represent complex data distributions.",
      "categoryId": "d05f2a80-334c-41d4-b0db-02c71638e9d8",
      "subcategoryIds": [
        "b1eec4d6-cc4c-49e7-b264-0ef204a7f021",
        "8e8f3042-73bc-4826-b826-217fc2504594",
        "1af7a20e-5dce-48f9-a5e1-38cb3ea6b2ae",
        "b92801d9-2eed-4ae9-927d-f94e54f841a9",
        "79bdfa3a-0d5a-46ed-82b8-85447cdfdf75"
      ]
    },
    {
      "id": "17ae9e24-7c85-4091-a5db-089ef5591f58",
      "name": "Energy-Based Models (EBMs)",
      "definition": "Energy-Based Models (EBMs) are a class of probabilistic models in machine learning that define a scalar energy function over input configurations, where lower energy indicates higher likelihood. Instead of explicitly modeling probability distributions directly, EBMs assign energy values to data points and learn to assign low energies to observed data while assigning higher energies to unlikely configurations. This approach enables modeling complex data distributions and facilitates tasks such as density estimation, generative modeling, and unsupervised learning.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "2fd23381-1b6b-41b7-adf6-f797dcff53d2",
        "4304b376-e2dd-4475-a205-53d4b839e50c",
        "e51eda89-e791-4ae7-a017-f7d9145e9dfb",
        "a7d03bed-7235-4bc5-8daa-af6514c7320d",
        "2a95f5b4-98c6-4efc-8406-edf5bca000c9"
      ]
    },
    {
      "id": "37a7df7f-ed14-4291-b418-c85a9a91eebd",
      "name": "Energy-Based Models Extensions",
      "definition": "Energy-Based Models Extensions refer to the advanced variations and adaptations of fundamental energy-based models (EBMs) in machine learning. EBMs are a class of probabilistic models that associate an energy value with each configuration of variables, where lower energies correspond to more probable configurations. Extensions of these models incorporate new architectures, training techniques, and applications that build upon the core principles of EBMs, aiming to improve their expressiveness, efficiency, and practicality in various tasks such as generation, classification, and representation learning.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "8ecd6bb2-5a15-4c29-b707-72721e1d0a36",
        "e51eda89-e791-4ae7-a017-f7d9145e9dfb",
        "dd33f637-8b74-499c-9229-96b369533b0b",
        "2a95f5b4-98c6-4efc-8406-edf5bca000c9",
        "dd204a62-5692-406d-9a21-d228e04bc020"
      ]
    },
    {
      "id": "77d36f0c-664f-4769-8fd1-09be7f6a5486",
      "name": "Energy-Based Reinforcement Learning",
      "definition": "Energy-Based Reinforcement Learning (EBRL) is an approach that integrates principles from energy-based models into the reinforcement learning framework. It conceptualizes the agent's goal as minimizing or managing an energy function associated with states and actions, enabling the system to learn policies that prefer low-energy configurations which correspond to desirable or optimal behaviors. This paradigm often involves defining an energy landscape where policy optimization is achieved through energy minimization, facilitating more flexible and expressive representations of complex decision-making tasks in environments with high-dimensional or structured data.",
      "categoryId": null,
      "subcategoryIds": []
    },
    {
      "id": "bf2b3f6f-9ff5-4c0d-a1f3-d9eedd2838a3",
      "name": "Ensemble Averaging",
      "definition": "Ensemble Averaging is a statistical technique in machine learning where predictions from multiple models or multiple instances of a model are combined by averaging their outputs. This approach aims to enhance prediction accuracy and stability by reducing the variance associated with individual models, thereby producing a more robust and reliable estimate of the target variable or class.",
      "categoryId": "90081538-133d-4daa-842e-dd866ccc294a",
      "subcategoryIds": [
        "e08561ed-178a-4ecd-956b-9317d5630cd3",
        "37b54e2c-13bd-4c4d-a859-c39e2fb8eea0",
        "30044e99-ef6e-43d5-bab9-da162bfd09ba",
        "d888959d-8582-4494-8cc9-eb5ce56ea839",
        "28f9280c-f44a-45ba-98f5-40e6a1724b0c"
      ]
    },
    {
      "id": "65cfbb23-b804-4b8c-aabc-644cc6a9e9a7",
      "name": "ensemble distillation",
      "definition": "Ensemble distillation is a machine learning technique that involves transferring the collective knowledge of an ensemble of models into a single, compact model. By doing so, it aims to combine the high accuracy and robustness of ensembles with the efficiency and simplicity of a single model, typically through a process known as knowledge distillation. In essence, ensemble distillation involves training a single model (the student) to replicate the predictions of an ensemble (the teacher), thereby capturing the ensemble\u2019s performance while reducing computational complexity.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "4b8e54fb-8712-49ee-bec9-6909266fd348",
        "a5ff2600-aa41-4762-8ba7-80fc7cee4e6b",
        "25ef6ff2-d15f-4fb4-af32-9108ceb6f659",
        "dc3002a2-4a77-414c-b527-67a4997447db",
        "2df47eec-dc34-4850-b588-665760e8d581"
      ]
    },
    {
      "id": "21ae77ca-cd43-4ae8-9d7e-cd39534f5797",
      "name": "Ensemble Diversity",
      "definition": "Ensemble Diversity refers to the measure of variability or difference among the individual models within an ensemble method in machine learning. It quantifies how distinct the predictions of the constituent models are, which is crucial because higher diversity among models generally leads to better ensemble performance by reducing correlated errors and improving generalization. Ensemble methods, such as Random Forests or Boosting, leverage diversity to combine the strengths of multiple models, thus enhancing overall prediction accuracy and robustness.",
      "categoryId": "568523b2-fa1a-4a9e-b2e7-c894832e26e2",
      "subcategoryIds": [
        "a6d0c0c3-c6b8-4dec-a63b-5bbf0ae315f5",
        "e1bdc998-7073-40c7-b5f6-933bab821d14",
        "3378b567-5cde-40e8-91c2-365cd90546fe",
        "eeb723d2-6147-4b24-b400-0a154b358997",
        "0b6d87ab-60ce-4d2a-8418-66d14c664673"
      ]
    },
    {
      "id": "18812784-0542-4b5f-99c1-ddcf6f532d28",
      "name": "Ensemble Diversity Techniques",
      "definition": "Ensemble Diversity Techniques refer to methods that aim to increase the diversity among individual models within an ensemble. These techniques are designed to ensure that models make different errors or predictions, thereby enabling the ensemble to benefit from their varied perspectives. By promoting diversity, ensemble methods can improve overall predictive performance, robustness, and generalization capabilities beyond what individual models can achieve alone.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "4e5fdbcf-9c3b-44aa-8577-e93f45f8c4e0",
        "f5d30122-fb5b-4b5e-ab91-45f368d7ad83",
        "fab5b3fe-3d21-4bdc-8855-b88e657d9216",
        "94104f48-0061-432c-9ed6-9018ece61755",
        "417ae609-09df-4130-9e2b-36155b382e8a"
      ]
    },
    {
      "id": "7ccc3ca6-7b23-4534-9c04-c3aa74f17c5c",
      "name": "Ensemble Diversity Techniques Extensions",
      "definition": "Ensemble Diversity Techniques Extensions refer to advanced methods and strategies used to enhance the diversity within ensemble learning models. Ensemble learning combines multiple models, such as classifiers or regressors, to improve overall performance and robustness. These extensions specifically focus on promoting diversity among the individual models to reduce correlation and errors, leading to more accurate and reliable ensemble predictions. Techniques include various methods for encouraging varied model behaviors, such as specialized training procedures, data manipulation strategies, and model architecture modifications, tailored to extend or improve upon traditional diversity techniques.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "1e35ffee-05a9-4571-94d4-77756456debf",
        "8f31e2cc-de02-479e-acb9-d6001be355e4",
        "878c1b31-e88c-4c56-b12e-8259eb312ce3",
        "f5d30122-fb5b-4b5e-ab91-45f368d7ad83",
        "fab5b3fe-3d21-4bdc-8855-b88e657d9216"
      ]
    },
    {
      "id": "ffbb35fc-f213-4bcd-a08d-503bd32ec3f8",
      "name": "Ensemble Gradient Boosting",
      "definition": "Ensemble Gradient Boosting is a machine learning technique that combines multiple weak learners, typically decision trees, to produce a strong predictive model. It builds an ensemble sequentially, where each subsequent model attempts to correct the errors of the combined preceding models, utilizing gradient descent techniques to optimize model performance. This approach enhances prediction accuracy, robustness, and generalization capabilities compared to individual models.",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38",
      "subcategoryIds": [
        "9c77f0de-3d59-417e-9572-316a26ce9e27",
        "1e35ed9a-a95a-4693-bb98-1e56a49dbfcb",
        "192eba82-dbd6-4f91-a211-a4121d7b775c",
        "acf8482e-f0e5-41d7-b96f-56b976868802",
        "4c21c4d7-8d93-4a2c-9ea4-03cd90621694"
      ]
    },
    {
      "id": "3ba5d18c-6726-405f-82b0-86fb708e91e1",
      "name": "Fisher Information",
      "definition": "Fisher Information is a fundamental concept in statistical estimation theory, quantifying the amount of information that an observable random variable carries about an unknown parameter upon which the probability depends. It is mathematically defined as the expected value of the squared score, which is the gradient of the log-likelihood function with respect to the parameter. Essentially, Fisher Information measures the sensitivity of the likelihood function to changes in the parameter, providing insights into the precision with which the parameter can be estimated from data.",
      "categoryId": "93b6daed-ada5-467e-bb57-c4b278896740",
      "subcategoryIds": [
        "48c4499f-7cc2-4d7a-b0e0-20f42a8077ba",
        "b49154e7-159b-484b-859d-685e2cc54831",
        "19548fe5-ee17-479b-b5f5-0f2205bc2f4b",
        "80893482-da3f-43ff-a237-ea803d0b39e8",
        "81615611-76b6-4a86-bd77-8c3ed6c85e5e"
      ]
    },
    {
      "id": "7d7c6930-0e64-4724-a322-51005b378a23",
      "name": "Fisher Information Matrix",
      "definition": "The Fisher Information Matrix (FIM) is a fundamental concept in statistics and information theory that quantifies the amount of information that an observable random variable carries about unknown parameters upon which the probability depends. Mathematically, it is a matrix of second-order partial derivatives of the log-likelihood function with respect to the parameters, representing the curvature of the likelihood surface. In the context of AI and Machine Learning, the FIM is used to analyze parameter estimability, optimize training processes, and understand model sensitivity.",
      "categoryId": "a08d705b-8994-4bcf-9c82-17c75c3bc367",
      "subcategoryIds": [
        "d3812fad-73c3-4d68-ae08-75426c127c98",
        "5329233d-e893-4511-8d75-49b3f382c2af",
        "39742e93-589a-4e30-83ab-a6a90ceea6ce",
        "2bdfe829-326f-4dda-a399-2ef3268ed16c",
        "e90d7b50-b12c-4944-b395-85fc32d1fc0d"
      ]
    },
    {
      "id": "7db613c8-28ba-4071-8ede-9cfc393d1c8e",
      "name": "Fisher Vector",
      "definition": "The Fisher Vector is a powerful encoding method used in computer vision and pattern recognition tasks to represent sets of local features, such as SIFT descriptors, in a fixed-length, discriminative feature vector. It combines the benefits of probabilistic modeling and feature aggregation by encoding deviations of data points from a generative model, typically a Gaussian Mixture Model (GMM). This approach yields a compact and informative representation useful for tasks like image classification, object recognition, and clustering.",
      "categoryId": "f697ffdc-db4e-4058-938b-63083e5204a2",
      "subcategoryIds": [
        "a25b29f5-3ad4-429a-ad2e-3de3dacd73e0",
        "3abc130f-c77a-4ced-87cc-77c5c70ca310",
        "43d73341-07fe-428e-bace-0583976863ea",
        "9d9af0b9-4bd1-431d-832f-78f88a05422a",
        "c9bea7f4-145d-451c-977e-4a5aa52409b6"
      ]
    },
    {
      "id": "e5f26d3d-0af2-4011-b086-e5cd87a3fdd5",
      "name": "Fisher Vector Encoding",
      "definition": "Fisher Vector Encoding is a technique used in computer vision and machine learning to represent a set of local image features as a fixed-length, high-dimensional vector. It encodes the distribution of local descriptors (such as SIFT features) relative to a learned probabilistic model, typically a Gaussian Mixture Model (GMM). This encoded representation captures rich statistical information about the local features, making it suitable for tasks like image classification, retrieval, and object recognition. The Fisher Vector method combines the ideas of generative modeling and discriminative classification, offering a powerful tool for feature aggregation and representation in high-dimensional spaces.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "96ac26e6-28ae-4409-b9e8-a88401724e80",
        "cebe5f85-a68c-4dc9-a2f3-623cc085cb33",
        "3a35cb2a-392b-41f5-8720-5d772f18bd83",
        "f814aadf-073b-40cf-81c7-6e83763ff62a",
        "21f9f1a2-3abb-4825-8de8-0f060fadac18"
      ]
    },
    {
      "id": "72863aae-2910-4935-a909-22afc1951520",
      "name": "Fisher's Exact Test",
      "definition": "Fisher's Exact Test is a statistical significance test used to determine if there are nonrandom associations between two categorical variables in a contingency table, especially in cases with small sample sizes. It computes the exact probability of observing the data under the null hypothesis of independence, making it a precise alternative to the Chi-squared test when sample sizes are limited.",
      "categoryId": "a08d705b-8994-4bcf-9c82-17c75c3bc367",
      "subcategoryIds": [
        "0ac77f84-cc43-4a63-98d0-3055e399e5be",
        "4acce7cb-063a-4740-a1a7-48422eda355b",
        "f2a9c10a-7cff-4ec5-8e8e-eb853e32cd0f",
        "b000ce27-ad7f-42ee-8e9b-47155d14646b",
        "6bea9bda-1081-474f-8dde-bea4765f6faf"
      ]
    },
    {
      "id": "6ecdb112-38c8-49a3-a94a-b8137e9d8c05",
      "name": "Fitness Function",
      "definition": "A fitness function is a fundamental component in optimization algorithms, particularly within evolutionary algorithms and genetic algorithms. It is a function that evaluates and assigns a fitness score to a given solution or individual within a population. The score quantifies how well the solution performs relative to the problem's objectives, serving as a guide for selecting better solutions and generating subsequent generations. By providing a scalar measure of solution quality, the fitness function enables the optimization process to progressively improve the solutions over iterations.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "c39b0e3d-9a44-4cf4-8a10-7174855c7d95",
        "e5f2339d-b008-4ed8-96a8-a8adadae1aa7",
        "b2d78c8f-42fc-4292-acad-0bad865e2ec8",
        "5a6248c0-b39e-4ed2-9ea3-09d7ee1af6e5",
        "6cc2794b-837e-4697-a617-ac5554db873f"
      ]
    },
    {
      "id": "cab197aa-d556-4018-a934-9b018b90195a",
      "name": "flash attention",
      "definition": "Flash attention is an advanced attention mechanism designed to optimize the traditional transformer attention process by significantly reducing computational complexity and memory usage. It achieves this by approximating or selectively focusing on relevant parts of the input sequence, enabling faster and more efficient processing, especially for long sequences. This technique allows models to handle larger inputs and longer context windows without the prohibitive resource demands associated with conventional attention mechanisms.",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1",
      "subcategoryIds": [
        "278f0946-f5d6-4b81-83f7-be95908fc244",
        "1e882a33-9eca-476e-8bfc-655f2dcd1b11",
        "df2d4561-41c3-44b8-a4c1-fa3f6f25a44c",
        "26d10b88-6142-48ea-bea1-a58b4cc44073",
        "adc35ee6-b920-4ff5-ab44-61123c70ceb5"
      ]
    },
    {
      "id": "03288df9-0a74-4cef-9990-d06361a35457",
      "name": "flash distillation",
      "definition": "Flash distillation is a separation process primarily used in chemical engineering and distillation industries, where a mixture is rapidly vaporized and condensed to separate its components based on differences in volatility. In an AI/ML context, the term is metaphorically adapted to describe a rapid, focused process of distilling complex data, models, or knowledge into simpler, more manageable representations, often facilitating efficient model training or interpretability.",
      "categoryId": "f3cc5848-17f6-4279-a475-458a184ce408",
      "subcategoryIds": [
        "50f7fdbd-8abd-45c6-a55a-8212cb798125",
        "49ab17c3-3b0b-4741-a01f-7f1afc388ec8",
        "4e510063-8b04-404d-8dad-aa8cf0378080",
        "44b7164f-5080-4d12-b8af-18d23e85f32b",
        "02ff7687-c3ff-47e3-bf40-8e3d9777a7eb"
      ]
    },
    {
      "id": "1b07d48c-8ddf-4b24-947e-d363c486c05e",
      "name": "Flexible Neural Networks",
      "definition": "Flexible Neural Networks are a class of neural network architectures designed to adapt their structure, parameters, or activation functions dynamically during training or inference to better suit specific tasks or data distributions. Unlike traditional fixed-architecture models, flexible neural networks can modify their configuration to enhance learning efficiency, generalization, and robustness, enabling more versatile and efficient AI systems.",
      "categoryId": "2bd8b40c-79f5-4b84-813f-a70ebe2d5360",
      "subcategoryIds": [
        "d7c9fd52-3854-4713-9e2d-fd73a703a05c",
        "7ad310ec-2721-493c-9ab9-eeeb27f30bf9",
        "768d0f71-5e12-4f4a-b735-756718b5900f",
        "c20300a0-ab48-4681-8aba-1de0f2205fa5",
        "317dbdcd-6ce3-491f-af9e-437cb402feb9"
      ]
    },
    {
      "id": "096a72fd-c476-46b2-a041-b9746896b7cc",
      "name": "Flow-based Generative Models",
      "definition": "Flow-based Generative Models are a class of deep learning models designed to generate complex data such as images, audio, and text by learning invertible transformations of simple probability distributions into data distributions. They leverage a series of invertible functions, enabling exact likelihood computation and efficient sampling, making them a powerful tool for generative tasks where precise data modeling is essential.",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d",
      "subcategoryIds": [
        "df565de2-ff54-4edb-8dbe-5d0a811c60eb",
        "1b5fd874-a8af-4c95-bcbe-f6732b54fe6b",
        "b07870e9-caba-4d1f-9dfd-5004b9df06f3",
        "cad6b1fd-dd50-40b7-95c4-6e2f5eedccad",
        "909ad962-b285-4960-aba1-33c85b72b991"
      ]
    },
    {
      "id": "ad2a1b50-df9f-4fa9-856e-a0eebce82de7",
      "name": "Flow-Based Generative Models Enhancements",
      "definition": "Flow-Based Generative Models Enhancements refer to advanced techniques and modifications aimed at improving the efficiency, scalability, and quality of flow-based generative models. These models are a class of probabilistic models that learn to generate data by transforming simple distributions into complex ones through a series of invertible mappings. Enhancements focus on optimizing these transformations, making them computationally more efficient and capable of capturing intricate data distributions more accurately.",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d",
      "subcategoryIds": [
        "8b703eee-4941-4c4c-a1a7-96a5885e8609",
        "b07870e9-caba-4d1f-9dfd-5004b9df06f3",
        "1b5fd874-a8af-4c95-bcbe-f6732b54fe6b",
        "c0a0666b-5f5e-4280-b5da-ca71af519ab5",
        "8db1dc80-adf1-41bd-9313-022e2f74284b"
      ]
    },
    {
      "id": "5d2b7142-c348-40cc-b39f-90991877e778",
      "name": "Flow-based Generative Models Extensions",
      "definition": "Flow-based Generative Models Extensions refer to advanced developments and modifications of existing flow-based generative models, which are a class of probabilistic models used to generate new data by learning invertible transformations between complex data distributions and simple base distributions. These extensions aim to improve the models' expressiveness, scalability, computational efficiency, and quality of generated samples, often by integrating novel architectures, training techniques, or hybrid approaches to address the limitations of traditional flow-based models.",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d",
      "subcategoryIds": [
        "df0d439d-1192-485d-8e29-3e50ddf8924a",
        "b07870e9-caba-4d1f-9dfd-5004b9df06f3",
        "3c945745-4bb3-420f-8ebb-f58a85baca20",
        "d307b6bf-89b1-4920-9335-ee24f127a383",
        "2d58e1bb-bb7b-4562-98e3-b00e2e69b8e8"
      ]
    },
    {
      "id": "a153db37-343c-4001-8a7a-eff617c6939c",
      "name": "Flow-based Generative Models Techniques",
      "definition": "Flow-based Generative Models Techniques are a class of generative models in machine learning that utilize invertible transformations, or 'flows,' to model complex data distributions. These models transform simple base distributions, such as Gaussian noise, into complex data distributions through a series of invertible, differentiable mappings. The key advantage of flow-based models is their ability to efficiently compute both the likelihood of data points and generate new samples, making them highly valuable for tasks requiring exact density estimation and high-quality sample generation.",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d",
      "subcategoryIds": [
        "49ef5038-6b0e-4828-89ce-2c6fceaef501",
        "1b5fd874-a8af-4c95-bcbe-f6732b54fe6b",
        "b07870e9-caba-4d1f-9dfd-5004b9df06f3",
        "df8b7d5d-70c0-4286-9c03-00922f9642d2",
        "944d40cf-53e5-4605-93d4-63805c4d88c8"
      ]
    },
    {
      "id": "1fa42b28-8c24-4ea5-a32f-4f4e0e303946",
      "name": "Flow-based Models",
      "definition": "Flow-based models are a class of generative models in machine learning that utilize invertible neural networks to map complex data distributions to simple latent distributions, typically Gaussian. These models employ a series of invertible transformations, allowing for both efficient data generation by sampling from the latent space and precise data likelihood computation. Unlike other generative models such as GANs or VAEs, flow-based models provide exact and tractable likelihood estimation, making them highly suitable for tasks requiring detailed density modeling.",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d",
      "subcategoryIds": [
        "72a731b6-ee71-438f-b1c3-cf90989f54a7",
        "0a7b29b7-bbf9-487c-b28c-85f189713da6",
        "2af107aa-a52f-43ff-9ba5-9bf19ee791d0",
        "6d3e3289-f175-4e7b-9abf-8333f4291fe3",
        "94bedad1-22da-46cb-bc55-255af3613ccc"
      ]
    },
    {
      "id": "ce8bef49-557d-4cd0-9b2e-9c63b84a2a5e",
      "name": "Flow-Based Models Enhancement",
      "definition": "Flow-Based Models Enhancement refers to the techniques and strategies employed to improve the performance, efficiency, and applicability of flow-based generative models in machine learning. These models leverage invertible transformations to map simple probability distributions to complex data distributions, facilitating high-quality data generation and density estimation. Enhancements in this domain aim to address challenges such as computational complexity, scalability, and the quality of generated samples, often by optimizing network architectures, training procedures, or combining flow-based models with other methods to better capture data intricacies.",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d",
      "subcategoryIds": [
        "85e91bde-a240-40a7-b83a-854b2198d817",
        "9766ddbd-f435-4f1d-bb81-7868645385f4",
        "1b5fd874-a8af-4c95-bcbe-f6732b54fe6b",
        "b07870e9-caba-4d1f-9dfd-5004b9df06f3",
        "944d40cf-53e5-4605-93d4-63805c4d88c8"
      ]
    },
    {
      "id": "265dc81c-26a6-49b6-b808-30533aeba66b",
      "name": "Flow-Based Models Enhancements",
      "definition": "Flow-Based Models Enhancements refer to the recent advancements and refinements made to flow-based generative models, which are a class of likelihood-based generative models that utilize invertible transformations to map complex data distributions to simple latent spaces. These enhancements aim to improve model performance, stability, scalability, and expressiveness, enabling more accurate data generation, better sampling quality, and more efficient training processes. By integrating new architectures, optimization techniques, and regularization methods, flow-based model enhancements seek to address challenges such as limited capacity, computational complexity, and the ability to model high-dimensional data effectively.",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38",
      "subcategoryIds": [
        "66f78ac6-0fad-46e3-a004-5edc16eb8aae",
        "ed753c26-3e2c-447a-9bed-98ac6e603f9f",
        "b047564a-b5c0-44aa-b377-fadf885dd4ca",
        "76e717f5-395f-4351-b0d4-52ad90da22e9",
        "ec0d1aac-fa0c-4225-a525-3833ac77b0bd"
      ]
    },
    {
      "id": "51ebda45-fe22-48f8-a639-4b60dfb4420d",
      "name": "Flow-Based Models Techniques",
      "definition": "Flow-Based Models Techniques are a class of probabilistic generative models that utilize invertible transformations to map complex data distributions onto simpler latent spaces. By achieving invertibility, these models can efficiently compute exact likelihoods and generate high-quality samples, making them particularly effective for density estimation and data generation tasks. Examples include RealNVP, Glow, and NICE. These models leverage a sequence of invertible, differentiable functions, allowing both sampling and likelihood evaluation to be performed efficiently within the same framework.",
      "categoryId": null,
      "subcategoryIds": []
    },
    {
      "id": "02e5d3d3-19f7-4ce0-9ea4-883a72c34518",
      "name": "Flow-Based Models Techniques Enhancements",
      "definition": "Flow-Based Models Techniques Enhancements refer to advanced methods and innovations designed to improve the capabilities, efficiency, and applicability of flow-based generative models in machine learning. Flow-based models are a class of probabilistic models that leverage invertible transformations to map complex data distributions to simple latent spaces, enabling both efficient sampling and exact likelihood computation. Enhancements in these techniques aim to address limitations such as computational complexity, model expressiveness, and scalability, thereby broadening the scope of flow-based models in various AI applications.",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d",
      "subcategoryIds": [
        "4f16e4b7-8c7c-4f39-a04b-b70b6888dfa7",
        "6d3e3289-f175-4e7b-9abf-8333f4291fe3",
        "4e8787b3-8a70-49a1-b8c2-83ea320e99fe",
        "1b5fd874-a8af-4c95-bcbe-f6732b54fe6b",
        "42f7a74d-b0fa-49a6-8844-b24ec328c41c"
      ]
    },
    {
      "id": "68b8d197-bb6d-45d6-999d-9c8c45e44471",
      "name": "Flow-Based Models Variants",
      "definition": "Flow-Based Models Variants refer to a class of generative models in machine learning that leverage invertible neural networks to transform simple probability distributions into complex data distributions through a sequence of invertible transformations. These models enable exact likelihood computation and high-quality data generation by modeling the data distribution through reversible mappings, making them an important subset within the broader landscape of generative modeling techniques.",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d",
      "subcategoryIds": [
        "4ffa2658-c00f-42b8-a3ae-a76a9a2e5262",
        "b07870e9-caba-4d1f-9dfd-5004b9df06f3",
        "1b5fd874-a8af-4c95-bcbe-f6732b54fe6b",
        "c0a0666b-5f5e-4280-b5da-ca71af519ab5",
        "944d40cf-53e5-4605-93d4-63805c4d88c8"
      ]
    },
    {
      "id": "16b4bc0e-856d-4263-b558-73070dfcdbb8",
      "name": "Flow-Based Models Variants Techniques",
      "definition": "Flow-Based Models Variants Techniques refer to a class of generative models in machine learning that utilize invertible transformations to map data distributions to latent spaces and vice versa. These models leverage the concept of flow-based transformations, which are designed to be reversible and computationally efficient, enabling exact likelihood evaluation and efficient sampling. Variants and techniques within this category improve upon basic flow models by introducing more flexible architectures, better scalability, improved generative capabilities, and enhanced training methods.",
      "categoryId": null,
      "subcategoryIds": []
    },
    {
      "id": "3d78fb3c-ae82-4328-ae1c-5c5a83228f67",
      "name": "Flow-based Neural Networks",
      "definition": "Flow-based Neural Networks (FBNNs) are a class of neural network architectures that leverage continuous, invertible transformations\u2014often called 'flows'\u2014to model complex probability distributions and enable efficient sampling, density estimation, and data transformation. These models are grounded in the idea of transforming simple, prior distributions (like Gaussian) into complex data distributions through a series of learned, invertible functions, allowing exact likelihood computation and flexible modeling of data structures.",
      "categoryId": "8e501b08-14ea-4c6c-bbe8-0e8a0c7dfa17",
      "subcategoryIds": [
        "a48f5302-7c7f-493a-a7a0-e648af878063",
        "57202a5b-09b0-4d88-afb6-3cf302f52828",
        "94cd104c-0afb-4c96-bddc-2052ea685696",
        "cdd23d8e-f7b9-4902-9b50-ece12463c342",
        "69b08c53-32ad-4a3f-aff3-72d6efb68476"
      ]
    },
    {
      "id": "59c1e340-5aa8-41d7-a7a3-6bf5b5ce79ad",
      "name": "Fluency Metrics",
      "definition": "Fluency Metrics refer to quantitative measures used to evaluate how smoothly, efficiently, and confidently a language model or AI system generates text. These metrics serve as indicators of the naturalness and coherence of AI-generated language outputs, assessing aspects such as grammatical correctness, lexical diversity, and the ease of understanding by human users. In the context of AI/ML, fluency metrics are essential tools for evaluating the quality of language generation models and ensuring that their outputs are human-like and contextually appropriate.",
      "categoryId": "9c2d686b-dc1c-4ed7-bf77-2cbe83efde08",
      "subcategoryIds": [
        "7520fdf2-df96-4f39-b4c3-53f2d8919655",
        "14579579-5636-464c-91dd-3ff3c541cb08",
        "23243f43-8bcb-41d3-acd0-03c4cf700d51",
        "adf28be7-79e6-4ef1-b8a7-eaf424779252",
        "a41a087e-25f5-4fd6-964f-5ab8427600ba"
      ]
    },
    {
      "id": "57e22d56-1836-404f-9d96-a8000d4d4c1c",
      "name": "Focal Loss",
      "definition": "Focal Loss is a specialized loss function designed to address class imbalance in machine learning tasks, particularly in object detection scenarios. It modifies the traditional cross-entropy loss by down-weighting well-classified examples, thereby focusing the training process on hard, misclassified examples. This encourages the model to learn more effectively from challenging samples, improving overall detection performance.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "399f0b5d-4aa1-47f3-a9b7-220ca272aefc",
        "c89f17ea-9f53-4364-8224-740b4849dbbc",
        "07d2d46f-f247-4cc5-80e3-aea381e010b8",
        "3e4888cd-add3-444d-a04c-f2ca8ee8063a",
        "5d38820d-77b5-4989-bb38-b887e8eb7007"
      ]
    },
    {
      "id": "22ac8214-49ad-4759-9530-cbbfd7b262dd",
      "name": "Focal Loss (already in your list as \"Focal loss\")",
      "definition": "Focal Loss is a specialized loss function designed to address the issue of class imbalance in classification tasks, particularly in object detection scenarios. It modifies the standard cross-entropy loss by emphasizing hard-to-classify examples and down-weighting the contribution of well-classified instances, thereby improving model performance on imbalanced datasets.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "399f0b5d-4aa1-47f3-a9b7-220ca272aefc",
        "3ffd7102-687d-4707-a2b6-74461b12c371",
        "3e4888cd-add3-444d-a04c-f2ca8ee8063a",
        "68fa65d9-3fdc-41d2-b6e6-5baf963c89db",
        "2b8346c2-5f83-49ca-8b92-114caa5cb2d7"
      ]
    },
    {
      "id": "e1c28bb6-ad97-4e73-bfaa-614323116302",
      "name": "Focal Loss Extensions",
      "definition": "Focal Loss Extensions refer to modifications and enhancements of the original Focal Loss function, designed to address class imbalance and improve model performance in complex classification tasks. These extensions adapt the core principles of Focal Loss to various scenarios, tailoring their focus on difficult or misclassified examples while reducing the influence of well-classified instances, thus aiding models in learning more effective representations in imbalanced datasets.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "34eba7dc-2b03-445d-be2b-589be710be82",
        "520db4ac-b075-4e9d-9b71-7184c1db5909",
        "fa46bd2f-67e3-4d01-8bb7-90fe85d43d7d",
        "4f75aab2-6a09-4264-827e-0f3a7d0a0541",
        "b06e68ad-6a06-4f80-b0ea-65be6b75265e"
      ]
    },
    {
      "id": "30447ef2-fe9e-4974-96a7-d41bbfd88cf0",
      "name": "Focal Loss Extensions Enhancements",
      "definition": "Focal Loss Extensions Enhancements refer to modifications and improvements made to the original Focal Loss function, aiming to address specific challenges or improve performance in machine learning models, particularly within the context of imbalanced datasets. These extensions often involve tuning parameters, incorporating additional mechanisms, or combining Focal Loss with other loss functions to better handle difficult examples, improve convergence, or enhance model robustness.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "531d40b1-9a34-44ac-8f35-2a2b78cc39d1",
        "8a7866e7-6068-48e0-b00f-3c19cb05aa4d",
        "fa46bd2f-67e3-4d01-8bb7-90fe85d43d7d",
        "3282f8e2-17d2-4b30-9e68-db713e61334a",
        "5e7cd7f6-5446-423b-af52-d1564d03cd6a"
      ]
    },
    {
      "id": "bff7b52a-9189-4430-b12d-fe97f9217bc0",
      "name": "Focal Loss Extensions Techniques",
      "definition": "Focal Loss Extensions Techniques refer to a set of methods and modifications developed to enhance the original focal loss function, primarily aimed at improving the training of deep learning models for tasks such as object detection, class imbalance handling, and hard example mining. These techniques modify or extend the basic focal loss to better address challenges like false positives, class imbalance, and difficult examples, thereby improving model performance and robustness in complex scenarios.",
      "categoryId": "8e501b08-14ea-4c6c-bbe8-0e8a0c7dfa17",
      "subcategoryIds": [
        "440d1e4e-4cb7-405a-82b4-39a4cdd8a65c",
        "156f3f97-b8d5-48e4-a3b7-77bc5967f6c5",
        "8f9aae04-365a-4241-99fc-2b4e1210c2b9",
        "48d53dcf-075b-4885-9ff9-d803894b688e",
        "ffbee2d8-552f-4002-bc75-b2ad4b1a10d5"
      ]
    },
    {
      "id": "909e1fc1-4446-4d4b-b0e3-bd1bda547cbe",
      "name": "Focal Loss Extensions Techniques Enhancements",
      "definition": "Focal Loss Extensions Techniques Enhancements refer to various modifications and improvements applied to the original Focal Loss function to overcome its limitations and extend its applicability. Focal Loss was initially designed to address class imbalance in object detection tasks by down-weighting easy negatives and focusing the training on hard, misclassified examples. Extensions and enhancements involve incorporating additional parameters, adaptive weighting schemes, or integrating with other loss functions to improve model performance, robustness, and convergence in diverse scenarios.",
      "categoryId": null,
      "subcategoryIds": []
    },
    {
      "id": "ac873d07-0628-4923-90c8-fe735d2036b1",
      "name": "Focal Loss for Object Detection",
      "definition": "Focal Loss is a specialized loss function designed for addressing class imbalance in object detection tasks, particularly in scenarios where there are vastly more background or easy negative examples than foreground or hard positive examples. It modifies the standard cross-entropy loss by down-weighting well-classified examples, thereby focusing more on difficult, misclassified instances. This approach enhances the training of models like RetinaNet, leading to improved detection accuracy, especially for small or hard-to-detect objects.",
      "categoryId": null,
      "subcategoryIds": []
    },
    {
      "id": "c15b232c-392e-497b-b402-d3606b7c822b",
      "name": "Focal Loss Variants",
      "definition": "Focal Loss Variants are a family of loss functions designed to address class imbalance and hard example mining in classification tasks, particularly in object detection and imbalanced datasets. These variants modify the original Focal Loss to improve model focus on challenging, misclassified, or less frequent examples by dynamically scaling the loss assigned to each example based on its predicted probability, thereby enhancing the model's ability to learn from difficult cases while reducing the influence of well-classified examples.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "46f7b48d-f7cb-442f-be7e-28d47e50574e",
        "3e4888cd-add3-444d-a04c-f2ca8ee8063a",
        "07d2d46f-f247-4cc5-80e3-aea381e010b8",
        "c89f17ea-9f53-4364-8224-740b4849dbbc",
        "3ffd7102-687d-4707-a2b6-74461b12c371"
      ]
    },
    {
      "id": "a4db2a19-4362-4884-a96b-f20b9e0aab22",
      "name": "Focal Loss Variants and Extensions",
      "definition": "Focal Loss Variants and Extensions refer to a family of modifications and enhancements to the original focal loss function, which was introduced to improve object detection models' ability to handle class imbalance and hard-to-classify examples. These variants aim to adapt the core principles of focal loss to different applications, incorporate additional parameters, or address specific challenges in training deep neural networks by modifying the loss function to focus more on difficult samples and suppress easy ones.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "46f7b48d-f7cb-442f-be7e-28d47e50574e",
        "34eba7dc-2b03-445d-be2b-589be710be82",
        "fa46bd2f-67e3-4d01-8bb7-90fe85d43d7d",
        "973965bc-bef9-48ec-8034-0fc7704fe422",
        "d7c020f4-fb99-4f6c-9ebc-cc68f0a2fa34"
      ]
    },
    {
      "id": "992ff48a-d9c1-4e0a-93c3-17afb7ede38a",
      "name": "Focal Loss Variants and Extensions Extensions",
      "definition": "Focal Loss Variants and Extensions refer to a class of modifications and improvements to the original Focal Loss function, designed to enhance the training of deep neural networks, particularly in addressing class imbalance and difficult-to-classify examples. These variants adapt the core idea of assigning different weights to hard and easy examples, enabling models to focus more on challenging cases, thus improving performance in tasks such as object detection, segmentation, and classification where class imbalance is prevalent.",
      "categoryId": "f001a980-b036-4a8b-a7b0-290e7b1c9a77",
      "subcategoryIds": [
        "9417273e-477f-46a4-88f5-bb5e6e35944e",
        "e2dcaf9e-35e3-43fb-8030-57691881a1c0",
        "87df4289-9bc5-4f6b-8459-fae13dc80623",
        "bb127a8f-0f65-4ef1-a809-b8dfe100c002",
        "7078f677-44ff-42da-a6a5-9a452029e658"
      ]
    },
    {
      "id": "ca95115a-0d6f-420a-a9b0-de0f362177a5",
      "name": "Focal Loss Variants and Extensions Techniques",
      "definition": "Focal Loss Variants and Extensions Techniques refer to a collection of loss functions and methodological adaptations designed to address specific challenges in training machine learning models, particularly in object detection and class imbalance scenarios. These techniques build upon the original Focal Loss, introducing modifications such as class-specific adjustments, multi-scale extensions, and adaptive weighting schemes to improve model performance in complex tasks involving difficult or minority class samples.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "46f7b48d-f7cb-442f-be7e-28d47e50574e",
        "34eba7dc-2b03-445d-be2b-589be710be82",
        "2e9ca9e9-4b4d-48d9-8a81-85d2832c4624",
        "973965bc-bef9-48ec-8034-0fc7704fe422",
        "3282f8e2-17d2-4b30-9e68-db713e61334a"
      ]
    },
    {
      "id": "4e54846d-7853-42e9-b807-1be48c7635cb",
      "name": "Forced decoding",
      "definition": "Forced decoding is a technique used in sequence-to-sequence models, particularly in natural language processing tasks such as machine translation and speech recognition. It involves using the true, ground-truth output sequence (or a partially correct sequence) as part of the decoding process during training, rather than relying solely on the model's own predictions. This approach helps stabilize training by guiding the model towards correct output sequences and reducing the impact of accumulated errors that can occur during autonomous decoding.",
      "categoryId": "9c2d686b-dc1c-4ed7-bf77-2cbe83efde08",
      "subcategoryIds": [
        "7d03feca-5798-49a9-8721-a33b35c5170a",
        "bff2de96-3d19-4cce-ab9c-4e6858489471",
        "05517f8c-44d8-443e-81e6-047173397cd8",
        "bacded76-f6e7-44d3-874c-a2e42ba23ec0",
        "da33ba6d-243b-432f-9d65-54c0cb1059f2"
      ]
    },
    {
      "id": "eb1898e6-8957-4c36-befe-c611fdbd889e",
      "name": "Forecasting",
      "definition": "Forecasting in AI and machine learning refers to the process of predicting future data points, trends, or outcomes based on historical data. It involves analyzing temporal data to estimate future values, aiding in decision-making across various domains such as finance, weather prediction, supply chain management, and more. By leveraging statistical models, machine learning algorithms, and deep learning techniques, forecasting aims to provide accurate and reliable predictions that inform strategic planning and operational efficiency.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "0dac0fc4-3a0b-4015-8cb2-76db144a0970",
        "d7b2af52-d528-43e6-a17f-d59cbbeabebe",
        "a19c9ec7-daa8-4402-a3b1-df9a55f4246b",
        "8b1416d4-5e3b-4bf1-9388-57fb3e629843",
        "a565f81c-6ebe-4b7b-abe0-4ed6ad9abefb"
      ]
    },
    {
      "id": "91af450e-7003-4358-91dc-68c2e6ec093b",
      "name": "Forest Fire Model",
      "definition": "The Forest Fire Model is a type of cellular automaton used to simulate the spread of forest fires within a forested landscape. It employs a grid-based system where each cell represents a tree or an empty space, and the fire propagates based on state transitions governed by simple rules. This model serves as a simplified abstraction to study complex phenomena such as wildfire dynamics, propagation patterns, and the conditions that influence fire spread.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "720cae1b-2d91-4570-a3a6-137918aaf756",
        "bab81fff-07a6-463f-9b7c-dd33496cac8f",
        "403f5211-7e0f-476b-a598-44320a0bd409",
        "8ad22e67-0f72-40d2-9cab-16be05d66a53",
        "61eabdb8-0e94-4c81-bfc8-c77fbab77b2d",
        "33e748fe-6f4e-403f-8a61-6ca9b9ed13c7",
        "e1e8a3b5-9acf-4878-be2c-72759231f580",
        "68a8448f-cf78-4840-bfce-e437ec7ec034",
        "9c503921-3a2e-4d43-8c3d-1b4e613d2f3f",
        "cb75937e-b06c-4697-9e03-e9f0241a32e3"
      ]
    },
    {
      "id": "4b2989d1-566d-41ac-82cb-f86640235a62",
      "name": "Formal Concept Analysis",
      "definition": "Formal Concept Analysis (FCA) is a mathematical framework and method for data analysis that facilitates the discovery of inherent relationships and groupings within data sets. It is based on lattice theory and provides a systematic way to derive conceptual hierarchies from data, typically represented through formal contexts. FCA enables the identification of formal concepts, which are pairs consisting of a set of objects and a set of attributes that precisely describe a particular grouping, thus revealing the conceptual structure of data in an interpretable form.",
      "categoryId": "3e4c5e60-7266-4d25-8242-b6f3b9a4b190",
      "subcategoryIds": [
        "0edf077b-d37f-4a83-b98e-c5cee88589a6",
        "043be617-2cbb-4fac-9cc9-d6415fbc4ebd",
        "68257faa-dc39-4603-aed4-a72a6a9b00ad",
        "9feb9273-4eee-47e9-a0d1-e266cca8dd42",
        "b7450a52-e083-4b4c-9c38-7380357662d0"
      ]
    },
    {
      "id": "f51b8f1b-3e76-4ae2-b8a0-4f1008df5448",
      "name": "Forward and Inverse Reinforcement Learning",
      "definition": "Forward and Inverse Reinforcement Learning are two advanced paradigms within the field of reinforcement learning that focus on understanding and inferring decision-making policies. Forward Reinforcement Learning involves an agent learning a policy to maximize cumulative reward through interactions with an environment. Inverse Reinforcement Learning, on the other hand, aims to deduce the underlying reward function or objectives that an expert agent appears to optimize, based on observing its behavior. These techniques are essential for applications where explicit reward functions are difficult to specify, but expert demonstrations are available, facilitating the development of intelligent systems that learn from human or expert behaviors.",
      "categoryId": "68a5cba0-fded-4081-b8ab-4e9e975b8706",
      "subcategoryIds": [
        "b204675e-95df-41a1-9b31-b7d94221f09b",
        "ec22789c-c449-4f07-9b1b-e61730384fcb",
        "54e7121c-bc11-48ad-88b6-8654c6248c52",
        "f82407aa-1b01-4d0b-9b8b-1ea2df162606",
        "4ae29e50-6a1a-4e9e-863b-1c5a3522f039"
      ]
    },
    {
      "id": "33764a87-978e-468c-8e8b-2dca1a6e6bb2",
      "name": "Forward Chaining",
      "definition": "Forward chaining is a method used in rule-based systems and expert systems within artificial intelligence to derive conclusions or make decisions. It operates by starting with known facts or data and applying inference rules sequentially to infer new facts, progressing forward toward a goal. The process continues until the goal is achieved or no further inference is possible, effectively working in a data-driven manner to build up conclusions from existing information.",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1",
      "subcategoryIds": [
        "0452d4bc-5397-4db2-a43a-f0afb34a9688",
        "0f2a13a9-0897-4218-8339-70906555f9da",
        "7c1a240f-6619-465d-9833-615eb952fb20",
        "e50bb273-c8d7-4cbf-a3ae-e9e08e9106d6",
        "a2e12fc1-02bf-48f7-bda8-a9e9d2b97827"
      ]
    },
    {
      "id": "7566ae39-9163-4a94-9158-2c038387ea5c",
      "name": "Forward Diffusion Process",
      "definition": "The Forward Diffusion Process is a fundamental concept in generative modeling, particularly within diffusion-based generative models. It describes the process of gradually adding random noise to a data sample over a series of steps, transforming it into pure noise. This process is inverted during generation, where noise is systematically denoised to produce new data samples that resemble the original data distribution. Essentially, forward diffusion models how data degrades with added noise, serving as a preparatory step for the reverse process that generates new data.",
      "categoryId": "62590c8a-eeee-4408-b5ec-71614f20da3d",
      "subcategoryIds": [
        "eeebe374-3802-491d-8dd5-7b73067d7a4e",
        "6d3e3289-f175-4e7b-9abf-8333f4291fe3",
        "2f20476b-92ce-4f6b-9938-86be90b6f2f8",
        "b7d3db7f-b813-4456-9525-0f5a00afde39",
        "fcabc1dc-b655-49bd-9710-22b714f6ae97"
      ]
    },
    {
      "id": "73132cbe-25ca-4bc9-9ee9-298a0d1fc4b5",
      "name": "Forward Pass",
      "definition": "The 'Forward Pass' in AI/ML refers to the process of propagating input data through a neural network to generate an output or prediction. It involves computing the output of each neuron or layer by applying mathematical operations such as weighted sums followed by activation functions, moving sequentially from the input layer to the output layer. This process is fundamental in prediction tasks, enabling the model to transform raw data into meaningful results.",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38",
      "subcategoryIds": [
        "eaf47bb2-e211-49c6-ab68-17da87ccc419",
        "44fbdd23-5eec-422c-b223-f6bf0493d6fa",
        "c71a3022-4886-4a54-851a-17e5325b3a1b",
        "a62f0a0a-208b-478b-a998-5c37057322e3",
        "0edb723a-8aee-46c6-a8fb-22b5b3a82365"
      ]
    },
    {
      "id": "f4c33a3f-997e-43cb-941b-efbd637e7e06",
      "name": "Foundation Model",
      "definition": "A Foundation Model is a large-scale, pre-trained machine learning model that has been trained on broad, diverse datasets and can be adapted to a wide range of downstream tasks with minimal additional training. These models serve as versatile bases for many applications, enabling developers to leverage extensive pre-existing knowledge encoded within them, thereby reducing the need to train models from scratch for specific tasks.",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38",
      "subcategoryIds": [
        "b5bbbd59-7e62-4168-b005-4c3985d2778a",
        "4aff76ce-31cf-4101-8dd1-aeedbd2f522a",
        "dd4ea1a2-f336-48e4-8f8b-b60450a7b109",
        "44fbdd23-5eec-422c-b223-f6bf0493d6fa",
        "89854309-3160-47ce-8cae-070aa916fdc1"
      ]
    },
    {
      "id": "ec25c753-47c5-440b-b9c7-4d27a278bb75",
      "name": "foundation model-based segmentation",
      "definition": "Foundation model-based segmentation refers to the application of large-scale, pre-trained foundational models\u2014such as those based on transformer architectures\u2014to the task of segmenting images, videos, or other data modalities. These models serve as versatile backbone frameworks that can be fine-tuned or adapted to produce precise and context-aware segmentation masks, effectively enabling the automated delineation of objects, regions, or features within complex data. This approach leverages the extensive knowledge encoded in the foundation models to improve segmentation accuracy, robustness, and generalization across diverse datasets and tasks.",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38",
      "subcategoryIds": [
        "96d4d033-f428-4ea7-9c34-2a01daa28884",
        "b6a56d63-07c4-496e-9257-9a038cba90ef",
        "0b3ae715-d1c5-4233-b3a3-e26d930adc87",
        "d2ee9f2d-d5ab-4736-8403-0d3b26b68a77",
        "7c1443d7-de0c-4e96-a1b8-e19a6a92f234"
      ]
    },
    {
      "id": "efb919c8-f53c-4462-b83e-b53274fbd489",
      "name": "Foundation Models",
      "definition": "Foundation Models are large-scale machine learning models trained on broad, diverse datasets that serve as a base for a wide range of downstream tasks. These models are designed to learn general representations of data, enabling them to be fine-tuned or adapted to specific applications with minimal additional training. Examples include models like GPT, BERT, and CLIP, which can perform various natural language processing, computer vision, and multimodal tasks effectively across multiple domains.",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38",
      "subcategoryIds": [
        "c436de57-4333-47b6-bfee-02aa25d7fbb7",
        "fc36f5e7-1074-4d81-a41b-f5b8f3522221",
        "44fbdd23-5eec-422c-b223-f6bf0493d6fa",
        "89854309-3160-47ce-8cae-070aa916fdc1",
        "7c1443d7-de0c-4e96-a1b8-e19a6a92f234"
      ]
    },
    {
      "id": "40b06e65-07d1-46e2-9962-884d1e81a4b0",
      "name": "Foundational AI Model",
      "definition": "A Foundational AI Model refers to a large-scale, pre-trained artificial intelligence model that is designed to serve as a general-purpose platform for various downstream tasks across multiple domains. These models are typically trained on massive datasets and encapsulate broad knowledge, enabling them to be fine-tuned or adapted for specific applications such as language understanding, image recognition, or other AI tasks. They act as the base upon which specialized AI systems can be built, reducing the need for training from scratch and accelerating development processes in AI/ML.",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38",
      "subcategoryIds": [
        "ebe00f5f-aee9-4961-988e-bb52d0f73448",
        "351ad74d-b16f-435f-b61e-c0b145807c8b",
        "48969b49-e42f-453e-824b-2046d5a236a8",
        "7b582048-fc5f-4ff3-82c0-2c9acf397c14",
        "60904928-3e0f-43c1-a1d1-f7c2e8d5eb3c"
      ]
    },
    {
      "id": "8ab90646-4e00-4d6d-b01d-0d2b7fd6fd11",
      "name": "Fourier Features",
      "definition": "Fourier Features refer to a technique in machine learning and signal processing where data is transformed into a feature space using Fourier basis functions. This approach involves projecting input data onto a set of sinusoidal functions (sines and cosines) with varying frequencies, enabling the model to effectively capture and represent complex patterns and periodicities within the data. Fourier Features are commonly employed to enhance the expressiveness of models, particularly in tasks requiring the modeling of high-frequency components and long-range dependencies.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "7029cf5d-a3c4-46a8-a789-a486607ca1ca",
        "8d9e8ad8-efa0-47ad-b762-57153d72955c",
        "eb2703ff-cc93-4895-9569-0b8e54742696",
        "d24dd52f-003b-4df5-8e30-e1ac8ad0b850",
        "608b3750-2570-4c52-906f-c01cf20e05fc"
      ]
    },
    {
      "id": "9957e0ed-5090-47ff-97a0-c93ad8419229",
      "name": "Fourier Features in Neural Networks",
      "definition": "Fourier features in neural networks refer to a technique where input data is mapped into a high-dimensional space using sinusoidal functions based on Fourier transformations. This approach leverages the properties of Fourier transforms to enable neural networks to better capture and represent high-frequency variations and intricate patterns within the data, thereby enhancing the model's expressive capacity and generalization, especially in tasks involving signals, images, and other complex data distributions.",
      "categoryId": "2b22b5bb-853f-4223-b261-3529a749faa5",
      "subcategoryIds": [
        "ff30c244-b37e-4030-a75c-2e7e5346d98d",
        "2a6095cf-35c8-43de-85ae-030eeb712f8d",
        "084037c6-aefe-47e6-8a4c-e09f298f0bfb",
        "ad0ad4f3-d588-4337-8d09-6d0f15c89400",
        "e4c6bde1-e37d-4a37-984a-b172ef6ffd41"
      ]
    },
    {
      "id": "a351af41-98e7-4fd5-bf95-98e7d2aeb0ec",
      "name": "Fourier Neural Operator",
      "definition": "The Fourier Neural Operator (FNO) is a type of neural network architecture designed for efficiently learning mappings between functions, particularly those governed by partial differential equations (PDEs). It leverages Fourier transforms to capture global information and facilitate faster, more accurate approximations of complex functional relationships across different domains. FNOs are especially useful in scientific computing, physics-informed modeling, and numerical simulations where traditional neural networks may struggle with high-dimensional data or require extensive computational resources.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "9effa62d-67f4-444d-a608-939315cf3b51",
        "77427602-fb3e-4eb1-961f-85228fcd2332",
        "97036176-e7b0-4d87-b532-6c503bcf02dd",
        "bdeb1ffa-765e-476d-848b-cc2f59e15dda",
        "09c41ca5-5d87-4619-a486-9ff5c7ebb456"
      ]
    },
    {
      "id": "547004d0-fc23-4f85-bc45-9cd1e4e32daa",
      "name": "Fourier Neural Operators",
      "definition": "Fourier Neural Operators (FNOs) are a class of deep learning models designed to learn mappings between infinite-dimensional function spaces. They extend the concept of neural operators by incorporating Fourier transforms to efficiently capture integral and differential operators. This approach enables FNOs to model complex physical systems described by partial differential equations (PDEs) with high accuracy and computational efficiency, making them powerful tools for tasks such as simulation, modeling, and control in scientific computing.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "7c85f82c-279b-4279-b456-e15bb86eda5d",
        "77427602-fb3e-4eb1-961f-85228fcd2332",
        "97036176-e7b0-4d87-b532-6c503bcf02dd",
        "a770b0dc-c167-42c4-988e-9b7495563d24",
        "e20ed8d3-19c3-46a2-ade6-a3dc8924b5d0"
      ]
    },
    {
      "id": "e5f23193-9ef7-474c-87b2-bd22d7d61ba3",
      "name": "Fourier Neural Operators Enhancements",
      "definition": "Fourier Neural Operators (FNOs) are a class of neural network architectures designed to approximate solutions to partial differential equations (PDEs) efficiently. They leverage Fourier transforms to parameterize integral operators, enabling the neural network to learn mappings between infinite-dimensional function spaces. Enhancements of Fourier Neural Operators refer to recent modifications and improvements aimed at increasing their accuracy, computational efficiency, and applicability to complex or high-dimensional PDE problems. These enhancements often include advanced spectral methods, improved network architectures, and optimized training techniques that extend the capabilities of the original FNO framework.",
      "categoryId": "2bd8b40c-79f5-4b84-813f-a70ebe2d5360",
      "subcategoryIds": [
        "e6634ca6-dc2d-405e-a61d-f98139c02001",
        "8a14aefa-dbf5-4440-a223-98b8109dea21",
        "2ea66079-7712-44cb-a9c3-46d11d25b60b",
        "5df44f83-2802-4dca-ab3a-0f5f4e52a37a",
        "53ffc314-2de5-46ab-9a7d-56b70ba1ddd6"
      ]
    },
    {
      "id": "4b0fa52b-e1ca-4b5f-a2f5-8bfcd1d03f0f",
      "name": "Fourier Neural Operators Extensions",
      "definition": "Fourier Neural Operators (FNOs) are a class of neural network architectures designed to efficiently learn operators that map between infinite-dimensional function spaces. They extend traditional neural networks by incorporating Fourier transforms to handle complex, high-dimensional problems such as solving partial differential equations (PDEs). The 'extensions' of Fourier Neural Operators refer to various modifications and enhancements aimed at improving their accuracy, efficiency, and applicability across different types of problems and data regimes.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "97036176-e7b0-4d87-b532-6c503bcf02dd",
        "a3c00a97-9243-49dd-9d58-a32bcc82802b",
        "edffd131-fd6a-4398-b0fb-f86572de4957",
        "cd9577ab-2712-4bc2-a1ec-3bdbc0be4155",
        "7f19d104-aea0-49bb-a63e-fb2280c13428"
      ]
    },
    {
      "id": "77934ae0-f69c-44a8-acba-fb54c7f63a77",
      "name": "Fourier Neural Operators Techniques",
      "definition": "Fourier Neural Operators (FNOs) are a class of neural network architectures designed to efficiently learn mappings between functions, especially those arising in the context of partial differential equations (PDEs). They leverage the Fourier transform to operate in the frequency domain, enabling the models to capture global and multiscale features of functions. Unlike traditional neural networks that approximate pointwise mappings, FNOs are capable of learning operators that map entire functions to other functions, making them highly effective for parametric PDE problems, model reduction, and scientific computing applications.",
      "categoryId": null,
      "subcategoryIds": []
    },
    {
      "id": "26146ce7-4359-41ec-98af-0011869953ae",
      "name": "Fourier Neural Operators Techniques Enhancements",
      "definition": "Fourier Neural Operators Enhancements refer to advanced techniques and modifications applied to Fourier Neural Operators (FNOs), which are a class of machine learning models designed to efficiently learn mappings between infinite-dimensional function spaces. These enhancements aim to improve the accuracy, scalability, and generalization capabilities of FNOs, enabling them to solve complex partial differential equations (PDEs) and related scientific computing tasks more effectively. By integrating additional methods such as improved spectral representations, multi-resolution analysis, or hybrid architectures, these techniques push the boundaries of FNO performance and applicability in various scientific and engineering domains.",
      "categoryId": "2bd8b40c-79f5-4b84-813f-a70ebe2d5360",
      "subcategoryIds": [
        "328c7b33-a1fb-49bd-a2a8-baad831edaef",
        "8a14aefa-dbf5-4440-a223-98b8109dea21",
        "2ea66079-7712-44cb-a9c3-46d11d25b60b",
        "fd1b802d-75aa-4296-ae3a-45c2aa62fbd7",
        "6116a152-90c1-43b7-a9a2-b2d0fcd2c4a2"
      ]
    },
    {
      "id": "55ea56cb-ca85-4d71-8f5b-175a791ab980",
      "name": "Fourier Neural Operators Techniques Extensions",
      "definition": "Fourier Neural Operators (FNOs) are a class of advanced neural network architectures designed to efficiently learn mappings between functions, especially in the context of solving partial differential equations (PDEs). They extend traditional neural networks by integrating Fourier transforms within the model structure to capture complex, multiscale patterns in data. By leveraging Fourier transforms, FNOs enable the neural network to handle high-dimensional, continuous spatial-temporal data directly, making them powerful tools for simulating physical systems, fluid dynamics, and other scientific computing tasks.",
      "categoryId": null,
      "subcategoryIds": []
    },
    {
      "id": "4eda5ab0-5e12-4fd2-90ee-f2359c323ad5",
      "name": "Fourier Neural Operators Techniques Extensions Techni...(truncated 32118 characters)...xical semantics embeddings",
      "definition": "Fourier Neural Operators (FNOs) are a class of neural network architectures designed to efficiently learn mappings between functions, particularly in the context of solving parametric partial differential equations (PDEs). These models extend traditional neural networks by incorporating the Fourier transform to operate directly in the frequency domain, enabling rapid and accurate approximations of solutions to complex mathematical problems. The goal of FNOs is to combine the strengths of neural networks and spectral methods, facilitating their application to high-dimensional, continuous problems prevalent in scientific computing and engineering simulations.",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38",
      "subcategoryIds": [
        "805dbf01-b8eb-4462-a124-5bd7d364ad7f",
        "27000128-d1d6-4c84-9bb9-9990b1d3a64a",
        "1166af08-8173-4e62-8f38-f7c011a34fcb",
        "26b605fd-3f04-421d-8b55-0578f03c4c45",
        "818f8a69-cdd3-46a0-84e5-7317034d9010"
      ]
    },
    {
      "id": "6da8be31-e712-475e-859c-6cc018e2331e",
      "name": "Fourier Neural Operators Techniques Extensions Techniques",
      "definition": "Fourier Neural Operators (FNOs) are a class of machine learning models that leverage the mathematical framework of Fourier transforms to efficiently learn solution operators of Partial Differential Equations (PDEs). Extensions and techniques associated with Fourier Neural Operators involve various methods aimed at improving their accuracy, efficiency, and applicability to complex problems. These techniques include modifications to the neural network architecture, integration of multi-scale features, incorporation of physics-informed constraints, and adaptations to handle non-linear or high-dimensional problems, thereby broadening the scope and performance of FNOs in scientific computing and AI applications.",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1",
      "subcategoryIds": [
        "a7f02e9a-cca5-42f5-91a7-b035f8794474",
        "cfb6b232-af70-4e94-89cb-fbc2132140fe",
        "e4f1a9de-654c-45fb-8972-5ddf9739c13f",
        "f41ab917-9023-4063-870c-b1cfbc8aedb8",
        "69804a22-5ab0-4944-8e12-d26a5e0ad0e4"
      ]
    },
    {
      "id": "676eb257-27ff-4631-a62b-a677da59c495",
      "name": "Fourier Neural Operators Techniques Extensions Techniques Enhancements Techniques",
      "definition": "Fourier Neural Operators (FNOs) are an innovative class of neural network architectures designed to efficiently learn operators that map between infinite-dimensional function spaces. They extend traditional neural network capabilities by incorporating Fourier transforms to capture global frequency information, enabling the modeling of complex, nonlinear, and high-dimensional partial differential equations (PDEs). Techniques, extensions, and enhancements related to Fourier Neural Operators refer to various improvements, modifications, and adaptations aimed at increasing their accuracy, efficiency, robustness, and applicability across different scientific and engineering domains, often involving novel architectures, training algorithms, or integration with other AI methods.",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38",
      "subcategoryIds": [
        "90020ff5-1a88-4179-8184-3f946cc0282d",
        "831812cd-b79a-4496-b8d3-48c3157e6640",
        "1f5c1df3-1e8e-4a13-b2f4-b6e0b24069a4",
        "ccc1a144-fe67-4a0e-8228-638f629a9a9e",
        "25e9c249-de44-43c7-a877-3090643e7bf8"
      ]
    },
    {
      "id": "c9003168-a1a6-46a5-bd9a-d2a1d3f7d204",
      "name": "Fourier Transform in CNNs",
      "definition": "The Fourier Transform in CNNs refers to the application of Fourier analysis techniques to convolutional neural networks (CNNs). It involves transforming data, such as images or feature maps, from the spatial domain into the frequency domain. This transformation allows for more efficient processing, analysis, and understanding of the frequency components within the data, which can enhance various tasks like feature extraction, filtering, and model efficiency.",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1",
      "subcategoryIds": [
        "288adc51-8347-43e4-ae30-bba27a20a6b5",
        "f1a3b404-894e-41b4-9d5d-509b4c3cc1dd",
        "da9e7ef5-f58d-4f0d-938c-dc16898c4127",
        "e3c9d0a0-6022-4992-a349-da41e1ff7af7",
        "770e5216-f145-4a60-93f5-95a554af63b6"
      ]
    },
    {
      "id": "13179a49-089d-401b-bb54-0dd29c91bcb4",
      "name": "Fowlkes-Mallows Index",
      "definition": "The Fowlkes-Mallows Index is a statistical measure used to evaluate the similarity between two clusterings or partitions of a dataset. It quantifies the agreement between the clusters by considering the number of pairs of points that are either clustered together or separated in both partitionings. The index ranges from 0 to 1, where a value closer to 1 indicates higher similarity, and a value near 0 reflects dissimilar clusterings. This metric is widely used in clustering validation to assess the quality of clustering algorithms and their results.",
      "categoryId": "de8842d5-eb45-4c4d-b8f3-15f9a39657f4",
      "subcategoryIds": [
        "434a6b76-d87b-436e-a9e6-7d3c804dd4af",
        "97d5a2aa-f632-4799-8547-3a189b8aa0cd",
        "4cd7e9f5-808d-4006-945c-561fae84f308",
        "91d18692-e830-4291-a4e4-8783780e78a0",
        "59e42d62-4e5d-452c-895f-b5bd6e6c2c2b"
      ]
    },
    {
      "id": "608b3a8c-54f1-4f5f-bf9b-35a84165afd4",
      "name": "FP-Growth Algorithm",
      "definition": "The FP-Growth (Frequent Pattern Growth) Algorithm is a popular data mining technique used for discovering frequent itemsets within large transactional databases. Unlike traditional algorithms such as Apriori, FP-Growth employs a compact data structure called the FP-tree to efficiently compress the database, enabling faster discovery of frequent patterns without candidate generation. This method is particularly effective for market basket analysis, where identifying items that frequently co-occur can inform decision-making and strategic planning.",
      "categoryId": "f4a166e4-92f8-4e53-bbd2-66c352a23c5e",
      "subcategoryIds": [
        "c2ea442e-e554-4e3d-a8ee-4788e283f06e",
        "e40d54c8-695c-497d-8f93-287e4d502e95",
        "3606be39-a025-4128-a7b8-0d4f126a17b4",
        "6c227fc9-f93d-43cc-a2c0-e3429bf64047",
        "c803e3cd-c958-4c72-aa47-c307993ae423"
      ]
    },
    {
      "id": "f29daeeb-2799-44d5-abca-68cd7ee7b9ce",
      "name": "fp16 quantization",
      "definition": "FP16 quantization, also known as half-precision floating-point quantization, is a technique used to reduce the numerical precision of floating-point values in neural network models from 32-bit single-precision (FP32) to 16-bit (FP16). This process involves converting model parameters, activations, and weights to FP16 format, thereby decreasing memory usage and computational load. By employing FP16 quantization, models can run faster and more efficiently, especially on hardware that supports half-precision operations, without significantly compromising accuracy in many cases.",
      "categoryId": "8e501b08-14ea-4c6c-bbe8-0e8a0c7dfa17",
      "subcategoryIds": [
        "2bd5cd9a-4544-4bb1-973e-4df22959431b",
        "3234b5b7-ec8d-4442-90b5-3dbce7c7ec56",
        "f2e979ac-0e96-4314-8779-9d30593e7ec0",
        "c1f0a55e-645c-485b-a51d-49803323d374",
        "cc1fe632-a197-464c-ae0c-fc42334681cd"
      ]
    },
    {
      "id": "408d6692-bcc3-42a3-9c66-dc9423331075",
      "name": "FPGAs for AI",
      "definition": "FPGAs (Field-Programmable Gate Arrays) are integrated circuits that can be configured by a customer or a designer after manufacturing, enabling tailored hardware acceleration for various tasks. In the context of AI, FPGAs are utilized to execute neural networks and other computationally intensive algorithms with high throughput and low latency, often outperforming traditional CPUs and even GPUs in certain applications. They offer a flexible platform for deploying AI models directly in hardware, facilitating rapid customization and optimization for specific AI workloads.",
      "categoryId": "b8efc3ce-ee01-45f6-98b1-b4f2f8403af6",
      "subcategoryIds": [
        "7a5d363f-ed0f-4f99-9d18-154aaa91a6e3",
        "cafdc916-4de3-428a-aa0f-167414fc6ba9",
        "e022f1be-e09e-4a41-935a-1d21d0174ef0",
        "7d23c6fa-5c6e-454b-90b3-88fdd52d32e9",
        "1c5fd97e-ae20-46e7-a91d-41b302a2793a"
      ]
    },
    {
      "id": "65b0cd50-89e7-4a2b-bde5-2472d94ac026",
      "name": "Fractal Network Models",
      "definition": "Fractal Network Models are a class of computational frameworks that incorporate the principles of fractal geometry into the design and analysis of neural networks and other AI architectures. These models utilize self-similar, recursive structures to represent complex, hierarchical, and irregular patterns found in data, allowing for efficient modeling of intricate natural phenomena and complex systems. They often mimic the fractal patterns observed in nature, such as coastlines, snowflakes, and vascular systems, enabling more flexible and robust learning representations.",
      "categoryId": null,
      "subcategoryIds": []
    },
    {
      "id": "05b015a1-8d9c-4244-8c65-bdf31a11c244",
      "name": "Fractal Networks",
      "definition": "Fractal Networks refer to neural network architectures that incorporate fractal geometries or self-similar patterns into their design. These networks utilize fractal principles to enable multiscale feature extraction, hierarchical organization, and efficient parameter sharing. By embedding fractal structures within neural architectures, they aim to capture complex, multiscale patterns in data more effectively than traditional architectures, often resulting in improved learning capabilities and generalization.",
      "categoryId": null,
      "subcategoryIds": []
    },
    {
      "id": "b3fc2739-d39d-4ca3-b8e6-4dc0c9b458ec",
      "name": "Fractional Calculus",
      "definition": "Fractional Calculus is a branch of mathematical analysis that extends the concepts of derivatives and integrals to non-integer (fractional) orders. Unlike traditional calculus, which deals with integer-order differentiation and integration, fractional calculus allows for derivatives and integrals of arbitrary, non-integer orders, providing a powerful tool for modeling complex, memory-dependent, and anomalous processes. It encompasses various definitions, such as the Riemann-Liouville, Caputo, and Gr\u00fcnwald-Letnikov formulations, each suited to different applications and problem types.",
      "categoryId": "0bf30cf3-9e76-4a60-bafa-42b77b5eb474",
      "subcategoryIds": [
        "5fcd55f1-942a-4d0f-b2f2-3bbdf92c5ecd",
        "cbdbee02-b615-42b7-9b4c-bcd64ef6ad72",
        "766b7b97-0eca-4ccb-a081-cdd5b26b8490",
        "f0521863-8a1b-486f-bb24-cf9f2697665a",
        "531212b9-f73a-4ac4-9bc8-bf05305424ee"
      ]
    },
    {
      "id": "39299f5e-73d9-44ab-8d34-9168871ce892",
      "name": "Frame Stacking",
      "definition": "Frame stacking is a technique used in machine learning, particularly in processing sequential data such as audio or video signals. It involves combining multiple consecutive frames or data slices into a single, extended feature vector. This approach allows models to leverage temporal context, capturing the dynamics and transitions between frames more effectively than considering each frame independently.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "01d1df87-6e06-45e1-8443-d4fe95ab67b0",
        "3bcad920-efbc-4dbf-a3e5-e47f74e7e24d",
        "6150643a-e0ed-4b9d-95d9-5f4ab0e69a78",
        "79c1dcd8-1d8e-4e3f-a192-f910a9c72bb4",
        "a1ad0275-7b39-4d7c-bf6c-9143f49e7bb7"
      ]
    },
    {
      "id": "e96dbc2b-435e-48cf-babc-906bcb64a336",
      "name": "Frame-based Representation",
      "definition": "Frame-based Representation is a symbolic knowledge representation technique used in artificial intelligence to model and organize information about the world. It employs structures called 'frames' to encapsulate stereotyped data about objects, situations, or concepts, including attributes (slots) and their associated values, as well as relationships between frames. This approach allows AI systems to simulate human-like understanding by structuring knowledge in a way that captures various aspects of entities and their interconnections systematically.",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1",
      "subcategoryIds": [
        "e4af570a-2b16-49e1-a7ea-476fbb20d910"
      ]
    },
    {
      "id": "4745e823-d58a-49f6-ad7d-4cab7341ff92",
      "name": "Fr\u00e9chet Inception Distance (FID)",
      "definition": "Fr\u00e9chet Inception Distance (FID) is a quantitative metric used to evaluate the quality of images generated by generative models, such as Generative Adversarial Networks (GANs). It measures the similarity between the distribution of generated images and real images by calculating the Fr\u00e9chet distance (also known as Wasserstein-2 distance) between their feature distributions. In practice, features are extracted from a pre-trained Inception network, and the mean and covariance of these features are compared to assess how closely the generated images mimic real data in terms of visual quality and diversity.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "6cc2794b-837e-4697-a617-ac5554db873f",
        "4dd88458-186a-4127-a208-9c243598b4d4",
        "62ea1f24-abc5-46d9-842b-d41ff25ac1dc",
        "14a74e59-9fd1-412d-a29d-34a5123cf7ed",
        "b0f89030-4291-47f6-89b7-454435c911e4"
      ]
    },
    {
      "id": "1e80a547-0191-4fa2-bceb-1f74629905d8",
      "name": "Frequency Based Algorithm",
      "definition": "A Frequency Based Algorithm is a type of algorithm that analyzes data by examining the frequency at which certain events, patterns, or elements occur within a dataset. These algorithms leverage statistical measures of frequency to identify, classify, or predict outcomes based on how often specific features or signals appear. Commonly used in areas like signal processing, pattern recognition, and data mining, frequency-based algorithms are fundamental in extracting meaningful insights from large volumes of data by focusing on the prevalence of specific attributes.",
      "categoryId": null,
      "subcategoryIds": []
    },
    {
      "id": "776a81ec-d5ee-4146-a9d6-f00bd75d0152",
      "name": "Frequency Encoding",
      "definition": "Frequency Encoding is a categorical data encoding technique used in machine learning to convert categorical variables into numerical format by replacing each category with its corresponding frequency or count within the dataset. This method transforms categories into numerical values based on how often they appear, facilitating their use in algorithms that require numerical input.",
      "categoryId": "316ca6bb-f333-42fa-bb20-ddc3944c0961",
      "subcategoryIds": [
        "d30519ae-b610-4ac6-a7b6-d9e9689071d8",
        "ef6d3977-585b-4c1b-9d39-ae9e99d16b18",
        "1cc08efe-13c7-46e6-819b-72c37291c7d9",
        "f1d0d618-9704-4200-b7da-7ef7e5272a41",
        "f5b07a84-7532-4bdc-84ad-ff3456f8fc55"
      ]
    },
    {
      "id": "036af7d5-ffd1-4c85-a891-246117cfc480",
      "name": "Frequency Penalty",
      "definition": "Frequency Penalty is a parameter used in natural language processing models, particularly in text generation tasks, to influence the diversity of the generated outputs. It functions by adjusting the likelihood of repeated tokens or phrases, effectively penalizing the model for generating the same or similar tokens multiple times. By modulating this penalty, developers can control the repetitiveness of the output, encouraging more varied and creative responses from the language model.",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1",
      "subcategoryIds": [
        "c7661545-2da5-4cf7-83dc-655f04f7e13a",
        "4795d07c-f55a-44a7-abe6-6c281cf87a6b",
        "66a4a8f8-1249-4238-af3c-4cbb6fbda9d0",
        "5fd6193c-74a7-4df4-9f17-8a2e3aa4cbf9",
        "55808d82-17ad-411b-bfcc-c4e6455f52bc"
      ]
    },
    {
      "id": "890c44fa-bf0c-41fb-befc-9736da8174e5",
      "name": "frequency thresholding",
      "definition": "Frequency thresholding is a technique used in data preprocessing and feature selection within AI and machine learning workflows. It involves setting a minimum frequency count or proportion for feature occurrence, such as words in text data or categorical variables in structured data. Features that occur less frequently than this threshold are discarded, under the assumption that infrequent features may contribute noise, cause overfitting, or have limited predictive power. This method helps in reducing dimensionality, improving computational efficiency, and enhancing model performance by focusing on more representative and informative features.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "ea42938b-ab43-47ba-bad6-91e3de58e614",
        "197947bc-33d7-4715-9931-619ddd440adb",
        "3cdb3439-4c9a-41eb-bc61-b1f36b6377c2",
        "c74120e9-9918-40c5-abc5-d5059bb9634d",
        "945b606f-5af9-48f3-864b-89cf8d2fd5f4"
      ]
    },
    {
      "id": "cb8adfed-7357-4541-a8e5-a905edbae00e",
      "name": "Frequency-based algorithms",
      "definition": "Frequency-based algorithms are a class of methods in machine learning that analyze the frequency or occurrence patterns of data features, patterns, or events within datasets. These algorithms utilize statistical measures such as counting how often specific data points or patterns appear to make predictions or classifications. They are often employed in areas like natural language processing, anomaly detection, and pattern recognition, where understanding the distribution of data elements is crucial for effective decision-making.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "3af56afe-d2ba-4494-bc0b-69a128dc6dfe",
        "94b5ea03-112f-491b-ba53-c5b2ad79f47b",
        "ab7a09cb-1f32-44f2-987d-c4a9c7ab5601",
        "f7c48efe-f107-47a7-a979-d74bdd1de57b",
        "90d735e5-b431-4a61-bd38-f16c249914d1"
      ]
    },
    {
      "id": "fbb5bee9-cca1-47a5-98e9-f29c41d72a2e",
      "name": "frequency-based sampling",
      "definition": "Frequency-based sampling is a data selection technique in which data points are sampled according to their frequency or occurrence rates within a dataset. This approach emphasizes resampling data based on how often specific events, features, or classes occur, allowing models to better understand and learn from the underlying data distribution. It is often used to address issues such as class imbalance, where certain classes are overrepresented or underrepresented, ensuring more balanced and representative training data.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "6d461300-3bd8-4048-9ddb-02ec66a0e5ca",
        "7ff5f124-db54-44e8-83b1-c5800bcf11a9",
        "dcf95069-65d9-4bf8-a79e-0a941b0068f2",
        "f57e7def-3aeb-40b8-a5a5-959995b80afc",
        "c7df8c85-dc92-40fd-89a4-ad12ae1af2c4"
      ]
    },
    {
      "id": "77032e41-0115-4796-9eb1-9dc71e246e66",
      "name": "Label forcing",
      "definition": "Label forcing is a semi-supervised learning technique used in machine learning to improve model performance by leveraging both labeled and unlabeled data. It involves assigning or 'forcing' label predictions onto unlabeled data points based on certain confidence criteria or auxiliary models, and then retraining the model using this expanded dataset. The process aims to enhance the model\u2019s ability to generalize, especially when labeled data is scarce, by propagating label information from a small set of labeled examples to a larger pool of unlabeled data through iterative refinement.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "5841cf9e-1f53-41e7-92f8-95b347c672d2",
        "38ef180c-a426-4866-8265-2dc47c4ce628",
        "65e4360d-ff4f-4b22-93de-cd656c61adcc",
        "fd5086b8-26c9-41ac-b709-5f76d0e137d4",
        "ab1f5577-046e-4bbc-a593-e9a22a353e40"
      ]
    },
    {
      "id": "2a28d905-72c1-493f-9792-8ac53c1ced98",
      "name": "Label Noise",
      "definition": "Label noise refers to inaccuracies or errors in the labels assigned to training data in supervised machine learning tasks. Specifically, it occurs when the labels provided for data instances are incorrect, inconsistent, or ambiguous, which can mislead the learning algorithm and impair its ability to model the underlying patterns accurately. This form of noise is a common challenge in real-world datasets where labels are often generated through manual processes, crowdsourcing, or automated labeling techniques that are prone to mistakes.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "717e5f5f-d1ec-47fe-ba34-0face182e973",
        "7eff4991-c335-4116-a2ec-3bb4069c26bd",
        "c74120e9-9918-40c5-abc5-d5059bb9634d",
        "80ad2c65-5896-4d9a-9a08-425982837266",
        "829d8301-e6e8-4195-bc9a-f69f5f4c2f37"
      ]
    },
    {
      "id": "db64efb8-7871-4565-b718-784628da8374",
      "name": "Label Propagation",
      "definition": "Label Propagation is a semi-supervised machine learning algorithm used for data classification and clustering, particularly in graph-based data structures. It propagates labels from a small set of labeled data points to unlabeled data points through iterative processes, leveraging the inherent structure of the data to improve labeling accuracy. The core idea is to exploit the similarity between data points, where similar points are likely to share the same label, thereby enabling effective learning even with limited labeled data.",
      "categoryId": "b1801e0d-e24b-4ad2-9e47-20e042487137",
      "subcategoryIds": [
        "6277a764-6509-44a1-9888-3da4f33b0949",
        "61d3b748-2f4b-47b2-a940-6584e7353f64",
        "6c6c89a2-c827-4583-8a72-f54397e14772",
        "e3fe0460-00c1-46ff-a9eb-bc6f61fc92d4",
        "85abdbff-4fa9-4802-9a55-94d4a4942e64"
      ]
    },
    {
      "id": "034bd386-93a1-4b32-acf5-c30eded5da72",
      "name": "Label Propagation (Already in your list)",
      "definition": "Label Propagation is a semi-supervised learning algorithm used primarily for graph-based data to assign labels to unlabeled nodes based on the labels of their neighboring nodes. It operates by iteratively updating the labels of data points through the propagation of label information across the graph structure, leveraging the assumption that connected nodes are likely to share similar labels. This technique is especially useful in scenarios where labeled data is scarce but unlabeled data is abundant, enabling the algorithm to infer labels effectively by exploiting the intrinsic structure of the data graph.",
      "categoryId": null,
      "subcategoryIds": []
    },
    {
      "id": "64af5a0e-511e-4212-b6a1-eeb816b90239",
      "name": "Label Smoothing",
      "definition": "Label smoothing is a regularization technique used in training classification models, particularly neural networks, to prevent the model from becoming overconfident in its predictions. Instead of assigning a probability of 1 to the correct class and 0 to all others, label smoothing distributes a small portion of the probability mass to the incorrect classes. This results in more calibrated and generalizable models by encouraging less confident predictions and reducing overfitting.",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38",
      "subcategoryIds": [
        "192eba82-dbd6-4f91-a211-a4121d7b775c",
        "eaf47bb2-e211-49c6-ab68-17da87ccc419",
        "b307fcf0-bfb7-4250-97ec-b0504e397d1a",
        "269d48b7-c2ee-4489-8220-09cc6676736e",
        "500feb9c-2bee-4206-a708-b2e0574a07a6"
      ]
    },
    {
      "id": "33b61336-129f-4bea-8549-8d1569307948",
      "name": "Label Smoothing Techniques",
      "definition": "Label smoothing is a regularization technique used in training classification models, particularly neural networks, to improve generalization and prevent the model from becoming overly confident in its predictions. Instead of assigning a probability of 1 to the correct class and 0 to all others in the target distribution, label smoothing distributes a small portion of the probability mass uniformly across all classes. This approach effectively softens the target labels, leading to improved model calibration and often enhanced performance on unseen data.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "9d2e9b86-37a6-4f53-afc7-2c22f2d00ab6",
        "21abdc69-e38c-419b-8070-3c0ad92a9258",
        "e20ed8d3-19c3-46a2-ade6-a3dc8924b5d0",
        "717e5f5f-d1ec-47fe-ba34-0face182e973",
        "c89f17ea-9f53-4364-8224-740b4849dbbc"
      ]
    },
    {
      "id": "00d84079-2bc7-4d9f-996b-2534985f66e2",
      "name": "Ladder Nets",
      "definition": "Ladder Nets are a type of neural network architecture that combines elements of traditional convolutional neural networks (CNNs) with ladder-style connections. They are designed to facilitate efficient feature extraction and hierarchical information flow by incorporating skip connections that pass features across different layers, thereby improving the network's ability to learn complex patterns and representations in data such as images, speech, or sequential information.",
      "categoryId": null,
      "subcategoryIds": []
    },
    {
      "id": "4ffba0ba-ac58-4222-93fe-a69c07060c92",
      "name": "Ladder Nets Enhancements",
      "definition": "Ladder Nets Enhancements refer to advanced modifications and improvements applied to Ladder Networks, a semi-supervised learning architecture that integrates supervised and unsupervised learning principles. These enhancements aim to improve feature representation, training efficiency, and robustness of the model by incorporating additional layers, regularization techniques, and optimization strategies to better leverage both labeled and unlabeled data during training.",
      "categoryId": "2bd8b40c-79f5-4b84-813f-a70ebe2d5360",
      "subcategoryIds": [
        "6c11893c-3708-41f2-8988-0a621ded3ff4",
        "6116a152-90c1-43b7-a9a2-b2d0fcd2c4a2",
        "a1bbc4a4-1eba-48e0-a1b6-f88a22c8b336",
        "6825c0f6-bd3f-4e2b-b32e-dc1d7aa93d62",
        "8aa51cd4-a40f-45cc-9b59-082c9c89fe5f"
      ]
    },
    {
      "id": "0ffd5945-d7a8-4b41-b341-31113c45f1a6",
      "name": "Ladder Nets Enhancements Techniques",
      "definition": "Ladder Nets Enhancements Techniques refer to series of advanced modifications and optimization strategies applied to Ladder Networks, a semi-supervised learning architecture. These techniques aim to improve the network's performance, robustness, and efficiency by refining its layered structure, regularization methods, and training procedures, thereby enabling better exploitation of limited labeled data in various machine learning tasks.",
      "categoryId": "f001a980-b036-4a8b-a7b0-290e7b1c9a77",
      "subcategoryIds": [
        "d0c315ba-d0fc-45d2-a7a1-fa3806ed0f5f",
        "e0af036b-97b7-47c6-8b71-bb0b8eac7e32",
        "b698f681-8035-42cd-8aa4-d4c89d8b7596",
        "71548cd6-c850-4fb4-bf69-9d6966472ae8",
        "e2582031-e34a-4191-88c9-baa5bb85a0bc"
      ]
    },
    {
      "id": "f24b2202-91c9-40cb-80c1-04a484cc8a96",
      "name": "Ladder Nets Extensions",
      "definition": "Ladder Networks Extensions refer to advanced modifications and augmentations to the original Ladder Networks architecture, which are designed to improve semi-supervised learning capabilities by incorporating additional layers, pathways, or connectivity patterns. These extensions aim to enhance the network\u2019s ability to leverage both labeled and unlabeled data effectively, often resulting in better feature extraction, improved robustness, and increased training efficiency in various machine learning tasks.",
      "categoryId": "f001a980-b036-4a8b-a7b0-290e7b1c9a77",
      "subcategoryIds": [
        "23947227-bebd-470c-a41f-2a70e9dcbc61",
        "a5a622f0-5c23-49f9-a770-5261071c0021",
        "537ad2e9-dcd6-45e6-990f-924314c64bd4",
        "1b9ec128-1abc-4495-93cb-26e5580bd282",
        "0feffada-0883-4b17-8059-95e09534b06c"
      ]
    },
    {
      "id": "024adba7-1162-43cc-8c17-239bed753941",
      "name": "Ladder Nets Extensions Techniques",
      "definition": "Ladder Nets Extensions Techniques refer to advanced methods used to enhance the architecture and functionality of Ladder Networks, a class of semi-supervised learning models. These techniques aim to improve the network's ability to learn from limited labeled data by extending the base Ladder Network with additional layers, connections, or modules, thereby increasing model capacity and representation power while maintaining efficient learning characteristics.",
      "categoryId": null,
      "subcategoryIds": []
    },
    {
      "id": "4183d75d-0dfb-4ddf-8aa5-490bae473fb3",
      "name": "Lambda Architecture",
      "definition": "Lambda Architecture is an architectural design pattern for processing massive quantities of real-time and batch data efficiently and reliably. It aims to provide a comprehensive data processing framework that combines real-time data streams with batch processing workflows to deliver scalable, fault-tolerant, and low-latency data analytics solutions. This architecture integrates different processing models to harness their respective strengths, ensuring accuracy, freshness, and historical context in data analytics and machine learning applications.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "43336c9d-a92f-48d4-97ed-281d3231c1f9",
        "29d9b6be-0418-46e6-8391-464125537f9f",
        "f1342943-3e53-4710-8570-2f0a6e1c8972",
        "bfa33835-6e46-4a2c-97d9-d87a5742f95c",
        "4592f465-e47b-4c0e-b5b5-4ba1b514d250"
      ]
    },
    {
      "id": "a23e0ad2-d1fd-4c2d-aa86-0eaa2e9f1717",
      "name": "Language Generation Evaluation",
      "definition": "Language Generation Evaluation refers to the process of systematically assessing the quality, accuracy, coherence, and relevance of text generated by language models. It involves using various metrics, benchmarks, and human judgments to determine how well AI-generated language outputs meet desired standards of readability, factual correctness, and contextual appropriateness. This evaluation is crucial for refining models and ensuring their outputs are reliable for practical applications.",
      "categoryId": null,
      "subcategoryIds": []
    },
    {
      "id": "cc838856-1902-420b-ba5a-38e445037412",
      "name": "Language Generation in Robotics",
      "definition": "Language Generation in Robotics refers to the application of natural language processing (NLP) and artificial intelligence techniques to enable robots to produce coherent, contextually appropriate, and human-like language responses. This involves not only understanding human language input but also generating meaningful spoken or written language to interact effectively with humans in various contexts, such as service robots, autonomous assistants, or collaborative agents.",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38",
      "subcategoryIds": [
        "145e60d6-3340-462d-8e7c-d5571b984d0b",
        "ef558e5f-113f-470a-8e6b-350323ccf65a",
        "17e9a6cd-6875-4cb6-8111-e9ccf61db5e8",
        "0fa7d136-1535-4501-b511-3e50188ea504",
        "8d03c94f-6d92-483c-bcc8-74270975585e"
      ]
    },
    {
      "id": "c7aa4316-1ba2-45ef-ba4d-109bddbdfbdc",
      "name": "language model adaptation",
      "definition": "Language model adaptation refers to the process of modifying or fine-tuning pre-trained language models to better suit specific tasks, domains, or datasets. This involves adjusting the model's parameters using additional training on targeted data, enabling the model to generate more accurate, relevant, and contextually appropriate outputs within a particular application or domain. The goal of language model adaptation is to enhance the performance and utility of language models in real-world scenarios by making them more aligned with specific linguistic, cultural, or domain-specific nuances.",
      "categoryId": null,
      "subcategoryIds": []
    },
    {
      "id": "00d98e0a-7b8c-419a-8073-cae637716c27",
      "name": "language model evaluation",
      "definition": "Language model evaluation refers to the systematic process of assessing the performance, accuracy, and quality of language models\u2014such as neural networks trained to understand, generate, and interpret human language. It involves applying various metrics, benchmarks, and testing procedures to determine how well a language model meets specific linguistic, contextual, and task-oriented requirements, thereby guiding model development and deployment in real-world applications.",
      "categoryId": "9c2d686b-dc1c-4ed7-bf77-2cbe83efde08",
      "subcategoryIds": [
        "82e15f41-5ca8-4ec1-940d-deee20b46632",
        "cfd77b58-be64-41ec-85f9-aa5c0375c076",
        "bd935dd5-a1bd-4be4-a49d-76362395b483",
        "3d5c7536-0a87-4246-8f10-0b20dce40339",
        "1116b6a3-f459-40fc-a258-6f29b8895020"
      ]
    },
    {
      "id": "535fb702-93ef-41da-b23b-93d1abf5229e",
      "name": "Language Model Fine-Tuning",
      "definition": "Language Model Fine-Tuning refers to the process of adapting a pre-trained language model to perform well on a specific task or domain by further training it on task-specific data. This technique leverages the general language understanding captured during initial large-scale training and refines it to meet particular application requirements, enhancing accuracy, relevance, and performance in targeted language tasks.",
      "categoryId": "908d0be6-c964-4196-a519-24e707e1f1b1",
      "subcategoryIds": [
        "c8151e87-b5a8-4540-8065-9fdb92af2e4d",
        "e825b76d-32d0-4cd9-9395-06960c0f93ca",
        "f41ab917-9023-4063-870c-b1cfbc8aedb8",
        "f2b57728-ae40-40b5-bb47-aa27643c0eff",
        "a7e16ba8-97bf-43c9-94aa-d6edcbb6fe15"
      ]
    },
    {
      "id": "b010368a-30cb-4cbe-809b-e754ed98dbfe",
      "name": "Language Model Pretraining",
      "definition": "Language Model Pretraining refers to the process of training a neural network-based language model on a large corpus of text data before it is fine-tuned for specific downstream tasks. This pretraining enables the model to learn general language representations, understanding syntax, semantics, and contextual relationships, which can be later adapted for tasks such as translation, summarization, question-answering, and more. The core idea is to leverage vast amounts of unlabeled text data to develop a versatile and robust language understanding system that reduces the need for task-specific labeled datasets.",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38",
      "subcategoryIds": [
        "145e60d6-3340-462d-8e7c-d5571b984d0b",
        "fc36f5e7-1074-4d81-a41b-f5b8f3522221",
        "44fbdd23-5eec-422c-b223-f6bf0493d6fa",
        "7c1443d7-de0c-4e96-a1b8-e19a6a92f234",
        "8c1a451e-cdcb-49cd-8e3d-5d8e8449ef4f"
      ]
    },
    {
      "id": "a935b604-da41-424e-b990-aaaf3ef88a08",
      "name": "Language Modeling",
      "definition": "Language modeling is a fundamental task in natural language processing (NLP) that involves developing algorithms and systems capable of understanding, generating, and predicting human language. Essentially, a language model assigns probabilities to sequences of words or tokens, enabling applications such as speech recognition, machine translation, text generation, and autocomplete systems. Modern language models, especially those based on deep learning architectures like transformers, have dramatically advanced the capacity to comprehend and produce human-like text with contextual understanding.",
      "categoryId": "9c2d686b-dc1c-4ed7-bf77-2cbe83efde08",
      "subcategoryIds": [
        "6cbc1861-8494-4cb5-a387-28977b54ce35",
        "adf28be7-79e6-4ef1-b8a7-eaf424779252",
        "b2dd0de1-08a9-4fca-9c15-37669eec1a5b",
        "a86b4cf2-835a-4943-b679-5a50bf9a3995",
        "94865aec-f25c-43f8-8022-eebd19226f47"
      ]
    },
    {
      "id": "00f8c453-8e96-4456-9479-6529593516c7",
      "name": "Language Models",
      "definition": "Language models are a class of artificial intelligence systems designed to understand, generate, and manipulate human language. They are trained on large corpora of text data to learn statistical patterns, syntax, semantics, and contextual relationships among words and phrases. These models can perform a variety of language-related tasks such as translation, summarization, question-answering, and text generation, making them fundamental tools in natural language processing (NLP).",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38",
      "subcategoryIds": [
        "e012e44e-75ae-4dbb-821f-25f15131ae75",
        "c65f8e28-b4d5-4bb2-a26d-b64709d6ca8e",
        "54a55b8b-1947-43e0-986e-6aec946c36b8",
        "015d982c-366d-4823-af3a-a9d61dc60eb3",
        "189800e6-acc9-4249-be49-8161680e9981"
      ]
    },
    {
      "id": "3223b945-24d8-42e1-b6c2-69b619af9e4e",
      "name": "Language Models (e.g., BERT, GPT)",
      "definition": "Language models are a class of artificial intelligence models designed to understand, generate, and manipulate human language. They process large amounts of text data to learn the statistical and contextual patterns of language, enabling tasks such as translation, summarization, question answering, and conversation simulation. Examples include models like BERT (Bidirectional Encoder Representations from Transformers) and GPT (Generative Pre-trained Transformer), which are built on transformer architectures and have significantly advanced natural language processing (NLP).",
      "categoryId": null,
      "subcategoryIds": []
    },
    {
      "id": "df1d876c-3231-473f-8c4e-07b8595b6a30",
      "name": "Laplacian Distribution",
      "definition": "The Laplacian distribution, also known as the double exponential distribution, is a continuous probability distribution characterized by a sharp peak at its mean and symmetric exponential tails on either side. It is defined by two parameters: the location parameter (which indicates the distribution's central point) and the scale parameter (which influences the spread or dispersion). The probability density function (PDF) of the Laplacian distribution embodies a sharp peak at the mean with exponential decay in both directions, making it useful for modeling data with frequent small deviations and outliers.",
      "categoryId": "7e3a5556-560d-464a-a3d5-60eeb033a538",
      "subcategoryIds": [
        "1512fdbc-58e5-413a-85fe-886cf0f5eae9",
        "67558f98-8ff3-4162-8609-ffed526dfd6f",
        "34e3aaf0-7bd1-416d-8c73-91ad7c1654e4",
        "6d66a85d-6d8b-487a-beae-8316a3102775",
        "6da3b7ee-074e-449b-bb59-9f0c5c4127e5"
      ]
    },
    {
      "id": "db2d0eed-40f7-47dd-ab93-f26ff64ee209",
      "name": "Laplacian Regularization",
      "definition": "Laplacian Regularization is a technique used in machine learning and graph-based learning algorithms that leverages the Laplacian matrix of a graph to impose smoothness constraints on functions defined over data points. It encourages the learned function to vary smoothly across the data manifold, thereby improving generalization especially in semi-supervised learning scenarios. This regularization term incorporates the graph structure to penalize models for significant variations across neighboring data points, ensuring consistency and coherence in the learned representations.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "65943156-2a6a-4551-9ffa-dc798daa465b",
        "12cd9e10-302e-45d2-bbcc-e24d0b28f761",
        "84bfe21f-cb18-46df-8d4e-2aff6c652856",
        "5841cf9e-1f53-41e7-92f8-95b347c672d2",
        "c6eab35e-4b2c-4acd-859d-432c9eaf7564"
      ]
    },
    {
      "id": "8fe01cb6-221e-4ba1-85f2-1b08e2a762aa",
      "name": "Large Foundation Models",
      "definition": "Large Foundation Models are extensive pre-trained machine learning models that serve as the groundwork for a wide range of downstream AI tasks. These models are characterized by their massive size, often containing billions or even trillions of parameters, enabling them to understand and generate complex data like language, images, or multimodal content. They are typically trained on vast and diverse datasets, allowing them to capture broad contextual understanding which can then be fine-tuned for specific applications.",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38",
      "subcategoryIds": [
        "89854309-3160-47ce-8cae-070aa916fdc1",
        "25bd4f43-ad8c-4ef1-b0d7-d328e7ec949f",
        "934c9604-f4b6-451a-bea9-4820e2e73f89",
        "44fbdd23-5eec-422c-b223-f6bf0493d6fa",
        "7c1443d7-de0c-4e96-a1b8-e19a6a92f234"
      ]
    },
    {
      "id": "2b9b40a8-8137-4b3a-936b-b05191ae5487",
      "name": "Large Language Models (LLMs)",
      "definition": "Large Language Models (LLMs) are advanced artificial intelligence systems designed to understand, generate, and manipulate human language at a high level of complexity. These models are built using deep learning techniques, particularly transformer architectures, and are trained on vast amounts of text data to learn linguistic patterns, semantics, and contextual relationships. LLMs can perform a wide range of language tasks, including translation, summarization, question-answering, and text generation, often achieving human-like performance.",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38",
      "subcategoryIds": [
        "eb3eae56-6459-4acb-93f1-4c1f5d9bb860",
        "145e60d6-3340-462d-8e7c-d5571b984d0b",
        "b37a3aa3-242c-4a60-9b65-49ab3fa73cf6",
        "44fbdd23-5eec-422c-b223-f6bf0493d6fa",
        "c436de57-4333-47b6-bfee-02aa25d7fbb7"
      ]
    },
    {
      "id": "fd1f8242-8f2c-4c3c-a82c-7b083b50110d",
      "name": "Large Model Architecture",
      "definition": "A Large Model Architecture refers to a type of neural network design characterized by having a vast number of parameters, often ranging from hundreds of millions to trillions. These models are built to process and learn from massive datasets, enabling them to perform complex tasks such as natural language understanding, image recognition, and decision-making with high accuracy. Examples include transformer-based models like GPT-3 and large-scale convolutional neural networks used in computer vision. The primary goal of large model architectures is to leverage extensive capacity to capture intricate patterns and relationships within data, resulting in more powerful and versatile AI systems.",
      "categoryId": "fa3cecb7-bf1f-4d3d-91a5-f8f1e02a1e38",
      "subcategoryIds": [
        "e012e44e-75ae-4dbb-821f-25f15131ae75",
        "b6a56d63-07c4-496e-9257-9a038cba90ef",
        "4bdd3ae4-6f87-41b3-96d3-c40779279200",
        "89854309-3160-47ce-8cae-070aa916fdc1",
        "25bd4f43-ad8c-4ef1-b0d7-d328e7ec949f"
      ]
    },
    {
      "id": "5f40428d-dbe2-4e8b-8bb9-ab49ec622c90",
      "name": "Lasso",
      "definition": "Lasso, short for Least Absolute Shrinkage and Selection Operator, is a regression analysis method that performs both variable selection and regularization to enhance the prediction accuracy and interpretability of statistical models. It introduces a penalty equivalent to the absolute value of the magnitude of coefficients to constrain or shrink some coefficients to zero, effectively selecting a simpler model by excluding less important features.",
      "categoryId": "7a8744d8-74cd-49fa-9af2-ddab358362f5",
      "subcategoryIds": [
        "717e5f5f-d1ec-47fe-ba34-0face182e973",
        "e323ff31-f033-4fcb-8441-720a7d9f7c4d",
        "6ddd0fc7-f1ea-44ab-85ee-e0daeeab88d9",
        "8b0e734d-7d86-40a9-a344-394899bfe536",
        "3cdb3439-4c9a-41eb-bc61-b1f36b6377c2"
      ]
    },
    {
      "id": "e9b00bc0-3cbc-41a7-b8c0-cd032c063abd",
      "name": "Lasso Regression",
      "definition": "Lasso Regression, also known as Least Absolute Shrinkage and Selection Operator (Lasso), is a statistical method used in linear regression models to perform both variable selection and regularization. It introduces a penalty equal to the absolute value of the magnitude of coefficients, which encourages sparsity in the model by shrinking some coefficients exactly to zero. This enhances the model's interpretability and helps prevent overfitting, especially when dealing with high-dimensional data.",
      "categoryId": "691a0b1e-82ca-49f5-a362-e61040cc378e",
      "subcategoryIds": [
        "e534835e-3fee-4d3d-9282-ce4e3b7ef22a",
        "e856a97c-6285-4dd0-9275-f7f25905a46a",
        "a6ea097c-8df3-4242-bf53-efe27e7a4d94",
        "69726424-68c4-496a-979f-cf339a985d59",
        "6ff59bfc-0a38-484f-a5c3-bee728be2c5d"
      ]
    }
  ]
}