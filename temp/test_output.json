{
  "categories": [
    {
      "id": "0fbac59f-eee4-4d35-b953-d78936fbe47c",
      "name": "Introduction"
    },
    {
      "id": "15ce7bff-fea7-4e47-b1cf-df1306d0dbce",
      "name": "Prerequisites"
    },
    {
      "id": "cdf287a6-37f4-4331-a806-76b00be15bd2",
      "name": "Theoretical Concepts"
    },
    {
      "id": "5fb3b02b-1d0d-47be-aae1-f95a616dbb28",
      "name": "How It Works"
    },
    {
      "id": "edafe3ba-9279-453b-8bb1-3fdc32628bb7",
      "name": "Variants or Extensions"
    },
    {
      "id": "f2e132f1-ba46-4d57-80e6-755315290985",
      "name": "Applications"
    },
    {
      "id": "c39c4b12-0fff-4c2c-a990-ece444aa3198",
      "name": "Implementation"
    },
    {
      "id": "53afd201-442d-49cc-b36c-e352b5c87efd",
      "name": "Evaluation and Metrics"
    },
    {
      "id": "edd1d443-ac6f-41cf-bb6e-c8db30bea430",
      "name": "Advantages and Disadvantages"
    },
    {
      "id": "dcc030b0-a6a7-4121-b06a-27667c079094",
      "name": "Ethics and Responsible AI"
    },
    {
      "id": "504e638d-3ac8-455d-8305-de1745397b71",
      "name": "Historical Context"
    },
    {
      "id": "cc0e8676-a838-476f-9087-e92d77c705b4",
      "name": "Illustration or Diagram"
    },
    {
      "id": "2a0187d5-706e-4876-9be3-209d38e6905b",
      "name": "Related Concepts"
    },
    {
      "id": "7462140d-8753-478b-8425-83964aa33d7e",
      "name": "Case Studies"
    },
    {
      "id": "e990a774-2c8b-414d-be87-53a6c35bcc37",
      "name": "Interviews with Experts"
    },
    {
      "id": "18586372-58a8-45b4-a250-b1e7580ebde9",
      "name": "Hands-on Tutorials"
    },
    {
      "id": "6fb8875a-6c5c-427d-9f89-a029bee2651f",
      "name": "Interactive Elements"
    },
    {
      "id": "72c4888a-04b1-4ca7-afab-ac47d28f0a64",
      "name": "Industry Insights"
    },
    {
      "id": "a7d8f5b3-bc02-4f5a-aa7c-c4a37f603c76",
      "name": "Common Challenges and Pitfalls"
    },
    {
      "id": "0c119c7b-b700-4065-9b26-4816fd16798b",
      "name": "Real-world Datasets and Benchmarks"
    },
    {
      "id": "8fa71c2a-659a-4f60-812d-5ab80b425491",
      "name": "Tools and Frameworks"
    },
    {
      "id": "362d1e69-ced0-4e8f-b1ed-e6aacdfd7197",
      "name": "Did You Know?"
    },
    {
      "id": "b620faba-b5d5-448f-963a-8b7844f2d639",
      "name": "Quick Quiz"
    },
    {
      "id": "5ede9c7b-72b5-4b4e-851d-3a1e7ff439bc",
      "name": "Further Reading"
    },
    {
      "id": "fcdf62dd-62db-4919-be2a-b9fcba903f83",
      "name": "Project Suggestions"
    },
    {
      "id": "92906f47-ab71-4213-8a74-376e034b8874",
      "name": "Recommended Websites and Courses"
    },
    {
      "id": "4ae1123c-4441-490a-8b6f-33420f994295",
      "name": "Collaboration and Community"
    },
    {
      "id": "94be7771-e94b-4bee-a859-d976ac67bb4f",
      "name": "Research Papers"
    },
    {
      "id": "feb2a4ac-ccc1-46cb-ab32-0983e73b11df",
      "name": "Career Guidance"
    },
    {
      "id": "efcef7ac-b951-4a49-839e-f8ee23abbab6",
      "name": "Future Directions"
    },
    {
      "id": "1b70dfe5-99ef-4fa6-ba5a-d0ef2275498a",
      "name": "Glossary"
    },
    {
      "id": "6b30c1c3-e064-44fe-b2ed-efddaa4422c1",
      "name": "FAQs"
    },
    {
      "id": "3dbcf17e-e7ac-42d7-81cf-655351cc1f18",
      "name": "Tags and Keywords"
    },
    {
      "id": "b7f52a8c-f7de-4191-a997-04ffdcb1e535",
      "name": "Appendices"
    },
    {
      "id": "a283bfaa-3e75-451f-b2a8-fa0cf268c2d1",
      "name": "Index"
    },
    {
      "id": "d9c5c155-7558-42a5-9eda-5ff814ac94ef",
      "name": "References"
    },
    {
      "id": "32dca218-0f46-4081-b800-2bf71a036d4e",
      "name": "Conclusion"
    },
    {
      "id": "674800d3-a06f-4a5a-96eb-23df08ec34a9",
      "name": "Metadata"
    },
    {
      "id": "8c9eb367-e7e9-4fd0-ab74-96eac9687439",
      "name": "Best Practices"
    },
    {
      "id": "dcf5c837-65ec-46e5-b931-47107f4abe28",
      "name": "Security Considerations"
    },
    {
      "id": "4293d3d6-f2d9-4440-92ad-cdd3e70f0ce0",
      "name": "Optimization Techniques"
    },
    {
      "id": "6f72d3d7-a3e7-40e5-9e06-9a29c8145e68",
      "name": "Comparison with Alternatives"
    },
    {
      "id": "680d3998-490a-41df-b5dc-447682d109cc",
      "name": "Probability Theory, Mathematical Functions, Fourier Analysis, Random Variables, Distribution Characterization, Limit Theorems, Statistical Inference, Signal Processing"
    },
    {
      "id": "665ee489-ab09-419e-99e6-01965647cabf",
      "name": "distance metrics, Chebyshev Distance, L\u221e norm, maximum metric, ML algorithms, data analysis, spatial measurement, vector distance, pathfinding, clustering, similarity measures"
    },
    {
      "id": "1e59096b-cfbb-4eb3-a096-5e2f576eaefb",
      "name": "Neural Networks, Polynomial Approximation, Chebyshev Polynomials, Spectral Methods, Numerical Analysis, Function Approximation, Orthogonal Polynomials, Machine Learning Architectures, Spectral Neural Networks, Numerical Methods in AI"
    },
    {
      "id": "a2b559f3-f074-42dc-b4a8-ef046c026fee",
      "name": "Neural Networks, Polynomial Approximation, Spectral Methods, Chebyshev Polynomials, Machine Learning, Numerical Analysis, Function Approximation, Orthogonal Polynomials, Scientific Computing, Spectral Neural Networks"
    },
    {
      "id": "ac53191f-1511-40c9-a288-3134a8a9a240",
      "name": "Machine Learning, Deep Learning, Neural Networks, Approximation Theory, Spectral Methods"
    },
    {
      "id": "5a62c975-6105-4a66-b090-20bc1c9a0ee7",
      "name": "Machine Learning"
    },
    {
      "id": "83d6a18e-b5fa-484b-a283-2fe2a04a7f55",
      "name": "Deep Learning, Neural Networks, Generative Models, GANs, Image Processing, Upsampling Techniques, Convolutional Layers, Image Artifacts, Computer Vision, AI Image Generation"
    },
    {
      "id": "9ffda2e3-be3d-4a9f-be94-b35157408227",
      "name": "Machine Learning, Neural Networks, Model Optimization, Checkpoint Averaging, Model Ensembling, Training Techniques, Regularization, Deep Learning, Model Checkpointing"
    },
    {
      "id": "340460e6-76f8-4e83-91f8-7dd3be9160c7",
      "name": "machine learning"
    },
    {
      "id": "fb2e3e64-8f43-4894-b6dc-ad586e2fbc28",
      "name": "Artificial Intelligence, Machine Learning, Cheminformatics, Computational Chemistry, Chemical Data Analysis, Molecular Modeling, Data Science in Chemistry, Drug Discovery, Chemical Informatics Tools, Data Mining in Chemistry"
    },
    {
      "id": "12c5346d-024e-4f8f-83d8-d03a4d9566c3",
      "name": "Statistics, Hypothesis Testing, Categorical Data Analysis, Statistical Tests, Data Science, Machine Learning, Data Analysis, Chi-Square Test"
    },
    {
      "id": "563bd0ab-7fe2-4b23-8313-af266ea1e7ce",
      "name": "Statistics, Hypothesis Testing, Categorical Data Analysis, Chi-Square Test, Contingency Tables, Goodness-of-Fit, Statistical Inference, Data Science, Machine Learning, Data Analysis"
    },
    {
      "id": "70e5c8ee-6ffc-44a3-a93b-0e128f76de7b",
      "name": "Linear Algebra, Matrix Decomposition, Numerical Methods, Machine Learning, Statistical Computing, Optimization, Covariance Matrices, Probabilistic Models, Scientific Computing"
    },
    {
      "id": "5c03d1f2-97fc-4206-bb4f-9e2f15b68d52",
      "name": "Matrix Factorization, Numerical Linear Algebra, Optimization Algorithms, Machine Learning, Quadratic Programming, Linear Systems, Computational Mathematics"
    },
    {
      "id": "212c0bfc-492f-413d-80ef-2698ec40f6d5",
      "name": "Computer Vision, Image Processing, Digital Photography, Lens Optics, Optical Aberrations, Color Correction, Post-Processing Algorithms, Machine Learning in Imaging, Photography Software, Visual Quality Improvement"
    },
    {
      "id": "fb74b630-0c1e-4357-a666-e6ebaa5c57d8",
      "name": "Graph Theory, Network Science, Random Graph Models, Complex Networks, Scale-Free Networks, Degree Distribution, Probabilistic Models, Network Modeling, Chung\u2013Lu Model, Graph Algorithms"
    },
    {
      "id": "64b59a62-30fe-4723-a08d-76e47241446a",
      "name": "Machine Learning, Data Preprocessing, Natural Language Processing, Sequence Modeling, Data Segmentation, Hierarchical Structures, Data Management, NLP Techniques, Data Chunking, AI Data Handling"
    },
    {
      "id": "447d3cca-4128-4815-9d65-719cf7a5a101",
      "name": "Natural Language Processing (NLP), Text Processing, Machine Learning, Artificial Intelligence, Language Modeling"
    },
    {
      "id": "ba7781e2-bd34-4175-aecd-4bb74d245e2d",
      "name": "AI/ML, Evaluation Metrics, Image Captioning, CIDEr Score, Natural Language Processing, Computer Vision, Machine Learning, Deep Learning, Caption Generation, Model Assessment"
    },
    {
      "id": "466eb4b3-2643-49c4-8454-47f94ed42f85",
      "name": "machine learning, computer vision, image classification, datasets, CIFAR-10, neural networks, deep learning, image datasets, pattern recognition, AI datasets"
    },
    {
      "id": "28162c27-8489-4760-9c1c-7ffe085efab1",
      "name": "computer vision, image classification, deep learning, datasets, convolutional neural networks, transfer learning, machine learning education, AI datasets, pattern recognition"
    },
    {
      "id": "5909a0b9-d8e5-49a2-8bd3-f68946002ded",
      "name": "Machine Learning, Incremental Learning, Continual Learning, Classification, Artificial Intelligence, Model Adaptation, Online Learning, Lifelong Learning, Neural Networks, Data Streams"
    },
    {
      "id": "8d439733-28d7-48c0-a53d-3e0e48c350c4",
      "name": "Electrical Engineering, Circuit Analysis, Electrical Circuits, Network Theorems, Ohm's Law, Kirchhoff's Laws, AC/DC Circuits, Electrical Principles, Circuit Theorems, Electronic Design"
    },
    {
      "id": "0c063e4e-a976-49cd-b067-8d697e37b074",
      "name": "Computational Complexity, Circuit Complexity, Boolean Circuits, Digital Circuit Design, Computational Theory, Complexity Classes, Hardware Optimization, Theoretical Computer Science, Algorithm Efficiency, Lower Bounds"
    },
    {
      "id": "cfc56cf8-bd54-4a8b-9b3f-5e8ce0bb635e",
      "name": "Circuit analysis, semiconductor devices, transistor modeling, VLSI design, electronics fundamentals, circuit simulation, SPICE, device physics, integrated circuits, electrical engineering"
    },
    {
      "id": "4a45a0bd-1af8-41e2-9ad9-21bf28654409",
      "name": "Signal Processing, Digital Signal Processing, Convolution, Circular Convolution, Fourier Transform, FFT, Discrete-Time Signals, MATLAB, Python, Signal Analysis"
    },
    {
      "id": "a918ded9-99e6-4ff2-a92f-93f8c0f32adf",
      "name": "Convolutional Neural Networks, Padding Techniques, Circular Padding, Data Preprocessing, Periodic Data, Image Processing, Signal Analysis, Deep Learning Fundamentals, Neural Network Architecture, Edge Effects"
    },
    {
      "id": "b16c54b9-1e16-44e0-8f81-96cde9210d00",
      "name": "Convolutional Neural Networks, CNN, Padding Techniques, Circular Padding, Periodic Data Processing, Deep Learning, Neural Network Architecture, Signal Processing, Data Continuity, Machine Learning, AI"
    },
    {
      "id": "cdc6501d-b0fc-4dde-9848-5e706c8fa375",
      "name": "Machine Learning, Deep Learning, Explainability, Model Interpretability, Visualization, CNN, Convolutional Neural Networks, CAM, Grad-CAM, Score-CAM, Neural Network Explanations, AI Transparency"
    },
    {
      "id": "49774b02-9fd2-41e9-9d67-f8c0901195c0",
      "name": "machine learning, computer vision, deep learning, CNN, interpretability, visualization, image classification, model explanation"
    },
    {
      "id": "bd52977c-f080-4693-ad04-13ebf83b3438",
      "name": "Machine Learning, Data Imbalance, Classification, Data Preprocessing, Resampling Techniques, SMOTE, Model Bias, Model Evaluation, Data Science, AI Challenges"
    },
    {
      "id": "bb904414-df50-475e-9142-59e155300580",
      "name": "Machine Learning, Class Imbalance, Class Weighting, Data Preprocessing, Model Optimization, Supervised Learning, Imbalanced Dataset Handling, Sklearn, TensorFlow, Model Tuning"
    },
    {
      "id": "463c8d62-656f-4479-b28e-3b49fbccc87f",
      "name": "Machine Learning, Loss Functions, Class Imbalance, Data Imbalance, Classification, Model Optimization, Deep Learning, Cost-sensitive Learning, Imbalanced Datasets, Model Training Techniques"
    },
    {
      "id": "a1c8d4d1-6f9e-4689-808d-d472c6cdb804",
      "name": "Machine Learning, Data Preprocessing, Data Sampling, Class Imbalance, Imbalanced Datasets, Sampling Techniques, Data Augmentation, Model Training Strategies, AI Data Handling"
    },
    {
      "id": "46a7e47f-f3b4-4f60-9da0-d5def5325232",
      "name": "Machine Learning, Loss Functions, Class Imbalance, Class-weighted Loss, Cost-sensitive Learning, Imbalanced Data, Model Optimization, Classification, Data Augmentation, Model Training Techniques"
    },
    {
      "id": "638b1e9b-d328-40ff-b394-5a617ed4ee0a",
      "name": "Machine Learning, Classification, Supervised Learning, Data Science, Pattern Recognition, AI Algorithms, Data Classification, Predictive Modeling, Machine Learning Algorithms, Model Evaluation"
    },
    {
      "id": "ad6f7632-68e4-4117-85c7-7bc4bee08896",
      "name": "Machine Learning, Decision Trees, Classification, Regression, CART, Supervised Learning, Data Mining, Predictive Modeling, Data Science, Ensemble Methods"
    },
    {
      "id": "19f8687d-78e2-404b-b32b-b5dab8063e1c",
      "name": "Machine Learning, Classification, Model Evaluation, Performance Metrics, Data Science, Supervised Learning, Model Validation, ROC Curve, Precision, Recall, F1-Score, Confusion Matrix"
    },
    {
      "id": "56ed7f8c-a501-4986-a441-19c3c8a7fbfc",
      "name": "Supervised Learning, Machine Learning, Classification, Data Science, Pattern Recognition, AI, Model Training, Algorithms, Data Classification, Predictive Modeling"
    },
    {
      "id": "aaaa9c42-d813-43dc-8d14-0cef0d46ae59",
      "name": "machine learning, classification, model evaluation, metrics, sklearn, classification report, precision, recall, F1-score, support, supervised learning, model assessment, performance metrics"
    },
    {
      "id": "68fab1ce-0ab7-47bb-8999-9548eddf2d65",
      "name": "Multi-Label Classification, Machine Learning, Classifier Chains, Dependency Modeling, Multi-Output Models, Ensemble Methods, Supervised Learning, AI, Data Science"
    },
    {
      "id": "ce8840a2-b630-42e6-bfa3-82fb58079cf8",
      "name": "Generative Models, Diffusion Models, Machine Learning, AI Art Generation, Neural Networks, Model Guidance Techniques, AI Creativity, Unsupervised Learning, AI Sampling Methods, Deep Learning"
    },
    {
      "id": "679ad49b-3245-4a91-838a-49cdf3e200d3",
      "name": "AI Security, Sentiment Analysis, Claude Model, Machine Learning Security, NLP Security, Adversarial Attacks, AI Ethics, Data Privacy, Model Robustness, AI Safety"
    },
    {
      "id": "99d529f2-49fc-4886-8873-56c007857d96",
      "name": "AI, Machine Learning, Thermodynamics, Clausius-Clapeyron Relation, Phase Transitions, Materials Science, Thermal Modeling, Data Analysis, AI in Physics, Educational Resources"
    },
    {
      "id": "34461a4f-ae39-45c3-b7ed-85671d17fde1",
      "name": "Artificial Intelligence, Machine Learning, MLOps, Experiment Tracking, Model Management, Data Science Tools, Automation, AI Infrastructure, Open-Source, Workflow Orchestration"
    },
    {
      "id": "4a7824c8-0363-4203-88d1-225a0e0beeff",
      "name": "Artificial Intelligence, Machine Learning, Vision-Language Models, Multimodal AI, Contrastive Learning, Neural Networks, Embedding Spaces, Zero-Shot Classification, OpenAI, Deep Learning, Computer Vision, Natural Language Processing"
    },
    {
      "id": "ba60df6e-a2b2-4e46-9e06-508c2a008ce8",
      "name": "AI"
    },
    {
      "id": "99dd1378-9357-476f-8f24-cd073bf1a574",
      "name": "Machine Learning, Neural Networks, Optimization, Gradient Descent, Gradient Clipping, Training Stability, Deep Learning Techniques, Regularization"
    },
    {
      "id": "28541ed0-da62-422a-b170-9d900cdb203b",
      "name": "Machine Learning, Deep Learning, Neural Networks, Optimization Techniques, Gradient Descent, Model Training, Regularization, Exploding Gradients, Gradient Clipping, AI Training Methods"
    },
    {
      "id": "3f34ecb9-feff-4003-84e1-762cf3af049f",
      "name": "Machine Learning, Neural Networks, Optimization Techniques, Gradient Clipping, Deep Learning, Training Stability, Exploding Gradients, Model Regularization, AI Training Strategies"
    },
    {
      "id": "456a3d25-7e42-45e1-b4ea-6aaf5331896f",
      "name": "Machine Learning, Deep Learning, Neural Networks, Optimization Techniques, Gradient Clipping, Training Stability, Recurrent Neural Networks, Exploding Gradients, Gradient Norms, Model Regularization"
    },
    {
      "id": "45cfcd6f-d63d-47eb-9064-4d861f7f0a87",
      "name": "Machine Learning, Optimization, Gradient Descent, Regularization, Neural Networks, Training Stability, Gradient Clipping, Deep Learning, Model Regularization Techniques, Training Optimization"
    },
    {
      "id": "5b9b4489-8554-42b2-b9ef-726c4094abde",
      "name": "Graph Theory, Network Analysis, Community Detection, Social Networks, Clusters, Data Science, Graph Algorithms, Machine Learning, Network Structures, Clique Detection"
    },
    {
      "id": "523e51fa-1776-427e-89d2-fb66abda68ac",
      "name": "Data Mining, Pattern Mining, Frequent Itemsets, Closed Itemsets, Association Rules, Market Basket Analysis, Machine Learning, Pattern Recognition, Data Analytics, Knowledge Discovery"
    },
    {
      "id": "99a37e49-c26c-436a-ba47-f1aef82840f9",
      "name": "Graph Theory, Network Analysis, Centrality Measures, Social Network Analysis, Data Science, Network Metrics, Machine Learning, Data Visualization"
    },
    {
      "id": "b45fcd23-167a-4cd7-8c94-f11731bcd9bb",
      "name": "Time-series Analysis, Clustering, Machine Learning, Data Mining, Unsupervised Learning, Pattern Recognition"
    },
    {
      "id": "81c4a614-b379-4963-8334-e5408557d7c0",
      "name": "Semi-supervised learning, Clustering, Unsupervised learning, Data segmentation, Machine learning assumptions, Data clustering algorithms, Decision boundaries, Data visualization"
    },
    {
      "id": "7d6cb905-5b1d-481d-90a9-6b51f2614970",
      "name": "Clustering, Evaluation Metrics, Machine Learning, Data Science, Unsupervised Learning, Cluster Purity, Data Analysis, Clustering Validation, Classification"
    },
    {
      "id": "a9ca6fd3-8237-49d6-96e7-0d4d4836417b",
      "name": "Statistics, Data Collection, Sampling Methods, Cluster Sampling, Data Science, Survey Design, Data Analysis, Research Methods, Probability Theory"
    },
    {
      "id": "abe90435-b123-4570-91c9-5d75aa6b1137",
      "name": "Machine Learning, Unsupervised Learning, Clustering, Data Analysis, Data Mining, Pattern Recognition, Data Segmentation, K-Means, Hierarchical Clustering, Density-Based Clustering, Model Evaluation, Data Science"
    },
    {
      "id": "7d85022d-32b0-458c-a129-1a17dbda756c",
      "name": "Machine Learning, Unsupervised Learning, Clustering Algorithms, Data Mining, Data Clustering, K-Means, Hierarchical Clustering, Density-Based Clustering, Data Segmentation, Pattern Recognition"
    },
    {
      "id": "8ee2f9cb-ba78-418e-b60b-ca1be79782ed",
      "name": "Machine Learning, Unsupervised Learning, Clustering Algorithms, K-means, Hierarchical Clustering, Data Science, Pattern Recognition, Data Mining"
    },
    {
      "id": "6cecb1d1-4a3a-4cc4-b410-1763dcb9c8fd",
      "name": "Machine Learning, Clustering, Model Evaluation, Unsupervised Learning, Data Science"
    },
    {
      "id": "98e00305-a0e6-470c-bcdb-5fc3d41529a1",
      "name": "Clustering, Unsupervised Learning, Data Mining, Clustering Validation, Stability Analysis, Machine Learning, Data Science, Pattern Recognition, Algorithm Robustness, Consensus Clustering"
    },
    {
      "id": "68a64e29-b936-44d7-b45b-686e1894cb1a",
      "name": "Artificial Intelligence"
    },
    {
      "id": "af0d3e9a-be4c-41d0-ae56-19261235ee12",
      "name": "Artificial Intelligence, Machine Learning, Affective Computing, Emotion Recognition, Sentiment Analysis, Multimodal Data, Human-Computer Interaction, Behavioral Computing, Emotional Intelligence, Neural Networks"
    },
    {
      "id": "f01a4b2f-a392-4675-b2a9-612f06d647cf",
      "name": "Artificial Intelligence, Machine Learning, Emotion Recognition, Affective Computing, Human-Computer Interaction, Sentiment Analysis, Behavioral Analytics, Emotional AI, Computer Vision, Speech Processing, Physiological Signal Analysis"
    },
    {
      "id": "3b842afb-d83f-4bb8-a0e2-cf778b74a044",
      "name": "Artificial Intelligence, Machine Learning, Affective Computing, Human-Computer Interaction, Emotional Intelligence in AI"
    },
    {
      "id": "4de95ba3-dedf-4233-98cb-8f7eb0c8058e",
      "name": "Natural Language Processing, Affective Computing, Sentiment Analysis, Emotional AI, Human-Computer Interaction, Machine Learning, Deep Learning, Language Models, AI Ethics"
    },
    {
      "id": "29e1619d-6ec8-4e59-8855-1a00917a9623",
      "name": "Artificial Intelligence, Machine Learning, Affective Computing, Human-Computer Interaction, AI Technologies"
    },
    {
      "id": "6e31bbb4-9129-425e-a193-4e07f430785c",
      "name": "artificial intelligence, emotional intelligence, affective computing, human-computer interaction, machine learning, emotion recognition, AI ethics, user experience, natural language processing, psychology of emotions"
    },
    {
      "id": "96d4e364-7e9b-493c-a398-4b7d643efd9a",
      "name": "Bayesian Regression, Empirical Bayes, Hierarchical Models, Statistical Learning, Data-Driven Priors, Regularization Techniques, High-Dimensional Data, Machine Learning, Probabilistic Modeling, Bayesian Inference"
    },
    {
      "id": "745016eb-9726-4ddd-9c6b-84ab3e8b1332",
      "name": "Probability, Empirical Probability, Data Analysis, Statistics, Data Science, Machine Learning, Data-Driven Decision Making, Statistical Estimation, Probabilistic Models"
    },
    {
      "id": "fe214b9b-c980-497d-a515-3b8b3504d7d4",
      "name": "AI, Machine Learning, Empowerment, Reinforcement Learning, Human-AI Interaction, Autonomous Systems, Ethical AI, AI Systems, Data-Driven Decision Making, AI Education"
    },
    {
      "id": "78767fc3-5f08-4d3d-82b9-26db014a1c2e",
      "name": "Machine Learning, Deep Learning, Neural Networks, Autoencoders, Sequence Modeling, Natural Language Processing, Transformers, Embeddings, Data Compression, AI Architectures, Representation Learning, Encoder-Decoder Models"
    },
    {
      "id": "b69a2d8b-dad1-443d-90ab-12b5f4027536",
      "name": "Machine Learning, Deep Learning, Neural Networks, Attention Mechanisms, Transformers, Natural Language Processing, Sequence Models, Self-Attention, Encoder-Decoder Architecture, AI Interpretability"
    },
    {
      "id": "ea83ce7d-9872-4d79-a642-9bcc96b2a786",
      "name": "Artificial Intelligence, Machine Learning, Deep Learning, Neural Networks, Sequence Modeling"
    },
    {
      "id": "fe9d572f-1680-4948-a970-90fc6c37aaa4",
      "name": "Artificial Intelligence, Machine Learning, Neural Networks, Sequence-to-Sequence Models, NLP, Deep Learning, Attention Mechanisms, Transformer Models, Language Translation, Model Architectures, AI Applications"
    },
    {
      "id": "bad8c175-0ed7-4251-8c3b-27626f157f7d",
      "name": "AI, Machine Learning, Neural Networks, Sequence-to-Sequence Models, Encoder-Decoder Architecture, Attention Mechanisms, Transformers, NLP, Deep Learning, Model Extensions, Natural Language Processing"
    },
    {
      "id": "a5638ce6-55a8-4763-a612-7f8551cb8cac",
      "name": "Machine Learning, Natural Language Processing, Sequence-to-Sequence Models, Neural Networks, Attention Mechanisms, Transformers, Deep Learning Extensions, AI Model Architectures, Language Modeling, Model Optimization"
    },
    {
      "id": "0aa60663-e0b4-4ef5-ae64-3c483f7afd5a",
      "name": "Neural Networks, Sequence-to-Sequence Models, Attention Mechanisms, Transformer Architecture, Natural Language Processing, Deep Learning, Model Enhancements, Machine Learning Techniques, AI Model Optimization, Transfer Learning"
    },
    {
      "id": "2001811c-9dd3-4342-a62e-f433016eeae7",
      "name": "Artificial Intelligence, Machine Learning, Neural Networks, Sequence Models, Encoder-Decoder Architectures, Attention Mechanisms, Transformer Models, Deep Learning Techniques, Natural Language Processing (NLP), Model Extensions, Model Optimization, AI Research, Educational Resources"
    },
    {
      "id": "24247e7a-85ff-412c-9af4-b043791f7c88",
      "name": "Artificial Intelligence, Machine Learning, Natural Language Processing, Neural Networks, Deep Learning, Encoder-Decoder Architecture, Pretraining, Transformers, NLP Models, Language Models, AI Training Techniques"
    },
    {
      "id": "f14cce6a-073b-45c1-b7fe-9e7538a2a4d2",
      "name": "Machine Learning, Data Preprocessing, Feature Engineering, Data Transformation, Categorical Data, Encoding Techniques, Data Preparation, Data Science"
    },
    {
      "id": "a7f77665-b31f-4cf7-b129-008639037452",
      "name": "AI, Machine Learning, Natural Language Processing, Dialogue Systems, End-to-End Systems, Neural Networks, Conversational AI, Deep Learning, NLP Architectures, AI in Human-Computer Interaction"
    },
    {
      "id": "348a13c1-41bd-4413-8ce0-a4ad78c0358e",
      "name": "Artificial Intelligence, Machine Learning, Model Compression, Knowledge Distillation, Deep Learning, Neural Networks, Model Optimization"
    },
    {
      "id": "85e0dc26-c36b-4187-a352-67187084ef8c",
      "name": "Generative Adversarial Networks, GANs, Energy-Based Models, Autoencoders, Deep Learning, Unsupervised Learning, Generative Models, Machine Learning, Neural Networks, EBGANs"
    },
    {
      "id": "7ffdbcb8-700c-4730-aaba-29a5fc49d37f",
      "name": "Energy-Based Models (EBMs) are a class of probabilistic models that assign an energy score to each configuration of their input variables. Key tags associated with EBMs include machine learning, probabilistic modeling, energy functions, unsupervised learning, generative models, Boltzmann Machines, Restricted Boltzmann Machines, deep learning, optimization, and statistical mechanics. These models are often utilized for unsupervised feature learning, density estimation, and generative tasks, leveraging energy functions to define probability distributions over data. Related concepts include Markov Random Fields, contrastive divergence, and deep energy models, which highlight their connections to physics-inspired approaches and neural network architectures."
    },
    {
      "id": "c48babb1-acda-4625-9709-8bc8d7bf9bd0",
      "name": "Machine Learning, Deep Learning, Probabilistic Models, Generative Models, Energy-Based Models, EBMs, Unsupervised Learning, AI Modeling, Generative AI, Probabilistic Inference, Contrastive Divergence, Markov Chain Monte Carlo, Feature Learning, Anomaly Detection"
    },
    {
      "id": "073242ce-b826-433d-a4b1-60144b3c102d",
      "name": "Machine Learning, Probabilistic Models, Representation Learning, Unsupervised Learning, Artificial Intelligence, Pattern Recognition"
    },
    {
      "id": "4ada477a-e788-4c6d-80e5-d6ec17091d8f",
      "name": "Reinforcement Learning"
    },
    {
      "id": "f0152ff9-bc55-45ab-a823-876d73f66be1",
      "name": "Ensemble Methods, Machine Learning, Model Averaging, Bagging, Ensemble Techniques, Prediction Models, Data Science, Supervised Learning, Model Robustness, Variance Reduction"
    },
    {
      "id": "36912372-b061-4b9d-8426-7654ac27ae37",
      "name": "Machine Learning, Model Compression, Ensemble Methods, Knowledge Distillation, Deep Learning, Model Optimization, AI Techniques, Neural Networks, Transfer Learning"
    },
    {
      "id": "e1ae4119-a579-4651-a75a-35ee0178ffd5",
      "name": "Ensemble Learning, Model Diversity, Machine Learning Techniques, Ensemble Methods, Bagging, Boosting, Random Forest, Classifier Performance, Ensemble Optimization, Model Variance"
    },
    {
      "id": "1cdf390f-d4d8-498d-8fb8-9d22d378fec4",
      "name": "Machine Learning, Ensemble Methods, Diversity Techniques, Bagging, Boosting, Random Forests, Model Ensemble, Model Diversity, Ensemble Learning Strategies, Supervised Learning"
    },
    {
      "id": "c95a51f5-d135-4cab-b941-31ed73daf6e6",
      "name": "Machine Learning, Ensemble Methods, Diversity Techniques, Ensemble Extensions, Advanced Ensemble Strategies, Model Robustness, Classification, Regression, Boosting, Bagging, Heterogeneous Ensembles"
    },
    {
      "id": "eac19e39-8d2a-42bd-b373-3e273a6ffca1",
      "name": "Artificial Intelligence, Machine Learning, Data Science, Predictive Modeling, Ensemble Methods"
    },
    {
      "id": "f8ae95b2-95e4-4eab-ae95-6d5cfb679aaa",
      "name": "Statistical Estimation, Information Theory, Parameter Estimation, Machine Learning, Data Analysis, Cram\u00e9r-Rao Bound, Likelihood Function, Variance, Statistical Inference, Model Optimization"
    },
    {
      "id": "4ede7644-9540-41a6-b14d-731552eef08a",
      "name": "Statistics, Information Theory, Estimation Theory, Machine Learning, Data Science, Parameter Estimation, Fisher Information, Statistical Inference, Optimization, Neural Networks, Natural Gradient, Information Geometry"
    }
  ],
  "subcategories": [
    {
      "id": "f3f4805f-45d9-4a05-abda-f23bd47a548b",
      "name": "Probability Theory",
      "categoryId": "680d3998-490a-41df-b5dc-447682d109cc"
    },
    {
      "id": "05b48352-052c-4f33-b5a7-2599407e5aba",
      "name": "Characteristic Function",
      "categoryId": "680d3998-490a-41df-b5dc-447682d109cc"
    },
    {
      "id": "e2ff16fe-684c-4e42-aed3-d642a5641fbe",
      "name": "Distribution Functions",
      "categoryId": "680d3998-490a-41df-b5dc-447682d109cc"
    },
    {
      "id": "2b72d889-5a52-4624-aecc-c5be761ad177",
      "name": "Random Variables",
      "categoryId": "680d3998-490a-41df-b5dc-447682d109cc"
    },
    {
      "id": "4ed7fe6f-56f5-4e48-a322-2819274d7d37",
      "name": "Fourier Analysis",
      "categoryId": "680d3998-490a-41df-b5dc-447682d109cc"
    },
    {
      "id": "0bcd1ec9-5696-4060-982e-a4a7b51d2a17",
      "name": "Fourier Transform",
      "categoryId": "680d3998-490a-41df-b5dc-447682d109cc"
    },
    {
      "id": "88f33cb1-c54a-44c5-bdb4-2cbb3cf039ea",
      "name": "Complex-Valued Functions",
      "categoryId": "680d3998-490a-41df-b5dc-447682d109cc"
    },
    {
      "id": "663524e2-917d-405b-8690-940b2f875e7b",
      "name": "Moment Generating Functions",
      "categoryId": "680d3998-490a-41df-b5dc-447682d109cc"
    },
    {
      "id": "228cab07-c497-46c3-a773-02fb182fdf44",
      "name": "Statistical Characterization",
      "categoryId": "680d3998-490a-41df-b5dc-447682d109cc"
    },
    {
      "id": "82627264-1f75-4b81-abe7-1d1f49d920c6",
      "name": "Distance Metrics",
      "categoryId": "665ee489-ab09-419e-99e6-01965647cabf"
    },
    {
      "id": "9cec66eb-d183-4c77-a7b4-bee72e26084a",
      "name": "Geometric Measures",
      "categoryId": "665ee489-ab09-419e-99e6-01965647cabf"
    },
    {
      "id": "9cf09219-dc13-41ad-98f7-6fa43a3fc704",
      "name": "Mathematical Foundations",
      "categoryId": "665ee489-ab09-419e-99e6-01965647cabf"
    },
    {
      "id": "bac7c0c4-de0b-487f-8d2c-b6b8f9914981",
      "name": "High-Dimensional Spaces",
      "categoryId": "665ee489-ab09-419e-99e6-01965647cabf"
    },
    {
      "id": "7353ec13-380c-440d-a625-eda8aeeb9626",
      "name": "Quantitative Analysis",
      "categoryId": "665ee489-ab09-419e-99e6-01965647cabf"
    },
    {
      "id": "b0adb3e3-9099-429b-abc6-9d81930c5281",
      "name": "Norms and Metrics",
      "categoryId": "665ee489-ab09-419e-99e6-01965647cabf"
    },
    {
      "id": "7eaa3378-bcd6-4696-b79d-27fe631a55ca",
      "name": "Machine Learning Foundations",
      "categoryId": "665ee489-ab09-419e-99e6-01965647cabf"
    },
    {
      "id": "c4d256b8-5798-4615-ae71-77e32e6a302b",
      "name": "Data Similarity Measures",
      "categoryId": "665ee489-ab09-419e-99e6-01965647cabf"
    },
    {
      "id": "241ab512-d0c1-4d66-afaa-7b290c607d0c",
      "name": "Neural Networks",
      "categoryId": "1e59096b-cfbb-4eb3-a096-5e2f576eaefb"
    },
    {
      "id": "b04452b7-3caa-4186-bc2b-f10001d25391",
      "name": "Approximation Theory",
      "categoryId": "1e59096b-cfbb-4eb3-a096-5e2f576eaefb"
    },
    {
      "id": "1fd2f6ec-cc31-4ef9-b3c8-d05f11a30f91",
      "name": "Learning Algorithms",
      "categoryId": "1e59096b-cfbb-4eb3-a096-5e2f576eaefb"
    },
    {
      "id": "cbaf55df-97ae-41ea-b69c-bfd9d38c791f",
      "name": "Function Approximation",
      "categoryId": "1e59096b-cfbb-4eb3-a096-5e2f576eaefb"
    },
    {
      "id": "ae44e23e-fb1f-4311-a752-0075506d0d76",
      "name": "Polynomial Approximation",
      "categoryId": "1e59096b-cfbb-4eb3-a096-5e2f576eaefb"
    },
    {
      "id": "a8fd51bc-0220-45cb-a21d-b65d9a13cb86",
      "name": "Basis Functions",
      "categoryId": "1e59096b-cfbb-4eb3-a096-5e2f576eaefb"
    },
    {
      "id": "c5791478-d526-4c85-a42c-d9e11b2057ea",
      "name": "Nonlinear Networks",
      "categoryId": "1e59096b-cfbb-4eb3-a096-5e2f576eaefb"
    },
    {
      "id": "00d7f937-f833-4cc5-9f3a-b368c49803cd",
      "name": "Active Learning",
      "categoryId": "1e59096b-cfbb-4eb3-a096-5e2f576eaefb"
    },
    {
      "id": "0c3e5b8b-feac-43d1-9031-280e0f8c46ec",
      "name": "Adaptive Systems",
      "categoryId": "1e59096b-cfbb-4eb3-a096-5e2f576eaefb"
    },
    {
      "id": "b0546e62-7232-4156-8021-e3854a6e21f9",
      "name": "Approximation Theory",
      "categoryId": "a2b559f3-f074-42dc-b4a8-ef046c026fee"
    },
    {
      "id": "890ab428-ce60-4dd5-a63b-678770fbb5fb",
      "name": "Polynomial Approximation",
      "categoryId": "a2b559f3-f074-42dc-b4a8-ef046c026fee"
    },
    {
      "id": "e61f7a1e-d871-42b7-8805-dbd10eb14a3b",
      "name": "Spectral Methods",
      "categoryId": "a2b559f3-f074-42dc-b4a8-ef046c026fee"
    },
    {
      "id": "71d2dd9d-1e90-4e22-a67e-2011d40214bd",
      "name": "Neural Network Architectures",
      "categoryId": "a2b559f3-f074-42dc-b4a8-ef046c026fee"
    },
    {
      "id": "ee423599-ba5d-4bcf-8dde-6f376f19dc8b",
      "name": "Function Approximation",
      "categoryId": "a2b559f3-f074-42dc-b4a8-ef046c026fee"
    },
    {
      "id": "68253480-5383-403d-978d-da9b853d4041",
      "name": "Orthogonal Polynomials",
      "categoryId": "a2b559f3-f074-42dc-b4a8-ef046c026fee"
    },
    {
      "id": "815ccd95-c54e-4bc0-936e-ae758934973f",
      "name": "Chebyshev Polynomials",
      "categoryId": "a2b559f3-f074-42dc-b4a8-ef046c026fee"
    },
    {
      "id": "f573806d-0dc1-4a1a-aa54-2d4871e72e40",
      "name": "Polynomial Bases",
      "categoryId": "a2b559f3-f074-42dc-b4a8-ef046c026fee"
    },
    {
      "id": "ab2b39f9-6e8e-4cfd-813e-49ddcedc13a5",
      "name": "Kernel Methods",
      "categoryId": "a2b559f3-f074-42dc-b4a8-ef046c026fee"
    },
    {
      "id": "bb491161-91ab-4b0d-87c4-cb12e09bf05a",
      "name": "Function Spaces",
      "categoryId": "a2b559f3-f074-42dc-b4a8-ef046c026fee"
    },
    {
      "id": "9bc4f248-e691-4537-aa0c-a75addaf8d07",
      "name": "Polynomial Approximation",
      "categoryId": "ac53191f-1511-40c9-a288-3134a8a9a240"
    },
    {
      "id": "b910ee8a-64ab-463c-993f-3d2ebc2934d7",
      "name": "Spectral Neural Networks",
      "categoryId": "ac53191f-1511-40c9-a288-3134a8a9a240"
    },
    {
      "id": "486b256f-2329-4de7-b479-769e7aa78196",
      "name": "Orthogonal Polynomials",
      "categoryId": "ac53191f-1511-40c9-a288-3134a8a9a240"
    },
    {
      "id": "566ab6f9-de4a-40df-8d16-d4698dfdaf16",
      "name": "Activation Functions",
      "categoryId": "ac53191f-1511-40c9-a288-3134a8a9a240"
    },
    {
      "id": "9b6e3f63-8658-435c-8e05-a4979c2b45bc",
      "name": "Function Approximation in ML",
      "categoryId": "ac53191f-1511-40c9-a288-3134a8a9a240"
    },
    {
      "id": "11616930-a53a-4245-9cf8-54ecc86ac209",
      "name": "Model Checkpointing",
      "categoryId": "5a62c975-6105-4a66-b090-20bc1c9a0ee7"
    },
    {
      "id": "ac66c4cb-6739-4187-bd5b-f8828922e0f6",
      "name": "Training Checkpoints",
      "categoryId": "5a62c975-6105-4a66-b090-20bc1c9a0ee7"
    },
    {
      "id": "c1e0fc98-291c-4ced-b05a-3e5bba4ef70c",
      "name": "Model Saving",
      "categoryId": "5a62c975-6105-4a66-b090-20bc1c9a0ee7"
    },
    {
      "id": "71b90170-aa6c-49f1-9ccd-c5dec52fdf80",
      "name": "Training Resilience",
      "categoryId": "5a62c975-6105-4a66-b090-20bc1c9a0ee7"
    },
    {
      "id": "0e07188b-b036-4d19-bbb6-c29d335c8463",
      "name": "Memory Management in ML",
      "categoryId": "5a62c975-6105-4a66-b090-20bc1c9a0ee7"
    },
    {
      "id": "0a6c4802-75b8-4588-8b22-2c1a94792a51",
      "name": "Model State Preservation",
      "categoryId": "5a62c975-6105-4a66-b090-20bc1c9a0ee7"
    },
    {
      "id": "f6a30827-457c-4980-bf66-f8f674ac997a",
      "name": "Iteration Snapshots",
      "categoryId": "5a62c975-6105-4a66-b090-20bc1c9a0ee7"
    },
    {
      "id": "5357579b-8186-40d8-81e4-2b30ef788f21",
      "name": "Training Progress Saving",
      "categoryId": "5a62c975-6105-4a66-b090-20bc1c9a0ee7"
    },
    {
      "id": "c5a8918c-3842-42cf-ac60-9151ed723c8b",
      "name": "Fault Tolerance in ML",
      "categoryId": "5a62c975-6105-4a66-b090-20bc1c9a0ee7"
    },
    {
      "id": "c2781fd2-f691-4197-a442-cf3ec12668f5",
      "name": "Model Versioning",
      "categoryId": "5a62c975-6105-4a66-b090-20bc1c9a0ee7"
    },
    {
      "id": "da9668c1-5c83-485e-a7f4-2cd58a9ad465",
      "name": "AI",
      "categoryId": "83d6a18e-b5fa-484b-a283-2fe2a04a7f55"
    },
    {
      "id": "30dd504f-4e5d-4bcf-a617-d7605d78bb0b",
      "name": "model optimization",
      "categoryId": "9ffda2e3-be3d-4a9f-be94-b35157408227"
    },
    {
      "id": "ddad5cb8-24c4-465d-b0eb-491fc07fde4a",
      "name": "training techniques",
      "categoryId": "9ffda2e3-be3d-4a9f-be94-b35157408227"
    },
    {
      "id": "ca5d2121-d60a-45b2-80e6-d845525b1d5c",
      "name": "neural network training",
      "categoryId": "9ffda2e3-be3d-4a9f-be94-b35157408227"
    },
    {
      "id": "820c0d0b-4a55-4877-9b3f-d39e57edfb60",
      "name": "model ensemble methods",
      "categoryId": "9ffda2e3-be3d-4a9f-be94-b35157408227"
    },
    {
      "id": "27192d30-a304-4c06-9389-ea47948c11f8",
      "name": "quality model selection",
      "categoryId": "9ffda2e3-be3d-4a9f-be94-b35157408227"
    },
    {
      "id": "0bb1eb04-da9a-409d-a4c8-778aff810d0f",
      "name": "Model Checkpoints",
      "categoryId": "340460e6-76f8-4e83-91f8-7dd3be9160c7"
    },
    {
      "id": "055e4cbd-a666-47e0-9665-116b991b6dbf",
      "name": "Training Progress",
      "categoryId": "340460e6-76f8-4e83-91f8-7dd3be9160c7"
    },
    {
      "id": "828f9a24-079f-4010-957a-5f7f1df964a3",
      "name": "Model Saving",
      "categoryId": "340460e6-76f8-4e83-91f8-7dd3be9160c7"
    },
    {
      "id": "2c829f08-5abb-4fff-bcd0-b9f9f8711db8",
      "name": "Model Restoration",
      "categoryId": "340460e6-76f8-4e83-91f8-7dd3be9160c7"
    },
    {
      "id": "81c79501-3467-40bd-8669-f52c9093136d",
      "name": "Model Versioning",
      "categoryId": "340460e6-76f8-4e83-91f8-7dd3be9160c7"
    },
    {
      "id": "9c54eb41-fbb8-415d-a3ba-e6e1780dfdd3",
      "name": "Checkpoint Files",
      "categoryId": "340460e6-76f8-4e83-91f8-7dd3be9160c7"
    },
    {
      "id": "d7ad43df-259b-44f9-853a-75987d381792",
      "name": "Training States",
      "categoryId": "340460e6-76f8-4e83-91f8-7dd3be9160c7"
    },
    {
      "id": "e0eef9f9-517f-4d3f-ad78-66ce3a6d291d",
      "name": "Model Management",
      "categoryId": "340460e6-76f8-4e83-91f8-7dd3be9160c7"
    },
    {
      "id": "f88b0a6d-c4a9-4919-b7ac-f0b09eccb312",
      "name": "Transfer Learning Checkpoints",
      "categoryId": "340460e6-76f8-4e83-91f8-7dd3be9160c7"
    },
    {
      "id": "8111a27d-df99-4621-9286-9b2ca5b4aac4",
      "name": "Fine-tuning Checkpoints",
      "categoryId": "340460e6-76f8-4e83-91f8-7dd3be9160c7"
    },
    {
      "id": "30e81db6-7992-44ce-a8b6-a416cb338c44",
      "name": "Cheminformatics",
      "categoryId": "fb2e3e64-8f43-4894-b6dc-ad586e2fbc28"
    },
    {
      "id": "c7f06c37-8c31-4d3b-b3ec-452b551ca78e",
      "name": "Chemical Data Analysis",
      "categoryId": "fb2e3e64-8f43-4894-b6dc-ad586e2fbc28"
    },
    {
      "id": "ab7ef821-5251-4eda-9f13-62b047595199",
      "name": "Molecular Modeling",
      "categoryId": "fb2e3e64-8f43-4894-b6dc-ad586e2fbc28"
    },
    {
      "id": "0a648af2-f26d-4245-9d80-13c58aaa6cf8",
      "name": "Quantitative Structure-Activity Relationship (QSAR)",
      "categoryId": "fb2e3e64-8f43-4894-b6dc-ad586e2fbc28"
    },
    {
      "id": "9d713fbe-5538-4f8d-bf69-dc1a48faede2",
      "name": "Chemoinformatics",
      "categoryId": "fb2e3e64-8f43-4894-b6dc-ad586e2fbc28"
    },
    {
      "id": "21721683-53d3-4cdd-9ab5-ba99424c009b",
      "name": "Chemical Databases",
      "categoryId": "fb2e3e64-8f43-4894-b6dc-ad586e2fbc28"
    },
    {
      "id": "0cd1ac0b-70d2-4ae4-9473-b36520021027",
      "name": "Structure-Based Drug Design",
      "categoryId": "fb2e3e64-8f43-4894-b6dc-ad586e2fbc28"
    },
    {
      "id": "36aa0e15-6896-4a53-a130-cd5ef4f36900",
      "name": "Chemical Informatics",
      "categoryId": "fb2e3e64-8f43-4894-b6dc-ad586e2fbc28"
    },
    {
      "id": "13eefb8a-4bb1-4aea-905e-6324375d7cf5",
      "name": "Chemical Information Science",
      "categoryId": "fb2e3e64-8f43-4894-b6dc-ad586e2fbc28"
    },
    {
      "id": "441896f0-3a95-4a98-9fc2-d3e9a00600aa",
      "name": "Statistical Hypothesis Testing",
      "categoryId": "12c5346d-024e-4f8f-83d8-d03a4d9566c3"
    },
    {
      "id": "69bdd9dd-4ba2-4c3c-b875-1ed1cf44855f",
      "name": "Categorical Data Analysis",
      "categoryId": "12c5346d-024e-4f8f-83d8-d03a4d9566c3"
    },
    {
      "id": "7a69ebfa-3d09-475e-b11a-b4cd7f6364c7",
      "name": "Contingency Tables",
      "categoryId": "12c5346d-024e-4f8f-83d8-d03a4d9566c3"
    },
    {
      "id": "278c15f6-f65d-4d1d-97a0-9d6481c9590e",
      "name": "Independence Testing",
      "categoryId": "12c5346d-024e-4f8f-83d8-d03a4d9566c3"
    },
    {
      "id": "550919e8-3500-4e88-acdf-f5a0a635bba2",
      "name": "Goodness-of-Fit Tests",
      "categoryId": "12c5346d-024e-4f8f-83d8-d03a4d9566c3"
    },
    {
      "id": "1d04ae5c-9b19-4be4-b287-c170d60e962b",
      "name": "Non-parametric Testing",
      "categoryId": "12c5346d-024e-4f8f-83d8-d03a4d9566c3"
    },
    {
      "id": "04f704c2-459d-46a1-9429-3f03b3379b11",
      "name": "Chi-Square Distribution",
      "categoryId": "12c5346d-024e-4f8f-83d8-d03a4d9566c3"
    },
    {
      "id": "bf807d1c-ee9f-4c9b-b315-cc92489a090e",
      "name": "Statistical Significance",
      "categoryId": "12c5346d-024e-4f8f-83d8-d03a4d9566c3"
    },
    {
      "id": "4ff4e49d-a9ad-48b1-9a0e-7b89d69eb669",
      "name": "p-Values",
      "categoryId": "12c5346d-024e-4f8f-83d8-d03a4d9566c3"
    },
    {
      "id": "1d4702ab-bccb-48dd-9ed4-15407330c23a",
      "name": "Statistical Hypothesis Testing",
      "categoryId": "563bd0ab-7fe2-4b23-8313-af266ea1e7ce"
    },
    {
      "id": "4819cb85-d997-4365-915b-b341f98c63a8",
      "name": "Categorical Data Analysis",
      "categoryId": "563bd0ab-7fe2-4b23-8313-af266ea1e7ce"
    },
    {
      "id": "ccd3c288-4096-4f90-8124-01522c04eb51",
      "name": "Goodness-of-Fit Tests",
      "categoryId": "563bd0ab-7fe2-4b23-8313-af266ea1e7ce"
    },
    {
      "id": "3d879572-cdb4-4a74-a9e5-b9e19dab312f",
      "name": "Independence Tests",
      "categoryId": "563bd0ab-7fe2-4b23-8313-af266ea1e7ce"
    },
    {
      "id": "033fee81-70df-4b80-b7ab-78434ae123ec",
      "name": "Chi-Square Distribution",
      "categoryId": "563bd0ab-7fe2-4b23-8313-af266ea1e7ce"
    },
    {
      "id": "d98b3039-84c8-4ad0-a412-db3de5caf95c",
      "name": "Data Distributions",
      "categoryId": "563bd0ab-7fe2-4b23-8313-af266ea1e7ce"
    },
    {
      "id": "626e93dd-8a4b-4951-862a-1f1d280ac36f",
      "name": "Non-parametric Tests",
      "categoryId": "563bd0ab-7fe2-4b23-8313-af266ea1e7ce"
    },
    {
      "id": "de317901-3e43-473f-a5f0-d0e0641d6a69",
      "name": "Contingency Tables",
      "categoryId": "563bd0ab-7fe2-4b23-8313-af266ea1e7ce"
    },
    {
      "id": "84b40c7b-54ef-4d89-acfe-99f9fb89b4ed",
      "name": "Assumption Checks",
      "categoryId": "563bd0ab-7fe2-4b23-8313-af266ea1e7ce"
    },
    {
      "id": "fd5890d4-88e2-4cbd-bcf7-b0b0e93dc2da",
      "name": "Linear Algebra",
      "categoryId": "70e5c8ee-6ffc-44a3-a93b-0e128f76de7b"
    },
    {
      "id": "e7c4fa45-2bc6-4248-b89f-37eab11dc0bc",
      "name": "Matrix Decomposition",
      "categoryId": "70e5c8ee-6ffc-44a3-a93b-0e128f76de7b"
    },
    {
      "id": "a16fd655-0cc4-4ec1-9310-89e3efce7086",
      "name": "Numerical Methods",
      "categoryId": "70e5c8ee-6ffc-44a3-a93b-0e128f76de7b"
    },
    {
      "id": "fc21c177-496e-446a-8fd1-51875351c45e",
      "name": "Matrix Factorization",
      "categoryId": "70e5c8ee-6ffc-44a3-a93b-0e128f76de7b"
    },
    {
      "id": "53755238-03dd-45d6-a723-5c6cb607c919",
      "name": "Numerical Linear Algebra",
      "categoryId": "70e5c8ee-6ffc-44a3-a93b-0e128f76de7b"
    },
    {
      "id": "fe2da627-9a5a-4e84-9cbb-4055cd65ea49",
      "name": "Advanced Matrix Techniques",
      "categoryId": "70e5c8ee-6ffc-44a3-a93b-0e128f76de7b"
    },
    {
      "id": "e928f515-326a-405e-9c5c-2a89a0abeff4",
      "name": "Optimization Techniques",
      "categoryId": "5c03d1f2-97fc-4206-bb4f-9e2f15b68d52"
    },
    {
      "id": "7bd18d6e-0b99-4f1c-9109-13b8b154c259",
      "name": "Numerical Methods",
      "categoryId": "5c03d1f2-97fc-4206-bb4f-9e2f15b68d52"
    },
    {
      "id": "2ea01666-59bd-4802-9971-d387dc7eca0c",
      "name": "Matrix Decomposition",
      "categoryId": "5c03d1f2-97fc-4206-bb4f-9e2f15b68d52"
    },
    {
      "id": "ea0b3e43-5d60-4205-8a02-ae5bcdc9d51f",
      "name": "Linear Algebra",
      "categoryId": "5c03d1f2-97fc-4206-bb4f-9e2f15b68d52"
    },
    {
      "id": "62e7ba5c-9f5c-41a3-89fb-ffb818b97d14",
      "name": "Convex Optimization",
      "categoryId": "5c03d1f2-97fc-4206-bb4f-9e2f15b68d52"
    },
    {
      "id": "bc9e7c13-5934-497f-9c12-60d5d56eece1",
      "name": "Machine Learning Algorithms",
      "categoryId": "5c03d1f2-97fc-4206-bb4f-9e2f15b68d52"
    },
    {
      "id": "30ddc8e0-ba38-4b64-bd82-4f813df02db6",
      "name": "Numerical Stability",
      "categoryId": "5c03d1f2-97fc-4206-bb4f-9e2f15b68d52"
    },
    {
      "id": "3c9433a2-6e32-4e4d-b6e5-399b1ca88c1c",
      "name": "Positive Definite Matrices",
      "categoryId": "5c03d1f2-97fc-4206-bb4f-9e2f15b68d52"
    },
    {
      "id": "b1b2cdab-1fe5-4f92-8a6d-1ba80c7436a5",
      "name": "Computational Mathematics",
      "categoryId": "5c03d1f2-97fc-4206-bb4f-9e2f15b68d52"
    },
    {
      "id": "a49533ec-ad9b-49ef-b37a-d2e89c60976e",
      "name": "Image Processing",
      "categoryId": "212c0bfc-492f-413d-80ef-2698ec40f6d5"
    },
    {
      "id": "1fce6fc8-e2c3-4121-9c40-eaca2884d48f",
      "name": "Computational Photography",
      "categoryId": "212c0bfc-492f-413d-80ef-2698ec40f6d5"
    },
    {
      "id": "2be0886f-44b3-4323-9889-0ed0ed1ad7f0",
      "name": "Optical Corrections",
      "categoryId": "212c0bfc-492f-413d-80ef-2698ec40f6d5"
    },
    {
      "id": "a663f666-73e0-483c-b04e-bb1f9cdf93dd",
      "name": "Digital Imaging",
      "categoryId": "212c0bfc-492f-413d-80ef-2698ec40f6d5"
    },
    {
      "id": "de7dc2c0-dae3-45cd-9f4d-620850b08188",
      "name": "Image Enhancement",
      "categoryId": "212c0bfc-492f-413d-80ef-2698ec40f6d5"
    },
    {
      "id": "920678e4-db4a-4386-ae14-81ca051503a1",
      "name": "Photography Techniques",
      "categoryId": "212c0bfc-492f-413d-80ef-2698ec40f6d5"
    },
    {
      "id": "0a0212fe-7000-4c10-916e-c52b13554dc8",
      "name": "Computer Vision",
      "categoryId": "212c0bfc-492f-413d-80ef-2698ec40f6d5"
    },
    {
      "id": "dc3388ff-1a4b-47d4-838b-35f7f15ba561",
      "name": "Sensor Calibration",
      "categoryId": "212c0bfc-492f-413d-80ef-2698ec40f6d5"
    },
    {
      "id": "8d2a63f1-6f5e-4c6b-9c23-321ad267fdcc",
      "name": "Graph Theory",
      "categoryId": "fb74b630-0c1e-4357-a666-e6ebaa5c57d8"
    },
    {
      "id": "10b02936-8d15-4d9a-91ba-7d395ee30882",
      "name": "Random Graph Models",
      "categoryId": "fb74b630-0c1e-4357-a666-e6ebaa5c57d8"
    },
    {
      "id": "f364eb18-7adb-43a2-bba1-84c9bc9b13a8",
      "name": "Network Science",
      "categoryId": "fb74b630-0c1e-4357-a666-e6ebaa5c57d8"
    },
    {
      "id": "f466fe73-3bdc-41e0-a1dc-f354e9d180c1",
      "name": "Probability Theory",
      "categoryId": "fb74b630-0c1e-4357-a666-e6ebaa5c57d8"
    },
    {
      "id": "53659160-f02c-4ced-b521-baf95bf0b78b",
      "name": "Complex Networks",
      "categoryId": "fb74b630-0c1e-4357-a666-e6ebaa5c57d8"
    },
    {
      "id": "4bd05fd9-46c3-4fd8-bc99-c862a5fb2888",
      "name": "Scale-Free Networks",
      "categoryId": "fb74b630-0c1e-4357-a666-e6ebaa5c57d8"
    },
    {
      "id": "43f47fcf-5ba9-444d-a83d-1ba29f4f3a2b",
      "name": "Network Topology",
      "categoryId": "fb74b630-0c1e-4357-a666-e6ebaa5c57d8"
    },
    {
      "id": "603f0b15-3d29-46c1-a21c-09a5c9b0e638",
      "name": "Stochastic Processes",
      "categoryId": "fb74b630-0c1e-4357-a666-e6ebaa5c57d8"
    },
    {
      "id": "cfea1333-f07b-4ef6-954f-ba42e7588011",
      "name": "Degree Distribution",
      "categoryId": "fb74b630-0c1e-4357-a666-e6ebaa5c57d8"
    },
    {
      "id": "b05dc864-0c98-49d1-8518-334d8c01e91f",
      "name": "Network Modeling",
      "categoryId": "fb74b630-0c1e-4357-a666-e6ebaa5c57d8"
    },
    {
      "id": "518975c6-2337-41e2-86e9-c477e084233a",
      "name": "Natural Language Processing (NLP)",
      "categoryId": "64b59a62-30fe-4723-a08d-76e47241446a"
    },
    {
      "id": "d46b89f9-c4c7-4b0c-9fe1-b7b780e369dc",
      "name": "Data Preprocessing",
      "categoryId": "64b59a62-30fe-4723-a08d-76e47241446a"
    },
    {
      "id": "9e546b58-75ff-41d7-a947-b6e3456a326e",
      "name": "Sequence Modeling",
      "categoryId": "64b59a62-30fe-4723-a08d-76e47241446a"
    },
    {
      "id": "3f53bedd-b1e9-45ff-90df-bf32d735e382",
      "name": "Embedding Techniques",
      "categoryId": "64b59a62-30fe-4723-a08d-76e47241446a"
    },
    {
      "id": "ac8ecbf7-31a4-4c0c-9f6f-b003182c5127",
      "name": "Hierarchical Clustering",
      "categoryId": "64b59a62-30fe-4723-a08d-76e47241446a"
    },
    {
      "id": "ed24896c-0f0b-4933-8e66-8d739e641fdf",
      "name": "Tokenization Methods",
      "categoryId": "64b59a62-30fe-4723-a08d-76e47241446a"
    },
    {
      "id": "782bbcaf-2156-44b6-a5f8-655bda5fd56d",
      "name": "Contextual Analysis",
      "categoryId": "64b59a62-30fe-4723-a08d-76e47241446a"
    },
    {
      "id": "aab3e1ff-527f-41c7-a6ad-d9294c99927b",
      "name": "Memory Networks",
      "categoryId": "64b59a62-30fe-4723-a08d-76e47241446a"
    },
    {
      "id": "540cb804-5b2d-4514-92ed-a0b05edaa893",
      "name": "Neural Networks",
      "categoryId": "64b59a62-30fe-4723-a08d-76e47241446a"
    },
    {
      "id": "6881de0e-a3fe-4567-9496-addf2cc88705",
      "name": "Deep Learning.",
      "categoryId": "64b59a62-30fe-4723-a08d-76e47241446a"
    },
    {
      "id": "bb86b0be-9376-41ea-9b27-f6d089e7c4be",
      "name": "Tokenization",
      "categoryId": "447d3cca-4128-4815-9d65-719cf7a5a101"
    },
    {
      "id": "97384207-c954-45a3-9a99-e1731ac769da",
      "name": "Text Segmentation",
      "categoryId": "447d3cca-4128-4815-9d65-719cf7a5a101"
    },
    {
      "id": "8928f874-1859-4967-a936-60b5f345a268",
      "name": "Sequence Modeling",
      "categoryId": "447d3cca-4128-4815-9d65-719cf7a5a101"
    },
    {
      "id": "5a3f612e-95c5-4646-b881-0b8cd408d9e5",
      "name": "Linguistic Features",
      "categoryId": "447d3cca-4128-4815-9d65-719cf7a5a101"
    },
    {
      "id": "40d65690-393c-4c9b-850b-48fba9705a32",
      "name": "Contextual Embedding",
      "categoryId": "447d3cca-4128-4815-9d65-719cf7a5a101"
    },
    {
      "id": "e3a0c7c7-1920-4e96-b6fd-aa2319adf4b1",
      "name": "Natural Language Processing (NLP)",
      "categoryId": "ba7781e2-bd34-4175-aecd-4bb74d245e2d"
    },
    {
      "id": "bbc809fa-a193-425e-bfca-4ee2ef0294bd",
      "name": "Automatic Image Captioning",
      "categoryId": "ba7781e2-bd34-4175-aecd-4bb74d245e2d"
    },
    {
      "id": "eaaf4a04-8769-4491-8a06-426b528a1503",
      "name": "Image Caption Evaluation",
      "categoryId": "ba7781e2-bd34-4175-aecd-4bb74d245e2d"
    },
    {
      "id": "64c0a5e8-9fe0-4308-873b-240d267e7c07",
      "name": "Text Similarity Metrics",
      "categoryId": "ba7781e2-bd34-4175-aecd-4bb74d245e2d"
    },
    {
      "id": "cc6ca068-6c85-48f8-bb43-9e676f8869d1",
      "name": "Evaluation Criteria for Generated Content",
      "categoryId": "ba7781e2-bd34-4175-aecd-4bb74d245e2d"
    },
    {
      "id": "06efbd67-6d2a-4099-9211-76099bf9dc4c",
      "name": "Caption Quality Assessment",
      "categoryId": "ba7781e2-bd34-4175-aecd-4bb74d245e2d"
    },
    {
      "id": "e3807803-1d35-4b8d-bc1d-13ba230d7b74",
      "name": "Image Classification",
      "categoryId": "466eb4b3-2643-49c4-8454-47f94ed42f85"
    },
    {
      "id": "716a8a8b-0ae5-4b7b-89b5-32436303f472",
      "name": "Computer Vision",
      "categoryId": "466eb4b3-2643-49c4-8454-47f94ed42f85"
    },
    {
      "id": "487208f8-8fe5-4db9-b1ce-bdb67bb1e71f",
      "name": "Dataset",
      "categoryId": "466eb4b3-2643-49c4-8454-47f94ed42f85"
    },
    {
      "id": "cb43a3a8-8795-42c3-a3b9-5ed35b97f3c0",
      "name": "CIFAR-10",
      "categoryId": "466eb4b3-2643-49c4-8454-47f94ed42f85"
    },
    {
      "id": "acd47e8a-76af-414a-ad4c-4745b7234a60",
      "name": "Deep Learning",
      "categoryId": "466eb4b3-2643-49c4-8454-47f94ed42f85"
    },
    {
      "id": "ed2927d4-378b-47bd-84d7-342eabe3cd9f",
      "name": "Machine Learning",
      "categoryId": "466eb4b3-2643-49c4-8454-47f94ed42f85"
    },
    {
      "id": "75ec7315-1fe8-4017-9186-17fb79f1911c",
      "name": "Dataset Benchmark",
      "categoryId": "466eb4b3-2643-49c4-8454-47f94ed42f85"
    },
    {
      "id": "99f529af-97b5-4812-81c8-2627d4391599",
      "name": "Visual Recognition",
      "categoryId": "466eb4b3-2643-49c4-8454-47f94ed42f85"
    },
    {
      "id": "a3b6ce31-1b91-4bd3-b27a-cecacc1db69e",
      "name": "Supervised Learning",
      "categoryId": "466eb4b3-2643-49c4-8454-47f94ed42f85"
    },
    {
      "id": "2bd46a0c-b377-427a-8b00-60185ee27a0f",
      "name": "Data Augmentation",
      "categoryId": "466eb4b3-2643-49c4-8454-47f94ed42f85"
    },
    {
      "id": "060ab062-3eee-4e3c-905a-f4b9b408df86",
      "name": "Image Classification",
      "categoryId": "28162c27-8489-4760-9c1c-7ffe085efab1"
    },
    {
      "id": "7f84d92b-959b-4bb1-94ec-7650d7463531",
      "name": "Dataset",
      "categoryId": "28162c27-8489-4760-9c1c-7ffe085efab1"
    },
    {
      "id": "4197108f-3080-4164-b1d9-a3ee6510a95b",
      "name": "Computer Vision",
      "categoryId": "28162c27-8489-4760-9c1c-7ffe085efab1"
    },
    {
      "id": "8bf0afdf-cf13-4abd-823e-a26d6e38c826",
      "name": "Multiclass Classification",
      "categoryId": "28162c27-8489-4760-9c1c-7ffe085efab1"
    },
    {
      "id": "5c44a8d1-44c1-4c47-bb30-fbeeec115f8f",
      "name": "Benchmark Dataset",
      "categoryId": "28162c27-8489-4760-9c1c-7ffe085efab1"
    },
    {
      "id": "d6497acd-88b6-4875-925a-2e3db39529cc",
      "name": "Visual Recognition",
      "categoryId": "28162c27-8489-4760-9c1c-7ffe085efab1"
    },
    {
      "id": "de7a1e73-b10f-4d1f-8329-b1468236ec1d",
      "name": "Dataset Annotation",
      "categoryId": "28162c27-8489-4760-9c1c-7ffe085efab1"
    },
    {
      "id": "5bc65814-11e5-4d96-8163-7da8ff832561",
      "name": "CNN Training",
      "categoryId": "28162c27-8489-4760-9c1c-7ffe085efab1"
    },
    {
      "id": "2b4b4f32-d0d9-441c-a088-0f52cae14ec3",
      "name": "Data Augmentation",
      "categoryId": "28162c27-8489-4760-9c1c-7ffe085efab1"
    },
    {
      "id": "75b4ab89-2261-46f5-b479-22c82d77aead",
      "name": "Dataset Curation",
      "categoryId": "28162c27-8489-4760-9c1c-7ffe085efab1"
    },
    {
      "id": "38ed4f8f-bb96-4709-9222-121db776411b",
      "name": "Class Incremental Learning (CIL) falls under the broader categories of Continual Learning",
      "categoryId": "5909a0b9-d8e5-49a2-8bd3-f68946002ded"
    },
    {
      "id": "4b870da8-12aa-42d3-bf90-758c1b3b4e7f",
      "name": "Lifelong Learning",
      "categoryId": "5909a0b9-d8e5-49a2-8bd3-f68946002ded"
    },
    {
      "id": "41745e3b-de89-48bd-aa4f-ad3c63ef7048",
      "name": "and Incremental Learning. It is a subfield dedicated to enabling models to learn from new data streams incrementally while retaining previously acquired knowledge",
      "categoryId": "5909a0b9-d8e5-49a2-8bd3-f68946002ded"
    },
    {
      "id": "e627d50a-25ce-469d-8bd6-4813512a4639",
      "name": "thus addressing issues like catastrophic forgetting. Related sub-category tags include Online Learning",
      "categoryId": "5909a0b9-d8e5-49a2-8bd3-f68946002ded"
    },
    {
      "id": "bd96d134-ef3d-48d8-a0a3-c96a08baa8d0",
      "name": "Adaptive Learning",
      "categoryId": "5909a0b9-d8e5-49a2-8bd3-f68946002ded"
    },
    {
      "id": "682ec6b3-a2e4-4515-8d01-e0208051747b",
      "name": "and Dynamic Model Updating.",
      "categoryId": "5909a0b9-d8e5-49a2-8bd3-f68946002ded"
    },
    {
      "id": "1cc89f45-1ac9-4c8f-a44e-098deee58c7d",
      "name": "Circuit Analysis",
      "categoryId": "8d439733-28d7-48c0-a53d-3e0e48c350c4"
    },
    {
      "id": "2ab3ed21-0f25-4030-b1b3-c77222d8b8b4",
      "name": "Electrical Engineering",
      "categoryId": "8d439733-28d7-48c0-a53d-3e0e48c350c4"
    },
    {
      "id": "681e79f6-1b19-49db-8784-3d65d6000395",
      "name": "Electronics",
      "categoryId": "8d439733-28d7-48c0-a53d-3e0e48c350c4"
    },
    {
      "id": "a832ff92-7b02-4a89-a104-88fed55cac81",
      "name": "Circuit Theory",
      "categoryId": "8d439733-28d7-48c0-a53d-3e0e48c350c4"
    },
    {
      "id": "2a85f7d9-b238-42cd-aa97-8856839c90d9",
      "name": "Circuit Simulation",
      "categoryId": "8d439733-28d7-48c0-a53d-3e0e48c350c4"
    },
    {
      "id": "5bed2b00-44f7-4008-937a-88d437726a3b",
      "name": "Signal Processing",
      "categoryId": "8d439733-28d7-48c0-a53d-3e0e48c350c4"
    },
    {
      "id": "d3840a1d-8b49-42be-8db1-c6f9a6b14c5c",
      "name": "Power Systems",
      "categoryId": "8d439733-28d7-48c0-a53d-3e0e48c350c4"
    },
    {
      "id": "fa892e24-4e0e-40f5-a63c-c77e9125e1a1",
      "name": "Analog Circuits",
      "categoryId": "8d439733-28d7-48c0-a53d-3e0e48c350c4"
    },
    {
      "id": "e0beb0f8-b5d1-48d6-81ad-99bb88056103",
      "name": "Digital Circuits",
      "categoryId": "8d439733-28d7-48c0-a53d-3e0e48c350c4"
    },
    {
      "id": "c8aa0a38-d745-479d-92bd-47ac7b4c3290",
      "name": "Transient Analysis",
      "categoryId": "8d439733-28d7-48c0-a53d-3e0e48c350c4"
    },
    {
      "id": "29d84352-a0d8-4c77-a02f-7597251c1a0b",
      "name": "Steady-State Analysis",
      "categoryId": "8d439733-28d7-48c0-a53d-3e0e48c350c4"
    },
    {
      "id": "835aa5c3-59c4-453a-899e-276c2a5e20f1",
      "name": "Complexity Theory",
      "categoryId": "0c063e4e-a976-49cd-b067-8d697e37b074"
    },
    {
      "id": "401409f9-6690-4d74-9233-1d724a085c3a",
      "name": "Computational Complexity",
      "categoryId": "0c063e4e-a976-49cd-b067-8d697e37b074"
    },
    {
      "id": "73785a63-707b-4bf7-bff9-652966e2e4c1",
      "name": "Boolean Circuits",
      "categoryId": "0c063e4e-a976-49cd-b067-8d697e37b074"
    },
    {
      "id": "52b9c168-a04c-4663-9901-0297b0632bbc",
      "name": "Logical Circuits",
      "categoryId": "0c063e4e-a976-49cd-b067-8d697e37b074"
    },
    {
      "id": "1092c4c7-5b2a-4891-a43d-141ad7adc372",
      "name": "Algorithm Analysis",
      "categoryId": "0c063e4e-a976-49cd-b067-8d697e37b074"
    },
    {
      "id": "9beb7ca0-6601-45c6-88d5-74d2fa6e0c66",
      "name": "Circuit Optimization",
      "categoryId": "0c063e4e-a976-49cd-b067-8d697e37b074"
    },
    {
      "id": "543d764d-f494-4914-9452-2b67183091dc",
      "name": "NP-Completeness",
      "categoryId": "0c063e4e-a976-49cd-b067-8d697e37b074"
    },
    {
      "id": "dc84b783-c036-4fbc-9c02-2948248c2ace",
      "name": "Circuit Depth",
      "categoryId": "0c063e4e-a976-49cd-b067-8d697e37b074"
    },
    {
      "id": "9be0354b-f9a7-4f3a-9c8a-b6fc47fc2610",
      "name": "Circuit Size",
      "categoryId": "0c063e4e-a976-49cd-b067-8d697e37b074"
    },
    {
      "id": "7a4f582e-2adc-40e5-9e51-b21169e45131",
      "name": "Boolean Function Complexity",
      "categoryId": "0c063e4e-a976-49cd-b067-8d697e37b074"
    },
    {
      "id": "177e6c22-1bcf-4967-a923-7c3b3a70d4aa",
      "name": "Circuit-level Analysis",
      "categoryId": "cfc56cf8-bd54-4a8b-9b3f-5e8ce0bb635e"
    },
    {
      "id": "a933f89d-385c-4707-a43f-277bf18e0b67",
      "name": "Digital Circuits",
      "categoryId": "cfc56cf8-bd54-4a8b-9b3f-5e8ce0bb635e"
    },
    {
      "id": "b59e7dae-0941-45f8-b2d7-55c021c8b974",
      "name": "Analog Circuits",
      "categoryId": "cfc56cf8-bd54-4a8b-9b3f-5e8ce0bb635e"
    },
    {
      "id": "34736b8d-0877-468a-885e-17343c7e248c",
      "name": "Circuit Simulation",
      "categoryId": "cfc56cf8-bd54-4a8b-9b3f-5e8ce0bb635e"
    },
    {
      "id": "f1a45b47-36d5-4d17-9973-61d4f01bfdf9",
      "name": "Electrical Engineering",
      "categoryId": "cfc56cf8-bd54-4a8b-9b3f-5e8ce0bb635e"
    },
    {
      "id": "366a9fdf-baf9-4ebf-aa68-8c847de59660",
      "name": "SPICE Modeling",
      "categoryId": "cfc56cf8-bd54-4a8b-9b3f-5e8ce0bb635e"
    },
    {
      "id": "b08b5fde-fbbf-4788-9803-5d02aac2e8aa",
      "name": "Circuit Testing",
      "categoryId": "cfc56cf8-bd54-4a8b-9b3f-5e8ce0bb635e"
    },
    {
      "id": "9c8a1b8f-4c45-4482-9a76-a2b27ab6855e",
      "name": "Transistor Models",
      "categoryId": "cfc56cf8-bd54-4a8b-9b3f-5e8ce0bb635e"
    },
    {
      "id": "e83cd601-cd42-451b-96bd-3d1431a9b589",
      "name": "Circuit Optimization",
      "categoryId": "cfc56cf8-bd54-4a8b-9b3f-5e8ce0bb635e"
    },
    {
      "id": "ac7bfe83-49cd-4f36-b53c-cf062df7b099",
      "name": "Electrical Design",
      "categoryId": "cfc56cf8-bd54-4a8b-9b3f-5e8ce0bb635e"
    },
    {
      "id": "0f626e92-7a4a-4476-b785-f07ff97abc0a",
      "name": "Signal Processing",
      "categoryId": "4a45a0bd-1af8-41e2-9ad9-21bf28654409"
    },
    {
      "id": "ab03bc54-a2e1-48eb-b9e3-47dfe44abddb",
      "name": "Digital Signal Processing (DSP)",
      "categoryId": "4a45a0bd-1af8-41e2-9ad9-21bf28654409"
    },
    {
      "id": "8d3aa4ca-9f32-4835-9bd1-9a511b4b6b7e",
      "name": "Discrete Mathematics",
      "categoryId": "4a45a0bd-1af8-41e2-9ad9-21bf28654409"
    },
    {
      "id": "7f9c2533-8649-48b8-b36a-724a362f87cb",
      "name": "Fourier Transform",
      "categoryId": "4a45a0bd-1af8-41e2-9ad9-21bf28654409"
    },
    {
      "id": "bb0762b7-83bf-4ae5-bfb7-8d895aff8ce5",
      "name": "Time Series Analysis",
      "categoryId": "4a45a0bd-1af8-41e2-9ad9-21bf28654409"
    },
    {
      "id": "40199a11-0941-4448-8327-3a56cfa28a9d",
      "name": "Linear Systems",
      "categoryId": "4a45a0bd-1af8-41e2-9ad9-21bf28654409"
    },
    {
      "id": "5628d191-72c9-4e18-95a2-633846874762",
      "name": "Spectral Analysis",
      "categoryId": "4a45a0bd-1af8-41e2-9ad9-21bf28654409"
    },
    {
      "id": "5163cf1e-d3b3-4bf8-8c6b-68c366de9778",
      "name": "Fourier Convolution",
      "categoryId": "4a45a0bd-1af8-41e2-9ad9-21bf28654409"
    },
    {
      "id": "c0082764-4f14-482d-9e9f-2c95751f0767",
      "name": "Periodic Signals",
      "categoryId": "4a45a0bd-1af8-41e2-9ad9-21bf28654409"
    },
    {
      "id": "b998af90-cc5f-4721-96f9-199f500b5e51",
      "name": "Convolutional Neural Networks (CNNs)",
      "categoryId": "a918ded9-99e6-4ff2-a92f-93f8c0f32adf"
    },
    {
      "id": "b885eb82-8507-4a69-9b16-a334bbd26553",
      "name": "Padding Techniques",
      "categoryId": "a918ded9-99e6-4ff2-a92f-93f8c0f32adf"
    },
    {
      "id": "e5da09f4-4a1b-4880-910e-ffec2cb3972c",
      "name": "Zero Padding",
      "categoryId": "a918ded9-99e6-4ff2-a92f-93f8c0f32adf"
    },
    {
      "id": "530c4911-a653-429a-a1e8-4313df15efa9",
      "name": "Spatial Padding",
      "categoryId": "a918ded9-99e6-4ff2-a92f-93f8c0f32adf"
    },
    {
      "id": "5559f7c6-cb23-40f5-be16-44ef82197c35",
      "name": "Edge Handling",
      "categoryId": "a918ded9-99e6-4ff2-a92f-93f8c0f32adf"
    },
    {
      "id": "8d3f241f-4521-4825-8f8d-90da3e9c0f9d",
      "name": "Data Augmentation",
      "categoryId": "a918ded9-99e6-4ff2-a92f-93f8c0f32adf"
    },
    {
      "id": "90b495d2-68e4-46e9-b27f-708442453455",
      "name": "Image Processing",
      "categoryId": "a918ded9-99e6-4ff2-a92f-93f8c0f32adf"
    },
    {
      "id": "50da4a5e-d50b-4c53-8f32-d656a9dbe011",
      "name": "Deep Learning Architectures",
      "categoryId": "a918ded9-99e6-4ff2-a92f-93f8c0f32adf"
    },
    {
      "id": "f1ed8780-2c79-40d4-8f5c-64dd68936e27",
      "name": "Convolutional Neural Networks",
      "categoryId": "b16c54b9-1e16-44e0-8f81-96cde9210d00"
    },
    {
      "id": "bcdf72d1-7f01-4a55-8082-05fae50a7cef",
      "name": "Padding Techniques",
      "categoryId": "b16c54b9-1e16-44e0-8f81-96cde9210d00"
    },
    {
      "id": "1f5631eb-cbaf-466f-93d3-6247be166bf2",
      "name": "Circular Padding",
      "categoryId": "b16c54b9-1e16-44e0-8f81-96cde9210d00"
    },
    {
      "id": "6a48d8a0-7fd1-4b27-9e9b-faf52fa2234e",
      "name": "Image Processing",
      "categoryId": "b16c54b9-1e16-44e0-8f81-96cde9210d00"
    },
    {
      "id": "6464e3aa-3970-4e9c-a686-5d92dc23a916",
      "name": "Deep Learning Architectures",
      "categoryId": "b16c54b9-1e16-44e0-8f81-96cde9210d00"
    },
    {
      "id": "37717dd4-7765-43b2-9ca0-b780b598a83d",
      "name": "Data Augmentation",
      "categoryId": "b16c54b9-1e16-44e0-8f81-96cde9210d00"
    },
    {
      "id": "a5a91d77-f776-4445-af6f-5663eedbc27d",
      "name": "Feature Extraction",
      "categoryId": "b16c54b9-1e16-44e0-8f81-96cde9210d00"
    },
    {
      "id": "bcf69db8-e268-4652-9211-c4b007da0ad2",
      "name": "Convolution Operations",
      "categoryId": "b16c54b9-1e16-44e0-8f81-96cde9210d00"
    },
    {
      "id": "79369efc-ec16-4fb1-977d-cb36e01d820c",
      "name": "Computer Vision",
      "categoryId": "cdc6501d-b0fc-4dde-9848-5e706c8fa375"
    },
    {
      "id": "a2217b1d-e4fa-46cf-a91c-91df5b24fd99",
      "name": "Deep Learning",
      "categoryId": "cdc6501d-b0fc-4dde-9848-5e706c8fa375"
    },
    {
      "id": "99d70521-c1dd-4067-abc0-494c5990c2e9",
      "name": "Model Interpretability",
      "categoryId": "cdc6501d-b0fc-4dde-9848-5e706c8fa375"
    },
    {
      "id": "aa4ec221-ebf2-4af9-9937-ae9ab5a181ee",
      "name": "Convolutional Neural Networks (CNNs)",
      "categoryId": "cdc6501d-b0fc-4dde-9848-5e706c8fa375"
    },
    {
      "id": "65d98989-995a-4111-865f-f5aa6a76a8df",
      "name": "Visualization Techniques",
      "categoryId": "cdc6501d-b0fc-4dde-9848-5e706c8fa375"
    },
    {
      "id": "309798a5-48b4-4fad-8f76-23f8e6b28be1",
      "name": "Explanation Methods",
      "categoryId": "cdc6501d-b0fc-4dde-9848-5e706c8fa375"
    },
    {
      "id": "70c1c99a-dd93-480a-a649-25f4a414bdc4",
      "name": "Feature Localization",
      "categoryId": "cdc6501d-b0fc-4dde-9848-5e706c8fa375"
    },
    {
      "id": "ecf99165-ec09-4b25-8dc2-e6decb547c92",
      "name": "Class Activation Maps (CAM)",
      "categoryId": "49774b02-9fd2-41e9-9d67-f8c0901195c0"
    },
    {
      "id": "f20fc60e-1d47-43d9-88e3-029a8b2c6757",
      "name": "visualization",
      "categoryId": "49774b02-9fd2-41e9-9d67-f8c0901195c0"
    },
    {
      "id": "ae784c77-5818-4abf-849b-711f84101a46",
      "name": "CNN interpretability",
      "categoryId": "49774b02-9fd2-41e9-9d67-f8c0901195c0"
    },
    {
      "id": "e047667b-657b-44cd-a571-ce3e01417559",
      "name": "image classification",
      "categoryId": "49774b02-9fd2-41e9-9d67-f8c0901195c0"
    },
    {
      "id": "1965ed3e-7de0-49e1-afce-f205f008c265",
      "name": "deep learning explainability",
      "categoryId": "49774b02-9fd2-41e9-9d67-f8c0901195c0"
    },
    {
      "id": "d2122874-d08e-4425-99dc-d4d0fcd198d0",
      "name": "feature localization",
      "categoryId": "49774b02-9fd2-41e9-9d67-f8c0901195c0"
    },
    {
      "id": "ed1bfc26-1ff2-48fc-ac48-054ca5dbc33a",
      "name": "model transparency",
      "categoryId": "49774b02-9fd2-41e9-9d67-f8c0901195c0"
    },
    {
      "id": "01261d29-6f88-4f9a-8e37-e574c03d015c",
      "name": "heatmaps",
      "categoryId": "49774b02-9fd2-41e9-9d67-f8c0901195c0"
    },
    {
      "id": "6ce46488-f979-436d-9ae2-98fcc44a5364",
      "name": "neural network visualization",
      "categoryId": "49774b02-9fd2-41e9-9d67-f8c0901195c0"
    },
    {
      "id": "f3edf737-f251-48ef-aab4-df6a3d9799be",
      "name": "spatial attention",
      "categoryId": "49774b02-9fd2-41e9-9d67-f8c0901195c0"
    },
    {
      "id": "45cbac75-b186-4991-88a2-ec52fa82b282",
      "name": "Data Sampling",
      "categoryId": "5a62c975-6105-4a66-b090-20bc1c9a0ee7"
    },
    {
      "id": "4c16281d-d7a4-45e2-9010-f2a76c283056",
      "name": "Class Balancing",
      "categoryId": "5a62c975-6105-4a66-b090-20bc1c9a0ee7"
    },
    {
      "id": "56ddb9c4-f014-43c8-bd34-008d4694cb24",
      "name": "Imbalanced Datasets",
      "categoryId": "5a62c975-6105-4a66-b090-20bc1c9a0ee7"
    },
    {
      "id": "d3445899-90d1-4a48-98c2-96f619bf4cc7",
      "name": "Data Augmentation",
      "categoryId": "5a62c975-6105-4a66-b090-20bc1c9a0ee7"
    },
    {
      "id": "0ff4b0f1-3c02-4373-afde-218b7f62f763",
      "name": "Data Resampling",
      "categoryId": "5a62c975-6105-4a66-b090-20bc1c9a0ee7"
    },
    {
      "id": "6b1b79af-3cf9-43c6-ab44-6ca7cd6f7a2f",
      "name": "Synthetic Data Generation",
      "categoryId": "5a62c975-6105-4a66-b090-20bc1c9a0ee7"
    },
    {
      "id": "1af4ee20-cd41-4b86-ba40-7e9b37c152aa",
      "name": "Oversampling",
      "categoryId": "5a62c975-6105-4a66-b090-20bc1c9a0ee7"
    },
    {
      "id": "ad800734-ded5-4719-b63c-5a8dd209026f",
      "name": "Undersampling",
      "categoryId": "5a62c975-6105-4a66-b090-20bc1c9a0ee7"
    },
    {
      "id": "b9606870-7670-4040-8644-156c481f5495",
      "name": "Data Preprocessing",
      "categoryId": "5a62c975-6105-4a66-b090-20bc1c9a0ee7"
    },
    {
      "id": "747db0f9-cf77-4a0c-b9fe-07c08a8d7645",
      "name": "Class Imbalance",
      "categoryId": "bd52977c-f080-4693-ad04-13ebf83b3438"
    },
    {
      "id": "d22a68ae-60e1-4474-be84-6efd00dd14c6",
      "name": "Data Imbalance",
      "categoryId": "bd52977c-f080-4693-ad04-13ebf83b3438"
    },
    {
      "id": "1648e82e-576a-4f23-8fb4-880e74802a12",
      "name": "Skewed Data",
      "categoryId": "bd52977c-f080-4693-ad04-13ebf83b3438"
    },
    {
      "id": "d3775ae0-b366-4634-b8e4-098ad5442f8f",
      "name": "Imbalanced Datasets",
      "categoryId": "bd52977c-f080-4693-ad04-13ebf83b3438"
    },
    {
      "id": "1e5867a0-9368-4be8-b925-cb053c6cc9eb",
      "name": "Classification Challenges",
      "categoryId": "bd52977c-f080-4693-ad04-13ebf83b3438"
    },
    {
      "id": "cb4df37d-fe58-45b8-9b25-519bec68cd66",
      "name": "Minority Class",
      "categoryId": "bd52977c-f080-4693-ad04-13ebf83b3438"
    },
    {
      "id": "68468857-2a8b-42fe-b6fd-1c7e00445a5c",
      "name": "Majority Class",
      "categoryId": "bd52977c-f080-4693-ad04-13ebf83b3438"
    },
    {
      "id": "ab872113-d9c3-4a06-91aa-61d0e87228d8",
      "name": "Data Distribution",
      "categoryId": "bd52977c-f080-4693-ad04-13ebf83b3438"
    },
    {
      "id": "3068ceee-b1fe-4bf9-89d7-2cf8a32c8509",
      "name": "Dataset Bias",
      "categoryId": "bd52977c-f080-4693-ad04-13ebf83b3438"
    },
    {
      "id": "27c72a08-3e58-42f5-83b0-6360d1db33b7",
      "name": "Machine Learning Data Issues",
      "categoryId": "bd52977c-f080-4693-ad04-13ebf83b3438"
    },
    {
      "id": "dd0ab711-3dd4-485f-bd3e-213221004379",
      "name": "Supervised Learning",
      "categoryId": "bb904414-df50-475e-9142-59e155300580"
    },
    {
      "id": "8e8db03e-022d-4cb5-9b88-637cc5eecce4",
      "name": "Imbalanced Datasets",
      "categoryId": "bb904414-df50-475e-9142-59e155300580"
    },
    {
      "id": "add54705-2a78-45e4-b694-85debb3e8fa9",
      "name": "Model Optimization",
      "categoryId": "bb904414-df50-475e-9142-59e155300580"
    },
    {
      "id": "f5eed3f6-8e99-453b-a06f-5e1ad29100ec",
      "name": "Cost-sensitive Learning",
      "categoryId": "bb904414-df50-475e-9142-59e155300580"
    },
    {
      "id": "41693121-fac8-4368-a463-af96bce13c0e",
      "name": "Loss Function Customization",
      "categoryId": "bb904414-df50-475e-9142-59e155300580"
    },
    {
      "id": "92bd8b12-04d9-410f-83ac-46f5e9a3be74",
      "name": "Class Imbalance Handling",
      "categoryId": "bb904414-df50-475e-9142-59e155300580"
    },
    {
      "id": "537e1280-bcdb-46cb-91c0-515879b77ac6",
      "name": "Machine Learning Techniques",
      "categoryId": "bb904414-df50-475e-9142-59e155300580"
    },
    {
      "id": "b3c6d341-9892-4765-bcd1-1aaf4f24ee31",
      "name": "Model Evaluation Strategies",
      "categoryId": "bb904414-df50-475e-9142-59e155300580"
    },
    {
      "id": "78d23e9b-e7a3-4421-ac6c-0bfb123f7653",
      "name": "Class-balanced Loss",
      "categoryId": "463c8d62-656f-4479-b28e-3b49fbccc87f"
    },
    {
      "id": "801d406b-9e96-43ed-ba03-23e7ca864df8",
      "name": "Loss Functions",
      "categoryId": "463c8d62-656f-4479-b28e-3b49fbccc87f"
    },
    {
      "id": "255dc7ad-1975-4e0c-b687-69320d5c52b7",
      "name": "Imbalanced Data",
      "categoryId": "463c8d62-656f-4479-b28e-3b49fbccc87f"
    },
    {
      "id": "ffcf8640-2d93-4a0a-a850-0c1630df1371",
      "name": "Machine Learning",
      "categoryId": "463c8d62-656f-4479-b28e-3b49fbccc87f"
    },
    {
      "id": "ac93184c-278e-485b-a938-13c0cfe71eeb",
      "name": "Deep Learning",
      "categoryId": "463c8d62-656f-4479-b28e-3b49fbccc87f"
    },
    {
      "id": "5f40701a-080a-4507-9f58-92f302fd497c",
      "name": "Class Imbalance",
      "categoryId": "463c8d62-656f-4479-b28e-3b49fbccc87f"
    },
    {
      "id": "ce23a085-4bac-4a0a-9679-5b774a07543f",
      "name": "Data Sampling",
      "categoryId": "463c8d62-656f-4479-b28e-3b49fbccc87f"
    },
    {
      "id": "9d0e5d01-0770-46be-acf1-734e13fde338",
      "name": "Loss Weighting",
      "categoryId": "463c8d62-656f-4479-b28e-3b49fbccc87f"
    },
    {
      "id": "1890e963-42d6-4c76-bdeb-a14b05d450d6",
      "name": "Cost-sensitive Learning",
      "categoryId": "463c8d62-656f-4479-b28e-3b49fbccc87f"
    },
    {
      "id": "566bcae2-1986-46fa-8efd-cdc0c54ba198",
      "name": "Model Optimization",
      "categoryId": "463c8d62-656f-4479-b28e-3b49fbccc87f"
    },
    {
      "id": "22c826c5-2c60-466b-b3d8-5ab436acbc30",
      "name": "Machine Learning",
      "categoryId": "a1c8d4d1-6f9e-4689-808d-d472c6cdb804"
    },
    {
      "id": "c146bde0-6d33-4cba-8bff-b0a30b80d61f",
      "name": "Data Sampling",
      "categoryId": "a1c8d4d1-6f9e-4689-808d-d472c6cdb804"
    },
    {
      "id": "6e6a0b06-4ccb-4f9f-8463-f3338e315a34",
      "name": "Class Imbalance",
      "categoryId": "a1c8d4d1-6f9e-4689-808d-d472c6cdb804"
    },
    {
      "id": "eb875b95-76c7-4c25-8fb3-034669f16d28",
      "name": "Data Balancing Techniques",
      "categoryId": "a1c8d4d1-6f9e-4689-808d-d472c6cdb804"
    },
    {
      "id": "b60506ab-e49f-4645-b1ab-c4bbf6b7dfb3",
      "name": "Supervised Learning",
      "categoryId": "a1c8d4d1-6f9e-4689-808d-d472c6cdb804"
    },
    {
      "id": "e1b388e7-6296-436e-93c6-1dd45d7328e0",
      "name": "Dataset Preparation",
      "categoryId": "a1c8d4d1-6f9e-4689-808d-d472c6cdb804"
    },
    {
      "id": "f93d3ce7-bcf9-44fa-8d7a-262aa178aff2",
      "name": "Supervised Learning",
      "categoryId": "46a7e47f-f3b4-4f60-9da0-d5def5325232"
    },
    {
      "id": "e37a03a9-d06a-45a5-98b8-a626c6d8b205",
      "name": "Loss Functions",
      "categoryId": "46a7e47f-f3b4-4f60-9da0-d5def5325232"
    },
    {
      "id": "63ba9db6-37cd-4ae2-98cf-2cca483bd54e",
      "name": "Class Imbalance",
      "categoryId": "46a7e47f-f3b4-4f60-9da0-d5def5325232"
    },
    {
      "id": "b5e7cc4f-6693-4f7c-9cf4-8e740c62176d",
      "name": "Model Optimization",
      "categoryId": "46a7e47f-f3b4-4f60-9da0-d5def5325232"
    },
    {
      "id": "2c1e07da-873b-4014-a501-c583bef42644",
      "name": "Cost-sensitive Learning",
      "categoryId": "46a7e47f-f3b4-4f60-9da0-d5def5325232"
    },
    {
      "id": "0bab0a9f-5b8f-4bf5-8445-b9a1e4b770b9",
      "name": "Data Sampling Strategies",
      "categoryId": "46a7e47f-f3b4-4f60-9da0-d5def5325232"
    },
    {
      "id": "c0557b9b-e7d6-41f6-96ad-c6ad51bfb9a5",
      "name": "Classification",
      "categoryId": "638b1e9b-d328-40ff-b394-5a617ed4ee0a"
    },
    {
      "id": "725c561f-8b92-42e0-b5ab-5d3a334df9e0",
      "name": "Supervised Learning",
      "categoryId": "638b1e9b-d328-40ff-b394-5a617ed4ee0a"
    },
    {
      "id": "95e24e6a-557b-469e-9aef-f6ba83e99e42",
      "name": "Binary Classification",
      "categoryId": "638b1e9b-d328-40ff-b394-5a617ed4ee0a"
    },
    {
      "id": "381ce894-6397-476f-b5c9-e08edc6c337f",
      "name": "Multiclass Classification",
      "categoryId": "638b1e9b-d328-40ff-b394-5a617ed4ee0a"
    },
    {
      "id": "7327b7b4-63c7-4dad-a856-42363085c64a",
      "name": "Multi-label Classification",
      "categoryId": "638b1e9b-d328-40ff-b394-5a617ed4ee0a"
    },
    {
      "id": "d66df000-b60f-493e-aa35-fd829e8c3783",
      "name": "Logistic Regression",
      "categoryId": "638b1e9b-d328-40ff-b394-5a617ed4ee0a"
    },
    {
      "id": "4b8eaeaf-e8f8-477a-9756-017e01bb43d2",
      "name": "Decision Trees",
      "categoryId": "638b1e9b-d328-40ff-b394-5a617ed4ee0a"
    },
    {
      "id": "665e92e0-8b74-4f03-bdf5-b42b6857bc85",
      "name": "Support Vector Machines",
      "categoryId": "638b1e9b-d328-40ff-b394-5a617ed4ee0a"
    },
    {
      "id": "93f3b4c4-3c09-457a-8723-6e60c93a4c5c",
      "name": "Neural Networks",
      "categoryId": "638b1e9b-d328-40ff-b394-5a617ed4ee0a"
    },
    {
      "id": "62712664-7b23-41b2-aa8c-354bc556b326",
      "name": "Probabilistic Models",
      "categoryId": "638b1e9b-d328-40ff-b394-5a617ed4ee0a"
    },
    {
      "id": "a436aa09-2c29-457a-8eb2-51ee5e4f3529",
      "name": "Pattern Recognition",
      "categoryId": "638b1e9b-d328-40ff-b394-5a617ed4ee0a"
    },
    {
      "id": "4dc05e06-8550-4409-87f0-988a213fa1bb",
      "name": "Data Labeling",
      "categoryId": "638b1e9b-d328-40ff-b394-5a617ed4ee0a"
    },
    {
      "id": "93564c03-dca6-4305-9377-37f91b06073d",
      "name": "Feature Extraction",
      "categoryId": "638b1e9b-d328-40ff-b394-5a617ed4ee0a"
    },
    {
      "id": "156de980-a456-49d6-9ce3-5848c7d29057",
      "name": "Model Evaluation",
      "categoryId": "638b1e9b-d328-40ff-b394-5a617ed4ee0a"
    },
    {
      "id": "767ae498-e397-46f0-8860-686ed602a225",
      "name": "Confusion Matrix",
      "categoryId": "638b1e9b-d328-40ff-b394-5a617ed4ee0a"
    },
    {
      "id": "f2ce54a0-77c8-41d7-a60a-7a71fb39c591",
      "name": "Supervised Learning",
      "categoryId": "ad6f7632-68e4-4117-85c7-7bc4bee08896"
    },
    {
      "id": "fbee121d-8daa-493a-8a59-6dcca35f7858",
      "name": "Decision Trees",
      "categoryId": "ad6f7632-68e4-4117-85c7-7bc4bee08896"
    },
    {
      "id": "8e6f72cf-6a35-4855-b57f-1fc0541a022e",
      "name": "Classification and Regression",
      "categoryId": "ad6f7632-68e4-4117-85c7-7bc4bee08896"
    },
    {
      "id": "2642625c-0dd6-4681-b9ae-1e0f92c20867",
      "name": "Predictive Modeling",
      "categoryId": "ad6f7632-68e4-4117-85c7-7bc4bee08896"
    },
    {
      "id": "5acddb06-5935-41bd-bfaa-4410e3911039",
      "name": "Machine Learning Algorithms",
      "categoryId": "ad6f7632-68e4-4117-85c7-7bc4bee08896"
    },
    {
      "id": "f5edcbab-98f5-4e28-b49c-ec0cee0f73cf",
      "name": "Tree-Based Methods",
      "categoryId": "ad6f7632-68e4-4117-85c7-7bc4bee08896"
    },
    {
      "id": "632a4716-2e55-4c89-add1-78cad5a4dc65",
      "name": "Data Mining",
      "categoryId": "ad6f7632-68e4-4117-85c7-7bc4bee08896"
    },
    {
      "id": "0e68de4a-8249-4fe0-b08a-b0ea56386f17",
      "name": "Pattern Recognition",
      "categoryId": "ad6f7632-68e4-4117-85c7-7bc4bee08896"
    },
    {
      "id": "e2b6d42d-5f24-40f2-ab1b-368583c3a430",
      "name": "Data Analysis",
      "categoryId": "ad6f7632-68e4-4117-85c7-7bc4bee08896"
    },
    {
      "id": "8b811db7-040c-48e5-b3b5-1d766dbbe012",
      "name": "Machine Learning Techniques",
      "categoryId": "ad6f7632-68e4-4117-85c7-7bc4bee08896"
    },
    {
      "id": "c69f6044-95e4-46c8-b4d2-aa2fbfdf3df6",
      "name": "supervised learning",
      "categoryId": "19f8687d-78e2-404b-b32b-b5dab8063e1c"
    },
    {
      "id": "3cf59ebf-409e-4bd1-8549-930625dccd3e",
      "name": "model evaluation",
      "categoryId": "19f8687d-78e2-404b-b32b-b5dab8063e1c"
    },
    {
      "id": "6f904920-9e86-4848-82fd-b45d2b861009",
      "name": "model performance metrics",
      "categoryId": "19f8687d-78e2-404b-b32b-b5dab8063e1c"
    },
    {
      "id": "79cc9a54-2a74-49b0-8748-c33b361fef94",
      "name": "confusion matrix",
      "categoryId": "19f8687d-78e2-404b-b32b-b5dab8063e1c"
    },
    {
      "id": "2eae901b-6ad8-43f1-8404-37febcc6f7c2",
      "name": "precision",
      "categoryId": "19f8687d-78e2-404b-b32b-b5dab8063e1c"
    },
    {
      "id": "79285ea5-783f-4379-a1aa-c4bedbdb9ed4",
      "name": "recall",
      "categoryId": "19f8687d-78e2-404b-b32b-b5dab8063e1c"
    },
    {
      "id": "658bc576-0605-4da8-b4c7-4df1f5c5d022",
      "name": "F1 score",
      "categoryId": "19f8687d-78e2-404b-b32b-b5dab8063e1c"
    },
    {
      "id": "ed9f81df-680f-4898-baaf-dd25d117d7e8",
      "name": "ROC curve",
      "categoryId": "19f8687d-78e2-404b-b32b-b5dab8063e1c"
    },
    {
      "id": "84e1c761-1424-4684-a45d-61bc6f93f790",
      "name": "AUC",
      "categoryId": "19f8687d-78e2-404b-b32b-b5dab8063e1c"
    },
    {
      "id": "e7e37691-5105-490f-96bb-693c12783fd7",
      "name": "cross-validation",
      "categoryId": "19f8687d-78e2-404b-b32b-b5dab8063e1c"
    },
    {
      "id": "efd4cf4d-70f1-427d-9c47-b99a638ddbce",
      "name": "accuracy",
      "categoryId": "19f8687d-78e2-404b-b32b-b5dab8063e1c"
    },
    {
      "id": "c9e17a68-d519-478b-a10f-3214efd37d96",
      "name": "hypothesis testing",
      "categoryId": "19f8687d-78e2-404b-b32b-b5dab8063e1c"
    },
    {
      "id": "923cdb68-c0a7-4f90-bb10-673f9f6c213c",
      "name": "bias-variance tradeoff",
      "categoryId": "19f8687d-78e2-404b-b32b-b5dab8063e1c"
    },
    {
      "id": "12674661-36ee-4264-be70-5545f20f9880",
      "name": "Classification Problems",
      "categoryId": "56ed7f8c-a501-4986-a441-19c3c8a7fbfc"
    },
    {
      "id": "225bbc7a-fe01-4e2b-943e-37fa1f6ff5e1",
      "name": "Supervised Learning",
      "categoryId": "56ed7f8c-a501-4986-a441-19c3c8a7fbfc"
    },
    {
      "id": "eae5994c-a671-472f-9f78-9651e0a56043",
      "name": "Pattern Recognition",
      "categoryId": "56ed7f8c-a501-4986-a441-19c3c8a7fbfc"
    },
    {
      "id": "b882c43d-fdea-4eef-a859-3eafc3b95d38",
      "name": "Discrete Labels",
      "categoryId": "56ed7f8c-a501-4986-a441-19c3c8a7fbfc"
    },
    {
      "id": "f6be36df-90a7-481d-80df-ffb2a225d8b7",
      "name": "Binary Classification",
      "categoryId": "56ed7f8c-a501-4986-a441-19c3c8a7fbfc"
    },
    {
      "id": "868499c4-1e53-4ffe-8e41-ee8a17873787",
      "name": "Multi-class Classification",
      "categoryId": "56ed7f8c-a501-4986-a441-19c3c8a7fbfc"
    },
    {
      "id": "d431dca4-9e00-4154-bf36-22a4158ef829",
      "name": "Supervised Algorithms",
      "categoryId": "56ed7f8c-a501-4986-a441-19c3c8a7fbfc"
    },
    {
      "id": "0cd6ac23-c3e1-4b5f-8030-493d0830b83a",
      "name": "Label Prediction",
      "categoryId": "56ed7f8c-a501-4986-a441-19c3c8a7fbfc"
    },
    {
      "id": "f5c15b71-d2ac-46b0-837a-d7547416c294",
      "name": "Data Labels",
      "categoryId": "56ed7f8c-a501-4986-a441-19c3c8a7fbfc"
    },
    {
      "id": "9f9f9fc2-5032-4ae2-912f-f0273bb9d37c",
      "name": "Categorization",
      "categoryId": "56ed7f8c-a501-4986-a441-19c3c8a7fbfc"
    },
    {
      "id": "5c5b96ed-cf59-4ce6-814a-bc0a1a9f2c74",
      "name": "Classification report",
      "categoryId": "aaaa9c42-d813-43dc-8d14-0cef0d46ae59"
    },
    {
      "id": "8a2fc8f3-00bb-4de1-8c84-5e6d591cef80",
      "name": "performance metrics",
      "categoryId": "aaaa9c42-d813-43dc-8d14-0cef0d46ae59"
    },
    {
      "id": "08481df2-f8f3-47cb-8a91-d25793125fb8",
      "name": "model evaluation",
      "categoryId": "aaaa9c42-d813-43dc-8d14-0cef0d46ae59"
    },
    {
      "id": "9baebda5-83db-4056-b02d-972604f6a519",
      "name": "precision",
      "categoryId": "aaaa9c42-d813-43dc-8d14-0cef0d46ae59"
    },
    {
      "id": "1f1db145-c380-4992-a877-83f21d1c95ab",
      "name": "recall",
      "categoryId": "aaaa9c42-d813-43dc-8d14-0cef0d46ae59"
    },
    {
      "id": "2309068b-8cb0-4633-9b07-be5e50e56f8b",
      "name": "F1-score",
      "categoryId": "aaaa9c42-d813-43dc-8d14-0cef0d46ae59"
    },
    {
      "id": "d1cb926a-e20d-4cb7-9f8c-42ca3ef31f98",
      "name": "confusion matrix",
      "categoryId": "aaaa9c42-d813-43dc-8d14-0cef0d46ae59"
    },
    {
      "id": "3436d2ed-7f3d-4e1d-a39f-fdde3c5453cc",
      "name": "accuracy",
      "categoryId": "aaaa9c42-d813-43dc-8d14-0cef0d46ae59"
    },
    {
      "id": "a0e02c15-4478-4fe1-bc99-6cb483ee2d47",
      "name": "multi-class classification",
      "categoryId": "aaaa9c42-d813-43dc-8d14-0cef0d46ae59"
    },
    {
      "id": "b51ac583-6a90-4e9b-9f57-f514ad1198ca",
      "name": "binary classification",
      "categoryId": "aaaa9c42-d813-43dc-8d14-0cef0d46ae59"
    },
    {
      "id": "76eb3082-c306-4971-90ef-b7a09009f1fa",
      "name": "model assessment",
      "categoryId": "aaaa9c42-d813-43dc-8d14-0cef0d46ae59"
    },
    {
      "id": "500c19c3-3e04-4b61-abeb-6f2a51c4447d",
      "name": "Multi-label Classification",
      "categoryId": "68fab1ce-0ab7-47bb-8999-9548eddf2d65"
    },
    {
      "id": "7822845b-9d30-4198-80eb-31cbc4285739",
      "name": "Chain-Based Methods",
      "categoryId": "68fab1ce-0ab7-47bb-8999-9548eddf2d65"
    },
    {
      "id": "e868cfa5-2af4-4d05-bfba-5da582c42c8a",
      "name": "Sequential Modeling",
      "categoryId": "68fab1ce-0ab7-47bb-8999-9548eddf2d65"
    },
    {
      "id": "57935547-77a2-45fa-af0b-0de76cf20497",
      "name": "Ensemble Techniques",
      "categoryId": "68fab1ce-0ab7-47bb-8999-9548eddf2d65"
    },
    {
      "id": "0ccd9065-97b8-4c73-9aa2-89de7304a708",
      "name": "Multi-Output Classification",
      "categoryId": "68fab1ce-0ab7-47bb-8999-9548eddf2d65"
    },
    {
      "id": "8cad6594-91c1-4306-a0b4-22c34a68ee7e",
      "name": "Multi-Label Learning",
      "categoryId": "68fab1ce-0ab7-47bb-8999-9548eddf2d65"
    },
    {
      "id": "62de61f2-5215-4555-859f-d6ed101d9f8b",
      "name": "Dependency Modeling",
      "categoryId": "68fab1ce-0ab7-47bb-8999-9548eddf2d65"
    },
    {
      "id": "394a0149-da74-4de6-94ee-afe65bdb74a1",
      "name": "Predictive Modeling",
      "categoryId": "68fab1ce-0ab7-47bb-8999-9548eddf2d65"
    },
    {
      "id": "529d2187-0870-4070-95fa-175990027b9c",
      "name": "Structured Prediction",
      "categoryId": "68fab1ce-0ab7-47bb-8999-9548eddf2d65"
    },
    {
      "id": "9260e55f-a30c-4589-8b66-5fec0ab4e83c",
      "name": "Machine Learning",
      "categoryId": "ce8840a2-b630-42e6-bfa3-82fb58079cf8"
    },
    {
      "id": "44e30b58-544f-4b04-b5ad-e06c174eb2d7",
      "name": "Deep Learning",
      "categoryId": "ce8840a2-b630-42e6-bfa3-82fb58079cf8"
    },
    {
      "id": "2db1d4d8-dff8-4d6c-8c48-0cb5207bb9c9",
      "name": "Generative Models",
      "categoryId": "ce8840a2-b630-42e6-bfa3-82fb58079cf8"
    },
    {
      "id": "2ec4809e-88ad-4eb6-b7d6-f34ef7f180eb",
      "name": "Diffusion Models",
      "categoryId": "ce8840a2-b630-42e6-bfa3-82fb58079cf8"
    },
    {
      "id": "b7ca38d5-0048-4d83-8aa9-07c02bd0fa87",
      "name": "Text-to-Image Synthesis",
      "categoryId": "ce8840a2-b630-42e6-bfa3-82fb58079cf8"
    },
    {
      "id": "4a766364-3509-45b1-91a5-c2738db87cb4",
      "name": "Guidance Techniques",
      "categoryId": "ce8840a2-b630-42e6-bfa3-82fb58079cf8"
    },
    {
      "id": "52af2813-bb6d-4b42-a058-8b34de7122ed",
      "name": "Conditional Generation",
      "categoryId": "ce8840a2-b630-42e6-bfa3-82fb58079cf8"
    },
    {
      "id": "ff20e517-98fe-443c-b53c-a7c0e895ce07",
      "name": "Score-Based Models",
      "categoryId": "ce8840a2-b630-42e6-bfa3-82fb58079cf8"
    },
    {
      "id": "8ca13401-9660-4bfa-a3b0-be76b384457b",
      "name": "Model Conditioning",
      "categoryId": "ce8840a2-b630-42e6-bfa3-82fb58079cf8"
    },
    {
      "id": "1e574f67-bfeb-46bb-9ca5-771934b9b9a2",
      "name": "Unconditional Generation",
      "categoryId": "ce8840a2-b630-42e6-bfa3-82fb58079cf8"
    },
    {
      "id": "4a4be183-cc78-41de-8e37-9364e10fcc86",
      "name": "Sentiment Analysis",
      "categoryId": "679ad49b-3245-4a91-838a-49cdf3e200d3"
    },
    {
      "id": "2fe821bd-c0ad-4c35-9fbe-529706afa76a",
      "name": "AI Security",
      "categoryId": "679ad49b-3245-4a91-838a-49cdf3e200d3"
    },
    {
      "id": "cd8afa1e-5bed-4685-bb24-b48042bdbfa4",
      "name": "Model Robustness",
      "categoryId": "679ad49b-3245-4a91-838a-49cdf3e200d3"
    },
    {
      "id": "973d8a70-4e45-488d-ac75-624bed7fa3e2",
      "name": "Privacy Risks",
      "categoryId": "679ad49b-3245-4a91-838a-49cdf3e200d3"
    },
    {
      "id": "d75cd912-d7b4-4dc1-a4b1-a60b03bf8e9c",
      "name": "Adversarial Attacks",
      "categoryId": "679ad49b-3245-4a91-838a-49cdf3e200d3"
    },
    {
      "id": "a7a75efd-c7b2-4e89-9ed7-e2a501374733",
      "name": "Data Integrity",
      "categoryId": "679ad49b-3245-4a91-838a-49cdf3e200d3"
    },
    {
      "id": "b4e6d187-f0cb-4d1c-b677-e8c3ff1345da",
      "name": "Classification Models",
      "categoryId": "679ad49b-3245-4a91-838a-49cdf3e200d3"
    },
    {
      "id": "16d9b756-93ff-46ea-a2de-84e7732b76e8",
      "name": "Ethical AI",
      "categoryId": "679ad49b-3245-4a91-838a-49cdf3e200d3"
    },
    {
      "id": "e13f6207-4e06-49f1-9aff-85dfb0aa71e6",
      "name": "Bias Detection",
      "categoryId": "679ad49b-3245-4a91-838a-49cdf3e200d3"
    },
    {
      "id": "4fe98b57-cfaa-4a16-9e07-cff2a66db6e8",
      "name": "Model Explainability",
      "categoryId": "679ad49b-3245-4a91-838a-49cdf3e200d3"
    },
    {
      "id": "1590d9e4-d560-4e9e-9765-12a2bcad6404",
      "name": "Data Privacy",
      "categoryId": "679ad49b-3245-4a91-838a-49cdf3e200d3"
    },
    {
      "id": "f2ae44ca-c4a9-4e34-b958-2ef3392ccc79",
      "name": "AI Safety",
      "categoryId": "679ad49b-3245-4a91-838a-49cdf3e200d3"
    },
    {
      "id": "677c5b5f-a712-464d-a8c1-debbd91d0901",
      "name": "Trustworthy AI",
      "categoryId": "679ad49b-3245-4a91-838a-49cdf3e200d3"
    },
    {
      "id": "7d061fc9-9fac-4696-a0cb-5e7c85992704",
      "name": "Natural Language Processing (NLP)",
      "categoryId": "679ad49b-3245-4a91-838a-49cdf3e200d3"
    },
    {
      "id": "a483c364-2214-41e5-8a4d-240722285286",
      "name": "AI Security Protocols",
      "categoryId": "679ad49b-3245-4a91-838a-49cdf3e200d3"
    },
    {
      "id": "af45e407-2f16-4a01-9013-17ce931d84e0",
      "name": "Thermodynamics",
      "categoryId": "99d529f2-49fc-4886-8873-56c007857d96"
    },
    {
      "id": "ee95d3bc-8c17-437f-861e-f420a02ac3f4",
      "name": "Climate Modeling",
      "categoryId": "99d529f2-49fc-4886-8873-56c007857d96"
    },
    {
      "id": "58867216-889a-4771-80d4-12a5ffb77580",
      "name": "Data-Driven Simulations",
      "categoryId": "99d529f2-49fc-4886-8873-56c007857d96"
    },
    {
      "id": "22fb4a18-7df5-420f-a666-9a2354b9c075",
      "name": "Fluid Mechanics",
      "categoryId": "99d529f2-49fc-4886-8873-56c007857d96"
    },
    {
      "id": "b71d7f75-c910-4dc6-90be-cbfd0b6471f1",
      "name": "Phase Transitions",
      "categoryId": "99d529f2-49fc-4886-8873-56c007857d96"
    },
    {
      "id": "6ddaed60-ab96-4bee-9ee4-f6d4fb7f5cc2",
      "name": "Material Science",
      "categoryId": "99d529f2-49fc-4886-8873-56c007857d96"
    },
    {
      "id": "1babd10d-29fa-423d-a711-adc84e7c459c",
      "name": "Computational Thermodynamics",
      "categoryId": "99d529f2-49fc-4886-8873-56c007857d96"
    },
    {
      "id": "644d1346-a9af-4cad-90e2-eff2ad056c9f",
      "name": "Statistical Mechanics",
      "categoryId": "99d529f2-49fc-4886-8873-56c007857d96"
    },
    {
      "id": "8d444b9e-2b92-46d8-98c5-a83562c49edf",
      "name": "Physical Chemistry",
      "categoryId": "99d529f2-49fc-4886-8873-56c007857d96"
    },
    {
      "id": "822c2390-133c-49b3-9055-1d1fcdffb236",
      "name": "Energy Systems",
      "categoryId": "99d529f2-49fc-4886-8873-56c007857d96"
    },
    {
      "id": "3eb14e8c-6b3f-4d67-b0b5-58916771c29a",
      "name": "Artificial Intelligence",
      "categoryId": "34461a4f-ae39-45c3-b7ed-85671d17fde1"
    },
    {
      "id": "68401081-e036-4493-a777-18d2f69baa34",
      "name": "Machine Learning",
      "categoryId": "34461a4f-ae39-45c3-b7ed-85671d17fde1"
    },
    {
      "id": "54a75024-82de-4698-8692-0c531ffbbbf7",
      "name": "Automated Machine Learning",
      "categoryId": "34461a4f-ae39-45c3-b7ed-85671d17fde1"
    },
    {
      "id": "f8bbc8cd-7ddb-42e7-913d-aae09e88019b",
      "name": "MLOps",
      "categoryId": "34461a4f-ae39-45c3-b7ed-85671d17fde1"
    },
    {
      "id": "d1a421ec-7cd5-4370-9d0f-36c70bc0b37f",
      "name": "Experiment Management",
      "categoryId": "34461a4f-ae39-45c3-b7ed-85671d17fde1"
    },
    {
      "id": "7cf01f22-2607-4f19-b8e6-e8bcafdec97e",
      "name": "Workflow Orchestration",
      "categoryId": "34461a4f-ae39-45c3-b7ed-85671d17fde1"
    },
    {
      "id": "cc5d07ab-ced0-47f3-b305-4135cda2bc16",
      "name": "Model Training",
      "categoryId": "34461a4f-ae39-45c3-b7ed-85671d17fde1"
    },
    {
      "id": "1cf14460-9ee3-4710-ab58-9c12b7355c32",
      "name": "Model Deployment",
      "categoryId": "34461a4f-ae39-45c3-b7ed-85671d17fde1"
    },
    {
      "id": "ef11be24-b201-4e25-92fa-bbf38a41bec5",
      "name": "Model Monitoring",
      "categoryId": "34461a4f-ae39-45c3-b7ed-85671d17fde1"
    },
    {
      "id": "ec2805cd-2f35-4153-b298-e5c8690942a6",
      "name": "AI Platform",
      "categoryId": "34461a4f-ae39-45c3-b7ed-85671d17fde1"
    },
    {
      "id": "ac50f6e3-601e-46b3-a949-a0e8895782a8",
      "name": "Reproducibility",
      "categoryId": "34461a4f-ae39-45c3-b7ed-85671d17fde1"
    },
    {
      "id": "3f54be3f-1c17-4e21-acb7-e8f9dfd52a6f",
      "name": "Collaboration Tools",
      "categoryId": "34461a4f-ae39-45c3-b7ed-85671d17fde1"
    },
    {
      "id": "e829c2f4-ddef-4b70-8320-569cb03b66c4",
      "name": "Computer Vision",
      "categoryId": "4a7824c8-0363-4203-88d1-225a0e0beeff"
    },
    {
      "id": "a3c847e8-d7c4-453c-b751-eebbe0fdea8f",
      "name": "Natural Language Processing",
      "categoryId": "4a7824c8-0363-4203-88d1-225a0e0beeff"
    },
    {
      "id": "d59476f0-9cd6-4db9-a55d-2866a272441f",
      "name": "Multimodal Learning",
      "categoryId": "4a7824c8-0363-4203-88d1-225a0e0beeff"
    },
    {
      "id": "a3903104-02d4-46e8-9268-37eec52625fa",
      "name": "Representation Learning",
      "categoryId": "4a7824c8-0363-4203-88d1-225a0e0beeff"
    },
    {
      "id": "72d227d8-3c90-4346-ba8f-867f728bfa84",
      "name": "Contrastive Learning",
      "categoryId": "4a7824c8-0363-4203-88d1-225a0e0beeff"
    },
    {
      "id": "b9e37820-2adf-4d1a-a39b-a4e479d94757",
      "name": "Pretraining",
      "categoryId": "4a7824c8-0363-4203-88d1-225a0e0beeff"
    },
    {
      "id": "3622e634-8e80-498b-9f6f-6402ed41389f",
      "name": "Visual Understanding",
      "categoryId": "4a7824c8-0363-4203-88d1-225a0e0beeff"
    },
    {
      "id": "9535467e-26b5-409d-978e-230d98d25aef",
      "name": "Language Models",
      "categoryId": "4a7824c8-0363-4203-88d1-225a0e0beeff"
    },
    {
      "id": "e179eb70-1553-42d0-8ddc-99bd6e9009fe",
      "name": "Deep Learning",
      "categoryId": "4a7824c8-0363-4203-88d1-225a0e0beeff"
    },
    {
      "id": "8099841b-2be3-4fcf-934a-c426d82187a6",
      "name": "Embeddings",
      "categoryId": "4a7824c8-0363-4203-88d1-225a0e0beeff"
    },
    {
      "id": "c0e8e1aa-1dba-4f07-be0e-1d0e5dc9d111",
      "name": "Natural Language Processing",
      "categoryId": "ba60df6e-a2b2-4e46-9e06-508c2a008ce8"
    },
    {
      "id": "3397efb9-cce0-4bfd-a2b0-9adb12df963d",
      "name": "Computer Vision",
      "categoryId": "ba60df6e-a2b2-4e46-9e06-508c2a008ce8"
    },
    {
      "id": "0514ffcf-33e2-47a0-b4d7-b9eace9b1783",
      "name": "Multimodal Learning",
      "categoryId": "ba60df6e-a2b2-4e46-9e06-508c2a008ce8"
    },
    {
      "id": "edbfb598-dc67-48f0-bc8f-9bbf574f32d3",
      "name": "Representation Learning",
      "categoryId": "ba60df6e-a2b2-4e46-9e06-508c2a008ce8"
    },
    {
      "id": "3daa4eb1-c696-4bb3-9c87-fb454d9da0f1",
      "name": "Deep Learning",
      "categoryId": "ba60df6e-a2b2-4e46-9e06-508c2a008ce8"
    },
    {
      "id": "3665e3a8-a68d-42dd-bdb7-f58b267e0cc2",
      "name": "Contrastive Learning",
      "categoryId": "ba60df6e-a2b2-4e46-9e06-508c2a008ce8"
    },
    {
      "id": "ec1bad91-f64d-4e09-ad11-58c69bb29d8d",
      "name": "Embedding Models",
      "categoryId": "ba60df6e-a2b2-4e46-9e06-508c2a008ce8"
    },
    {
      "id": "732b3f9a-cec1-4d9f-94cf-b708d7b111a0",
      "name": "Visual Language Models",
      "categoryId": "ba60df6e-a2b2-4e46-9e06-508c2a008ce8"
    },
    {
      "id": "3ef6211a-da11-46d2-9b3e-6786e0ea5c74",
      "name": "Pretraining",
      "categoryId": "ba60df6e-a2b2-4e46-9e06-508c2a008ce8"
    },
    {
      "id": "4bd2cd38-9210-4acb-a0e5-f0a04dc83d1c",
      "name": "Zero-shot Recognition",
      "categoryId": "ba60df6e-a2b2-4e46-9e06-508c2a008ce8"
    },
    {
      "id": "7c3d014d-9deb-47c9-b091-634deb91cba0",
      "name": "Optimization Techniques",
      "categoryId": "99dd1378-9357-476f-8f24-cd073bf1a574"
    },
    {
      "id": "c2b7822c-01d9-4cf6-add9-4c62969b2fd0",
      "name": "Gradient Clipping",
      "categoryId": "99dd1378-9357-476f-8f24-cd073bf1a574"
    },
    {
      "id": "78252823-5487-4b8c-8df5-974ee60addde",
      "name": "Regularization Methods",
      "categoryId": "99dd1378-9357-476f-8f24-cd073bf1a574"
    },
    {
      "id": "6667c48d-cb60-4f76-b80d-5587c8b32beb",
      "name": "Deep Learning Optimization",
      "categoryId": "99dd1378-9357-476f-8f24-cd073bf1a574"
    },
    {
      "id": "0ec976e1-d9cc-472d-811a-662eec230518",
      "name": "Gradient Management",
      "categoryId": "99dd1378-9357-476f-8f24-cd073bf1a574"
    },
    {
      "id": "5d53d6cd-43d8-40a6-a8da-b7642ac5c615",
      "name": "Training Stabilization",
      "categoryId": "99dd1378-9357-476f-8f24-cd073bf1a574"
    },
    {
      "id": "8248b90b-7738-464c-9bab-443899b1e118",
      "name": "Optimization Techniques",
      "categoryId": "28541ed0-da62-422a-b170-9d900cdb203b"
    },
    {
      "id": "6c6339d1-d773-41e8-bf72-d8dd8ccbeffa",
      "name": "Gradient Descent",
      "categoryId": "28541ed0-da62-422a-b170-9d900cdb203b"
    },
    {
      "id": "405028fe-c06b-4f34-96f7-e5e3e1b81dfa",
      "name": "Regularization",
      "categoryId": "28541ed0-da62-422a-b170-9d900cdb203b"
    },
    {
      "id": "11644ecd-3c34-4533-b294-96282b6f587b",
      "name": "Neural Network Training",
      "categoryId": "28541ed0-da62-422a-b170-9d900cdb203b"
    },
    {
      "id": "ea282468-d0a8-4a29-ab62-86232b4e6a8a",
      "name": "Deep Learning",
      "categoryId": "28541ed0-da62-422a-b170-9d900cdb203b"
    },
    {
      "id": "a9432a68-34fc-4bf5-9a8e-3a1c26f8be43",
      "name": "Backpropagation",
      "categoryId": "28541ed0-da62-422a-b170-9d900cdb203b"
    },
    {
      "id": "0ec288bb-f06d-48b8-bda3-ed193a70782d",
      "name": "Loss Function",
      "categoryId": "28541ed0-da62-422a-b170-9d900cdb203b"
    },
    {
      "id": "05efe36c-31c8-4bee-a311-5291a529b548",
      "name": "Model Stability",
      "categoryId": "28541ed0-da62-422a-b170-9d900cdb203b"
    },
    {
      "id": "7ba4fabc-abc2-4227-848e-7316bce6b302",
      "name": "Gradient Clipping",
      "categoryId": "3f34ecb9-feff-4003-84e1-762cf3af049f"
    },
    {
      "id": "2f1469a4-64ea-4e96-bc79-fd7b013455eb",
      "name": "Norm Clipping",
      "categoryId": "3f34ecb9-feff-4003-84e1-762cf3af049f"
    },
    {
      "id": "244dee7f-65d6-47f8-9d4c-0108d75bdbe5",
      "name": "Value Clipping",
      "categoryId": "3f34ecb9-feff-4003-84e1-762cf3af049f"
    },
    {
      "id": "f0dd9e3f-c089-4b92-b659-e97fd05c400d",
      "name": "Optimization Techniques",
      "categoryId": "3f34ecb9-feff-4003-84e1-762cf3af049f"
    },
    {
      "id": "ac15621e-0b9e-47d5-bcac-dc88546900b7",
      "name": "Training Stability",
      "categoryId": "3f34ecb9-feff-4003-84e1-762cf3af049f"
    },
    {
      "id": "85f7afc9-f8bf-4039-b8a9-c2ef863f018b",
      "name": "Deep Learning Regularization",
      "categoryId": "3f34ecb9-feff-4003-84e1-762cf3af049f"
    },
    {
      "id": "f667dcb4-91b1-43b3-ac2c-46e7936d3499",
      "name": "Convergence Acceleration",
      "categoryId": "3f34ecb9-feff-4003-84e1-762cf3af049f"
    },
    {
      "id": "2fac11e0-5457-4e33-9043-16b2fabccb1d",
      "name": "Optimization Techniques",
      "categoryId": "456a3d25-7e42-45e1-b4ea-6aaf5331896f"
    },
    {
      "id": "0e2904b5-f0d8-4b3d-8c4e-6dfeae4a97d0",
      "name": "Gradient Clipping",
      "categoryId": "456a3d25-7e42-45e1-b4ea-6aaf5331896f"
    },
    {
      "id": "db149b82-927f-49f2-9e2d-ee136b43a223",
      "name": "Neural Network Training",
      "categoryId": "456a3d25-7e42-45e1-b4ea-6aaf5331896f"
    },
    {
      "id": "e52e2247-080d-4d74-8b70-9a5207276766",
      "name": "Regularization Methods",
      "categoryId": "456a3d25-7e42-45e1-b4ea-6aaf5331896f"
    },
    {
      "id": "2fab4eb5-c67b-4cd8-8eb9-a90b45a77d72",
      "name": "Deep Learning Optimization",
      "categoryId": "456a3d25-7e42-45e1-b4ea-6aaf5331896f"
    },
    {
      "id": "8b4c5a01-c2e6-4933-96e2-f55d7c5d09f8",
      "name": "Stability Enhancements",
      "categoryId": "456a3d25-7e42-45e1-b4ea-6aaf5331896f"
    },
    {
      "id": "e1a2851a-fe39-4207-949a-7dd9629fee66",
      "name": "Model Training Techniques",
      "categoryId": "456a3d25-7e42-45e1-b4ea-6aaf5331896f"
    },
    {
      "id": "4d6e0eff-54b3-4e7c-a288-949e69bc406b",
      "name": "Gradient Clipping",
      "categoryId": "45cfcd6f-d63d-47eb-9064-4d861f7f0a87"
    },
    {
      "id": "d506c5a2-d4bd-4594-be72-dff874fd4ebf",
      "name": "Norm Clipping",
      "categoryId": "45cfcd6f-d63d-47eb-9064-4d861f7f0a87"
    },
    {
      "id": "c94f83b1-4d9c-4788-80d2-40119d1fa2f0",
      "name": "Training Stability",
      "categoryId": "45cfcd6f-d63d-47eb-9064-4d861f7f0a87"
    },
    {
      "id": "77cf5dea-490c-44a5-b819-4cf5f9b9a640",
      "name": "Optimization Techniques",
      "categoryId": "45cfcd6f-d63d-47eb-9064-4d861f7f0a87"
    },
    {
      "id": "c1a6d9a6-07f8-4dc3-8734-62e26e863b7f",
      "name": "Gradient Regularization",
      "categoryId": "45cfcd6f-d63d-47eb-9064-4d861f7f0a87"
    },
    {
      "id": "840fd2ff-3ee0-4712-8edd-d3aed22bb60e",
      "name": "Graph theory",
      "categoryId": "5b9b4489-8554-42b2-b9ef-726c4094abde"
    },
    {
      "id": "67454fb4-178a-4ae7-834a-31d615cdf145",
      "name": "Community detection",
      "categoryId": "5b9b4489-8554-42b2-b9ef-726c4094abde"
    },
    {
      "id": "9f35978b-d1af-487f-bfe9-17b04586c8ea",
      "name": "Network analysis",
      "categoryId": "5b9b4489-8554-42b2-b9ef-726c4094abde"
    },
    {
      "id": "16cc9a2a-4f90-41c6-af70-2d82de80b23a",
      "name": "Clustering",
      "categoryId": "5b9b4489-8554-42b2-b9ef-726c4094abde"
    },
    {
      "id": "00491d5a-6527-4076-a4e9-779c83f3b681",
      "name": "Subgraphs",
      "categoryId": "5b9b4489-8554-42b2-b9ef-726c4094abde"
    },
    {
      "id": "c3f998a7-f944-46d9-ad91-42affeaae732",
      "name": "Graph partitions",
      "categoryId": "5b9b4489-8554-42b2-b9ef-726c4094abde"
    },
    {
      "id": "67b2cea2-a6e5-478e-8779-a3beb1207f79",
      "name": "Structural analysis",
      "categoryId": "5b9b4489-8554-42b2-b9ef-726c4094abde"
    },
    {
      "id": "7617b62c-fd58-4c77-ac01-20055c8d5e7a",
      "name": "Social network analysis",
      "categoryId": "5b9b4489-8554-42b2-b9ef-726c4094abde"
    },
    {
      "id": "9b50f4d8-85f9-4dcf-8278-032b91113d77",
      "name": "Topology",
      "categoryId": "5b9b4489-8554-42b2-b9ef-726c4094abde"
    },
    {
      "id": "fb4ae7e9-c3b8-455d-963c-1a7e8b22219c",
      "name": "Combinatorics",
      "categoryId": "5b9b4489-8554-42b2-b9ef-726c4094abde"
    },
    {
      "id": "6903e8e0-8935-4149-9828-77a64b3978b2",
      "name": "Data Mining",
      "categoryId": "523e51fa-1776-427e-89d2-fb66abda68ac"
    },
    {
      "id": "e5a464a1-9683-485c-b906-120236908bb4",
      "name": "Frequent Itemset Mining",
      "categoryId": "523e51fa-1776-427e-89d2-fb66abda68ac"
    },
    {
      "id": "f605396c-809c-442c-a538-262425dfb48c",
      "name": "Association Rule Learning",
      "categoryId": "523e51fa-1776-427e-89d2-fb66abda68ac"
    },
    {
      "id": "a12b8eac-ce3f-402f-b51d-81104217cac8",
      "name": "Pattern Discovery",
      "categoryId": "523e51fa-1776-427e-89d2-fb66abda68ac"
    },
    {
      "id": "d5f398f3-6849-40df-afe1-0e81dc37002a",
      "name": "Market Basket Analysis",
      "categoryId": "523e51fa-1776-427e-89d2-fb66abda68ac"
    },
    {
      "id": "12141a3f-7e44-4366-b74e-7b98ced2c81a",
      "name": "Unsupervised Learning",
      "categoryId": "523e51fa-1776-427e-89d2-fb66abda68ac"
    },
    {
      "id": "5b22a92b-017b-4f46-a9af-d8418bf22166",
      "name": "Transaction Data",
      "categoryId": "523e51fa-1776-427e-89d2-fb66abda68ac"
    },
    {
      "id": "9aae7ac9-418b-4cb6-8390-f93a8058bfcd",
      "name": "Itemset Mining",
      "categoryId": "523e51fa-1776-427e-89d2-fb66abda68ac"
    },
    {
      "id": "4d4399f7-3b43-4a06-8f64-92f38118c65c",
      "name": "Support",
      "categoryId": "523e51fa-1776-427e-89d2-fb66abda68ac"
    },
    {
      "id": "a1cdccc9-2bc5-4760-8753-e7e3b36fb151",
      "name": "Confidence",
      "categoryId": "523e51fa-1776-427e-89d2-fb66abda68ac"
    },
    {
      "id": "0e2e5070-7bb1-4155-99be-7ff8aa8a6c9d",
      "name": "Apriori Algorithm",
      "categoryId": "523e51fa-1776-427e-89d2-fb66abda68ac"
    },
    {
      "id": "15990c50-1a72-45a9-92ff-c57f987a7c48",
      "name": "FP-Growth Algorithm",
      "categoryId": "523e51fa-1776-427e-89d2-fb66abda68ac"
    },
    {
      "id": "d7b22acf-05ae-4a9c-bcd4-786dca5eeb8d",
      "name": "Network Analysis",
      "categoryId": "99a37e49-c26c-436a-ba47-f1aef82840f9"
    },
    {
      "id": "56a302d7-8abe-42fb-ac18-1881e9154897",
      "name": "Centrality Measures",
      "categoryId": "99a37e49-c26c-436a-ba47-f1aef82840f9"
    },
    {
      "id": "5ab38784-a135-4807-b36e-4f50ba6c3715",
      "name": "Graph Theory",
      "categoryId": "99a37e49-c26c-436a-ba47-f1aef82840f9"
    },
    {
      "id": "401370c2-a5ac-4bc4-a998-50a50c140594",
      "name": "Data Science",
      "categoryId": "99a37e49-c26c-436a-ba47-f1aef82840f9"
    },
    {
      "id": "9a1a0dc8-e150-44d2-883d-e7f1ce21e199",
      "name": "Social Network Analysis",
      "categoryId": "99a37e49-c26c-436a-ba47-f1aef82840f9"
    },
    {
      "id": "e6449670-cd17-4bdd-8207-35bd94c2ed49",
      "name": "Complex Networks",
      "categoryId": "99a37e49-c26c-436a-ba47-f1aef82840f9"
    },
    {
      "id": "7b2570e4-ed75-42fc-80be-1d1e4b58486c",
      "name": "Node Importance",
      "categoryId": "99a37e49-c26c-436a-ba47-f1aef82840f9"
    },
    {
      "id": "1aa85b9d-50fe-41cf-bebd-28a1b8f63bd0",
      "name": "Graph Metrics",
      "categoryId": "99a37e49-c26c-436a-ba47-f1aef82840f9"
    },
    {
      "id": "4877303d-2525-4ad3-8a8a-c46d3461fa68",
      "name": "Structural Time-series",
      "categoryId": "b45fcd23-167a-4cd7-8c94-f11731bcd9bb"
    },
    {
      "id": "12fe26c9-2193-4e0b-85da-7fede83753a5",
      "name": "Temporal Data Mining",
      "categoryId": "b45fcd23-167a-4cd7-8c94-f11731bcd9bb"
    },
    {
      "id": "42738879-963b-4082-93e5-8de2527a58c8",
      "name": "Dynamic Clustering",
      "categoryId": "b45fcd23-167a-4cd7-8c94-f11731bcd9bb"
    },
    {
      "id": "605b5e37-05e4-4bac-a3e1-3be1247829ea",
      "name": "Structural Pattern Recognition",
      "categoryId": "b45fcd23-167a-4cd7-8c94-f11731bcd9bb"
    },
    {
      "id": "326bb3cf-434e-4028-8969-2585e8c8af17",
      "name": "Time-series Segmentation",
      "categoryId": "b45fcd23-167a-4cd7-8c94-f11731bcd9bb"
    },
    {
      "id": "ac4915e6-b09d-462d-9881-fb7809aa7885",
      "name": "Ubiquitous Data Analysis",
      "categoryId": "b45fcd23-167a-4cd7-8c94-f11731bcd9bb"
    },
    {
      "id": "006b7061-411a-4f16-88e8-7ceb69d83558",
      "name": "Semi-supervised Learning",
      "categoryId": "81c4a614-b379-4963-8334-e5408557d7c0"
    },
    {
      "id": "1c81a9d0-45e3-4328-979f-89f7f033a984",
      "name": "Unsupervised Learning",
      "categoryId": "81c4a614-b379-4963-8334-e5408557d7c0"
    },
    {
      "id": "5333b5de-6ad0-453d-8694-a0626f7f8075",
      "name": "Representation Learning",
      "categoryId": "81c4a614-b379-4963-8334-e5408557d7c0"
    },
    {
      "id": "c44324e3-e880-4f90-b322-4cc6aa68beb9",
      "name": "Data Clustering",
      "categoryId": "81c4a614-b379-4963-8334-e5408557d7c0"
    },
    {
      "id": "a8c670bd-a9cb-4322-84b6-e014f007b32e",
      "name": "Manifold Assumption",
      "categoryId": "81c4a614-b379-4963-8334-e5408557d7c0"
    },
    {
      "id": "fef81460-c322-4358-9a53-f2d580632375",
      "name": "Label Propagation",
      "categoryId": "81c4a614-b379-4963-8334-e5408557d7c0"
    },
    {
      "id": "3a999406-56ff-4860-9fe7-8a5a63c147ae",
      "name": "Pseudo-labeling",
      "categoryId": "81c4a614-b379-4963-8334-e5408557d7c0"
    },
    {
      "id": "3fb9fa0e-1e6d-43a8-9289-686a3ca16dd4",
      "name": "Dimensionality Reduction",
      "categoryId": "81c4a614-b379-4963-8334-e5408557d7c0"
    },
    {
      "id": "4bb655bd-c51f-4cc8-8e51-e7c8c515e8a2",
      "name": "Density Estimation",
      "categoryId": "81c4a614-b379-4963-8334-e5408557d7c0"
    },
    {
      "id": "144fca38-3b86-4312-89b0-263a34343e3e",
      "name": "Clustering",
      "categoryId": "7d6cb905-5b1d-481d-90a9-6b51f2614970"
    },
    {
      "id": "d46077bd-ba15-402a-800f-0fb8750f466d",
      "name": "Unsupervised Learning",
      "categoryId": "7d6cb905-5b1d-481d-90a9-6b51f2614970"
    },
    {
      "id": "43ebb9eb-c308-43db-a46c-ff228e6995bf",
      "name": "Data Validation",
      "categoryId": "7d6cb905-5b1d-481d-90a9-6b51f2614970"
    },
    {
      "id": "7d7a01c3-df8d-4c9e-a237-23677cf8d5c6",
      "name": "Model Evaluation",
      "categoryId": "7d6cb905-5b1d-481d-90a9-6b51f2614970"
    },
    {
      "id": "869367f1-2601-474e-bcdd-37573aed127c",
      "name": "Data Quality",
      "categoryId": "7d6cb905-5b1d-481d-90a9-6b51f2614970"
    },
    {
      "id": "1fcf0a77-3dfe-4d71-be91-6a312a84b41d",
      "name": "Intrinsic Cluster Quality Metrics",
      "categoryId": "7d6cb905-5b1d-481d-90a9-6b51f2614970"
    },
    {
      "id": "0c07f92a-db6c-4785-a643-694fa1ca80d0",
      "name": "Machine Learning Metrics",
      "categoryId": "7d6cb905-5b1d-481d-90a9-6b51f2614970"
    },
    {
      "id": "482b0347-5e06-410e-a5b9-2e7faef6b75b",
      "name": "Sampling Techniques",
      "categoryId": "a9ca6fd3-8237-49d6-96e7-0d4d4836417b"
    },
    {
      "id": "907658b0-0b6b-48eb-baeb-6d5e4508901f",
      "name": "Probability Sampling",
      "categoryId": "a9ca6fd3-8237-49d6-96e7-0d4d4836417b"
    },
    {
      "id": "834ed08f-5add-4f03-a954-9d6e9708b143",
      "name": "Data Collection Methods",
      "categoryId": "a9ca6fd3-8237-49d6-96e7-0d4d4836417b"
    },
    {
      "id": "76d69d32-8a02-4e24-8599-44ed73c4c0d6",
      "name": "Statistical Sampling",
      "categoryId": "a9ca6fd3-8237-49d6-96e7-0d4d4836417b"
    },
    {
      "id": "8b633a14-522f-46ff-bc73-960180ef34a5",
      "name": "Data Sampling in Machine Learning",
      "categoryId": "a9ca6fd3-8237-49d6-96e7-0d4d4836417b"
    },
    {
      "id": "133d263a-5265-4db2-805e-bd455fe8da79",
      "name": "Data Representation",
      "categoryId": "a9ca6fd3-8237-49d6-96e7-0d4d4836417b"
    },
    {
      "id": "c5816a52-513d-4ffc-bf90-dce68f6bc07c",
      "name": "Data Subsets",
      "categoryId": "a9ca6fd3-8237-49d6-96e7-0d4d4836417b"
    },
    {
      "id": "c07ad686-ee1a-4deb-85e1-496340579964",
      "name": "Statistical Methods",
      "categoryId": "a9ca6fd3-8237-49d6-96e7-0d4d4836417b"
    },
    {
      "id": "d2a2443f-aec7-467e-bb49-c94f3676472a",
      "name": "Data Analytics",
      "categoryId": "a9ca6fd3-8237-49d6-96e7-0d4d4836417b"
    },
    {
      "id": "ffbd621e-5af4-4ee7-aae7-266d842fd5d5",
      "name": "Data Sampling Strategies",
      "categoryId": "a9ca6fd3-8237-49d6-96e7-0d4d4836417b"
    },
    {
      "id": "bc53fbc6-c019-4b62-becd-16ed422f23d8",
      "name": "Clustering",
      "categoryId": "abe90435-b123-4570-91c9-5d75aa6b1137"
    },
    {
      "id": "042f419b-54c9-4711-8633-488e6294979d",
      "name": "Unsupervised Learning",
      "categoryId": "abe90435-b123-4570-91c9-5d75aa6b1137"
    },
    {
      "id": "e264ddc2-a0de-4742-8eb4-91a3cd4277bb",
      "name": "Data Segmentation",
      "categoryId": "abe90435-b123-4570-91c9-5d75aa6b1137"
    },
    {
      "id": "865c80d8-5cc3-4029-936e-fbdb08e91b02",
      "name": "Pattern Recognition",
      "categoryId": "abe90435-b123-4570-91c9-5d75aa6b1137"
    },
    {
      "id": "fdda88db-0674-4a5e-b0cb-9014581e4e8e",
      "name": "Grouping",
      "categoryId": "abe90435-b123-4570-91c9-5d75aa6b1137"
    },
    {
      "id": "541aad4a-35a1-432d-ae4c-26843636b5e3",
      "name": "Density-Based Clustering",
      "categoryId": "abe90435-b123-4570-91c9-5d75aa6b1137"
    },
    {
      "id": "c8612c10-60dc-4db8-bded-00850bf7b373",
      "name": "Hierarchical Clustering",
      "categoryId": "abe90435-b123-4570-91c9-5d75aa6b1137"
    },
    {
      "id": "208d8ffb-7a0b-4c16-b21d-de16a9335b85",
      "name": "Partitioning Methods",
      "categoryId": "abe90435-b123-4570-91c9-5d75aa6b1137"
    },
    {
      "id": "52c6618e-9977-45e3-ae16-7b235c3e22bc",
      "name": "Centroid-Based Clustering",
      "categoryId": "abe90435-b123-4570-91c9-5d75aa6b1137"
    },
    {
      "id": "9d2f3e56-4633-4bce-885c-c7c4ba54436e",
      "name": "Unsupervised Learning",
      "categoryId": "7d85022d-32b0-458c-a129-1a17dbda756c"
    },
    {
      "id": "1cc1e149-22d4-41e5-bd7b-c4b5ad9d8557",
      "name": "Data Clustering",
      "categoryId": "7d85022d-32b0-458c-a129-1a17dbda756c"
    },
    {
      "id": "b8950a09-cb5c-40fc-a829-75e214d8fdf8",
      "name": "Pattern Recognition",
      "categoryId": "7d85022d-32b0-458c-a129-1a17dbda756c"
    },
    {
      "id": "5f8948ad-90da-4c3c-84e7-801a4576d36e",
      "name": "Similarity Measures",
      "categoryId": "7d85022d-32b0-458c-a129-1a17dbda756c"
    },
    {
      "id": "687ed13b-6999-4c78-ae93-70a9f7d81fd5",
      "name": "Data Segmentation",
      "categoryId": "7d85022d-32b0-458c-a129-1a17dbda756c"
    },
    {
      "id": "bb8df5f3-56c7-4ec8-bf9c-d1817f826bc5",
      "name": "Density-Based Clustering",
      "categoryId": "7d85022d-32b0-458c-a129-1a17dbda756c"
    },
    {
      "id": "63f22431-663f-46a7-98c2-1d63542fa868",
      "name": "Partitioning Methods",
      "categoryId": "7d85022d-32b0-458c-a129-1a17dbda756c"
    },
    {
      "id": "0d08d81d-7a6b-460f-b601-43cddf97f3b1",
      "name": "Hierarchical Clustering",
      "categoryId": "7d85022d-32b0-458c-a129-1a17dbda756c"
    },
    {
      "id": "9dd8721c-205c-4a5f-a74c-0cac4e194aa4",
      "name": "Model-Based Clustering",
      "categoryId": "7d85022d-32b0-458c-a129-1a17dbda756c"
    },
    {
      "id": "fc8a7abe-6acf-4142-ac6d-1bf30884d955",
      "name": "Clustering Algorithms",
      "categoryId": "8ee2f9cb-ba78-418e-b60b-ca1be79782ed"
    },
    {
      "id": "0103c27a-c2f5-49ed-b839-ef1d4c941332",
      "name": "Unsupervised Learning",
      "categoryId": "8ee2f9cb-ba78-418e-b60b-ca1be79782ed"
    },
    {
      "id": "a45cd777-5cca-4a5a-b5ae-3c92494bc17f",
      "name": "Data Segmentation",
      "categoryId": "8ee2f9cb-ba78-418e-b60b-ca1be79782ed"
    },
    {
      "id": "ab6268ca-5396-4853-92c9-c497744d40f3",
      "name": "K-means",
      "categoryId": "8ee2f9cb-ba78-418e-b60b-ca1be79782ed"
    },
    {
      "id": "beeb4d3a-b68c-4d31-a37e-2806566266b1",
      "name": "Hierarchical Clustering",
      "categoryId": "8ee2f9cb-ba78-418e-b60b-ca1be79782ed"
    },
    {
      "id": "592afb3a-c4a1-4350-a878-28cdc7fbd089",
      "name": "Pattern Recognition",
      "categoryId": "8ee2f9cb-ba78-418e-b60b-ca1be79782ed"
    },
    {
      "id": "e0c8f48c-4e58-4da4-ab11-a624f5fe92bd",
      "name": "Data Mining",
      "categoryId": "8ee2f9cb-ba78-418e-b60b-ca1be79782ed"
    },
    {
      "id": "36a31f5f-d1dd-4080-bbe7-0141b94989f1",
      "name": "Grouping Methods",
      "categoryId": "8ee2f9cb-ba78-418e-b60b-ca1be79782ed"
    },
    {
      "id": "92758e77-1193-43f6-88a4-b688616bda2e",
      "name": "Similarity Measures",
      "categoryId": "8ee2f9cb-ba78-418e-b60b-ca1be79782ed"
    },
    {
      "id": "c8d074e9-e609-46d7-bbaa-fab49554703c",
      "name": "Distance Metrics",
      "categoryId": "8ee2f9cb-ba78-418e-b60b-ca1be79782ed"
    },
    {
      "id": "19f0f17e-5df4-40d4-8ecb-3e6e3ccb589f",
      "name": "Clustering Metrics",
      "categoryId": "6cecb1d1-4a3a-4cc4-b410-1763dcb9c8fd"
    },
    {
      "id": "32f0e93d-9d9e-4a95-a41b-c98002b4daf7",
      "name": "Silhouette Score",
      "categoryId": "6cecb1d1-4a3a-4cc4-b410-1763dcb9c8fd"
    },
    {
      "id": "3a8632ac-6f87-4558-8494-bbd8fc07353f",
      "name": "Davies-Bouldin Index",
      "categoryId": "6cecb1d1-4a3a-4cc4-b410-1763dcb9c8fd"
    },
    {
      "id": "7bccd76a-29fc-42ef-953a-cef5bf2362b0",
      "name": "Cluster Validation",
      "categoryId": "6cecb1d1-4a3a-4cc4-b410-1763dcb9c8fd"
    },
    {
      "id": "ea9d7fab-ad80-42be-bcb8-980ffd467490",
      "name": "Cluster Quality Metrics",
      "categoryId": "6cecb1d1-4a3a-4cc4-b410-1763dcb9c8fd"
    },
    {
      "id": "5c4f0cc6-8152-4126-b56b-f6ae58550066",
      "name": "Data Analysis",
      "categoryId": "6cecb1d1-4a3a-4cc4-b410-1763dcb9c8fd"
    },
    {
      "id": "673b060b-16a4-4310-a51b-09cdece78fd6",
      "name": "Model Selection",
      "categoryId": "6cecb1d1-4a3a-4cc4-b410-1763dcb9c8fd"
    },
    {
      "id": "c6e4067c-0208-4f73-9821-7ceb49a961cf",
      "name": "Unsupervised Learning",
      "categoryId": "98e00305-a0e6-470c-bcdb-5fc3d41529a1"
    },
    {
      "id": "cfc1b2ee-b76f-4b1f-a461-6473083870c4",
      "name": "Pattern Recognition",
      "categoryId": "98e00305-a0e6-470c-bcdb-5fc3d41529a1"
    },
    {
      "id": "4395ed62-ac70-42e6-8060-a9835831b667",
      "name": "Data Clustering",
      "categoryId": "98e00305-a0e6-470c-bcdb-5fc3d41529a1"
    },
    {
      "id": "1ef2f444-705e-4afb-9970-5165a1464e61",
      "name": "Stability Analysis",
      "categoryId": "98e00305-a0e6-470c-bcdb-5fc3d41529a1"
    },
    {
      "id": "b724b6f2-0499-4a97-a038-26a028195d3d",
      "name": "Validation Techniques",
      "categoryId": "98e00305-a0e6-470c-bcdb-5fc3d41529a1"
    },
    {
      "id": "ca6cb50a-9e97-4ffa-8cc1-6c2faab41cb2",
      "name": "Cluster Consistency",
      "categoryId": "98e00305-a0e6-470c-bcdb-5fc3d41529a1"
    },
    {
      "id": "07b34ee2-504c-4526-9bc0-3c4ce50c5345",
      "name": "Robustness Metrics",
      "categoryId": "98e00305-a0e6-470c-bcdb-5fc3d41529a1"
    },
    {
      "id": "c30960f4-d8fa-41c1-aee5-abf02a4c0cce",
      "name": "Emotion Generation",
      "categoryId": "68a64e29-b936-44d7-b45b-686e1894cb1a"
    },
    {
      "id": "d60fdee6-d158-46a6-ae3a-176e9e8ab237",
      "name": "Affective Computing",
      "categoryId": "68a64e29-b936-44d7-b45b-686e1894cb1a"
    },
    {
      "id": "426ce0dc-2742-46c2-a39f-a88204158289",
      "name": "Sentiment Synthesis",
      "categoryId": "68a64e29-b936-44d7-b45b-686e1894cb1a"
    },
    {
      "id": "11a998f3-9e39-465e-a7cc-49f8e6bbc1c1",
      "name": "Emotional AI",
      "categoryId": "68a64e29-b936-44d7-b45b-686e1894cb1a"
    },
    {
      "id": "d91c3f43-1766-414d-85f8-2a6875746748",
      "name": "Human-Computer Interaction",
      "categoryId": "68a64e29-b936-44d7-b45b-686e1894cb1a"
    },
    {
      "id": "2a591f8e-c267-4e37-90eb-c6d823925d28",
      "name": "Emotional Response Modeling",
      "categoryId": "68a64e29-b936-44d7-b45b-686e1894cb1a"
    },
    {
      "id": "2d93914f-caea-488f-aa54-b6db2b0103fe",
      "name": "Affective Signal Processing",
      "categoryId": "68a64e29-b936-44d7-b45b-686e1894cb1a"
    },
    {
      "id": "a4d95ab0-1183-496b-baaf-b72e5917fce5",
      "name": "Multimodal Emotion Recognition",
      "categoryId": "68a64e29-b936-44d7-b45b-686e1894cb1a"
    },
    {
      "id": "e11fe3cf-92ac-4312-8cc7-43aef753825e",
      "name": "Generative Emotional Content",
      "categoryId": "68a64e29-b936-44d7-b45b-686e1894cb1a"
    },
    {
      "id": "56c037c2-7a1b-487d-9e05-6bf58ab55df9",
      "name": "Computer-Generated Emotions",
      "categoryId": "68a64e29-b936-44d7-b45b-686e1894cb1a"
    },
    {
      "id": "a699f8b5-6ad4-433f-9261-4cca96790dfe",
      "name": "Emotion Modeling",
      "categoryId": "af0d3e9a-be4c-41d0-ae56-19261235ee12"
    },
    {
      "id": "15e46ca8-0a0e-44cb-bf9c-e78cd72b042e",
      "name": "Affective Computing",
      "categoryId": "af0d3e9a-be4c-41d0-ae56-19261235ee12"
    },
    {
      "id": "8e420c94-9956-4ea9-bbfb-88a5af767448",
      "name": "Sentiment Analysis",
      "categoryId": "af0d3e9a-be4c-41d0-ae56-19261235ee12"
    },
    {
      "id": "5b30f27a-6b64-4ef6-b6d0-0b7f41f44d11",
      "name": "Mood Detection",
      "categoryId": "af0d3e9a-be4c-41d0-ae56-19261235ee12"
    },
    {
      "id": "16828bab-507c-4d09-b7b9-3b397c8e04fb",
      "name": "Affect Recognition",
      "categoryId": "af0d3e9a-be4c-41d0-ae56-19261235ee12"
    },
    {
      "id": "89333833-1b80-4470-a06e-0e96b50351a4",
      "name": "Emotional Intelligence in AI",
      "categoryId": "af0d3e9a-be4c-41d0-ae56-19261235ee12"
    },
    {
      "id": "07b51996-b5e4-4423-a316-04cba541047c",
      "name": "Human-Computer Interaction",
      "categoryId": "af0d3e9a-be4c-41d0-ae56-19261235ee12"
    },
    {
      "id": "e3489958-89d2-4ade-bc2f-d8f877278ec5",
      "name": "User State Estimation",
      "categoryId": "af0d3e9a-be4c-41d0-ae56-19261235ee12"
    },
    {
      "id": "81700b6f-7ea6-4ef6-b776-c344e17143d6",
      "name": "Emotional Response Modeling",
      "categoryId": "af0d3e9a-be4c-41d0-ae56-19261235ee12"
    },
    {
      "id": "35af1664-d291-4cde-84f7-9119e457df35",
      "name": "Psychophysiological Signal Processing",
      "categoryId": "af0d3e9a-be4c-41d0-ae56-19261235ee12"
    },
    {
      "id": "4febc8d0-f59b-4766-a717-1eec51d184ab",
      "name": "Emotion Recognition",
      "categoryId": "f01a4b2f-a392-4675-b2a9-612f06d647cf"
    },
    {
      "id": "4c5b5df0-39f9-4b75-958f-fb939142865c",
      "name": "Affective Computing",
      "categoryId": "f01a4b2f-a392-4675-b2a9-612f06d647cf"
    },
    {
      "id": "371b7378-6541-45b1-8c90-194b089f58c9",
      "name": "Sentiment Analysis",
      "categoryId": "f01a4b2f-a392-4675-b2a9-612f06d647cf"
    },
    {
      "id": "1cdc1292-87f5-4857-bddc-0cdc2b59a659",
      "name": "Facial Expression Analysis",
      "categoryId": "f01a4b2f-a392-4675-b2a9-612f06d647cf"
    },
    {
      "id": "da9ff866-3e0b-4503-810f-25a36956937e",
      "name": "Voice Emotion Detection",
      "categoryId": "f01a4b2f-a392-4675-b2a9-612f06d647cf"
    },
    {
      "id": "0330b9d3-a608-46d5-a79c-9853dc95af60",
      "name": "Multimodal Emotion Recognition",
      "categoryId": "f01a4b2f-a392-4675-b2a9-612f06d647cf"
    },
    {
      "id": "fc0d059b-e9df-4caf-8b1d-d8ae1734bec7",
      "name": "Human-Computer Interaction",
      "categoryId": "f01a4b2f-a392-4675-b2a9-612f06d647cf"
    },
    {
      "id": "dbfe71aa-2624-4e1b-83c0-f221238921ee",
      "name": "Computational Psychology",
      "categoryId": "f01a4b2f-a392-4675-b2a9-612f06d647cf"
    },
    {
      "id": "ae31509d-ac7d-4197-b862-5e1e9fcd3af7",
      "name": "Emotion Recognition",
      "categoryId": "3b842afb-d83f-4bb8-a0e2-cf778b74a044"
    },
    {
      "id": "66c66a96-c493-4001-b489-db926d491bc9",
      "name": "Sentiment Analysis",
      "categoryId": "3b842afb-d83f-4bb8-a0e2-cf778b74a044"
    },
    {
      "id": "ccddfa17-5915-42da-b102-b0a71649cae1",
      "name": "Multimodal Data",
      "categoryId": "3b842afb-d83f-4bb8-a0e2-cf778b74a044"
    },
    {
      "id": "32b3d0b1-fba2-4d80-bb16-f83be97387fe",
      "name": "Data Collection",
      "categoryId": "3b842afb-d83f-4bb8-a0e2-cf778b74a044"
    },
    {
      "id": "bbcb112d-c770-4546-90f2-2e340bf1c74a",
      "name": "Feature Extraction",
      "categoryId": "3b842afb-d83f-4bb8-a0e2-cf778b74a044"
    },
    {
      "id": "ca148e70-2ab7-4898-856f-37fcb1ce8757",
      "name": "Ethical AI",
      "categoryId": "3b842afb-d83f-4bb8-a0e2-cf778b74a044"
    },
    {
      "id": "4f528423-1ab7-433a-a7fd-18edea54980d",
      "name": "Deep Learning for Emotions",
      "categoryId": "3b842afb-d83f-4bb8-a0e2-cf778b74a044"
    },
    {
      "id": "aa8127ea-e122-434a-b623-64f7f65f7d34",
      "name": "Affective Signal Processing",
      "categoryId": "3b842afb-d83f-4bb8-a0e2-cf778b74a044"
    },
    {
      "id": "99f7690e-21d1-4da2-b41d-a41f2ac31afd",
      "name": "Emotion-Aware Text Generation",
      "categoryId": "4de95ba3-dedf-4233-98cb-8f7eb0c8058e"
    },
    {
      "id": "ac0a8876-6bcb-44e3-9514-659104b1f214",
      "name": "Sentiment-Driven NLP",
      "categoryId": "4de95ba3-dedf-4233-98cb-8f7eb0c8058e"
    },
    {
      "id": "66d43e66-04f9-4b88-aabd-f3cd1a96f80e",
      "name": "Affective Computing",
      "categoryId": "4de95ba3-dedf-4233-98cb-8f7eb0c8058e"
    },
    {
      "id": "44fa114f-8010-4216-9983-4d08be244b18",
      "name": "Emotion Recognition",
      "categoryId": "4de95ba3-dedf-4233-98cb-8f7eb0c8058e"
    },
    {
      "id": "1e5329ee-0ec6-4c28-b7ea-b86942895fb6",
      "name": "Emotional Language Modeling",
      "categoryId": "4de95ba3-dedf-4233-98cb-8f7eb0c8058e"
    },
    {
      "id": "03c03f36-d50f-4211-ab3c-bb17f785c2db",
      "name": "Contextual Sentiment Analysis",
      "categoryId": "4de95ba3-dedf-4233-98cb-8f7eb0c8058e"
    },
    {
      "id": "a510988e-89aa-4ac6-9aa0-45ec13824106",
      "name": "Human-Like Text Generation",
      "categoryId": "4de95ba3-dedf-4233-98cb-8f7eb0c8058e"
    },
    {
      "id": "1d5b243a-6f7a-4c6e-8910-04c89844fe80",
      "name": "Affective Language Models.",
      "categoryId": "4de95ba3-dedf-4233-98cb-8f7eb0c8058e"
    },
    {
      "id": "e3962da4-1300-4f34-8e3b-47a37a8023d1",
      "name": "Emotion Recognition",
      "categoryId": "29e1619d-6ec8-4e59-8855-1a00917a9623"
    },
    {
      "id": "26c0a0c6-3467-4ea5-b8b6-e43ef8a63a21",
      "name": "Sentiment Analysis",
      "categoryId": "29e1619d-6ec8-4e59-8855-1a00917a9623"
    },
    {
      "id": "f088a94c-2017-49a1-a260-077ae81e2bf6",
      "name": "affective computing",
      "categoryId": "29e1619d-6ec8-4e59-8855-1a00917a9623"
    },
    {
      "id": "cc4f6344-7425-4cac-9019-3aa7cbd3daff",
      "name": "Affective Computing",
      "categoryId": "29e1619d-6ec8-4e59-8855-1a00917a9623"
    },
    {
      "id": "8f94c2e7-19df-4dd3-bc27-d7b9cfd63b6d",
      "name": "Emotion AI Frameworks",
      "categoryId": "29e1619d-6ec8-4e59-8855-1a00917a9623"
    },
    {
      "id": "fade7797-fee8-422f-b1e6-b7f1d088bb33",
      "name": "Emotion Recognition",
      "categoryId": "6e31bbb4-9129-425e-a193-4e07f430785c"
    },
    {
      "id": "5b8ee6a6-bc8a-4cb9-890b-b41c11eaf327",
      "name": "Affective Computing",
      "categoryId": "6e31bbb4-9129-425e-a193-4e07f430785c"
    },
    {
      "id": "ebc8f970-f010-4199-bf8e-eb03f858811c",
      "name": "Sentiment Analysis",
      "categoryId": "6e31bbb4-9129-425e-a193-4e07f430785c"
    },
    {
      "id": "637f03ec-a70f-49c3-9dfc-cee2e197211d",
      "name": "Human-Computer Interaction",
      "categoryId": "6e31bbb4-9129-425e-a193-4e07f430785c"
    },
    {
      "id": "3f3f650b-b336-4f06-84a3-88e12726cd4f",
      "name": "Emotion Detection",
      "categoryId": "6e31bbb4-9129-425e-a193-4e07f430785c"
    },
    {
      "id": "a7cd762a-1717-456c-8be7-38ce3053735c",
      "name": "Empathy in AI",
      "categoryId": "6e31bbb4-9129-425e-a193-4e07f430785c"
    },
    {
      "id": "c926deff-b9fa-47a1-9401-b3b079949943",
      "name": "Social Intelligence",
      "categoryId": "6e31bbb4-9129-425e-a193-4e07f430785c"
    },
    {
      "id": "6c20f033-4275-40e6-8e08-2b3f60ceb638",
      "name": "Facial Expression Analysis",
      "categoryId": "6e31bbb4-9129-425e-a193-4e07f430785c"
    },
    {
      "id": "08087803-963e-48c8-9732-3472ce98dc48",
      "name": "Voice Emotion Analysis",
      "categoryId": "6e31bbb4-9129-425e-a193-4e07f430785c"
    },
    {
      "id": "9d1b2a38-8707-486e-8eef-4adc14963b36",
      "name": "Behavioral Signal Processing",
      "categoryId": "6e31bbb4-9129-425e-a193-4e07f430785c"
    },
    {
      "id": "3666559f-5b03-46ae-939b-144176baeb08",
      "name": "Bayesian Statistics",
      "categoryId": "96d4e364-7e9b-493c-a398-4b7d643efd9a"
    },
    {
      "id": "af7be779-974a-4a87-bb20-0b56105583cb",
      "name": "Empirical Bayes",
      "categoryId": "96d4e364-7e9b-493c-a398-4b7d643efd9a"
    },
    {
      "id": "fd92ae92-3f11-4825-a870-6bd1c79b1d89",
      "name": "Regression Analysis",
      "categoryId": "96d4e364-7e9b-493c-a398-4b7d643efd9a"
    },
    {
      "id": "04ac7dfb-4694-4109-ad2b-4bfdd386d262",
      "name": "Hierarchical Models",
      "categoryId": "96d4e364-7e9b-493c-a398-4b7d643efd9a"
    },
    {
      "id": "9d74fb0e-9ed5-42b0-aabf-c2174300d81a",
      "name": "Statistical Estimation",
      "categoryId": "96d4e364-7e9b-493c-a398-4b7d643efd9a"
    },
    {
      "id": "52a070e0-b289-471e-b6ad-f0a5c324b672",
      "name": "Shrinkage Methods",
      "categoryId": "96d4e364-7e9b-493c-a398-4b7d643efd9a"
    },
    {
      "id": "abd66510-7357-4f12-82ae-9bd6c27e19ab",
      "name": "Regularization Techniques",
      "categoryId": "96d4e364-7e9b-493c-a398-4b7d643efd9a"
    },
    {
      "id": "e5ef048c-22c7-4c54-a986-914ae090ae8e",
      "name": "Statistics",
      "categoryId": "745016eb-9726-4ddd-9c6b-84ab3e8b1332"
    },
    {
      "id": "097ca210-50d1-468e-9108-fa0bbd506b0a",
      "name": "Probability Theory",
      "categoryId": "745016eb-9726-4ddd-9c6b-84ab3e8b1332"
    },
    {
      "id": "55983dd0-add5-4f57-8cdc-d1fe0dde8906",
      "name": "Data Analysis",
      "categoryId": "745016eb-9726-4ddd-9c6b-84ab3e8b1332"
    },
    {
      "id": "7bd25505-5235-4f56-9944-a47fe20d3e27",
      "name": "Empirical Methods",
      "categoryId": "745016eb-9726-4ddd-9c6b-84ab3e8b1332"
    },
    {
      "id": "aa66a5d1-24f4-4ade-9cf4-d2fd4e1319fa",
      "name": "Probabilistic Modeling",
      "categoryId": "745016eb-9726-4ddd-9c6b-84ab3e8b1332"
    },
    {
      "id": "6ca96e23-4c2b-4b39-a09e-e73a363d9d73",
      "name": "AI/ML Sub-category Tags: Reinforcement Learning",
      "categoryId": "fe214b9b-c980-497d-a515-3b8b3504d7d4"
    },
    {
      "id": "78485ea6-3040-4a6c-af78-9235cd057813",
      "name": "Autonomous Agents",
      "categoryId": "fe214b9b-c980-497d-a515-3b8b3504d7d4"
    },
    {
      "id": "75894913-898b-49ed-9558-336c5ed8d948",
      "name": "Decision-Making Systems",
      "categoryId": "fe214b9b-c980-497d-a515-3b8b3504d7d4"
    },
    {
      "id": "8e5f08cd-49bb-43d6-aace-9f36f494a0c0",
      "name": "Policy Optimization",
      "categoryId": "fe214b9b-c980-497d-a515-3b8b3504d7d4"
    },
    {
      "id": "855286c2-eaa7-4375-9f05-20d1e31a69f1",
      "name": "Reward Functions",
      "categoryId": "fe214b9b-c980-497d-a515-3b8b3504d7d4"
    },
    {
      "id": "008418fb-3821-4b44-81a1-d1758b2581ca",
      "name": "Autonomous Systems",
      "categoryId": "fe214b9b-c980-497d-a515-3b8b3504d7d4"
    },
    {
      "id": "32ae5a5c-8272-4b6f-9cc4-3d87c7b461f3",
      "name": "Multi-Agent Systems",
      "categoryId": "fe214b9b-c980-497d-a515-3b8b3504d7d4"
    },
    {
      "id": "34049a2f-b4f3-42ea-98e4-c0d8e9c2ca65",
      "name": "Adaptive Control",
      "categoryId": "fe214b9b-c980-497d-a515-3b8b3504d7d4"
    },
    {
      "id": "4620404f-bc4b-4503-8f94-93463698f030",
      "name": "Behavioral Cloning",
      "categoryId": "fe214b9b-c980-497d-a515-3b8b3504d7d4"
    },
    {
      "id": "15fd29ed-fd8f-46e1-8f44-e213375fe4d8",
      "name": "Hierarchical Reinforcement Learning",
      "categoryId": "fe214b9b-c980-497d-a515-3b8b3504d7d4"
    },
    {
      "id": "e9865c6c-190e-4c10-8bed-03d0bd8b6950",
      "name": "Dimensionality reduction",
      "categoryId": "78767fc3-5f08-4d3d-82b9-26db014a1c2e"
    },
    {
      "id": "e3e8314d-1d45-411d-ac22-aaa39e4018df",
      "name": "feature extraction",
      "categoryId": "78767fc3-5f08-4d3d-82b9-26db014a1c2e"
    },
    {
      "id": "9c6be5d4-0ed2-440c-8a89-f815f47f87fa",
      "name": "deep learning",
      "categoryId": "78767fc3-5f08-4d3d-82b9-26db014a1c2e"
    },
    {
      "id": "8375b546-c377-4a06-93d1-11f8b2469fc7",
      "name": "sequence modeling",
      "categoryId": "78767fc3-5f08-4d3d-82b9-26db014a1c2e"
    },
    {
      "id": "de1d620b-8237-426c-8b83-894cc70c6dcd",
      "name": "neural networks",
      "categoryId": "78767fc3-5f08-4d3d-82b9-26db014a1c2e"
    },
    {
      "id": "1549a250-025f-4419-ac96-63d772f28f9f",
      "name": "representation learning",
      "categoryId": "78767fc3-5f08-4d3d-82b9-26db014a1c2e"
    },
    {
      "id": "8b46e4ce-9e05-4640-bcd0-4da97cc9e767",
      "name": "natural language processing (NLP)",
      "categoryId": "78767fc3-5f08-4d3d-82b9-26db014a1c2e"
    },
    {
      "id": "29790394-022f-415d-bf2c-c33a656a7e36",
      "name": "computer vision",
      "categoryId": "78767fc3-5f08-4d3d-82b9-26db014a1c2e"
    },
    {
      "id": "9e2b1f1d-37f9-4ca7-885f-761fe24cee3e",
      "name": "autoencoders",
      "categoryId": "78767fc3-5f08-4d3d-82b9-26db014a1c2e"
    },
    {
      "id": "200b3221-dd3b-4115-9421-840d324924f5",
      "name": "variational autoencoders (VAEs)",
      "categoryId": "78767fc3-5f08-4d3d-82b9-26db014a1c2e"
    },
    {
      "id": "0b303d0e-bb27-4c8d-921d-6f85d0c901a3",
      "name": "sequence encoders",
      "categoryId": "78767fc3-5f08-4d3d-82b9-26db014a1c2e"
    },
    {
      "id": "ab05053d-c80e-4060-9b94-18da8fca04ec",
      "name": "transformer encoders",
      "categoryId": "78767fc3-5f08-4d3d-82b9-26db014a1c2e"
    },
    {
      "id": "80ddb6e8-c625-4c9c-a2ca-b48e9d8f99f5",
      "name": "convolutional encoders.",
      "categoryId": "78767fc3-5f08-4d3d-82b9-26db014a1c2e"
    },
    {
      "id": "f7a20f6b-aa87-484a-a2a8-d423b2343457",
      "name": "Natural Language Processing (NLP)",
      "categoryId": "b69a2d8b-dad1-443d-90ab-12b5f4027536"
    },
    {
      "id": "fb9a39c0-971a-4c1f-974a-93502a323e74",
      "name": "Deep Learning",
      "categoryId": "b69a2d8b-dad1-443d-90ab-12b5f4027536"
    },
    {
      "id": "7aedb156-f980-4ac8-a09f-97c6cdada5b6",
      "name": "Neural Networks",
      "categoryId": "b69a2d8b-dad1-443d-90ab-12b5f4027536"
    },
    {
      "id": "8937450a-a929-468c-8aff-733af89e48e3",
      "name": "Attention Mechanisms",
      "categoryId": "b69a2d8b-dad1-443d-90ab-12b5f4027536"
    },
    {
      "id": "c1e126a1-59b0-4d33-b742-fee2c18a8d5b",
      "name": "Sequence-to-Sequence Models",
      "categoryId": "b69a2d8b-dad1-443d-90ab-12b5f4027536"
    },
    {
      "id": "2f98bd2a-f69d-4f2f-ae1a-53426b62eefa",
      "name": "Transformer Architecture",
      "categoryId": "b69a2d8b-dad1-443d-90ab-12b5f4027536"
    },
    {
      "id": "8e29bb18-e551-4d82-a280-9e700b7fa395",
      "name": "Machine Translation",
      "categoryId": "b69a2d8b-dad1-443d-90ab-12b5f4027536"
    },
    {
      "id": "87222f1a-646e-45db-985c-a8b621d36872",
      "name": "Contextual Embeddings",
      "categoryId": "b69a2d8b-dad1-443d-90ab-12b5f4027536"
    },
    {
      "id": "3b035db3-5a91-4941-87cc-4373ff0c9b6a",
      "name": "Encoder-Decoder Architecture",
      "categoryId": "ea83ce7d-9872-4d79-a642-9bcc96b2a786"
    },
    {
      "id": "c23821af-08d2-403a-b806-33120a179ce5",
      "name": "Sequence-to-Sequence Models",
      "categoryId": "ea83ce7d-9872-4d79-a642-9bcc96b2a786"
    },
    {
      "id": "38bce737-1734-4f0c-a23f-c7c67a079d24",
      "name": "Recurrent Neural Networks (RNN)",
      "categoryId": "ea83ce7d-9872-4d79-a642-9bcc96b2a786"
    },
    {
      "id": "faea4126-e09c-4591-94cd-41d77d62c539",
      "name": "Long Short-Term Memory (LSTM)",
      "categoryId": "ea83ce7d-9872-4d79-a642-9bcc96b2a786"
    },
    {
      "id": "def610bf-33cd-419e-bd30-b03423054c3b",
      "name": "Gated Recurrent Units (GRU)",
      "categoryId": "ea83ce7d-9872-4d79-a642-9bcc96b2a786"
    },
    {
      "id": "24a70a24-ee7e-451c-823a-dfc320e65b38",
      "name": "Attention Mechanisms",
      "categoryId": "ea83ce7d-9872-4d79-a642-9bcc96b2a786"
    },
    {
      "id": "8ce017b2-ea8f-4fe1-b29e-d2940339f92a",
      "name": "Transformer Models",
      "categoryId": "ea83ce7d-9872-4d79-a642-9bcc96b2a786"
    },
    {
      "id": "29a10da7-5d93-444e-aa0d-2a3b1c6d942d",
      "name": "Encoder-Decoder Models",
      "categoryId": "fe9d572f-1680-4948-a970-90fc6c37aaa4"
    },
    {
      "id": "e692687c-38e1-4dc3-b3d2-02c08a432dba",
      "name": "Sequence-to-Sequence Models",
      "categoryId": "fe9d572f-1680-4948-a970-90fc6c37aaa4"
    },
    {
      "id": "77325037-85d6-4770-b0ee-3bf8d8525f63",
      "name": "Neural Network Architectures",
      "categoryId": "fe9d572f-1680-4948-a970-90fc6c37aaa4"
    },
    {
      "id": "0893c8be-0ad5-4097-ab56-f44a09f565a7",
      "name": "Recurrent Neural Networks",
      "categoryId": "fe9d572f-1680-4948-a970-90fc6c37aaa4"
    },
    {
      "id": "fe6c8da4-32e4-4dd8-aae1-43df40ddae8f",
      "name": "Transformers",
      "categoryId": "fe9d572f-1680-4948-a970-90fc6c37aaa4"
    },
    {
      "id": "78005868-52b7-47e2-a012-9d588fb4f192",
      "name": "Attention Mechanisms",
      "categoryId": "fe9d572f-1680-4948-a970-90fc6c37aaa4"
    },
    {
      "id": "e3ac7a70-9943-4b71-8a04-f5bc963a80d7",
      "name": "Deep Learning",
      "categoryId": "fe9d572f-1680-4948-a970-90fc6c37aaa4"
    },
    {
      "id": "895df966-878c-4076-8065-162b5f1b8086",
      "name": "Natural Language Processing",
      "categoryId": "fe9d572f-1680-4948-a970-90fc6c37aaa4"
    },
    {
      "id": "f854bf68-48f9-478b-b4a6-d356c72f148d",
      "name": "Machine Translation",
      "categoryId": "fe9d572f-1680-4948-a970-90fc6c37aaa4"
    },
    {
      "id": "0c8c973e-382b-4f9f-9fab-f9fdb694c435",
      "name": "Language Modeling",
      "categoryId": "fe9d572f-1680-4948-a970-90fc6c37aaa4"
    },
    {
      "id": "819dd03c-947e-4aa8-b8c9-71b34e783f03",
      "name": "Encoder-Decoder Models Extensions",
      "categoryId": "bad8c175-0ed7-4251-8c3b-27626f157f7d"
    },
    {
      "id": "fd5a43cc-9501-493b-bde8-9b3c5c2cba5b",
      "name": "Sequence-to-Sequence Models",
      "categoryId": "bad8c175-0ed7-4251-8c3b-27626f157f7d"
    },
    {
      "id": "cd97d907-eff2-487c-8eed-94a6268bb50d",
      "name": "Transformers",
      "categoryId": "bad8c175-0ed7-4251-8c3b-27626f157f7d"
    },
    {
      "id": "e95251f3-179f-41dc-88ca-74bcc3a14616",
      "name": "Attention Mechanisms",
      "categoryId": "bad8c175-0ed7-4251-8c3b-27626f157f7d"
    },
    {
      "id": "ffa9d99d-cc45-4e78-bcb4-4ea0e0ef5428",
      "name": "Multi-head Attention",
      "categoryId": "bad8c175-0ed7-4251-8c3b-27626f157f7d"
    },
    {
      "id": "aab479aa-f030-4a7c-9462-167168e2b95e",
      "name": "Positional Encodings",
      "categoryId": "bad8c175-0ed7-4251-8c3b-27626f157f7d"
    },
    {
      "id": "82ba991b-2542-4598-bc16-e6d60eafb178",
      "name": "Modular Architectures",
      "categoryId": "bad8c175-0ed7-4251-8c3b-27626f157f7d"
    },
    {
      "id": "6886072f-f7fb-430b-b700-d5515af9d730",
      "name": "Hierarchical Encodings",
      "categoryId": "bad8c175-0ed7-4251-8c3b-27626f157f7d"
    },
    {
      "id": "c446b584-ede1-4619-bc76-dff7a2c1caa5",
      "name": "Hybrid Models",
      "categoryId": "bad8c175-0ed7-4251-8c3b-27626f157f7d"
    },
    {
      "id": "137763cc-6deb-4543-8b8e-66acaa374ca0",
      "name": "Dynamic Memory Networks",
      "categoryId": "bad8c175-0ed7-4251-8c3b-27626f157f7d"
    },
    {
      "id": "f593830e-ed06-4ac9-90e1-cddef817464b",
      "name": "Encoder-Decoder Models Extensions",
      "categoryId": "a5638ce6-55a8-4763-a612-7f8551cb8cac"
    },
    {
      "id": "bd2dfdef-4542-4406-bab4-e5e64e4f4d96",
      "name": "Sequence-to-Sequence Models",
      "categoryId": "a5638ce6-55a8-4763-a612-7f8551cb8cac"
    },
    {
      "id": "15bc7bae-5471-40c3-8c34-5e5e0b6562c0",
      "name": "Attention Mechanisms",
      "categoryId": "a5638ce6-55a8-4763-a612-7f8551cb8cac"
    },
    {
      "id": "98f6ac63-4246-43c0-bf53-2a1b5df80b16",
      "name": "Transformer Architectures",
      "categoryId": "a5638ce6-55a8-4763-a612-7f8551cb8cac"
    },
    {
      "id": "e87cf46e-bbe9-4bb8-87d9-823b945ab660",
      "name": "Variants of Encoder-Decoder",
      "categoryId": "a5638ce6-55a8-4763-a612-7f8551cb8cac"
    },
    {
      "id": "1171fd80-4eeb-41cf-acfd-cc28dfdbec74",
      "name": "Adaptive Attention",
      "categoryId": "a5638ce6-55a8-4763-a612-7f8551cb8cac"
    },
    {
      "id": "011ca329-154a-49c2-b424-920bc2b63ce4",
      "name": "Multi-Head Attention",
      "categoryId": "a5638ce6-55a8-4763-a612-7f8551cb8cac"
    },
    {
      "id": "1becdea2-b85e-4858-9c30-62ecad349e78",
      "name": "Convolutional Encoders",
      "categoryId": "a5638ce6-55a8-4763-a612-7f8551cb8cac"
    },
    {
      "id": "7b0320af-58a8-4973-bac1-b84a3397b5ef",
      "name": "Recurrent Encoders",
      "categoryId": "a5638ce6-55a8-4763-a612-7f8551cb8cac"
    },
    {
      "id": "a55d22b4-a269-44a6-ad3f-41c4c48f823b",
      "name": "Dynamic Routing",
      "categoryId": "a5638ce6-55a8-4763-a612-7f8551cb8cac"
    },
    {
      "id": "f3ef92a3-ca60-4160-bdc2-ef358f74b237",
      "name": "Hierarchical Encoders",
      "categoryId": "a5638ce6-55a8-4763-a612-7f8551cb8cac"
    },
    {
      "id": "d28ba8f9-8f14-4d5c-b668-0a74e7143d12",
      "name": "Contextual Embeddings",
      "categoryId": "a5638ce6-55a8-4763-a612-7f8551cb8cac"
    },
    {
      "id": "ff262723-2db8-4992-9927-cfcfc95c9104",
      "name": "Model Compression Techniques",
      "categoryId": "a5638ce6-55a8-4763-a612-7f8551cb8cac"
    },
    {
      "id": "98fab91a-6730-4c23-a561-4681ffece846",
      "name": "Fine-tuning Strategies",
      "categoryId": "a5638ce6-55a8-4763-a612-7f8551cb8cac"
    },
    {
      "id": "2ca07b30-9749-4aac-8ecd-4f57fe17e8b8",
      "name": "Encoder-Decoder Models Extensions",
      "categoryId": "0aa60663-e0b4-4ef5-ae64-3c483f7afd5a"
    },
    {
      "id": "89fb0bdb-5de2-4c87-a398-0471cf3c6d91",
      "name": "Transformer Variants",
      "categoryId": "0aa60663-e0b4-4ef5-ae64-3c483f7afd5a"
    },
    {
      "id": "d56badd9-cc5b-49b5-ae7c-fbb8196ba539",
      "name": "Sequence-to-Sequence Architectures",
      "categoryId": "0aa60663-e0b4-4ef5-ae64-3c483f7afd5a"
    },
    {
      "id": "8c6c9bb8-dddd-42bb-bca4-b1919845288d",
      "name": "Attention Mechanisms",
      "categoryId": "0aa60663-e0b4-4ef5-ae64-3c483f7afd5a"
    },
    {
      "id": "a13a6cb3-4ebb-403c-8ffa-ca671135a29c",
      "name": "Residual Connections",
      "categoryId": "0aa60663-e0b4-4ef5-ae64-3c483f7afd5a"
    },
    {
      "id": "5b6cf733-dc2d-4e3c-9a58-e8df159e40a2",
      "name": "Convolutional Encoders/Decoders",
      "categoryId": "0aa60663-e0b4-4ef5-ae64-3c483f7afd5a"
    },
    {
      "id": "8c771e9b-6291-48ea-b985-297929bd06cd",
      "name": "Variational Extensions",
      "categoryId": "0aa60663-e0b4-4ef5-ae64-3c483f7afd5a"
    },
    {
      "id": "d8b17b6f-81d6-4f1a-9dd1-249bd3fd0f55",
      "name": "Multi-head Attention",
      "categoryId": "0aa60663-e0b4-4ef5-ae64-3c483f7afd5a"
    },
    {
      "id": "165a845f-d4b7-496a-9a40-21c116c29baa",
      "name": "Adaptive Encoding",
      "categoryId": "0aa60663-e0b4-4ef5-ae64-3c483f7afd5a"
    },
    {
      "id": "f28e3868-c2a6-426a-a551-2ecf172792da",
      "name": "Cross-Attention Techniques",
      "categoryId": "0aa60663-e0b4-4ef5-ae64-3c483f7afd5a"
    },
    {
      "id": "823ea39e-bdb8-4c45-a5e3-5043f5eb430f",
      "name": "Fine-tuning Strategies",
      "categoryId": "0aa60663-e0b4-4ef5-ae64-3c483f7afd5a"
    },
    {
      "id": "ccb10daa-e940-42fd-987b-e8163501e55d",
      "name": "Model Compression",
      "categoryId": "0aa60663-e0b4-4ef5-ae64-3c483f7afd5a"
    },
    {
      "id": "1ee0b00b-2c49-47d0-9ace-44426f3c0555",
      "name": "Transfer Learning in Encoders-Decoders",
      "categoryId": "0aa60663-e0b4-4ef5-ae64-3c483f7afd5a"
    },
    {
      "id": "ce86662e-0a01-46bf-a1d7-1e64a0a09900",
      "name": "Encoder-Decoder Models Extensions Techniques",
      "categoryId": "2001811c-9dd3-4342-a62e-f433016eeae7"
    },
    {
      "id": "6154820b-a937-4b3d-aac6-fb21e80d979a",
      "name": "Sequence-to-Sequence Learning",
      "categoryId": "2001811c-9dd3-4342-a62e-f433016eeae7"
    },
    {
      "id": "354e8c0c-8816-48de-83ee-20d438f3c5f2",
      "name": "Attention Mechanisms",
      "categoryId": "2001811c-9dd3-4342-a62e-f433016eeae7"
    },
    {
      "id": "ed22d86d-dd5e-4817-9c2b-04d4c7d94f57",
      "name": "Transformer Architectures",
      "categoryId": "2001811c-9dd3-4342-a62e-f433016eeae7"
    },
    {
      "id": "a6dda84c-0410-452e-b087-2bdce95f07bd",
      "name": "Model Optimization",
      "categoryId": "2001811c-9dd3-4342-a62e-f433016eeae7"
    },
    {
      "id": "5e4916c1-a4b6-4cbb-918f-a7b388dbd906",
      "name": "Transfer Learning",
      "categoryId": "2001811c-9dd3-4342-a62e-f433016eeae7"
    },
    {
      "id": "77a5c419-b7c4-41a0-8c01-bddf1909fd48",
      "name": "Multi-head Attention",
      "categoryId": "2001811c-9dd3-4342-a62e-f433016eeae7"
    },
    {
      "id": "b403158a-75fd-4c30-9cf9-a893abc28b1a",
      "name": "Self-Attention",
      "categoryId": "2001811c-9dd3-4342-a62e-f433016eeae7"
    },
    {
      "id": "2fead34f-2e3e-4f4d-8d30-4b458433aed3",
      "name": "Bidirectional Encoders",
      "categoryId": "2001811c-9dd3-4342-a62e-f433016eeae7"
    },
    {
      "id": "c21032c2-3d12-4eda-a762-b31e1e98d6a2",
      "name": "Data Augmentation for Sequence Models",
      "categoryId": "2001811c-9dd3-4342-a62e-f433016eeae7"
    },
    {
      "id": "2b6dfac6-ab22-46c3-b115-7de3765f88d8",
      "name": "Natural Language Processing",
      "categoryId": "24247e7a-85ff-412c-9af4-b043791f7c88"
    },
    {
      "id": "75e67b17-c989-43c5-b5b9-7251aaab2d28",
      "name": "Deep Learning",
      "categoryId": "24247e7a-85ff-412c-9af4-b043791f7c88"
    },
    {
      "id": "993583eb-5eaf-42f4-a6a1-af0df03b4b4a",
      "name": "Representation Learning",
      "categoryId": "24247e7a-85ff-412c-9af4-b043791f7c88"
    },
    {
      "id": "6ca16b0e-0092-4641-a965-1eb8fe569665",
      "name": "Sequence-to-Sequence Models",
      "categoryId": "24247e7a-85ff-412c-9af4-b043791f7c88"
    },
    {
      "id": "a1b1f1b1-a66c-431b-af1a-8ebf06d031b6",
      "name": "Self-supervised Learning",
      "categoryId": "24247e7a-85ff-412c-9af4-b043791f7c88"
    },
    {
      "id": "47a93d70-9007-4d6d-b2bf-e4665bd6073b",
      "name": "Pretraining",
      "categoryId": "24247e7a-85ff-412c-9af4-b043791f7c88"
    },
    {
      "id": "4e65928d-6bd9-4e81-bfc5-0dbfbea7fd67",
      "name": "Transformers",
      "categoryId": "24247e7a-85ff-412c-9af4-b043791f7c88"
    },
    {
      "id": "b8a70357-697b-40bd-bb4c-a2e2315074d3",
      "name": "Language Models",
      "categoryId": "24247e7a-85ff-412c-9af4-b043791f7c88"
    },
    {
      "id": "fc103e43-ad6c-4f5e-820e-a731db766fa4",
      "name": "Contextual Embeddings",
      "categoryId": "24247e7a-85ff-412c-9af4-b043791f7c88"
    },
    {
      "id": "f67a05a4-82e5-439b-ad9a-49f7b11ca373",
      "name": "Unsupervised Learning Techniques",
      "categoryId": "24247e7a-85ff-412c-9af4-b043791f7c88"
    },
    {
      "id": "6a5b2dea-a6ce-4294-bcd3-86a551f827aa",
      "name": "Encoding in machine learning primarily relates to data preprocessing techniques used to convert categorical",
      "categoryId": "f14cce6a-073b-45c1-b7fe-9e7538a2a4d2"
    },
    {
      "id": "67b67c62-14d2-4a9f-941d-c601e1043abd",
      "name": "textual",
      "categoryId": "f14cce6a-073b-45c1-b7fe-9e7538a2a4d2"
    },
    {
      "id": "3e20c048-79bf-4880-9cbf-129f5301e007",
      "name": "or complex data formats into numerical representations suitable for model ingestion. Common sub-category tags include 'One-Hot Encoding'",
      "categoryId": "f14cce6a-073b-45c1-b7fe-9e7538a2a4d2"
    },
    {
      "id": "0e367078-d3e0-41d5-b281-f8801fefdebe",
      "name": "'Label Encoding'",
      "categoryId": "f14cce6a-073b-45c1-b7fe-9e7538a2a4d2"
    },
    {
      "id": "623945e5-9edb-4f55-b6bf-3e01fbc38fc7",
      "name": "'Ordinal Encoding'",
      "categoryId": "f14cce6a-073b-45c1-b7fe-9e7538a2a4d2"
    },
    {
      "id": "0b24dbf9-f422-4bf6-83f2-c47d35a6b4a0",
      "name": "'Binary Encoding'",
      "categoryId": "f14cce6a-073b-45c1-b7fe-9e7538a2a4d2"
    },
    {
      "id": "a63179e7-8d3d-49f4-b62e-ce3c85172177",
      "name": "'Feature Hashing'",
      "categoryId": "f14cce6a-073b-45c1-b7fe-9e7538a2a4d2"
    },
    {
      "id": "15f50c05-15b9-489f-b484-14e8eb90e4f5",
      "name": "and 'Embedding'. These methods help machine learning algorithms interpret non-numeric data and capture the underlying relationships within categorical variables.",
      "categoryId": "f14cce6a-073b-45c1-b7fe-9e7538a2a4d2"
    },
    {
      "id": "f26c6243-5815-4f4e-83c2-097dc7681de9",
      "name": "Natural Language Processing",
      "categoryId": "a7f77665-b31f-4cf7-b129-008639037452"
    },
    {
      "id": "aaab80a2-cc1f-4e8c-b022-a2932b7a1f68",
      "name": "Dialogue Management",
      "categoryId": "a7f77665-b31f-4cf7-b129-008639037452"
    },
    {
      "id": "4b9973ff-b9ba-4665-96c0-fa06b72c9141",
      "name": "Speech Recognition",
      "categoryId": "a7f77665-b31f-4cf7-b129-008639037452"
    },
    {
      "id": "a68af72d-d19e-44ec-981e-143b8b7a3a31",
      "name": "Language Understanding",
      "categoryId": "a7f77665-b31f-4cf7-b129-008639037452"
    },
    {
      "id": "e799d799-21aa-4dc2-9b2b-269521016211",
      "name": "Sequence-to-Sequence Models",
      "categoryId": "a7f77665-b31f-4cf7-b129-008639037452"
    },
    {
      "id": "86d834d7-8223-451b-a6c3-ec9d101f8ee2",
      "name": "Reinforcement Learning",
      "categoryId": "a7f77665-b31f-4cf7-b129-008639037452"
    },
    {
      "id": "7070bc34-0c5b-40e7-8693-6777922ef12b",
      "name": "Deep Learning",
      "categoryId": "a7f77665-b31f-4cf7-b129-008639037452"
    },
    {
      "id": "3d5a0e4d-7c2f-4537-8e65-3a4142455a56",
      "name": "Conversational AI",
      "categoryId": "a7f77665-b31f-4cf7-b129-008639037452"
    },
    {
      "id": "013773e9-a181-4cc2-81cc-2bb221923492",
      "name": "Context-Aware Systems",
      "categoryId": "a7f77665-b31f-4cf7-b129-008639037452"
    },
    {
      "id": "34c9f827-db91-4c5c-9d8f-b1ce3c8eac9d",
      "name": "Transformer Models",
      "categoryId": "a7f77665-b31f-4cf7-b129-008639037452"
    },
    {
      "id": "89668d7b-c6ea-45bf-84af-7172196e5126",
      "name": "Model Distillation",
      "categoryId": "348a13c1-41bd-4413-8ce0-a4ad78c0358e"
    },
    {
      "id": "25f645bf-3041-4d4b-837c-6ab1f7aa1247",
      "name": "Energy-Based Models",
      "categoryId": "348a13c1-41bd-4413-8ce0-a4ad78c0358e"
    },
    {
      "id": "6abdc6d7-b16f-47e5-9d29-5d38b80ac18e",
      "name": "Energy Functions",
      "categoryId": "348a13c1-41bd-4413-8ce0-a4ad78c0358e"
    },
    {
      "id": "8304dea8-d06f-4a6d-81d9-30722ae5e475",
      "name": "Probabilistic Frameworks",
      "categoryId": "348a13c1-41bd-4413-8ce0-a4ad78c0358e"
    },
    {
      "id": "03f371dd-889f-422d-a7db-9bac3bf51288",
      "name": "Representation Learning",
      "categoryId": "348a13c1-41bd-4413-8ce0-a4ad78c0358e"
    },
    {
      "id": "e27eb7ec-5079-43b5-b652-c048e10c31f5",
      "name": "Teacher-Student Models",
      "categoryId": "348a13c1-41bd-4413-8ce0-a4ad78c0358e"
    },
    {
      "id": "daf11e75-153a-441e-900e-f27c7e02405e",
      "name": "Energy-Based Regularization",
      "categoryId": "348a13c1-41bd-4413-8ce0-a4ad78c0358e"
    },
    {
      "id": "2ffc5892-ae3f-42b9-bd73-f94ae8b1cd22",
      "name": "Energy-Based GANs (EBGANs)",
      "categoryId": "85e0dc26-c36b-4187-a352-67187084ef8c"
    },
    {
      "id": "4a91271a-f92e-4e96-9d38-bbb2ebdde845",
      "name": "Generative Adversarial Networks",
      "categoryId": "85e0dc26-c36b-4187-a352-67187084ef8c"
    },
    {
      "id": "24910d18-2f86-4e3f-b700-e2557b98c1fa",
      "name": "Energy-Based Models",
      "categoryId": "85e0dc26-c36b-4187-a352-67187084ef8c"
    },
    {
      "id": "76ca6724-894b-44e9-bfb0-36f39a63ae0f",
      "name": "Deep Learning",
      "categoryId": "85e0dc26-c36b-4187-a352-67187084ef8c"
    },
    {
      "id": "efb1a6fc-adf7-4f9e-97a6-eee1dea9264a",
      "name": "Unsupervised Learning",
      "categoryId": "85e0dc26-c36b-4187-a352-67187084ef8c"
    },
    {
      "id": "3ec78f1c-e094-4cad-8de8-3082089242b6",
      "name": "Generative Modeling",
      "categoryId": "85e0dc26-c36b-4187-a352-67187084ef8c"
    },
    {
      "id": "93d5253d-63ec-4f6a-a4b9-a8d734a32b83",
      "name": "Neural Networks",
      "categoryId": "85e0dc26-c36b-4187-a352-67187084ef8c"
    },
    {
      "id": "f02e9194-82a4-4e61-b3d4-c4774a74d8a7",
      "name": "Contrastive Divergence",
      "categoryId": "85e0dc26-c36b-4187-a352-67187084ef8c"
    },
    {
      "id": "74a16e7c-e562-4710-b68f-92cb8086890d",
      "name": "Energy-Based Models (EBMs)",
      "categoryId": "7ffdbcb8-700c-4730-aaba-29a5fc49d37f"
    },
    {
      "id": "0ed6a6be-30f0-411b-a2bd-6f31644c1aa0",
      "name": "Probabilistic Graphical Models",
      "categoryId": "7ffdbcb8-700c-4730-aaba-29a5fc49d37f"
    },
    {
      "id": "c05c4aea-0360-4866-9d4b-1e0db874c142",
      "name": "Generative Models",
      "categoryId": "7ffdbcb8-700c-4730-aaba-29a5fc49d37f"
    },
    {
      "id": "c5516522-8813-4dbf-8f1c-3c8595553ada",
      "name": "Energy Functions",
      "categoryId": "7ffdbcb8-700c-4730-aaba-29a5fc49d37f"
    },
    {
      "id": "4c3cbc87-c948-4c10-98e5-1778def5d2b3",
      "name": "Markov Random Fields",
      "categoryId": "7ffdbcb8-700c-4730-aaba-29a5fc49d37f"
    },
    {
      "id": "4043dec8-0796-440e-88bf-e645a281e2f9",
      "name": "Restricted Boltzmann Machines",
      "categoryId": "7ffdbcb8-700c-4730-aaba-29a5fc49d37f"
    },
    {
      "id": "83a94af6-6319-41df-94e2-ce97781b516f",
      "name": "Deep Energy Models",
      "categoryId": "7ffdbcb8-700c-4730-aaba-29a5fc49d37f"
    },
    {
      "id": "366a70da-8bf7-4f3d-80c9-4c2ed31dff36",
      "name": "Variational Autoencoders",
      "categoryId": "7ffdbcb8-700c-4730-aaba-29a5fc49d37f"
    },
    {
      "id": "278410f0-5945-4a2b-b4ad-cf33c6eb729d",
      "name": "Energy-Based Deep Learning",
      "categoryId": "7ffdbcb8-700c-4730-aaba-29a5fc49d37f"
    },
    {
      "id": "97512588-b103-4f2e-b6a9-4609470135e5",
      "name": "Latent Space Models",
      "categoryId": "7ffdbcb8-700c-4730-aaba-29a5fc49d37f"
    },
    {
      "id": "ee91132d-ffff-418e-a836-e6fde9a647d4",
      "name": "Energy-Based Models (EBMs)",
      "categoryId": "c48babb1-acda-4625-9709-8bc8d7bf9bd0"
    },
    {
      "id": "c1995e9a-26a4-4b6b-9424-8d8c49060574",
      "name": "Probabilistic Models",
      "categoryId": "c48babb1-acda-4625-9709-8bc8d7bf9bd0"
    },
    {
      "id": "e4d4942c-28ee-4586-8cc4-7adc9869b81f",
      "name": "Energy Functions",
      "categoryId": "c48babb1-acda-4625-9709-8bc8d7bf9bd0"
    },
    {
      "id": "af62d2b9-d675-42a1-8ba7-20dd74705dd1",
      "name": "Energy Landscape",
      "categoryId": "c48babb1-acda-4625-9709-8bc8d7bf9bd0"
    },
    {
      "id": "a2dfa327-ec4a-4801-9194-a0985c352217",
      "name": "Generative Models",
      "categoryId": "c48babb1-acda-4625-9709-8bc8d7bf9bd0"
    },
    {
      "id": "41742abe-8b2d-4ad3-8c70-8a8f98483742",
      "name": "Neural Energy Models",
      "categoryId": "c48babb1-acda-4625-9709-8bc8d7bf9bd0"
    },
    {
      "id": "5dbd11e1-e007-40bd-bd7d-b64e423298bb",
      "name": "Deep Learning",
      "categoryId": "c48babb1-acda-4625-9709-8bc8d7bf9bd0"
    },
    {
      "id": "9911252b-7a83-406e-b367-83d08b734130",
      "name": "Representation Learning",
      "categoryId": "c48babb1-acda-4625-9709-8bc8d7bf9bd0"
    },
    {
      "id": "3df0595b-8430-4484-9ac7-7aab0ab88546",
      "name": "Contrastive Divergence",
      "categoryId": "c48babb1-acda-4625-9709-8bc8d7bf9bd0"
    },
    {
      "id": "8ba79ca6-4657-4950-9b89-6ce0a1be5421",
      "name": "Markov Random Fields",
      "categoryId": "c48babb1-acda-4625-9709-8bc8d7bf9bd0"
    },
    {
      "id": "e39c6b90-85c3-43ea-a912-72ae7ac72605",
      "name": "Energy-Based Models",
      "categoryId": "073242ce-b826-433d-a4b1-60144b3c102d"
    },
    {
      "id": "74f04ed2-f3ce-4d5e-a9c8-81ec68c0c544",
      "name": "Energy Functions",
      "categoryId": "073242ce-b826-433d-a4b1-60144b3c102d"
    },
    {
      "id": "16598f33-5b9a-45a0-a668-d4172c68ad2e",
      "name": "Deep Energy Models",
      "categoryId": "073242ce-b826-433d-a4b1-60144b3c102d"
    },
    {
      "id": "e06ecb0a-194b-41db-82d9-086144c239cd",
      "name": "Generative Models",
      "categoryId": "073242ce-b826-433d-a4b1-60144b3c102d"
    },
    {
      "id": "afd99f9d-f7b2-420d-842e-25a372550a67",
      "name": "Markov Random Fields",
      "categoryId": "073242ce-b826-433d-a4b1-60144b3c102d"
    },
    {
      "id": "c2bd6404-7d98-4930-a29c-5ca6602a3544",
      "name": "Energy-Based Deep Learning",
      "categoryId": "073242ce-b826-433d-a4b1-60144b3c102d"
    },
    {
      "id": "58d3d088-2794-40b0-ab1c-c9a37537b794",
      "name": "Contrastive Divergence",
      "categoryId": "073242ce-b826-433d-a4b1-60144b3c102d"
    },
    {
      "id": "741aa725-0359-461f-be29-73d4ceccd60e",
      "name": "Variational Energy Models",
      "categoryId": "073242ce-b826-433d-a4b1-60144b3c102d"
    },
    {
      "id": "122c199a-5a13-4aae-83a2-9297791b9ed6",
      "name": "Reinforcement Learning",
      "categoryId": "4ada477a-e788-4c6d-80e5-d6ec17091d8f"
    },
    {
      "id": "63a150dd-e220-46b1-9df1-150ec75628eb",
      "name": "Energy-Based Models",
      "categoryId": "4ada477a-e788-4c6d-80e5-d6ec17091d8f"
    },
    {
      "id": "5e7df18a-a501-417d-b4e4-21062921a814",
      "name": "Unsupervised Learning",
      "categoryId": "4ada477a-e788-4c6d-80e5-d6ec17091d8f"
    },
    {
      "id": "dc949e6d-4ab5-4250-b5f8-edee67b1b77a",
      "name": "Deep Learning",
      "categoryId": "4ada477a-e788-4c6d-80e5-d6ec17091d8f"
    },
    {
      "id": "96bb374a-90f5-402b-a96c-7c46ce7a153a",
      "name": "Representation Learning",
      "categoryId": "4ada477a-e788-4c6d-80e5-d6ec17091d8f"
    },
    {
      "id": "051cd1f7-5990-450e-9271-620f7c33388a",
      "name": "Probabilistic Modeling",
      "categoryId": "4ada477a-e788-4c6d-80e5-d6ec17091d8f"
    },
    {
      "id": "d9d79c50-53e9-47fb-a3d2-4d6bbcf4cf91",
      "name": "Variational Methods",
      "categoryId": "4ada477a-e788-4c6d-80e5-d6ec17091d8f"
    },
    {
      "id": "8c3fb1d1-b819-494a-8b90-6e9a1c845132",
      "name": "Ensemble Averaging",
      "categoryId": "f0152ff9-bc55-45ab-a823-876d73f66be1"
    },
    {
      "id": "afd00e68-40e8-4d28-a955-3f1294a1fb25",
      "name": "Ensemble Methods",
      "categoryId": "f0152ff9-bc55-45ab-a823-876d73f66be1"
    },
    {
      "id": "f346a992-32b6-4e46-948d-0e1ad96e45cd",
      "name": "Aggregation Techniques",
      "categoryId": "f0152ff9-bc55-45ab-a823-876d73f66be1"
    },
    {
      "id": "04a6b3d8-395b-4606-ad0d-11b234ee6219",
      "name": "Voting",
      "categoryId": "f0152ff9-bc55-45ab-a823-876d73f66be1"
    },
    {
      "id": "73cc6634-6fd8-4fee-bfdd-6d94897cc7d7",
      "name": "Bagging",
      "categoryId": "f0152ff9-bc55-45ab-a823-876d73f66be1"
    },
    {
      "id": "0950964c-0dee-4558-8ec2-fa14a1f625f6",
      "name": "Boosting",
      "categoryId": "f0152ff9-bc55-45ab-a823-876d73f66be1"
    },
    {
      "id": "ef189b0c-80a6-4884-99a1-506258fa2a01",
      "name": "Random Forests",
      "categoryId": "f0152ff9-bc55-45ab-a823-876d73f66be1"
    },
    {
      "id": "316495af-7845-489b-8408-ebd3aea984d9",
      "name": "Model Averaging",
      "categoryId": "f0152ff9-bc55-45ab-a823-876d73f66be1"
    },
    {
      "id": "36f8d332-1a0d-4757-b717-7206b4f7cc4c",
      "name": "Prediction Aggregation",
      "categoryId": "f0152ff9-bc55-45ab-a823-876d73f66be1"
    },
    {
      "id": "77112380-13ae-4a14-b64b-46935ef66ed4",
      "name": "Ensemble Learning Techniques",
      "categoryId": "f0152ff9-bc55-45ab-a823-876d73f66be1"
    },
    {
      "id": "fb40d526-152d-4c70-b43b-b184291f84ab",
      "name": "Ensemble distillation",
      "categoryId": "36912372-b061-4b9d-8426-7654ac27ae37"
    },
    {
      "id": "54ee4a58-fa86-4686-9ff3-ae654ad721ba",
      "name": "model compression",
      "categoryId": "36912372-b061-4b9d-8426-7654ac27ae37"
    },
    {
      "id": "47dbc55c-c28f-4f6a-bef1-694006e56fbb",
      "name": "knowledge distillation",
      "categoryId": "36912372-b061-4b9d-8426-7654ac27ae37"
    },
    {
      "id": "4c1c3923-d113-4103-8612-d6e188d55e32",
      "name": "neural network compression",
      "categoryId": "36912372-b061-4b9d-8426-7654ac27ae37"
    },
    {
      "id": "99577fc2-8d1e-40fb-9330-3a1e954f171c",
      "name": "ensemble learning",
      "categoryId": "36912372-b061-4b9d-8426-7654ac27ae37"
    },
    {
      "id": "ab5bfb9a-1859-458e-a573-43686564d2af",
      "name": "model optimization",
      "categoryId": "36912372-b061-4b9d-8426-7654ac27ae37"
    },
    {
      "id": "2722e7e9-f578-45d3-9fa2-42744e62638d",
      "name": "AI model efficiency",
      "categoryId": "36912372-b061-4b9d-8426-7654ac27ae37"
    },
    {
      "id": "509d4bbe-40e3-44c6-b733-0e70b775c378",
      "name": "student-teacher models",
      "categoryId": "36912372-b061-4b9d-8426-7654ac27ae37"
    },
    {
      "id": "18452f6e-12a7-42e5-b950-a19cb4732df3",
      "name": "model simplification",
      "categoryId": "36912372-b061-4b9d-8426-7654ac27ae37"
    },
    {
      "id": "c65e8e15-872b-4f84-8767-5c17ca6c5c28",
      "name": "distillation techniques",
      "categoryId": "36912372-b061-4b9d-8426-7654ac27ae37"
    },
    {
      "id": "1088087c-7c6d-4dd5-b8f3-26f2290e23d8",
      "name": "Ensemble Diversity",
      "categoryId": "e1ae4119-a579-4651-a75a-35ee0178ffd5"
    },
    {
      "id": "3609ab40-a53f-4507-93d7-84e0503a7340",
      "name": "Model Diversity",
      "categoryId": "e1ae4119-a579-4651-a75a-35ee0178ffd5"
    },
    {
      "id": "a7af6de4-4ea1-47f3-bcd3-fd85e33515b9",
      "name": "Ensemble Learning",
      "categoryId": "e1ae4119-a579-4651-a75a-35ee0178ffd5"
    },
    {
      "id": "66365281-2c25-4fac-9389-451066e31c07",
      "name": "Bagging",
      "categoryId": "e1ae4119-a579-4651-a75a-35ee0178ffd5"
    },
    {
      "id": "26747c2c-719b-4f80-b3fb-e59efab19851",
      "name": "Boosting",
      "categoryId": "e1ae4119-a579-4651-a75a-35ee0178ffd5"
    },
    {
      "id": "8f619c02-2910-483e-b530-5567b9803167",
      "name": "Random Forest",
      "categoryId": "e1ae4119-a579-4651-a75a-35ee0178ffd5"
    },
    {
      "id": "98b7628e-733c-407d-9d6e-a3b79baf79a0",
      "name": "AdaBoost",
      "categoryId": "e1ae4119-a579-4651-a75a-35ee0178ffd5"
    },
    {
      "id": "74f26e55-c192-421b-a0be-126a18841c64",
      "name": "Stacking",
      "categoryId": "e1ae4119-a579-4651-a75a-35ee0178ffd5"
    },
    {
      "id": "bc1b5d2a-4514-4656-8be8-42412316251a",
      "name": "Voting",
      "categoryId": "e1ae4119-a579-4651-a75a-35ee0178ffd5"
    },
    {
      "id": "aae86531-d8e1-4539-a270-944ba03e2b00",
      "name": "Weak Learners",
      "categoryId": "e1ae4119-a579-4651-a75a-35ee0178ffd5"
    },
    {
      "id": "affe7014-5dc1-4caf-bb92-d8b2dfff1f81",
      "name": "Variance Reduction",
      "categoryId": "e1ae4119-a579-4651-a75a-35ee0178ffd5"
    },
    {
      "id": "edd78864-aaad-40d3-b4f5-7308c7293081",
      "name": "Bias-Variance Tradeoff",
      "categoryId": "e1ae4119-a579-4651-a75a-35ee0178ffd5"
    },
    {
      "id": "0ff7bcf5-7a0f-4fdc-bafc-328c6a3b3cd3",
      "name": "Ensemble Diversity Techniques",
      "categoryId": "1cdf390f-d4d8-498d-8fb8-9d22d378fec4"
    },
    {
      "id": "a9cd3916-74da-43fc-b286-7f531a235ac7",
      "name": "Bagging",
      "categoryId": "1cdf390f-d4d8-498d-8fb8-9d22d378fec4"
    },
    {
      "id": "ed87ac22-cd78-40c6-aa56-559af724050b",
      "name": "Boosting",
      "categoryId": "1cdf390f-d4d8-498d-8fb8-9d22d378fec4"
    },
    {
      "id": "3458feb1-335c-4ea3-b183-9038ce92d7bd",
      "name": "Stacking",
      "categoryId": "1cdf390f-d4d8-498d-8fb8-9d22d378fec4"
    },
    {
      "id": "aefa32ec-6d81-45f8-8c2e-fc6db9fb9617",
      "name": "Random Forests",
      "categoryId": "1cdf390f-d4d8-498d-8fb8-9d22d378fec4"
    },
    {
      "id": "0ef472e7-0e8f-40f4-a52d-404a3d7327db",
      "name": "Gradient Boosting",
      "categoryId": "1cdf390f-d4d8-498d-8fb8-9d22d378fec4"
    },
    {
      "id": "01394948-db81-4980-9a22-b8eb7547aa9c",
      "name": "Model Variance",
      "categoryId": "1cdf390f-d4d8-498d-8fb8-9d22d378fec4"
    },
    {
      "id": "b7873e2d-2a24-4285-a265-3d08be88feea",
      "name": "Model Correlation",
      "categoryId": "1cdf390f-d4d8-498d-8fb8-9d22d378fec4"
    },
    {
      "id": "c443cb1b-b0e2-4a55-b231-8a3cd59517a8",
      "name": "Base Learners",
      "categoryId": "1cdf390f-d4d8-498d-8fb8-9d22d378fec4"
    },
    {
      "id": "fed98d24-5a39-42d7-a736-accca5548a00",
      "name": "Ensemble Methods",
      "categoryId": "1cdf390f-d4d8-498d-8fb8-9d22d378fec4"
    },
    {
      "id": "478e7efd-328b-4ad8-bf8d-5e56add18d92",
      "name": "Model Diversity",
      "categoryId": "1cdf390f-d4d8-498d-8fb8-9d22d378fec4"
    },
    {
      "id": "f1ab8f46-c829-4020-b583-4120e7e8b063",
      "name": "Ensemble Stability",
      "categoryId": "1cdf390f-d4d8-498d-8fb8-9d22d378fec4"
    },
    {
      "id": "50cb9faf-29ab-4859-95a3-b66693183d16",
      "name": "Ensemble Diversity Techniques Extensions",
      "categoryId": "c95a51f5-d135-4cab-b941-31ed73daf6e6"
    },
    {
      "id": "fd5c37a7-b224-470e-b509-4127d1b01c39",
      "name": "Ensemble Methods",
      "categoryId": "c95a51f5-d135-4cab-b941-31ed73daf6e6"
    },
    {
      "id": "47e358fc-6e36-4c20-8227-44e8a7990458",
      "name": "Diversity Strategies",
      "categoryId": "c95a51f5-d135-4cab-b941-31ed73daf6e6"
    },
    {
      "id": "5958c35f-8ceb-4838-a69a-5861bc46bd5a",
      "name": "Bagging",
      "categoryId": "c95a51f5-d135-4cab-b941-31ed73daf6e6"
    },
    {
      "id": "5f4004a0-010b-4222-8f78-63e18a8d855d",
      "name": "Boosting",
      "categoryId": "c95a51f5-d135-4cab-b941-31ed73daf6e6"
    },
    {
      "id": "bdf48c9a-20f0-4294-a9bf-36394d3657ab",
      "name": "Random Forest",
      "categoryId": "c95a51f5-d135-4cab-b941-31ed73daf6e6"
    },
    {
      "id": "1d63cb00-12c0-4d54-900b-cff93a93578a",
      "name": "Stacking",
      "categoryId": "c95a51f5-d135-4cab-b941-31ed73daf6e6"
    },
    {
      "id": "3e89f1c3-bb92-4855-901f-0b3867c6f678",
      "name": "Model Diversity",
      "categoryId": "c95a51f5-d135-4cab-b941-31ed73daf6e6"
    },
    {
      "id": "23668e3a-0cc7-4ae5-bcfa-8e9a1e4f6c96",
      "name": "Error Correlation",
      "categoryId": "c95a51f5-d135-4cab-b941-31ed73daf6e6"
    },
    {
      "id": "be1406af-9293-47e6-8482-5abf16bedc3d",
      "name": "Ensemble Pruning",
      "categoryId": "c95a51f5-d135-4cab-b941-31ed73daf6e6"
    },
    {
      "id": "7c235db4-a9ec-4822-8acd-77be71d414a9",
      "name": "Dynamic Ensembles",
      "categoryId": "c95a51f5-d135-4cab-b941-31ed73daf6e6"
    },
    {
      "id": "550e655b-27c8-490b-b00f-07315aca437a",
      "name": "Diversity Metrics",
      "categoryId": "c95a51f5-d135-4cab-b941-31ed73daf6e6"
    },
    {
      "id": "c2bfb4cc-3a23-4c43-927c-6d07f17ad54e",
      "name": "Variance Reduction",
      "categoryId": "c95a51f5-d135-4cab-b941-31ed73daf6e6"
    },
    {
      "id": "6245cc63-6b95-44ad-9536-0fdcaa376f79",
      "name": "Error Decomposition",
      "categoryId": "c95a51f5-d135-4cab-b941-31ed73daf6e6"
    },
    {
      "id": "8a256791-dde4-452f-bcc2-07828b865c2e",
      "name": "Gradient Boosting",
      "categoryId": "eac19e39-8d2a-42bd-b373-3e273a6ffca1"
    },
    {
      "id": "5e324462-71c6-4b5e-a786-bef793924399",
      "name": "Ensemble Learning",
      "categoryId": "eac19e39-8d2a-42bd-b373-3e273a6ffca1"
    },
    {
      "id": "fd31db18-0a5b-4e05-986d-f88196079f87",
      "name": "Supervised Learning",
      "categoryId": "eac19e39-8d2a-42bd-b373-3e273a6ffca1"
    },
    {
      "id": "05f808c8-e6ce-4f8f-9c36-a95e2da7de2a",
      "name": "Decision Trees",
      "categoryId": "eac19e39-8d2a-42bd-b373-3e273a6ffca1"
    },
    {
      "id": "10ef95e7-686f-481a-97f2-9c6261db95b5",
      "name": "Boosting Algorithms",
      "categoryId": "eac19e39-8d2a-42bd-b373-3e273a6ffca1"
    },
    {
      "id": "6258d52c-ae0e-4e59-a729-49015aea6e81",
      "name": "Fisher Information",
      "categoryId": "f8ae95b2-95e4-4eab-ae95-6d5cfb679aaa"
    },
    {
      "id": "87d50543-ddcd-4ca5-a252-aa014635f0d3",
      "name": "Statistical Estimation",
      "categoryId": "f8ae95b2-95e4-4eab-ae95-6d5cfb679aaa"
    },
    {
      "id": "ef7c2cf0-0f0d-4c53-8d4b-722e4d73b042",
      "name": "Information Theory",
      "categoryId": "f8ae95b2-95e4-4eab-ae95-6d5cfb679aaa"
    },
    {
      "id": "421b5e84-b554-46b5-b8d9-decf25f6f247",
      "name": "Parameter Estimation",
      "categoryId": "f8ae95b2-95e4-4eab-ae95-6d5cfb679aaa"
    },
    {
      "id": "a91202d1-486f-448f-8fc1-7cf3f27dc7c3",
      "name": "Variance Bound",
      "categoryId": "f8ae95b2-95e4-4eab-ae95-6d5cfb679aaa"
    },
    {
      "id": "c9750481-ee88-4edc-a9b0-51a829d51420",
      "name": "Fisher Matrix",
      "categoryId": "f8ae95b2-95e4-4eab-ae95-6d5cfb679aaa"
    },
    {
      "id": "132e7388-603b-4f43-9955-131312fd5219",
      "name": "Information Content",
      "categoryId": "f8ae95b2-95e4-4eab-ae95-6d5cfb679aaa"
    },
    {
      "id": "fca23da8-1b28-4960-8ac5-1ca51e48b4c0",
      "name": "Estimator Efficiency",
      "categoryId": "f8ae95b2-95e4-4eab-ae95-6d5cfb679aaa"
    },
    {
      "id": "675a9e63-9e7d-427d-9c91-18639c775ff3",
      "name": "Optical Fisher Information",
      "categoryId": "f8ae95b2-95e4-4eab-ae95-6d5cfb679aaa"
    },
    {
      "id": "fec24241-1cf1-436f-8ace-7f4982ce0795",
      "name": "Data Sensitivity",
      "categoryId": "f8ae95b2-95e4-4eab-ae95-6d5cfb679aaa"
    },
    {
      "id": "6564937e-9f53-4ec5-9b0d-e82bd45a5831",
      "name": "Statistical Estimation",
      "categoryId": "4ede7644-9540-41a6-b14d-731552eef08a"
    },
    {
      "id": "d4d87c07-a726-4c49-ba40-9bf07075987f",
      "name": "Information Theory",
      "categoryId": "4ede7644-9540-41a6-b14d-731552eef08a"
    },
    {
      "id": "7d602303-93c7-48fa-a4f2-e37886d50c51",
      "name": "Parameter Estimation",
      "categoryId": "4ede7644-9540-41a6-b14d-731552eef08a"
    },
    {
      "id": "196068bd-8b8c-481a-b51e-f3f43f087fdd",
      "name": "Fisher Information",
      "categoryId": "4ede7644-9540-41a6-b14d-731552eef08a"
    },
    {
      "id": "08493c80-7a11-4dd1-8fe8-d28497e936e7",
      "name": "Covariance Matrices",
      "categoryId": "4ede7644-9540-41a6-b14d-731552eef08a"
    },
    {
      "id": "11b33a4b-c137-421c-92ef-6487beb7de47",
      "name": "Variance Bound",
      "categoryId": "4ede7644-9540-41a6-b14d-731552eef08a"
    },
    {
      "id": "ad063f80-45a2-446c-90e2-06f40fd02638",
      "name": "Asymptotic Theory",
      "categoryId": "4ede7644-9540-41a6-b14d-731552eef08a"
    },
    {
      "id": "1850ea8b-bb33-4276-b4b2-d7ed194e458c",
      "name": "Maximum Likelihood Estimation",
      "categoryId": "4ede7644-9540-41a6-b14d-731552eef08a"
    },
    {
      "id": "506530c7-1da9-4595-b95a-d60cfc2fe42d",
      "name": "Regularity Conditions",
      "categoryId": "4ede7644-9540-41a6-b14d-731552eef08a"
    },
    {
      "id": "0602b104-ba5d-4762-a504-12200bd2ac6b",
      "name": "Sensitivity Analysis",
      "categoryId": "4ede7644-9540-41a6-b14d-731552eef08a"
    }
  ],
  "terms": [
    {
      "id": "54251a86-b4d9-4ed7-899c-2863c8532111",
      "name": "Characteristic Function",
      "definition": "A characteristic function is a fundamental concept in probability theory and statistics that uniquely characterizes the probability distribution of a random variable. Formally, it is defined as the expected value of e^{itX}, where X is a random variable, t is a real number, and i is the imaginary unit. The characteristic function encapsulates all the information about the distribution of X and serves as a powerful tool for analyzing probability distributions, deriving properties, and proving limit theorems.",
      "categoryId": "680d3998-490a-41df-b5dc-447682d109cc",
      "subcategoryIds": [
        "f3f4805f-45d9-4a05-abda-f23bd47a548b",
        "05b48352-052c-4f33-b5a7-2599407e5aba",
        "e2ff16fe-684c-4e42-aed3-d642a5641fbe",
        "2b72d889-5a52-4624-aecc-c5be761ad177",
        "4ed7fe6f-56f5-4e48-a322-2819274d7d37",
        "0bcd1ec9-5696-4060-982e-a4a7b51d2a17",
        "88f33cb1-c54a-44c5-bdb4-2cbb3cf039ea",
        "663524e2-917d-405b-8690-940b2f875e7b",
        "228cab07-c497-46c3-a773-02fb182fdf44"
      ]
    },
    {
      "id": "de4c482f-97e2-41af-9cf8-207bf57e3a62",
      "name": "Chebyshev Distance",
      "definition": "Chebyshev Distance, also known as L-infinity norm or maximum metric, is a measure of distance between two points in a multidimensional space. It calculates the greatest difference across any single coordinate dimension between the two points, effectively capturing the maximum deviation. Mathematically, for two points p and q in n-dimensional space, Chebyshev distance is defined as the maximum absolute difference among their corresponding components: D(p, q) = max(|p_i - q_i|) for i in 1 to n.",
      "categoryId": "665ee489-ab09-419e-99e6-01965647cabf",
      "subcategoryIds": [
        "82627264-1f75-4b81-abe7-1d1f49d920c6",
        "9cec66eb-d183-4c77-a7b4-bee72e26084a",
        "9cf09219-dc13-41ad-98f7-6fa43a3fc704",
        "bac7c0c4-de0b-487f-8d2c-b6b8f9914981",
        "7353ec13-380c-440d-a625-eda8aeeb9626",
        "b0adb3e3-9099-429b-abc6-9d81930c5281",
        "7eaa3378-bcd6-4696-b79d-27fe631a55ca",
        "c4d256b8-5798-4615-ae71-77e32e6a302b"
      ]
    },
    {
      "id": "09b7e522-869d-4006-8c4d-5d814dcf7c35",
      "name": "Chebyshev Networks",
      "definition": "Chebyshev Networks are a class of neural network architectures that utilize Chebyshev polynomials as activation functions or basis functions. These networks leverage properties of Chebyshev polynomials to approximate complex functions efficiently, offering advantages in spectral approximation, stability, and convergence. They are often employed in scenarios requiring high-precision function approximation and can be adapted for various regression and classification tasks within the field of machine learning.",
      "categoryId": "1e59096b-cfbb-4eb3-a096-5e2f576eaefb",
      "subcategoryIds": [
        "241ab512-d0c1-4d66-afaa-7b290c607d0c",
        "b04452b7-3caa-4186-bc2b-f10001d25391",
        "1fd2f6ec-cc31-4ef9-b3c8-d05f11a30f91",
        "cbaf55df-97ae-41ea-b69c-bfd9d38c791f",
        "ae44e23e-fb1f-4311-a752-0075506d0d76",
        "a8fd51bc-0220-45cb-a21d-b65d9a13cb86",
        "c5791478-d526-4c85-a42c-d9e11b2057ea",
        "00d7f937-f833-4cc5-9f3a-b368c49803cd",
        "0c3e5b8b-feac-43d1-9031-280e0f8c46ec"
      ]
    },
    {
      "id": "2466154d-53d7-4760-b245-bb001b440748",
      "name": "Chebyshev Polynomial Networks",
      "definition": "Chebyshev Polynomial Networks are a class of neural network architectures that leverage Chebyshev polynomials to perform function approximation and spectral filtering within the network. They are designed to efficiently approximate complex functions by exploiting the mathematical properties of Chebyshev polynomials, which are a sequence of orthogonal polynomials with remarkable approximation capabilities. These networks incorporate polynomial expansions directly into their architecture, allowing for effective modeling of non-linear relationships while maintaining computational efficiency and stability.",
      "categoryId": "a2b559f3-f074-42dc-b4a8-ef046c026fee",
      "subcategoryIds": [
        "b0546e62-7232-4156-8021-e3854a6e21f9",
        "890ab428-ce60-4dd5-a63b-678770fbb5fb",
        "e61f7a1e-d871-42b7-8805-dbd10eb14a3b",
        "71d2dd9d-1e90-4e22-a67e-2011d40214bd",
        "ee423599-ba5d-4bcf-8dde-6f376f19dc8b",
        "68253480-5383-403d-978d-da9b853d4041",
        "815ccd95-c54e-4bc0-936e-ae758934973f",
        "f573806d-0dc1-4a1a-aa54-2d4871e72e40",
        "ab2b39f9-6e8e-4cfd-813e-49ddcedc13a5",
        "bb491161-91ab-4b0d-87c4-cb12e09bf05a"
      ]
    },
    {
      "id": "110d5fbb-4ae7-4105-91af-6f916ef9adce",
      "name": "Chebyshev Polynomials in Neural Networks",
      "definition": "Chebyshev polynomials are a sequence of orthogonal polynomials that arise in approximation theory and numerical analysis. In the context of neural networks, Chebyshev polynomials are used as activation functions or as basis functions within neural network architectures to improve approximation capabilities, enhance numerical stability, and facilitate spectral methods. Their properties allow neural networks to approximate complex functions efficiently by leveraging the polynomials' recurrence relations and orthogonality properties.",
      "categoryId": "ac53191f-1511-40c9-a288-3134a8a9a240",
      "subcategoryIds": [
        "9bc4f248-e691-4537-aa0c-a75addaf8d07",
        "b910ee8a-64ab-463c-993f-3d2ebc2934d7",
        "486b256f-2329-4de7-b479-769e7aa78196",
        "566ab6f9-de4a-40df-8d16-d4698dfdaf16",
        "9b6e3f63-8658-435c-8e05-a4979c2b45bc"
      ]
    },
    {
      "id": "5e44037b-afad-4558-9331-b99c01167b56",
      "name": "Check-pointing in Training",
      "definition": "Check-pointing in training refers to the process of saving the current state of a machine learning model during the training process. This typically involves storing the model's parameters, optimizer states, and other relevant information at specific intervals or after significant events. These saved states, known as checkpoints, can be used to resume training from that point in case of interruptions, or for later evaluation and model deployment. Check-pointing is an essential technique to prevent loss of progress, enable experimentation with different training strategies, and facilitate model versioning.",
      "categoryId": "5a62c975-6105-4a66-b090-20bc1c9a0ee7",
      "subcategoryIds": [
        "11616930-a53a-4245-9cf8-54ecc86ac209",
        "ac66c4cb-6739-4187-bd5b-f8828922e0f6",
        "c1e0fc98-291c-4ced-b05a-3e5bba4ef70c",
        "71b90170-aa6c-49f1-9ccd-c5dec52fdf80",
        "0e07188b-b036-4d19-bbb6-c29d335c8463",
        "0a6c4802-75b8-4588-8b22-2c1a94792a51",
        "f6a30827-457c-4980-bf66-f8f674ac997a",
        "5357579b-8186-40d8-81e4-2b30ef788f21",
        "c5a8918c-3842-42cf-ac60-9151ed723c8b",
        "c2781fd2-f691-4197-a442-cf3ec12668f5"
      ]
    },
    {
      "id": "a3eaeb95-ef6f-4437-9205-c0b2f056cc0e",
      "name": "Checkerboard Artifacts",
      "definition": "Checkerboard artifacts are visual distortions observed in images generated or processed by certain AI and machine learning models, especially in the context of image synthesis, super-resolution, and generative adversarial networks (GANs). These artifacts manifest as a regular grid-like pattern resembling a checkerboard, often leading to undesirable visual irregularities such as blockiness, uneven textures, or unnatural repetitive patterns that detract from the realism and quality of the generated images.",
      "categoryId": "83d6a18e-b5fa-484b-a283-2fe2a04a7f55",
      "subcategoryIds": [
        "da9668c1-5c83-485e-a7f4-2cd58a9ad465"
      ]
    },
    {
      "id": "fdecae97-866d-4943-8dc4-a4ab8e338221",
      "name": "checkpoint averaging",
      "definition": "Checkpoint averaging is a technique used during the training of machine learning models, particularly neural networks, where multiple model checkpoints (saved states at different training iterations) are combined, typically by averaging their parameters. This process helps produce a more generalized and stable model by smoothing out fluctuations that occur during the stochastic optimization process. Instead of relying solely on the final checkpoint, checkpoint averaging leverages the collective information from several intermediate models to improve performance and robustness.",
      "categoryId": "9ffda2e3-be3d-4a9f-be94-b35157408227",
      "subcategoryIds": [
        "30dd504f-4e5d-4bcf-a617-d7605d78bb0b",
        "ddad5cb8-24c4-465d-b0eb-491fc07fde4a",
        "ca5d2121-d60a-45b2-80e6-d845525b1d5c",
        "820c0d0b-4a55-4877-9b3f-d39e57edfb60",
        "27192d30-a304-4c06-9389-ea47948c11f8"
      ]
    },
    {
      "id": "1139fa67-762f-493a-8d96-37199e05d072",
      "name": "Checkpoints",
      "definition": "In the context of AI and machine learning, 'checkpoints' refer to saved states of a model during training, allowing practitioners to pause and resume training, evaluate model performance at different stages, or recover from interruptions. These snapshots capture the model's learned parameters such as weights and biases, enabling continuity and efficient experimentation.",
      "categoryId": "340460e6-76f8-4e83-91f8-7dd3be9160c7",
      "subcategoryIds": [
        "0bb1eb04-da9a-409d-a4c8-778aff810d0f",
        "055e4cbd-a666-47e0-9665-116b991b6dbf",
        "828f9a24-079f-4010-957a-5f7f1df964a3",
        "2c829f08-5abb-4fff-bcd0-b9f9f8711db8",
        "81c79501-3467-40bd-8669-f52c9093136d",
        "9c54eb41-fbb8-415d-a3ba-e6e1780dfdd3",
        "d7ad43df-259b-44f9-853a-75987d381792",
        "e0eef9f9-517f-4d3f-ad78-66ce3a6d291d",
        "f88b0a6d-c4a9-4919-b7ac-f0b09eccb312",
        "8111a27d-df99-4621-9286-9b2ca5b4aac4"
      ]
    },
    {
      "id": "3d3731c2-433b-46c4-bda6-b50d6bb23787",
      "name": "Cheminformatics",
      "definition": "Cheminformatics, also known as chemoinformatics, is an interdisciplinary field that combines principles of chemistry, computer science, and information technology to store, analyze, model, and visualize chemical data. It involves the application of computational techniques to solve chemical problems, facilitate chemical data management, and accelerate the discovery and development of new compounds, drugs, and materials.",
      "categoryId": "fb2e3e64-8f43-4894-b6dc-ad586e2fbc28",
      "subcategoryIds": [
        "30e81db6-7992-44ce-a8b6-a416cb338c44",
        "c7f06c37-8c31-4d3b-b3ec-452b551ca78e",
        "ab7ef821-5251-4eda-9f13-62b047595199",
        "0a648af2-f26d-4245-9d80-13c58aaa6cf8",
        "9d713fbe-5538-4f8d-bf69-dc1a48faede2",
        "21721683-53d3-4cdd-9ab5-ba99424c009b",
        "0cd1ac0b-70d2-4ae4-9473-b36520021027",
        "36aa0e15-6896-4a53-a130-cd5ef4f36900",
        "13eefb8a-4bb1-4aea-905e-6324375d7cf5"
      ]
    },
    {
      "id": "4d2fb10b-eb81-4c75-804b-edadbf002af3",
      "name": "Chi-Square Test",
      "definition": "The Chi-Square Test is a statistical method used to determine whether there is a significant association between two categorical variables. It assesses how well observed data fit the expected distribution under the assumption of independence. Essentially, it compares the observed frequencies in each category with the frequencies expected if there were no association, helping to identify relationships or dependencies within data sets.",
      "categoryId": "12c5346d-024e-4f8f-83d8-d03a4d9566c3",
      "subcategoryIds": [
        "441896f0-3a95-4a98-9fc2-d3e9a00600aa",
        "69bdd9dd-4ba2-4c3c-b875-1ed1cf44855f",
        "7a69ebfa-3d09-475e-b11a-b4cd7f6364c7",
        "278c15f6-f65d-4d1d-97a0-9d6481c9590e",
        "550919e8-3500-4e88-acdf-f5a0a635bba2",
        "1d04ae5c-9b19-4be4-b287-c170d60e962b",
        "04f704c2-459d-46a1-9429-3f03b3379b11",
        "bf807d1c-ee9f-4c9b-b315-cc92489a090e",
        "4ff4e49d-a9ad-48b1-9a0e-7b89d69eb669"
      ]
    },
    {
      "id": "f8c45463-ad75-49bc-9758-afc839256e3f",
      "name": "Chi-Square Tests",
      "definition": "Chi-Square Tests are statistical tools used to determine whether there is a significant association between categorical variables or to assess how well an observed distribution fits an expected distribution. These tests evaluate the independence of variables in contingency tables or the goodness-of-fit of an observed frequency distribution against a theoretical model. They are widely used in data analysis to identify relationships and to validate hypotheses involving categorical data.",
      "categoryId": "563bd0ab-7fe2-4b23-8313-af266ea1e7ce",
      "subcategoryIds": [
        "1d4702ab-bccb-48dd-9ed4-15407330c23a",
        "4819cb85-d997-4365-915b-b341f98c63a8",
        "ccd3c288-4096-4f90-8124-01522c04eb51",
        "3d879572-cdb4-4a74-a9e5-b9e19dab312f",
        "033fee81-70df-4b80-b7ab-78434ae123ec",
        "d98b3039-84c8-4ad0-a412-db3de5caf95c",
        "626e93dd-8a4b-4951-862a-1f1d280ac36f",
        "de317901-3e43-473f-a5f0-d0e0641d6a69",
        "84b40c7b-54ef-4d89-acfe-99f9fb89b4ed"
      ]
    },
    {
      "id": "5a6a7cc0-44d6-4f36-9fbe-8bbb81f52c59",
      "name": "Cholesky Decomposition",
      "definition": "Cholesky Decomposition is a numerical method used in linear algebra for decomposing a symmetric, positive-definite matrix into the product of a lower triangular matrix and its conjugate transpose. Specifically, for a given matrix A, the Cholesky decomposition finds a lower triangular matrix L such that A = LL\u1d57. This technique simplifies solving systems of linear equations, matrix inversion, and covariance matrix operations in various scientific and engineering computations.",
      "categoryId": "70e5c8ee-6ffc-44a3-a93b-0e128f76de7b",
      "subcategoryIds": [
        "fd5890d4-88e2-4cbd-bcf7-b0b0e93dc2da",
        "e7c4fa45-2bc6-4248-b89f-37eab11dc0bc",
        "a16fd655-0cc4-4ec1-9310-89e3efce7086",
        "fc21c177-496e-446a-8fd1-51875351c45e",
        "53755238-03dd-45d6-a723-5c6cb607c919",
        "fe2da627-9a5a-4e84-9cbb-4055cd65ea49"
      ]
    },
    {
      "id": "a1a56f1f-22fb-402b-bb58-b298ca42809a",
      "name": "Cholesky Decomposition in Optimization",
      "definition": "Cholesky Decomposition is a numerical method used to factorize a symmetric, positive-definite matrix into the product of a lower triangular matrix and its transpose. In the context of optimization, it is often employed to efficiently solve systems of linear equations, perform matrix inversions, and compute covariance matrices, thereby facilitating many algorithms in machine learning and statistical modeling.",
      "categoryId": "5c03d1f2-97fc-4206-bb4f-9e2f15b68d52",
      "subcategoryIds": [
        "e928f515-326a-405e-9c5c-2a89a0abeff4",
        "7bd18d6e-0b99-4f1c-9109-13b8b154c259",
        "2ea01666-59bd-4802-9971-d387dc7eca0c",
        "ea0b3e43-5d60-4205-8a02-ae5bcdc9d51f",
        "62e7ba5c-9f5c-41a3-89fb-ffb818b97d14",
        "bc9e7c13-5934-497f-9c12-60d5d56eece1",
        "30ddc8e0-ba38-4b64-bd82-4f813df02db6",
        "3c9433a2-6e32-4e4d-b6e5-399b1ca88c1c",
        "b1b2cdab-1fe5-4f92-8a6d-1ba80c7436a5"
      ]
    },
    {
      "id": "aaf1f67e-e1a7-4538-bc6b-e20597800ac1",
      "name": "Chromatic Aberration Correction",
      "definition": "Chromatic Aberration Correction refers to the process of identifying and mitigating color fringing and blurring artifacts in digital images and optical systems caused by the dispersion of light through lenses. This correction aims to enhance image clarity, color fidelity, and overall visual quality by compensating for the chromatic aberration that occurs when different wavelengths of light focus at different points in the optical path.",
      "categoryId": "212c0bfc-492f-413d-80ef-2698ec40f6d5",
      "subcategoryIds": [
        "a49533ec-ad9b-49ef-b37a-d2e89c60976e",
        "1fce6fc8-e2c3-4121-9c40-eaca2884d48f",
        "2be0886f-44b3-4323-9889-0ed0ed1ad7f0",
        "a663f666-73e0-483c-b04e-bb1f9cdf93dd",
        "de7dc2c0-dae3-45cd-9f4d-620850b08188",
        "920678e4-db4a-4386-ae14-81ca051503a1",
        "0a0212fe-7000-4c10-916e-c52b13554dc8",
        "dc3388ff-1a4b-47d4-838b-35f7f15ba561"
      ]
    },
    {
      "id": "917dc0d8-52dc-4668-90a0-b647df9a62a6",
      "name": "Chung\u2013Lu Model",
      "definition": "The Chung\u2013Lu Model is a random graph generation model used in network science to produce networks with a specified degree distribution. It falls under the category of inhomogeneous random graphs, where the probability of an edge existing between two nodes depends on assigned weights or propensities related to each node. This model is particularly useful for modeling complex networks such as social networks, biological networks, and information networks that exhibit heterogeneous degree distributions.",
      "categoryId": "fb74b630-0c1e-4357-a666-e6ebaa5c57d8",
      "subcategoryIds": [
        "8d2a63f1-6f5e-4c6b-9c23-321ad267fdcc",
        "10b02936-8d15-4d9a-91ba-7d395ee30882",
        "f364eb18-7adb-43a2-bba1-84c9bc9b13a8",
        "f466fe73-3bdc-41e0-a1dc-f354e9d180c1",
        "53659160-f02c-4ced-b521-baf95bf0b78b",
        "4bd05fd9-46c3-4fd8-bc99-c862a5fb2888",
        "43f47fcf-5ba9-444d-a83d-1ba29f4f3a2b",
        "603f0b15-3d29-46c1-a21c-09a5c9b0e638",
        "cfea1333-f07b-4ef6-954f-ba42e7588011",
        "b05dc864-0c98-49d1-8518-334d8c01e91f"
      ]
    },
    {
      "id": "8e21e697-62b2-46de-9307-4b4c7630c55c",
      "name": "Chunking",
      "definition": "Chunking in the context of AI and machine learning refers to the process of dividing data, sequences, or information into smaller, manageable, and meaningful segments called 'chunks.' This technique is used to simplify complex data, improve learning efficiency, and enhance the interpretability of models. In neural networks, especially in natural language processing (NLP) and speech recognition, chunking often involves segmenting continuous data streams into discrete units for better processing.",
      "categoryId": "64b59a62-30fe-4723-a08d-76e47241446a",
      "subcategoryIds": [
        "518975c6-2337-41e2-86e9-c477e084233a",
        "d46b89f9-c4c7-4b0c-9fe1-b7b780e369dc",
        "9e546b58-75ff-41d7-a947-b6e3456a326e",
        "3f53bedd-b1e9-45ff-90df-bf32d735e382",
        "ac8ecbf7-31a4-4c0c-9f6f-b003182c5127",
        "ed24896c-0f0b-4933-8e66-8d739e641fdf",
        "782bbcaf-2156-44b6-a5f8-655bda5fd56d",
        "aab3e1ff-527f-41c7-a6ad-d9294c99927b",
        "540cb804-5b2d-4514-92ed-a0b05edaa893",
        "6881de0e-a3fe-4567-9496-addf2cc88705"
      ]
    },
    {
      "id": "d1b82f5d-ec25-445d-b567-ab397bcc3554",
      "name": "Chunking in NLP",
      "definition": "Chunking in NLP (Natural Language Processing) is a technique used to segment and group words or tokens in a sentence into meaningful units called 'chunks.' These chunks typically represent syntactic constituents such as noun phrases, verb phrases, or other grammatical components. The process involves dividing text into these manageable segments to facilitate further analysis, understanding, or processing tasks like parsing, information extraction, and question answering. Unlike sentence-level parsing, chunking focuses on identifying and labeling these non-overlapping segments without necessarily constructing a complete hierarchical syntactic structure.",
      "categoryId": "447d3cca-4128-4815-9d65-719cf7a5a101",
      "subcategoryIds": [
        "bb86b0be-9376-41ea-9b27-f6d089e7c4be",
        "97384207-c954-45a3-9a99-e1731ac769da",
        "8928f874-1859-4967-a936-60b5f345a268",
        "5a3f612e-95c5-4646-b881-0b8cd408d9e5",
        "40d65690-393c-4c9b-850b-48fba9705a32"
      ]
    },
    {
      "id": "77f1e0ec-8f03-4aa8-8b87-37d4003eebdb",
      "name": "CIDEr Score",
      "definition": "The CIDEr (Consensus-based Image Description Evaluation) score is an automated metric used to evaluate the quality of image captions generated by machine learning models. It measures how closely a machine-generated caption aligns with human reference captions by analyzing the consensus among multiple references based on n-gram overlap, emphasizing the relevance and descriptiveness of the language used. CIDEr is designed to address the limitations of earlier metrics such as BLEU and ROUGE, by incorporating semantic importance and human consensus, making it particularly useful in tasks like image captioning and multimodal content description.",
      "categoryId": "ba7781e2-bd34-4175-aecd-4bb74d245e2d",
      "subcategoryIds": [
        "e3a0c7c7-1920-4e96-b6fd-aa2319adf4b1",
        "bbc809fa-a193-425e-bfca-4ee2ef0294bd",
        "eaaf4a04-8769-4491-8a06-426b528a1503",
        "64c0a5e8-9fe0-4308-873b-240d267e7c07",
        "cc6ca068-6c85-48f8-bb43-9e676f8869d1",
        "06efbd67-6d2a-4099-9211-76099bf9dc4c"
      ]
    },
    {
      "id": "c01a0b4e-5cb1-4484-8b1e-28afbe7dd7df",
      "name": "CIFAR-10 Dataset",
      "definition": "The CIFAR-10 dataset is a widely used benchmark dataset in the field of machine learning and computer vision. It consists of 60,000 32x32 color images divided into 10 distinct classes, with 6,000 images per class. The dataset is split into 50,000 training images and 10,000 test images, providing a foundation for developing and evaluating image classification algorithms. CIFAR-10 is designed to challenge models with its variety and complexity of images, making it a popular choice for assessing the performance of neural networks and other image recognition methods.",
      "categoryId": "466eb4b3-2643-49c4-8454-47f94ed42f85",
      "subcategoryIds": [
        "e3807803-1d35-4b8d-bc1d-13ba230d7b74",
        "716a8a8b-0ae5-4b7b-89b5-32436303f472",
        "487208f8-8fe5-4db9-b1ce-bdb67bb1e71f",
        "cb43a3a8-8795-42c3-a3b9-5ed35b97f3c0",
        "acd47e8a-76af-414a-ad4c-4745b7234a60",
        "ed2927d4-378b-47bd-84d7-342eabe3cd9f",
        "75ec7315-1fe8-4017-9186-17fb79f1911c",
        "99f529af-97b5-4812-81c8-2627d4391599",
        "a3b6ce31-1b91-4bd3-b27a-cecacc1db69e",
        "2bd46a0c-b377-427a-8b00-60185ee27a0f"
      ]
    },
    {
      "id": "606d0630-048e-4bc8-bfbd-7178898d8892",
      "name": "CIFAR-100 Dataset",
      "definition": "The CIFAR-100 Dataset is a widely used benchmark dataset in the field of machine learning and computer vision research. It consists of 60,000 color images divided into 100 different classes, with 600 images per class. The dataset is split into 50,000 training images and 10,000 test images. Each image is of size 32x32 pixels and has a corresponding label indicating its class. The dataset is designed to facilitate the development and evaluation of image classification algorithms, providing a challenging yet manageable dataset due to its diversity and complexity.",
      "categoryId": "28162c27-8489-4760-9c1c-7ffe085efab1",
      "subcategoryIds": [
        "060ab062-3eee-4e3c-905a-f4b9b408df86",
        "7f84d92b-959b-4bb1-94ec-7650d7463531",
        "4197108f-3080-4164-b1d9-a3ee6510a95b",
        "8bf0afdf-cf13-4abd-823e-a26d6e38c826",
        "5c44a8d1-44c1-4c47-bb30-fbeeec115f8f",
        "d6497acd-88b6-4875-925a-2e3db39529cc",
        "de7a1e73-b10f-4d1f-8329-b1468236ec1d",
        "5bc65814-11e5-4d96-8163-7da8ff832561",
        "2b4b4f32-d0d9-441c-a088-0f52cae14ec3",
        "75b4ab89-2261-46f5-b479-22c82d77aead"
      ]
    },
    {
      "id": "57258bba-2e9a-4c36-a752-498006cfaf3d",
      "name": "CIL (Class Incremental Learning)",
      "definition": "Class Incremental Learning (CIL) is a subset of continual learning where a model learns to recognize new classes over time without forgetting previously learned classes. It involves sequentially updating a classifier with new class data while maintaining high accuracy on earlier classes, effectively mimicking human-like learning abilities. CIL aims to address the challenges of dynamic environments where data and class distributions evolve, enabling AI systems to adapt incrementally rather than requiring retraining from scratch.",
      "categoryId": "5909a0b9-d8e5-49a2-8bd3-f68946002ded",
      "subcategoryIds": [
        "38ed4f8f-bb96-4709-9222-121db776411b",
        "4b870da8-12aa-42d3-bf90-758c1b3b4e7f",
        "41745e3b-de89-48bd-aa4f-ad3c63ef7048",
        "e627d50a-25ce-469d-8bd6-4813512a4639",
        "bd96d134-ef3d-48d8-a0a3-c96a08baa8d0",
        "682ec6b3-a2e4-4515-8d01-e0208051747b"
      ]
    },
    {
      "id": "d50117c3-3d6c-4468-af42-0998deca40a6",
      "name": "Circuit Analysis",
      "definition": "Circuit Analysis refers to the process of systematically understanding and evaluating electrical circuits to determine the behavior of current, voltage, and power within the network. It involves applying fundamental electrical principles and mathematical techniques to analyze how circuits respond under various conditions, enabling engineers and scientists to design, troubleshoot, and optimize electronic systems and devices.",
      "categoryId": "8d439733-28d7-48c0-a53d-3e0e48c350c4",
      "subcategoryIds": [
        "1cc89f45-1ac9-4c8f-a44e-098deee58c7d",
        "2ab3ed21-0f25-4030-b1b3-c77222d8b8b4",
        "681e79f6-1b19-49db-8784-3d65d6000395",
        "a832ff92-7b02-4a89-a104-88fed55cac81",
        "2a85f7d9-b238-42cd-aa97-8856839c90d9",
        "5bed2b00-44f7-4008-937a-88d437726a3b",
        "d3840a1d-8b49-42be-8db1-c6f9a6b14c5c",
        "fa892e24-4e0e-40f5-a63c-c77e9125e1a1",
        "e0beb0f8-b5d1-48d6-81ad-99bb88056103",
        "c8aa0a38-d745-479d-92bd-47ac7b4c3290",
        "29d84352-a0d8-4c77-a02f-7597251c1a0b"
      ]
    },
    {
      "id": "21772150-6eca-4042-9242-46f6e6f15016",
      "name": "Circuit Complexity",
      "definition": "Circuit complexity is a branch of computational complexity theory that focuses on quantifying the minimum resources required to compute a boolean function or perform a computation using logical circuits. It involves analyzing the size, depth, and gate count of combinational and sequential circuits necessary to implement specific functions, providing a measure of the computational difficulty and efficiency of implementing boolean functions in hardware or logical systems.",
      "categoryId": "0c063e4e-a976-49cd-b067-8d697e37b074",
      "subcategoryIds": [
        "835aa5c3-59c4-453a-899e-276c2a5e20f1",
        "401409f9-6690-4d74-9233-1d724a085c3a",
        "73785a63-707b-4bf7-bff9-652966e2e4c1",
        "52b9c168-a04c-4663-9901-0297b0632bbc",
        "1092c4c7-5b2a-4891-a43d-141ad7adc372",
        "9beb7ca0-6601-45c6-88d5-74d2fa6e0c66",
        "543d764d-f494-4914-9452-2b67183091dc",
        "dc84b783-c036-4fbc-9c02-2948248c2ace",
        "9be0354b-f9a7-4f3a-9c8a-b6fc47fc2610",
        "7a4f582e-2adc-40e5-9e51-b21169e45131"
      ]
    },
    {
      "id": "3718223a-a1f5-4807-99a1-3fc5eacd2be9",
      "name": "Circuit-level Analysis",
      "definition": "Circuit-level Analysis is a fundamental technique used in electronic engineering and computing to examine and understand the behavior of circuits at the individual component and connection level. In the context of AI/ML, it involves analyzing the hardware implementation of AI models, particularly neural networks, by studying the electrical and logical operations within the circuitry that execute these algorithms. This approach allows engineers and researchers to optimize hardware performance, detect faults, improve energy efficiency, and enhance the overall reliability of AI systems.",
      "categoryId": "cfc56cf8-bd54-4a8b-9b3f-5e8ce0bb635e",
      "subcategoryIds": [
        "177e6c22-1bcf-4967-a923-7c3b3a70d4aa",
        "a933f89d-385c-4707-a43f-277bf18e0b67",
        "b59e7dae-0941-45f8-b2d7-55c021c8b974",
        "34736b8d-0877-468a-885e-17343c7e248c",
        "f1a45b47-36d5-4d17-9973-61d4f01bfdf9",
        "366a9fdf-baf9-4ebf-aa68-8c847de59660",
        "b08b5fde-fbbf-4788-9803-5d02aac2e8aa",
        "9c8a1b8f-4c45-4482-9a76-a2b27ab6855e",
        "e83cd601-cd42-451b-96bd-3d1431a9b589",
        "ac7bfe83-49cd-4f36-b53c-cf062df7b099"
      ]
    },
    {
      "id": "8050364b-a50f-4775-956d-09226098d7b7",
      "name": "Circular Convolution",
      "definition": "Circular convolution is a mathematical operation used to combine two finite sequences (or signals) to produce a third sequence, representing their combined effect under periodic or cyclic conditions. Unlike linear convolution, which considers signals to be of infinite length or zero-padded outside their original domain, circular convolution assumes the signals are periodic with a fixed period, effectively wrapping around at the boundaries. This operation is fundamental in digital signal processing, especially in contexts involving discrete Fourier transforms (DFT) and fast Fourier transforms (FFT), where it enables efficient computation of convolutions through frequency domain multiplication.",
      "categoryId": "4a45a0bd-1af8-41e2-9ad9-21bf28654409",
      "subcategoryIds": [
        "0f626e92-7a4a-4476-b785-f07ff97abc0a",
        "ab03bc54-a2e1-48eb-b9e3-47dfe44abddb",
        "8d3aa4ca-9f32-4835-9bd1-9a511b4b6b7e",
        "7f9c2533-8649-48b8-b36a-724a362f87cb",
        "bb0762b7-83bf-4ae5-bfb7-8d895aff8ce5",
        "40199a11-0941-4448-8327-3a56cfa28a9d",
        "5628d191-72c9-4e18-95a2-633846874762",
        "5163cf1e-d3b3-4bf8-8c6b-68c366de9778",
        "c0082764-4f14-482d-9e9f-2c95751f0767"
      ]
    },
    {
      "id": "e6ccf95a-f86f-433a-b9e5-a95ba54e6f72",
      "name": "Circular Padding",
      "definition": "Circular padding is a padding technique used in convolutional neural networks (CNNs) where the input data is padded by wrapping around its own boundary elements, creating a seamless, circular extension of the original data. This method ensures that the convolutional kernels can process all regions of the input without losing information at the edges, effectively treating the data as if it were on a continuous loop.",
      "categoryId": "a918ded9-99e6-4ff2-a92f-93f8c0f32adf",
      "subcategoryIds": [
        "b998af90-cc5f-4721-96f9-199f500b5e51",
        "b885eb82-8507-4a69-9b16-a334bbd26553",
        "e5da09f4-4a1b-4880-910e-ffec2cb3972c",
        "530c4911-a653-429a-a1e8-4313df15efa9",
        "5559f7c6-cb23-40f5-be16-44ef82197c35",
        "8d3f241f-4521-4825-8f8d-90da3e9c0f9d",
        "90b495d2-68e4-46e9-b27f-708442453455",
        "50da4a5e-d50b-4c53-8f32-d656a9dbe011"
      ]
    },
    {
      "id": "b0d44823-78cb-443a-b701-1ba90533d4ed",
      "name": "Circular Padding in CNNs",
      "definition": "Circular Padding in Convolutional Neural Networks (CNNs) is a padding technique where the input feature map is extended by wrapping around its edges, allowing the values from one edge to be used to pad the opposite edge. Unlike zero-padding, which adds zeros around the borders, circular padding treats the input as if it is connected in a loop, creating a seamless wrap-around effect. This approach helps preserve the continuity of features at the borders, which can be particularly beneficial for tasks requiring seamless edge handling, such as in signal processing or image analysis where boundary artifacts need to be minimized.",
      "categoryId": "b16c54b9-1e16-44e0-8f81-96cde9210d00",
      "subcategoryIds": [
        "f1ed8780-2c79-40d4-8f5c-64dd68936e27",
        "bcdf72d1-7f01-4a55-8082-05fae50a7cef",
        "1f5631eb-cbaf-466f-93d3-6247be166bf2",
        "6a48d8a0-7fd1-4b27-9e9b-faf52fa2234e",
        "6464e3aa-3970-4e9c-a686-5d92dc23a916",
        "37717dd4-7765-43b2-9ca0-b780b598a83d",
        "a5a91d77-f776-4445-af6f-5663eedbc27d",
        "bcf69db8-e268-4652-9211-c4b007da0ad2"
      ]
    },
    {
      "id": "b76b9a97-e727-4683-ab8e-65f2de8186fe",
      "name": "Class Activation Mapping (CAM)",
      "definition": "Class Activation Mapping (CAM) is a visualization technique used in convolutional neural networks (CNNs) to identify the regions of an input image that are most influential in the model's decision-making process. CAM generates heatmaps indicating the areas within an image that contribute significantly to the predicted class, thereby providing interpretability and insight into the model's focus during classification tasks.",
      "categoryId": "cdc6501d-b0fc-4dde-9848-5e706c8fa375",
      "subcategoryIds": [
        "79369efc-ec16-4fb1-977d-cb36e01d820c",
        "a2217b1d-e4fa-46cf-a91c-91df5b24fd99",
        "99d70521-c1dd-4067-abc0-494c5990c2e9",
        "aa4ec221-ebf2-4af9-9937-ae9ab5a181ee",
        "65d98989-995a-4111-865f-f5aa6a76a8df",
        "309798a5-48b4-4fad-8f76-23f8e6b28be1",
        "70c1c99a-dd93-480a-a649-25f4a414bdc4"
      ]
    },
    {
      "id": "4cd47132-630a-4b4d-a495-8be3c9adb5a5",
      "name": "Class Activation Maps (CAM)",
      "definition": "Class Activation Maps (CAM) are visualization techniques used in convolutional neural networks (CNNs) to identify the regions in an input image that are most relevant for a specific class prediction. CAMs generate heatmaps that highlight these discriminative areas, providing insights into how the model interprets visual data and making it easier to understand model decisions at a localized level.",
      "categoryId": "49774b02-9fd2-41e9-9d67-f8c0901195c0",
      "subcategoryIds": [
        "ecf99165-ec09-4b25-8dc2-e6decb547c92",
        "f20fc60e-1d47-43d9-88e3-029a8b2c6757",
        "ae784c77-5818-4abf-849b-711f84101a46",
        "e047667b-657b-44cd-a571-ce3e01417559",
        "1965ed3e-7de0-49e1-afce-f205f008c265",
        "d2122874-d08e-4425-99dc-d4d0fcd198d0",
        "ed1bfc26-1ff2-48fc-ac48-054ca5dbc33a",
        "01261d29-6f88-4f9a-8e37-e574c03d015c",
        "6ce46488-f979-436d-9ae2-98fcc44a5364",
        "f3edf737-f251-48ef-aab4-df6a3d9799be"
      ]
    },
    {
      "id": "a5c9caf3-7817-4bbf-91ab-77141e646c45",
      "name": "Class Balanced Sampling",
      "definition": "Class Balanced Sampling is a data sampling technique used in machine learning to address class imbalance within a dataset. It involves selecting samples from each class in such a way that each class is equally represented during training, regardless of their original frequencies. This approach helps in reducing bias toward majority classes and improving the model\u2019s ability to learn minority class patterns, ultimately leading to more balanced and fair predictions.",
      "categoryId": "5a62c975-6105-4a66-b090-20bc1c9a0ee7",
      "subcategoryIds": [
        "45cbac75-b186-4991-88a2-ec52fa82b282",
        "4c16281d-d7a4-45e2-9010-f2a76c283056",
        "56ddb9c4-f014-43c8-bd34-008d4694cb24",
        "d3445899-90d1-4a48-98c2-96f619bf4cc7",
        "0ff4b0f1-3c02-4373-afde-218b7f62f763",
        "6b1b79af-3cf9-43c6-ab44-6ca7cd6f7a2f",
        "1af4ee20-cd41-4b86-ba40-7e9b37c152aa",
        "ad800734-ded5-4719-b63c-5a8dd209026f",
        "b9606870-7670-4040-8644-156c481f5495"
      ]
    },
    {
      "id": "6588b277-2200-4bf4-b0ea-2ee1074c4671",
      "name": "Class Imbalance",
      "definition": "Class imbalance refers to a situation in machine learning classification tasks where the distribution of classes within a dataset is uneven, with some classes significantly underrepresented compared to others. This imbalance can adversely affect the performance of models by causing them to be biased towards the majority classes, often leading to poor recognition or prediction accuracy for the minority classes. Addressing class imbalance is critical for developing robust and reliable AI systems, especially in applications where identifying rare events or minority class instances is vital, such as fraud detection, medical diagnosis, and anomaly detection.",
      "categoryId": "bd52977c-f080-4693-ad04-13ebf83b3438",
      "subcategoryIds": [
        "747db0f9-cf77-4a0c-b9fe-07c08a8d7645",
        "d22a68ae-60e1-4474-be84-6efd00dd14c6",
        "1648e82e-576a-4f23-8fb4-880e74802a12",
        "d3775ae0-b366-4634-b8e4-098ad5442f8f",
        "1e5867a0-9368-4be8-b925-cb053c6cc9eb",
        "cb4df37d-fe58-45b8-9b25-519bec68cd66",
        "68468857-2a8b-42fe-b6fd-1c7e00445a5c",
        "ab872113-d9c3-4a06-91aa-61d0e87228d8",
        "3068ceee-b1fe-4bf9-89d7-2cf8a32c8509",
        "27c72a08-3e58-42f5-83b0-6360d1db33b7"
      ]
    },
    {
      "id": "95fd2ef3-c510-4373-839f-d1bd220ef2fc",
      "name": "Class Weighting",
      "definition": "Class weighting is a technique used in machine learning to address class imbalance in classification tasks. It involves assigning different weights to different classes during model training, typically giving higher weights to underrepresented classes and lower weights to overrepresented ones. This approach helps the model pay more attention to minority classes, improving overall performance and fairness in imbalanced datasets.",
      "categoryId": "bb904414-df50-475e-9142-59e155300580",
      "subcategoryIds": [
        "dd0ab711-3dd4-485f-bd3e-213221004379",
        "8e8db03e-022d-4cb5-9b88-637cc5eecce4",
        "add54705-2a78-45e4-b694-85debb3e8fa9",
        "f5eed3f6-8e99-453b-a06f-5e1ad29100ec",
        "41693121-fac8-4368-a463-af96bce13c0e",
        "92bd8b12-04d9-410f-83ac-46f5e9a3be74",
        "537e1280-bcdb-46cb-91c0-515879b77ac6",
        "b3c6d341-9892-4765-bcd1-1aaf4f24ee31"
      ]
    },
    {
      "id": "96b5ac18-07e0-4362-aef4-04724b65ac97",
      "name": "Class-balanced Loss",
      "definition": "Class-balanced Loss is a loss function designed to mitigate the challenges posed by imbalanced datasets in machine learning. It emphasizes balancing the contribution of each class to the loss, ensuring that minority classes receive appropriate attention during training. This approach helps models perform better across all classes, especially when certain classes are underrepresented, by adjusting the loss computation to counteract class imbalance effects.",
      "categoryId": "463c8d62-656f-4479-b28e-3b49fbccc87f",
      "subcategoryIds": [
        "78d23e9b-e7a3-4421-ac6c-0bfb123f7653",
        "801d406b-9e96-43ed-ba03-23e7ca864df8",
        "255dc7ad-1975-4e0c-b687-69320d5c52b7",
        "ffcf8640-2d93-4a0a-a850-0c1630df1371",
        "ac93184c-278e-485b-a938-13c0cfe71eeb",
        "5f40701a-080a-4507-9f58-92f302fd497c",
        "ce23a085-4bac-4a0a-9679-5b774a07543f",
        "9d0e5d01-0770-46be-acf1-734e13fde338",
        "1890e963-42d6-4c76-bdeb-a14b05d450d6",
        "566bcae2-1986-46fa-8efd-cdc0c54ba198"
      ]
    },
    {
      "id": "380cd7f2-8a3d-423d-95fb-fdc1f69cfdf7",
      "name": "class-balanced sampling",
      "definition": "Class-balanced sampling is a technique used in machine learning to address class imbalance within datasets. It involves adjusting the probability of selecting samples from different classes during training to ensure that each class is adequately represented, thereby preventing the model from becoming biased towards the majority class. This can be achieved through methods such as oversampling minority classes, undersampling majority classes, or applying weighted sampling strategies. The goal is to improve model performance, especially in tasks where certain classes are underrepresented, by providing a more balanced training process.",
      "categoryId": "a1c8d4d1-6f9e-4689-808d-d472c6cdb804",
      "subcategoryIds": [
        "22c826c5-2c60-466b-b3d8-5ab436acbc30",
        "c146bde0-6d33-4cba-8bff-b0a30b80d61f",
        "6e6a0b06-4ccb-4f9f-8463-f3338e315a34",
        "eb875b95-76c7-4c25-8fb3-034669f16d28",
        "b60506ab-e49f-4645-b1ab-c4bbf6b7dfb3",
        "e1b388e7-6296-436e-93c6-1dd45d7328e0"
      ]
    },
    {
      "id": "b2414a93-eed9-4b6f-8e74-e2dd1a43a52a",
      "name": "Class-weighted Loss",
      "definition": "Class-weighted Loss is a technique used in machine learning to address class imbalance during model training. It involves assigning different weights to different classes in the loss function, thereby increasing the penalty for misclassifying minority classes and helping the model pay more attention to less frequent classes. This approach modifies the standard loss function to incorporate class-specific weights, aiming to improve overall model performance, especially when dealing with skewed datasets.",
      "categoryId": "46a7e47f-f3b4-4f60-9da0-d5def5325232",
      "subcategoryIds": [
        "f93d3ce7-bcf9-44fa-8d7a-262aa178aff2",
        "e37a03a9-d06a-45a5-98b8-a626c6d8b205",
        "63ba9db6-37cd-4ae2-98cf-2cca483bd54e",
        "b5e7cc4f-6693-4f7c-9cf4-8e740c62176d",
        "2c1e07da-873b-4014-a501-c583bef42644",
        "0bab0a9f-5b8f-4bf5-8445-b9a1e4b770b9"
      ]
    },
    {
      "id": "ebd901e7-d63a-4b8f-916e-530862c510ac",
      "name": "Classification",
      "definition": "Classification is a supervised machine learning technique where an algorithm learns to categorize data points into predefined classes or labels based on input features. It involves training a model on labeled datasets, enabling it to assign new, unseen data to one of the established categories. The primary goal of classification is to accurately predict the class label for each data instance, facilitating decision-making processes across various applications.",
      "categoryId": "638b1e9b-d328-40ff-b394-5a617ed4ee0a",
      "subcategoryIds": [
        "c0557b9b-e7d6-41f6-96ad-c6ad51bfb9a5",
        "725c561f-8b92-42e0-b5ab-5d3a334df9e0",
        "95e24e6a-557b-469e-9aef-f6ba83e99e42",
        "381ce894-6397-476f-b5c9-e08edc6c337f",
        "7327b7b4-63c7-4dad-a856-42363085c64a",
        "d66df000-b60f-493e-aa35-fd829e8c3783",
        "4b8eaeaf-e8f8-477a-9756-017e01bb43d2",
        "665e92e0-8b74-4f03-bdf5-b42b6857bc85",
        "93f3b4c4-3c09-457a-8723-6e60c93a4c5c",
        "62712664-7b23-41b2-aa8c-354bc556b326",
        "a436aa09-2c29-457a-8eb2-51ee5e4f3529",
        "4dc05e06-8550-4409-87f0-988a213fa1bb",
        "93564c03-dca6-4305-9377-37f91b06073d",
        "156de980-a456-49d6-9ce3-5848c7d29057",
        "767ae498-e397-46f0-8860-686ed602a225"
      ]
    },
    {
      "id": "ff850196-5abd-4199-b275-d2439ff0bb80",
      "name": "Classification and Regression Trees (CART)",
      "definition": "Classification and Regression Trees (CART) is a decision tree algorithm used for supervised machine learning tasks, primarily classification and regression. It constructs binary trees by splitting data based on feature values, aiming to improve predictive accuracy. The CART algorithm produces a tree structure where internal nodes represent feature-based splits, and leaf nodes represent output predictions, enabling easy interpretation of the model's decision-making process.",
      "categoryId": "ad6f7632-68e4-4117-85c7-7bc4bee08896",
      "subcategoryIds": [
        "f2ce54a0-77c8-41d7-a60a-7a71fb39c591",
        "fbee121d-8daa-493a-8a59-6dcca35f7858",
        "8e6f72cf-6a35-4855-b57f-1fc0541a022e",
        "2642625c-0dd6-4681-b9ae-1e0f92c20867",
        "5acddb06-5935-41bd-bfaa-4410e3911039",
        "f5edcbab-98f5-4e28-b49c-ec0cee0f73cf",
        "632a4716-2e55-4c89-add1-78cad5a4dc65",
        "0e68de4a-8249-4fe0-b08a-b0ea56386f17",
        "e2b6d42d-5f24-40f2-ab1b-368583c3a430",
        "8b811db7-040c-48e5-b3b5-1d766dbbe012"
      ]
    },
    {
      "id": "81eb8354-1a8c-403d-901a-cfaeae89356b",
      "name": "classification evaluation",
      "definition": "Classification evaluation refers to the process of assessing the performance of a classification model, which is designed to predict categorical labels for data instances. It involves using various metrics and methods to determine how accurately and efficiently the model assigns inputs to the correct classes, thereby enabling practitioners to understand the model's effectiveness and identify areas for improvement.",
      "categoryId": "19f8687d-78e2-404b-b32b-b5dab8063e1c",
      "subcategoryIds": [
        "c69f6044-95e4-46c8-b4d2-aa2fbfdf3df6",
        "3cf59ebf-409e-4bd1-8549-930625dccd3e",
        "6f904920-9e86-4848-82fd-b45d2b861009",
        "79cc9a54-2a74-49b0-8748-c33b361fef94",
        "2eae901b-6ad8-43f1-8404-37febcc6f7c2",
        "79285ea5-783f-4379-a1aa-c4bedbdb9ed4",
        "658bc576-0605-4da8-b4c7-4df1f5c5d022",
        "ed9f81df-680f-4898-baaf-dd25d117d7e8",
        "84e1c761-1424-4684-a45d-61bc6f93f790",
        "e7e37691-5105-490f-96bb-693c12783fd7",
        "efd4cf4d-70f1-427d-9c47-b99a638ddbce",
        "c9e17a68-d519-478b-a10f-3214efd37d96",
        "923cdb68-c0a7-4f90-bb10-673f9f6c213c"
      ]
    },
    {
      "id": "8000ab79-a9fa-4304-81ac-e387ef989d75",
      "name": "Classification Problem",
      "definition": "A Classification Problem in machine learning involves categorizing data points into predefined classes or categories based on their features. The goal is for the model to learn patterns from labeled training data so that it can predict the class labels of new, unseen data accurately. This type of problem is fundamental in environments where decision-making is based on categorization, such as spam detection, image recognition, and medical diagnosis.",
      "categoryId": "56ed7f8c-a501-4986-a441-19c3c8a7fbfc",
      "subcategoryIds": [
        "12674661-36ee-4264-be70-5545f20f9880",
        "225bbc7a-fe01-4e2b-943e-37fa1f6ff5e1",
        "eae5994c-a671-472f-9f78-9651e0a56043",
        "b882c43d-fdea-4eef-a859-3eafc3b95d38",
        "f6be36df-90a7-481d-80df-ffb2a225d8b7",
        "868499c4-1e53-4ffe-8e41-ee8a17873787",
        "d431dca4-9e00-4154-bf36-22a4158ef829",
        "0cd6ac23-c3e1-4b5f-8030-493d0830b83a",
        "f5c15b71-d2ac-46b0-837a-d7547416c294",
        "9f9f9fc2-5032-4ae2-912f-f0273bb9d37c"
      ]
    },
    {
      "id": "4fefc4bb-7fde-4cbd-9bb7-4ac95fb07ad6",
      "name": "classification report",
      "definition": "A classification report is a comprehensive evaluation tool in machine learning that provides detailed metrics to assess the performance of a classification model. It summarizes key performance indicators such as precision, recall, F1-score, and support for each class in a classification task, offering insights into how well the model distinguishes between different categories. Typically generated after predictions are made on test data, the classification report helps practitioners understand the strengths and weaknesses of their models in terms of class-wise performance.",
      "categoryId": "aaaa9c42-d813-43dc-8d14-0cef0d46ae59",
      "subcategoryIds": [
        "5c5b96ed-cf59-4ce6-814a-bc0a1a9f2c74",
        "8a2fc8f3-00bb-4de1-8c84-5e6d591cef80",
        "08481df2-f8f3-47cb-8a91-d25793125fb8",
        "9baebda5-83db-4056-b02d-972604f6a519",
        "1f1db145-c380-4992-a877-83f21d1c95ab",
        "2309068b-8cb0-4633-9b07-be5e50e56f8b",
        "d1cb926a-e20d-4cb7-9f8c-42ca3ef31f98",
        "3436d2ed-7f3d-4e1d-a39f-fdde3c5453cc",
        "a0e02c15-4478-4fe1-bc99-6cb483ee2d47",
        "b51ac583-6a90-4e9b-9f57-f514ad1198ca",
        "76eb3082-c306-4971-90ef-b7a09009f1fa"
      ]
    },
    {
      "id": "0d5f15c8-88ae-4045-b289-314ed56b341e",
      "name": "Classifier Chains",
      "definition": "Classifier Chains are a method used in multi-label classification tasks where multiple labels are predicted simultaneously for a given instance. This technique involves chaining individual binary classifiers, each responsible for predicting a specific label, with each classifier taking into account the predictions of previous classifiers in the chain. The goal is to exploit label correlations and interdependencies, improving overall classification accuracy in multi-label scenarios.",
      "categoryId": "68fab1ce-0ab7-47bb-8999-9548eddf2d65",
      "subcategoryIds": [
        "500c19c3-3e04-4b61-abeb-6f2a51c4447d",
        "7822845b-9d30-4198-80eb-31cbc4285739",
        "e868cfa5-2af4-4d05-bfba-5da582c42c8a",
        "57935547-77a2-45fa-af0b-0de76cf20497",
        "0ccd9065-97b8-4c73-9aa2-89de7304a708",
        "8cad6594-91c1-4306-a0b4-22c34a68ee7e",
        "62de61f2-5215-4555-859f-d6ed101d9f8b",
        "394a0149-da74-4de6-94ee-afe65bdb74a1",
        "529d2187-0870-4070-95fa-175990027b9c"
      ]
    },
    {
      "id": "b21778cc-a7ba-4ee7-99c1-0e92009946af",
      "name": "Classifier-Free Guidance",
      "definition": "Classifier-Free Guidance is a technique employed in generative models\u2014particularly in tasks like image synthesis and text generation\u2014that enhances the quality and diversity of generated outputs without relying on explicit classifier models. Instead of using an external classifier to steer the generation process, this approach integrates guidance directly into the model's sampling or inference procedure, allowing the model to produce high-fidelity results that adhere to desired attributes or prompts. It leverages learned, conditional information within the generative model itself, enabling more flexible and efficient control over the output while reducing dependence on separate classification components.",
      "categoryId": "ce8840a2-b630-42e6-bfa3-82fb58079cf8",
      "subcategoryIds": [
        "9260e55f-a30c-4589-8b66-5fec0ab4e83c",
        "44e30b58-544f-4b04-b5ad-e06c174eb2d7",
        "2db1d4d8-dff8-4d6c-8c48-0cb5207bb9c9",
        "2ec4809e-88ad-4eb6-b7d6-f34ef7f180eb",
        "b7ca38d5-0048-4d83-8aa9-07c02bd0fa87",
        "4a766364-3509-45b1-91a5-c2738db87cb4",
        "52af2813-bb6d-4b42-a058-8b34de7122ed",
        "ff20e517-98fe-443c-b53c-a7c0e895ce07",
        "8ca13401-9660-4bfa-a3b0-be76b384457b",
        "1e574f67-bfeb-46bb-9ca5-771934b9b9a2"
      ]
    },
    {
      "id": "7aeca873-0474-4c83-aa7a-266fee749be0",
      "name": "Claude Security Impact in Sentiment Analysis",
      "definition": "Claude security impact in sentiment analysis refers to the potential vulnerabilities, risks, and ethical considerations associated with the use of the Claude AI model (developed by Anthropic) when analyzing and interpreting sentiment data. This impact encompasses how the deployment of Claude can influence user privacy, data security, bias propagation, and the accuracy of sentiment detection, which in turn affects decision-making processes based on sentiment insights.",
      "categoryId": "679ad49b-3245-4a91-838a-49cdf3e200d3",
      "subcategoryIds": [
        "4a4be183-cc78-41de-8e37-9364e10fcc86",
        "2fe821bd-c0ad-4c35-9fbe-529706afa76a",
        "cd8afa1e-5bed-4685-bb24-b48042bdbfa4",
        "973d8a70-4e45-488d-ac75-624bed7fa3e2",
        "d75cd912-d7b4-4dc1-a4b1-a60b03bf8e9c",
        "a7a75efd-c7b2-4e89-9ed7-e2a501374733",
        "b4e6d187-f0cb-4d1c-b677-e8c3ff1345da",
        "16d9b756-93ff-46ea-a2de-84e7732b76e8",
        "e13f6207-4e06-49f1-9aff-85dfb0aa71e6",
        "4fe98b57-cfaa-4a16-9e07-cff2a66db6e8",
        "1590d9e4-d560-4e9e-9765-12a2bcad6404",
        "f2ae44ca-c4a9-4e34-b958-2ef3392ccc79",
        "677c5b5f-a712-464d-a8c1-debbd91d0901",
        "7d061fc9-9fac-4696-a0cb-5e7c85992704",
        "a483c364-2214-41e5-8a4d-240722285286"
      ]
    },
    {
      "id": "4d5c0b73-d0c7-4860-9084-eb53db3d1f74",
      "name": "Clausius-Clapeyron Relation in AI Thermodynamics",
      "definition": "The Clausius-Clapeyron relation is a fundamental thermodynamic equation that describes the phase transition between two states of matter, typically relating temperature and pressure during processes such as vaporization, condensation, sublimation, or melting. In the context of AI thermodynamics, this relation provides insights into how energy, entropy, and phase stability interact within models that emulate or simulate thermodynamic behaviors, often in the pursuit of optimizing energy-efficient AI hardware or understanding thermodynamic-inspired training algorithms.",
      "categoryId": "99d529f2-49fc-4886-8873-56c007857d96",
      "subcategoryIds": [
        "af45e407-2f16-4a01-9013-17ce931d84e0",
        "ee95d3bc-8c17-437f-861e-f420a02ac3f4",
        "58867216-889a-4771-80d4-12a5ffb77580",
        "22fb4a18-7df5-420f-a666-9a2354b9c075",
        "b71d7f75-c910-4dc6-90be-cbfd0b6471f1",
        "6ddaed60-ab96-4bee-9ee4-f6d4fb7f5cc2",
        "1babd10d-29fa-423d-a711-adc84e7c459c",
        "644d1346-a9af-4cad-90e2-eff2ad056c9f",
        "8d444b9e-2b92-46d8-98c5-a83562c49edf",
        "822c2390-133c-49b3-9055-1d1fcdffb236"
      ]
    },
    {
      "id": "6d8e660e-c9b5-4824-900e-476965212fe3",
      "name": "ClearML",
      "definition": "ClearML is an open-source platform designed to facilitate end-to-end machine learning workflows, encompassing experiment management, orchestration, and deployment. It provides tools for tracking, managing, and automating AI/ML projects, enabling data scientists and engineers to streamline development, collaboration, and reproducibility of models within a unified environment. By integrating various components such as experiment tracking, model versioning, and pipeline automation, ClearML aims to enhance efficiency and transparency in machine learning operations.",
      "categoryId": "34461a4f-ae39-45c3-b7ed-85671d17fde1",
      "subcategoryIds": [
        "3eb14e8c-6b3f-4d67-b0b5-58916771c29a",
        "68401081-e036-4493-a777-18d2f69baa34",
        "54a75024-82de-4698-8692-0c531ffbbbf7",
        "f8bbc8cd-7ddb-42e7-913d-aae09e88019b",
        "d1a421ec-7cd5-4370-9d0f-36c70bc0b37f",
        "7cf01f22-2607-4f19-b8e6-e8bcafdec97e",
        "cc5d07ab-ced0-47f3-b305-4135cda2bc16",
        "1cf14460-9ee3-4710-ab58-9c12b7355c32",
        "ef11be24-b201-4e25-92fa-bbf38a41bec5",
        "ec2805cd-2f35-4153-b298-e5c8690942a6",
        "ac50f6e3-601e-46b3-a949-a0e8895782a8",
        "3f54be3f-1c17-4e21-acb7-e8f9dfd52a6f"
      ]
    },
    {
      "id": "db69d095-7a5d-49e7-af70-1109b9329b65",
      "name": "CLIP (Contrastive Language-Image Pretraining)",
      "definition": "CLIP (Contrastive Language-Image Pretraining) is a neural network model developed by OpenAI that learns to connect visual concepts with their corresponding natural language descriptions. By jointly training on large-scale datasets of images and their associated textual captions, CLIP can recognize and retrieve images based on textual queries and generate descriptive captions, effectively bridging the gap between visual perception and language understanding in AI systems.",
      "categoryId": "4a7824c8-0363-4203-88d1-225a0e0beeff",
      "subcategoryIds": [
        "e829c2f4-ddef-4b70-8320-569cb03b66c4",
        "a3c847e8-d7c4-453c-b751-eebbe0fdea8f",
        "d59476f0-9cd6-4db9-a55d-2866a272441f",
        "a3903104-02d4-46e8-9268-37eec52625fa",
        "72d227d8-3c90-4346-ba8f-867f728bfa84",
        "b9e37820-2adf-4d1a-a39b-a4e479d94757",
        "3622e634-8e80-498b-9f6f-6402ed41389f",
        "9535467e-26b5-409d-978e-230d98d25aef",
        "e179eb70-1553-42d0-8ddc-99bd6e9009fe",
        "8099841b-2be3-4fcf-934a-c426d82187a6"
      ]
    },
    {
      "id": "139120e2-8e80-4c86-941f-f8ea561c464f",
      "name": "CLIP (Contrastive Language\u2013Image Pretraining)",
      "definition": "CLIP (Contrastive Language\u2013Image Pretraining) is an advanced machine learning model developed by OpenAI that is designed to understand and relate visual and textual data. It is trained to connect images and their accompanying descriptive text by learning a shared embedding space, enabling it to perform tasks such as image classification, retrieval, and zero-shot recognition without specific task-specific training. CLIP's architecture combines natural language processing and computer vision techniques, allowing it to interpret complex visual concepts based on language inputs.",
      "categoryId": "ba60df6e-a2b2-4e46-9e06-508c2a008ce8",
      "subcategoryIds": [
        "c0e8e1aa-1dba-4f07-be0e-1d0e5dc9d111",
        "3397efb9-cce0-4bfd-a2b0-9adb12df963d",
        "0514ffcf-33e2-47a0-b4d7-b9eace9b1783",
        "edbfb598-dc67-48f0-bc8f-9bbf574f32d3",
        "3daa4eb1-c696-4bb3-9c87-fb454d9da0f1",
        "3665e3a8-a68d-42dd-bdb7-f58b267e0cc2",
        "ec1bad91-f64d-4e09-ad11-58c69bb29d8d",
        "732b3f9a-cec1-4d9f-94cf-b708d7b111a0",
        "3ef6211a-da11-46d2-9b3e-6786e0ea5c74",
        "4bd2cd38-9210-4acb-a0e5-f0a04dc83d1c"
      ]
    },
    {
      "id": "dd8745ce-044b-4115-8dea-f0ac1e0b85d3",
      "name": "Clipped Gradient",
      "definition": "A clipped gradient refers to a technique in machine learning where the magnitude of the gradient vector is restricted or limited during training. This process, known as gradient clipping, involves setting a threshold and ensuring that the computed gradients do not exceed this value, effectively 'clipping' the gradient to a specified maximum norm or value. This approach helps prevent excessively large updates to model parameters, which can destabilize the training process, especially in models with deep architectures or recurrent neural networks. The primary goal of gradient clipping is to improve training stability and convergence by controlling the scale of weight updates.",
      "categoryId": "99dd1378-9357-476f-8f24-cd073bf1a574",
      "subcategoryIds": [
        "7c3d014d-9deb-47c9-b091-634deb91cba0",
        "c2b7822c-01d9-4cf6-add9-4c62969b2fd0",
        "78252823-5487-4b8c-8df5-974ee60addde",
        "6667c48d-cb60-4f76-b80d-5587c8b32beb",
        "0ec976e1-d9cc-472d-811a-662eec230518",
        "5d53d6cd-43d8-40a6-a8da-b7642ac5c615"
      ]
    },
    {
      "id": "a4cdeef0-32f2-4c8d-99b5-29e83eba5cb2",
      "name": "Clipping Gradients",
      "definition": "Clipping gradients is a technique used in training neural networks to prevent the explosion of gradient values, which can destabilize the training process. It involves setting a threshold (clip value) and scaling down the gradients for parameters whose gradients exceed this threshold, ensuring they remain within a manageable range. This process helps maintain stable convergence and improves training efficiency, especially in models with deep or recurrent architectures.",
      "categoryId": "28541ed0-da62-422a-b170-9d900cdb203b",
      "subcategoryIds": [
        "8248b90b-7738-464c-9bab-443899b1e118",
        "6c6339d1-d773-41e8-bf72-d8dd8ccbeffa",
        "405028fe-c06b-4f34-96f7-e5e3e1b81dfa",
        "11644ecd-3c34-4533-b294-96282b6f587b",
        "ea282468-d0a8-4a29-ab62-86232b4e6a8a",
        "a9432a68-34fc-4bf5-9a8e-3a1c26f8be43",
        "0ec288bb-f06d-48b8-bda3-ed193a70782d",
        "05efe36c-31c8-4bee-a311-5291a529b548"
      ]
    },
    {
      "id": "32c589fb-6712-4a68-8831-20dfcc388c54",
      "name": "Clipping Gradients Techniques",
      "definition": "Clipping gradients is a technique in machine learning used to prevent the problem of exploding gradients during the training of neural networks. It involves limiting or 'clipping' the magnitude of the gradients to a specified maximum value before updating the model parameters. This process helps stabilize training, especially in deep networks or recurrent neural networks, by ensuring that gradients do not become excessively large, which can cause numerical instability and impede convergence.",
      "categoryId": "3f34ecb9-feff-4003-84e1-762cf3af049f",
      "subcategoryIds": [
        "7ba4fabc-abc2-4227-848e-7316bce6b302",
        "2f1469a4-64ea-4e96-bc79-fd7b013455eb",
        "244dee7f-65d6-47f8-9d4c-0108d75bdbe5",
        "f0dd9e3f-c089-4b92-b659-e97fd05c400d",
        "ac15621e-0b9e-47d5-bcac-dc88546900b7",
        "85f7afc9-f8bf-4039-b8a9-c2ef863f018b",
        "f667dcb4-91b1-43b3-ac2c-46e7936d3499"
      ]
    },
    {
      "id": "2e401a5d-d373-463b-9d78-6a70ef648ccd",
      "name": "Clipping Gradients Techniques Extensions",
      "definition": "Clipping Gradients Techniques Extensions refer to methods used in deep learning to modify or restrict gradient values during the backpropagation process, aiming to improve training stability and model performance. Gradient clipping involves capping the magnitude of gradients to prevent issues such as exploding gradients, which can cause unstable updates and hinder convergence. Extensions of these techniques encompass various methods that adapt or enhance basic gradient clipping to better suit specific architectures, optimize training efficiency, or address unique challenges encountered in complex neural networks.",
      "categoryId": "456a3d25-7e42-45e1-b4ea-6aaf5331896f",
      "subcategoryIds": [
        "2fac11e0-5457-4e33-9043-16b2fabccb1d",
        "0e2904b5-f0d8-4b3d-8c4e-6dfeae4a97d0",
        "db149b82-927f-49f2-9e2d-ee136b43a223",
        "e52e2247-080d-4d74-8b70-9a5207276766",
        "2fab4eb5-c67b-4cd8-8eb9-a90b45a77d72",
        "8b4c5a01-c2e6-4933-96e2-f55d7c5d09f8",
        "e1a2851a-fe39-4207-949a-7dd9629fee66"
      ]
    },
    {
      "id": "933917de-5ccf-4843-990d-04fb81a8af1c",
      "name": "Clipping Norms in Gradient Descent",
      "definition": "Clipping norms in gradient descent refer to a regularization technique used to prevent excessively large gradients during the training process of neural networks. This method involves constraining the magnitude of the gradients by scaling them down whenever they exceed a predefined threshold, known as the clipping norm. The primary goal is to stabilize training, improve convergence, and prevent issues such as exploding gradients, which can hinder model performance and training efficiency.",
      "categoryId": "45cfcd6f-d63d-47eb-9064-4d861f7f0a87",
      "subcategoryIds": [
        "4d6e0eff-54b3-4e7c-a288-949e69bc406b",
        "d506c5a2-d4bd-4594-be72-dff874fd4ebf",
        "c94f83b1-4d9c-4788-80d2-40119d1fa2f0",
        "77cf5dea-490c-44a5-b819-4cf5f9b9a640",
        "c1a6d9a6-07f8-4dc3-8734-62e26e863b7f"
      ]
    },
    {
      "id": "32f55852-8727-43f6-a651-1218f96e17da",
      "name": "Clique",
      "definition": "In the context of graph theory and network analysis within AI and machine learning, a 'clique' is defined as a subset of nodes in a graph where every pair of nodes is directly connected by an edge. In other words, a clique forms a complete subgraph, meaning all nodes within the subset are mutually adjacent. This concept is used to identify tightly-knit groups within a network, where each member interacts with every other member, highlighting dense regions of connectivity relevant for various analysis tasks.",
      "categoryId": "5b9b4489-8554-42b2-b9ef-726c4094abde",
      "subcategoryIds": [
        "840fd2ff-3ee0-4712-8edd-d3aed22bb60e",
        "67454fb4-178a-4ae7-834a-31d615cdf145",
        "9f35978b-d1af-487f-bfe9-17b04586c8ea",
        "16cc9a2a-4f90-41c6-af70-2d82de80b23a",
        "00491d5a-6527-4076-a4e9-779c83f3b681",
        "c3f998a7-f944-46d9-ad91-42affeaae732",
        "67b2cea2-a6e5-478e-8779-a3beb1207f79",
        "7617b62c-fd58-4c77-ac01-20055c8d5e7a",
        "9b50f4d8-85f9-4dcf-8278-032b91113d77",
        "fb4ae7e9-c3b8-455d-963c-1a7e8b22219c"
      ]
    },
    {
      "id": "f2e786bc-75f5-4270-9116-419e88ac3058",
      "name": "Closed Frequent Itemsets",
      "definition": "Closed Frequent Itemsets are a specialized concept in the field of data mining and pattern discovery. They refer to itemsets within transactional datasets that are both frequent\u2014appearing in at least a specified minimum number of transactions (support threshold)\u2014and closed, meaning there is no super-set of the itemset with the same support. This ensures that closed frequent itemsets provide a compact, lossless representation of all frequent itemsets, capturing maximum information without redundancy. They serve as a fundamental component for generating association rules and for understanding the underlying structure of transactional data.",
      "categoryId": "523e51fa-1776-427e-89d2-fb66abda68ac",
      "subcategoryIds": [
        "6903e8e0-8935-4149-9828-77a64b3978b2",
        "e5a464a1-9683-485c-b906-120236908bb4",
        "f605396c-809c-442c-a538-262425dfb48c",
        "a12b8eac-ce3f-402f-b51d-81104217cac8",
        "d5f398f3-6849-40df-afe1-0e81dc37002a",
        "12141a3f-7e44-4366-b74e-7b98ced2c81a",
        "5b22a92b-017b-4f46-a9af-d8418bf22166",
        "9aae7ac9-418b-4cb6-8390-f93a8058bfcd",
        "4d4399f7-3b43-4a06-8f64-92f38118c65c",
        "a1cdccc9-2bc5-4760-8753-e7e3b36fb151",
        "0e2e5070-7bb1-4155-99be-7ff8aa8a6c9d",
        "15990c50-1a72-45a9-92ff-c57f987a7c48"
      ]
    },
    {
      "id": "6429613d-421e-42f5-8a02-91929f880707",
      "name": "Closeness Centrality",
      "definition": "Closeness Centrality is a measure used in network analysis to determine how close a node is to all other nodes within a graph. It quantifies the average shortest path distance from a given node to all other nodes, with higher closeness centrality values indicating nodes that are strategically positioned to quickly reach all others in the network. This metric is particularly useful for identifying influential or central nodes within social, communication, or transportation networks, facilitating the understanding of network efficiency and information flow.",
      "categoryId": "99a37e49-c26c-436a-ba47-f1aef82840f9",
      "subcategoryIds": [
        "d7b22acf-05ae-4a9c-bcd4-786dca5eeb8d",
        "56a302d7-8abe-42fb-ac18-1881e9154897",
        "5ab38784-a135-4807-b36e-4f50ba6c3715",
        "401370c2-a5ac-4bc4-a998-50a50c140594",
        "9a1a0dc8-e150-44d2-883d-e7f1ce21e199",
        "e6449670-cd17-4bdd-8207-35bd94c2ed49",
        "7b2570e4-ed75-42fc-80be-1d1e4b58486c",
        "1aa85b9d-50fe-41cf-bebd-28a1b8f63bd0"
      ]
    },
    {
      "id": "a659778d-2c0e-41fa-9fa1-5795f20c8f8d",
      "name": "CLUSTER (Clustering with Ubiquitous Structural Time-series)",
      "definition": "Clustering with Ubiquitous Structural Time-series (CLUSTER) is an advanced machine learning technique designed to identify inherent groupings within large-scale time-series data by incorporating structural and contextual information. This approach leverages clustering algorithms tailored to handle the complexities of temporal sequences, emphasizing the preservation of temporal patterns and structural features to reveal meaningful patterns across various domains such as finance, healthcare, and IoT systems.",
      "categoryId": "b45fcd23-167a-4cd7-8c94-f11731bcd9bb",
      "subcategoryIds": [
        "4877303d-2525-4ad3-8a8a-c46d3461fa68",
        "12fe26c9-2193-4e0b-85da-7fede83753a5",
        "42738879-963b-4082-93e5-8de2527a58c8",
        "605b5e37-05e4-4bac-a3e1-3be1247829ea",
        "326bb3cf-434e-4028-8969-2585e8c8af17",
        "ac4915e6-b09d-462d-9881-fb7809aa7885"
      ]
    },
    {
      "id": "3e397ff7-caa0-4113-9c64-17d25a0f5af1",
      "name": "Cluster Assumption",
      "definition": "The 'Cluster Assumption' is a fundamental concept in semi-supervised learning, which posits that data points within the same cluster are likely to share the same class label. It suggests that the decision boundary should lie in a low-density region, effectively separating clusters of different classes, thereby enabling classifiers to leverage unlabeled data by assuming that similar data points form coherent groups.",
      "categoryId": "81c4a614-b379-4963-8334-e5408557d7c0",
      "subcategoryIds": [
        "006b7061-411a-4f16-88e8-7ceb69d83558",
        "1c81a9d0-45e3-4328-979f-89f7f033a984",
        "5333b5de-6ad0-453d-8694-a0626f7f8075",
        "c44324e3-e880-4f90-b322-4cc6aa68beb9",
        "a8c670bd-a9cb-4322-84b6-e014f007b32e",
        "fef81460-c322-4358-9a53-f2d580632375",
        "3a999406-56ff-4860-9fe7-8a5a63c147ae",
        "3fb9fa0e-1e6d-43a8-9289-686a3ca16dd4",
        "4bb655bd-c51f-4cc8-8e51-e7c8c515e8a2"
      ]
    },
    {
      "id": "c1865b0a-50c2-4804-9a1f-219a82db23cc",
      "name": "cluster purity",
      "definition": "Cluster purity is a metric used to evaluate the quality of clustering algorithms by measuring the extent to which each cluster contains data points belonging predominantly to a single class or category. It quantifies how well the clusters correspond to predefined ground-truth labels, providing insight into the homogeneity of the clusters. A higher cluster purity indicates that the clusters are more homogeneous and that the clustering algorithm has effectively distinguished between different groups in the data.",
      "categoryId": "7d6cb905-5b1d-481d-90a9-6b51f2614970",
      "subcategoryIds": [
        "144fca38-3b86-4312-89b0-263a34343e3e",
        "d46077bd-ba15-402a-800f-0fb8750f466d",
        "43ebb9eb-c308-43db-a46c-ff228e6995bf",
        "7d7a01c3-df8d-4c9e-a237-23677cf8d5c6",
        "869367f1-2601-474e-bcdd-37573aed127c",
        "1fcf0a77-3dfe-4d71-be91-6a312a84b41d",
        "0c07f92a-db6c-4785-a643-694fa1ca80d0"
      ]
    },
    {
      "id": "ee87e633-20dc-4236-afc6-47644212440b",
      "name": "cluster sampling",
      "definition": "Cluster sampling is a statistical sampling technique used to select a subset of data from a population by dividing the entire population into distinct groups, or clusters, and then randomly selecting entire clusters for analysis. Instead of sampling individual data points, this method focuses on sampling whole groups, which simplifies data collection especially when the population is large or geographically dispersed. It is commonly used in survey research, quality control, and data collection processes within AI/ML workflows to efficiently gather representative data for training, testing, and analysis.",
      "categoryId": "a9ca6fd3-8237-49d6-96e7-0d4d4836417b",
      "subcategoryIds": [
        "482b0347-5e06-410e-a5b9-2e7faef6b75b",
        "907658b0-0b6b-48eb-baeb-6d5e4508901f",
        "834ed08f-5add-4f03-a954-9d6e9708b143",
        "76d69d32-8a02-4e24-8599-44ed73c4c0d6",
        "8b633a14-522f-46ff-bc73-960180ef34a5",
        "133d263a-5265-4db2-805e-bd455fe8da79",
        "c5816a52-513d-4ffc-bf90-dce68f6bc07c",
        "c07ad686-ee1a-4deb-85e1-496340579964",
        "d2a2443f-aec7-467e-bb49-c94f3676472a",
        "ffbd621e-5af4-4ee7-aae7-266d842fd5d5"
      ]
    },
    {
      "id": "896b79e0-ffc5-499f-9587-5362a5cc9e14",
      "name": "Clustering",
      "definition": "Clustering is an unsupervised machine learning technique used to group a set of objects or data points into clusters such that those within each cluster are more similar to each other than to those in other clusters. The primary goal of clustering is to discover natural groupings in data without prior labels or classifications, enabling insights into the underlying structure and patterns within the dataset. It is widely used in various applications, including customer segmentation, image analysis, market research, and pattern recognition.",
      "categoryId": "abe90435-b123-4570-91c9-5d75aa6b1137",
      "subcategoryIds": [
        "bc53fbc6-c019-4b62-becd-16ed422f23d8",
        "042f419b-54c9-4711-8633-488e6294979d",
        "e264ddc2-a0de-4742-8eb4-91a3cd4277bb",
        "865c80d8-5cc3-4029-936e-fbdb08e91b02",
        "fdda88db-0674-4a5e-b0cb-9014581e4e8e",
        "541aad4a-35a1-432d-ae4c-26843636b5e3",
        "c8612c10-60dc-4db8-bded-00850bf7b373",
        "208d8ffb-7a0b-4c16-b21d-de16a9335b85",
        "52c6618e-9977-45e3-ae16-7b235c3e22bc"
      ]
    },
    {
      "id": "b1fbf337-7e2a-4b49-9ee3-55be5907d04f",
      "name": "Clustering Algorithms",
      "definition": "Clustering Algorithms are a category of unsupervised machine learning techniques used to group a set of objects or data points into clusters such that items within the same cluster are more similar to each other than to those in other clusters. The primary goal is to identify inherent structures or patterns in unlabeled data, facilitating insights, segmentation, and exploration without prior knowledge of class labels.",
      "categoryId": "7d85022d-32b0-458c-a129-1a17dbda756c",
      "subcategoryIds": [
        "9d2f3e56-4633-4bce-885c-c7c4ba54436e",
        "1cc1e149-22d4-41e5-bd7b-c4b5ad9d8557",
        "b8950a09-cb5c-40fc-a829-75e214d8fdf8",
        "5f8948ad-90da-4c3c-84e7-801a4576d36e",
        "687ed13b-6999-4c78-ae93-70a9f7d81fd5",
        "bb8df5f3-56c7-4ec8-bf9c-d1817f826bc5",
        "63f22431-663f-46a7-98c2-1d63542fa868",
        "0d08d81d-7a6b-460f-b601-43cddf97f3b1",
        "9dd8721c-205c-4a5f-a74c-0cac4e194aa4"
      ]
    },
    {
      "id": "359c9a16-9b30-4c2b-a707-dafc1a42f19a",
      "name": "Clustering Algorithms (e.g., K-means, Hierarchical Clustering)",
      "definition": "Clustering algorithms are a class of unsupervised machine learning techniques used to group a set of objects or data points into clusters based on their features and similarities. The goal is to ensure that data points within the same cluster are more similar to each other than to those in other clusters. Popular examples include K-means clustering, which partitions data into a predefined number of clusters by minimizing intra-cluster variance, and Hierarchical Clustering, which builds a hierarchy of clusters either through agglomerative (bottom-up) or divisive (top-down) methods.",
      "categoryId": "8ee2f9cb-ba78-418e-b60b-ca1be79782ed",
      "subcategoryIds": [
        "fc8a7abe-6acf-4142-ac6d-1bf30884d955",
        "0103c27a-c2f5-49ed-b839-ef1d4c941332",
        "a45cd777-5cca-4a5a-b5ae-3c92494bc17f",
        "ab6268ca-5396-4853-92c9-c497744d40f3",
        "beeb4d3a-b68c-4d31-a37e-2806566266b1",
        "592afb3a-c4a1-4350-a878-28cdc7fbd089",
        "e0c8f48c-4e58-4da4-ab11-a624f5fe92bd",
        "36a31f5f-d1dd-4080-bbe7-0141b94989f1",
        "92758e77-1193-43f6-88a4-b688616bda2e",
        "c8d074e9-e609-46d7-bbaa-fab49554703c"
      ]
    },
    {
      "id": "f314d263-4c4f-4a9b-a84e-bf9c7219b7f5",
      "name": "Clustering Evaluation Metrics (e.g., silhouette score, Davies-Bouldin index)",
      "definition": "Clustering evaluation metrics are quantitative measures used to assess the quality and effectiveness of clustering algorithms. They help determine how well the data has been grouped into clusters, especially when true labels are unknown. The silhouette score and Davies-Bouldin index are two widely used metrics that provide insights into the cohesion and separation of clusters, enabling comparison between different clustering results and parameter settings.",
      "categoryId": "6cecb1d1-4a3a-4cc4-b410-1763dcb9c8fd",
      "subcategoryIds": [
        "19f0f17e-5df4-40d4-8ecb-3e6e3ccb589f",
        "32f0e93d-9d9e-4a95-a41b-c98002b4daf7",
        "3a8632ac-6f87-4558-8494-bbd8fc07353f",
        "7bccd76a-29fc-42ef-953a-cef5bf2362b0",
        "ea9d7fab-ad80-42be-bcb8-980ffd467490",
        "5c4f0cc6-8152-4126-b56b-f6ae58550066",
        "673b060b-16a4-4310-a51b-09cdece78fd6"
      ]
    },
    {
      "id": "c4371843-6328-47b2-a097-ef1f51fb391e",
      "name": "Clustering Stability",
      "definition": "Clustering Stability refers to the consistency of clustering results when the clustering process is applied multiple times under varying conditions, such as different initializations, data perturbations, or parameter settings. It measures how reliably a clustering algorithm can produce similar groupings, indicating the robustness of the identified clusters to changes in data or algorithmic parameters. High stability suggests that the discovered groups are meaningful and not artifacts of random initialization or noise, while low stability may indicate unreliable or unstable clustering outcomes.",
      "categoryId": "98e00305-a0e6-470c-bcdb-5fc3d41529a1",
      "subcategoryIds": [
        "c6e4067c-0208-4f73-9821-7ceb49a961cf",
        "cfc1b2ee-b76f-4b1f-a461-6473083870c4",
        "4395ed62-ac70-42e6-8060-a9835831b667",
        "1ef2f444-705e-4afb-9970-5165a1464e61",
        "b724b6f2-0499-4a97-a038-26a028195d3d",
        "ca6cb50a-9e97-4ffa-8cc1-6c2faab41cb2",
        "07b34ee2-504c-4526-9bc0-3c4ce50c5345"
      ]
    },
    {
      "id": "8d238012-6878-4c1b-b5ee-1f8c94a9da9e",
      "name": "Emotion Generation",
      "definition": "Emotion Generation refers to the process by which artificial intelligence systems are designed to recognize, simulate, or produce human-like emotional responses. It involves leveraging algorithms and models to generate emotions that can influence interactions, decision-making, or content creation within AI systems. This capability aims to enhance human-AI interactions by making them more natural, empathetic, and engaging.",
      "categoryId": "68a64e29-b936-44d7-b45b-686e1894cb1a",
      "subcategoryIds": [
        "c30960f4-d8fa-41c1-aee5-abf02a4c0cce",
        "d60fdee6-d158-46a6-ae3a-176e9e8ab237",
        "426ce0dc-2742-46c2-a39f-a88204158289",
        "11a998f3-9e39-465e-a7cc-49f8e6bbc1c1",
        "d91c3f43-1766-414d-85f8-2a6875746748",
        "2a591f8e-c267-4e37-90eb-c6d823925d28",
        "2d93914f-caea-488f-aa54-b6db2b0103fe",
        "a4d95ab0-1183-496b-baaf-b72e5917fce5",
        "e11fe3cf-92ac-4312-8cc7-43aef753825e",
        "56c037c2-7a1b-487d-9e05-6bf58ab55df9"
      ]
    },
    {
      "id": "b8d7be9a-eae4-4f13-9147-f41ab777aae1",
      "name": "Emotion Modeling",
      "definition": "Emotion Modeling in AI/ML refers to the process of designing systems that can recognize, simulate, interpret, or respond to human emotions. It involves creating computational frameworks that can analyze emotional cues, such as facial expressions, vocal tones, physiological signals, or contextual data, to understand emotional states or generate appropriate emotional responses. This field aims to endow machines with the ability to interact more naturally and empathetically with humans, enhancing user experience and enabling applications across diverse domains.",
      "categoryId": "af0d3e9a-be4c-41d0-ae56-19261235ee12",
      "subcategoryIds": [
        "a699f8b5-6ad4-433f-9261-4cca96790dfe",
        "15e46ca8-0a0e-44cb-bf9c-e78cd72b042e",
        "8e420c94-9956-4ea9-bbfb-88a5af767448",
        "5b30f27a-6b64-4ef6-b6d0-0b7f41f44d11",
        "16828bab-507c-4d09-b7b9-3b397c8e04fb",
        "89333833-1b80-4470-a06e-0e96b50351a4",
        "07b51996-b5e4-4423-a316-04cba541047c",
        "e3489958-89d2-4ade-bc2f-d8f877278ec5",
        "81700b6f-7ea6-4ef6-b776-c344e17143d6",
        "35af1664-d291-4cde-84f7-9119e457df35"
      ]
    },
    {
      "id": "69424a06-dbec-4b0b-ae24-dc704f50d515",
      "name": "Emotion Recognition",
      "definition": "Emotion Recognition refers to the process by which AI systems identify, interpret, and classify human emotions from various data sources such as facial expressions, voice intonations, body language, and physiological signals. This technology aims to understand human emotional states in real-time or from recorded data, enabling more natural and effective human-computer interactions. It plays a crucial role in applications ranging from customer service to mental health monitoring, facilitating empathetic and context-aware AI systems.",
      "categoryId": "f01a4b2f-a392-4675-b2a9-612f06d647cf",
      "subcategoryIds": [
        "4febc8d0-f59b-4766-a717-1eec51d184ab",
        "4c5b5df0-39f9-4b75-958f-fb939142865c",
        "371b7378-6541-45b1-8c90-194b089f58c9",
        "1cdc1292-87f5-4857-bddc-0cdc2b59a659",
        "da9ff866-3e0b-4503-810f-25a36956937e",
        "0330b9d3-a608-46d5-a79c-9853dc95af60",
        "fc0d059b-e9df-4caf-8b1d-d8ae1734bec7",
        "dbfe71aa-2624-4e1b-83c0-f221238921ee"
      ]
    },
    {
      "id": "184a9f0c-da3d-464c-a173-8edf2a1d9064",
      "name": "Emotion-aware Machine Learning",
      "definition": "Emotion-aware Machine Learning refers to a subset of artificial intelligence systems designed to detect, interpret, and respond to human emotions. These systems utilize various data inputs such as facial expressions, voice tone, physiological signals, and textual cues to understand emotional states. The goal is to enhance human-computer interaction by enabling machines to recognize emotional context and adapt their responses accordingly, thereby creating more empathetic and effective communication channels.",
      "categoryId": "3b842afb-d83f-4bb8-a0e2-cf778b74a044",
      "subcategoryIds": [
        "ae31509d-ac7d-4197-b862-5e1e9fcd3af7",
        "66c66a96-c493-4001-b489-db926d491bc9",
        "ccddfa17-5915-42da-b102-b0a71649cae1",
        "32b3d0b1-fba2-4d80-bb16-f83be97387fe",
        "bbcb112d-c770-4546-90f2-2e340bf1c74a",
        "ca148e70-2ab7-4898-856f-37fcb1ce8757",
        "4f528423-1ab7-433a-a7fd-18edea54980d",
        "aa8127ea-e122-434a-b623-64f7f65f7d34"
      ]
    },
    {
      "id": "a4172da6-2e03-4c77-b30f-1e8d664ac18b",
      "name": "Emotion-Aware Text Generation",
      "definition": "Emotion-Aware Text Generation refers to the development of AI systems capable of producing written content that not only conveys factual information but also detects, interprets, and expresses human emotions effectively. These systems analyze emotional cues within input data\u2014such as tone, context, or explicit sentiment indicators\u2014and generate text that aligns with or appropriately responds to these emotional signals, enhancing human-computer interaction through more empathetic and contextually appropriate communication.",
      "categoryId": "4de95ba3-dedf-4233-98cb-8f7eb0c8058e",
      "subcategoryIds": [
        "99f7690e-21d1-4da2-b41d-a41f2ac31afd",
        "ac0a8876-6bcb-44e3-9514-659104b1f214",
        "66d43e66-04f9-4b88-aabd-f3cd1a96f80e",
        "44fa114f-8010-4216-9983-4d08be244b18",
        "1e5329ee-0ec6-4c28-b7ea-b86942895fb6",
        "03c03f36-d50f-4211-ab3c-bb17f785c2db",
        "a510988e-89aa-4ac6-9aa0-45ec13824106",
        "1d5b243a-6f7a-4c6e-8910-04c89844fe80"
      ]
    },
    {
      "id": "d1023d19-fe71-46de-9d00-7c34967bcae0",
      "name": "Emotional AI",
      "definition": "Emotional AI, also known as affective computing, refers to the branch of artificial intelligence focused on recognizing, interpreting, processing, and simulating human emotions. It aims to enable machines to understand and respond to human affective states in a manner that is contextually appropriate, thereby creating more natural and empathetic interactions between humans and technology.",
      "categoryId": "29e1619d-6ec8-4e59-8855-1a00917a9623",
      "subcategoryIds": [
        "e3962da4-1300-4f34-8e3b-47a37a8023d1",
        "26c0a0c6-3467-4ea5-b8b6-e43ef8a63a21",
        "f088a94c-2017-49a1-a260-077ae81e2bf6",
        "cc4f6344-7425-4cac-9019-3aa7cbd3daff",
        "8f94c2e7-19df-4dd3-bc27-d7b9cfd63b6d"
      ]
    },
    {
      "id": "3ea6da71-7646-4237-b067-f11d1d5ef000",
      "name": "Emotional Intelligence in AI",
      "definition": "Emotional Intelligence in AI refers to the development and integration of systems capable of recognizing, understanding, managing, and responding to human emotions. It involves designing AI models that can interpret emotional cues from speech, text, facial expressions, and physiological signals to facilitate more natural and effective human-AI interactions. Unlike traditional AI systems that operate purely on logical or statistical data, emotionally intelligent AI aims to emulate human-like emotional awareness to improve communication, empathy, and user experience across various applications.",
      "categoryId": "6e31bbb4-9129-425e-a193-4e07f430785c",
      "subcategoryIds": [
        "fade7797-fee8-422f-b1e6-b7f1d088bb33",
        "5b8ee6a6-bc8a-4cb9-890b-b41c11eaf327",
        "ebc8f970-f010-4199-bf8e-eb03f858811c",
        "637f03ec-a70f-49c3-9dfc-cee2e197211d",
        "3f3f650b-b336-4f06-84a3-88e12726cd4f",
        "a7cd762a-1717-456c-8be7-38ce3053735c",
        "c926deff-b9fa-47a1-9401-b3b079949943",
        "6c20f033-4275-40e6-8e08-2b3f60ceb638",
        "08087803-963e-48c8-9732-3472ce98dc48",
        "9d1b2a38-8707-486e-8eef-4adc14963b36"
      ]
    },
    {
      "id": "4dc7cf55-2b45-46f7-b178-a5f395e198fb",
      "name": "Empirical Bayes Regression",
      "definition": "Empirical Bayes Regression is an advanced statistical technique that combines elements of Bayesian inference and frequentist estimation to perform regression analysis. It leverages observed data to estimate prior distributions empirically, enabling more adaptive and data-driven modeling, particularly in contexts with multiple related regression problems or high-dimensional data. The approach typically involves estimating hyperparameters from the data and then using these estimates for Bayesian inference in the regression task, resulting in a blending of empirical data insights with Bayesian probabilistic modeling.",
      "categoryId": "96d4e364-7e9b-493c-a398-4b7d643efd9a",
      "subcategoryIds": [
        "3666559f-5b03-46ae-939b-144176baeb08",
        "af7be779-974a-4a87-bb20-0b56105583cb",
        "fd92ae92-3f11-4825-a870-6bd1c79b1d89",
        "04ac7dfb-4694-4109-ad2b-4bfdd386d262",
        "9d74fb0e-9ed5-42b0-aabf-c2174300d81a",
        "52a070e0-b289-471e-b6ad-f0a5c324b672",
        "abd66510-7357-4f12-82ae-9bd6c27e19ab"
      ]
    },
    {
      "id": "c4051066-faeb-495f-a40d-f5a2e2f7c227",
      "name": "empirical probability",
      "definition": "Empirical probability refers to the probability of an event determined by observed data or actual experiments rather than theoretical calculations. It is calculated by dividing the number of times an event occurs by the total number of trials or observations, providing an empirical measure based on real-world evidence. This concept is fundamental in statistics and data analysis, serving as a basis for understanding uncertain phenomena through observed frequencies rather than assumptions or models.",
      "categoryId": "745016eb-9726-4ddd-9c6b-84ab3e8b1332",
      "subcategoryIds": [
        "e5ef048c-22c7-4c54-a986-914ae090ae8e",
        "097ca210-50d1-468e-9108-fa0bbd506b0a",
        "55983dd0-add5-4f57-8cdc-d1fe0dde8906",
        "7bd25505-5235-4f56-9944-a47fe20d3e27",
        "aa66a5d1-24f4-4ade-9cf4-d2fd4e1319fa"
      ]
    },
    {
      "id": "bc7c098e-5e14-4e97-ac55-a762b1b92e5f",
      "name": "Empowerment",
      "definition": "In the context of AI/ML, 'Empowerment' refers to the process of enabling systems, algorithms, or human stakeholders to make informed decisions, exert control, and enhance their capabilities through data, tools, and intelligent automation. It emphasizes augmenting capacity and fostering autonomy, allowing users and AI systems to operate more effectively within complex environments. Empowerment in AI often involves developing models and interfaces that provide users with clear insights and actionable options, thus promoting confidence and independence in decision-making processes.",
      "categoryId": "fe214b9b-c980-497d-a515-3b8b3504d7d4",
      "subcategoryIds": [
        "6ca96e23-4c2b-4b39-a09e-e73a363d9d73",
        "78485ea6-3040-4a6c-af78-9235cd057813",
        "75894913-898b-49ed-9558-336c5ed8d948",
        "8e5f08cd-49bb-43d6-aace-9f36f494a0c0",
        "855286c2-eaa7-4375-9f05-20d1e31a69f1",
        "008418fb-3821-4b44-81a1-d1758b2581ca",
        "32ae5a5c-8272-4b6f-9cc4-3d87c7b461f3",
        "34049a2f-b4f3-42ea-98e4-c0d8e9c2ca65",
        "4620404f-bc4b-4503-8f94-93463698f030",
        "15fd29ed-fd8f-46e1-8f44-e213375fe4d8"
      ]
    },
    {
      "id": "a6912570-3994-4d14-b721-45bb1e1d90e9",
      "name": "Encoder",
      "definition": "An encoder in machine learning and deep learning is a component or model responsible for transforming raw data into a more suitable or condensed representation, often capturing the essential features of the input. It maps high-dimensional, complex data into a lower-dimensional space, facilitating easier processing and understanding by subsequent model components. Encoders are fundamental in various architectures, including autoencoders, transformers, and sequence models, serving as the mechanism to extract meaningful features from raw data such as text, images, or signals.",
      "categoryId": "78767fc3-5f08-4d3d-82b9-26db014a1c2e",
      "subcategoryIds": [
        "e9865c6c-190e-4c10-8bed-03d0bd8b6950",
        "e3e8314d-1d45-411d-ac22-aaa39e4018df",
        "9c6be5d4-0ed2-440c-8a89-f815f47f87fa",
        "8375b546-c377-4a06-93d1-11f8b2469fc7",
        "de1d620b-8237-426c-8b83-894cc70c6dcd",
        "1549a250-025f-4419-ac96-63d772f28f9f",
        "8b46e4ce-9e05-4640-bcd0-4da97cc9e767",
        "29790394-022f-415d-bf2c-c33a656a7e36",
        "9e2b1f1d-37f9-4ca7-885f-761fe24cee3e",
        "200b3221-dd3b-4115-9421-840d324924f5",
        "0b303d0e-bb27-4c8d-921d-6f85d0c901a3",
        "ab05053d-c80e-4060-9b94-18da8fca04ec",
        "80ddb6e8-c625-4c9c-a2ca-b48e9d8f99f5"
      ]
    },
    {
      "id": "bf63df1d-dcec-4b77-ab40-4644c25bd196",
      "name": "Encoder Attention",
      "definition": "Encoder Attention refers to a mechanism used within neural network architectures, particularly in sequence-to-sequence models, that allows the model to selectively focus on different parts of the input sequence during processing. It enables the encoder to dynamically weigh the importance of each input token or feature, improving the contextual understanding and feature extraction necessary for tasks such as translation, summarization, and other NLP applications. Essentially, Encoder Attention enhances the encoding process by emphasizing relevant input information, which is then utilized by subsequent decoder modules.",
      "categoryId": "b69a2d8b-dad1-443d-90ab-12b5f4027536",
      "subcategoryIds": [
        "f7a20f6b-aa87-484a-a2a8-d423b2343457",
        "fb9a39c0-971a-4c1f-974a-93502a323e74",
        "7aedb156-f980-4ac8-a09f-97c6cdada5b6",
        "8937450a-a929-468c-8aff-733af89e48e3",
        "c1e126a1-59b0-4d33-b742-fee2c18a8d5b",
        "2f98bd2a-f69d-4f2f-ae1a-53426b62eefa",
        "8e29bb18-e551-4d82-a280-9e700b7fa395",
        "87222f1a-646e-45db-985c-a8b621d36872"
      ]
    },
    {
      "id": "da7c95fc-3b35-4e6e-92b0-d43273d5133b",
      "name": "Encoder-Decoder Architecture",
      "definition": "The Encoder-Decoder Architecture is a neural network framework primarily used for sequence-to-sequence tasks, where an input sequence is transformed into an output sequence. This architecture consists of two main components: the encoder, which processes and encodes the input data into a fixed-dimensional context vector or a series of hidden states; and the decoder, which generates the output sequence based on this encoded representation. It is widely used in applications such as machine translation, text summarization, and speech recognition, enabling models to handle variable-length sequences effectively.",
      "categoryId": "ea83ce7d-9872-4d79-a642-9bcc96b2a786",
      "subcategoryIds": [
        "3b035db3-5a91-4941-87cc-4373ff0c9b6a",
        "c23821af-08d2-403a-b806-33120a179ce5",
        "38bce737-1734-4f0c-a23f-c7c67a079d24",
        "faea4126-e09c-4591-94cd-41d77d62c539",
        "def610bf-33cd-419e-bd30-b03423054c3b",
        "24a70a24-ee7e-451c-823a-dfc320e65b38",
        "8ce017b2-ea8f-4fe1-b29e-d2940339f92a"
      ]
    },
    {
      "id": "1e9ad87f-8a84-491c-bbd6-b353971152cd",
      "name": "Encoder-Decoder Models",
      "definition": "Encoder-Decoder Models are a specialized class of neural network architectures designed to process input data into a different form or representation, often for tasks involving complex transformations such as language translation, image captioning, and sequence-to-sequence prediction. These models consist of two main components: the encoder, which converts the input into a fixed-length or variable-length internal representation, and the decoder, which generates the output from this representation. This setup enables flexible handling of structured input and output data, especially when the input and output differ in length or format.",
      "categoryId": "fe9d572f-1680-4948-a970-90fc6c37aaa4",
      "subcategoryIds": [
        "29a10da7-5d93-444e-aa0d-2a3b1c6d942d",
        "e692687c-38e1-4dc3-b3d2-02c08a432dba",
        "77325037-85d6-4770-b0ee-3bf8d8525f63",
        "0893c8be-0ad5-4097-ab56-f44a09f565a7",
        "fe6c8da4-32e4-4dd8-aae1-43df40ddae8f",
        "78005868-52b7-47e2-a012-9d588fb4f192",
        "e3ac7a70-9943-4b71-8a04-f5bc963a80d7",
        "895df966-878c-4076-8065-162b5f1b8086",
        "f854bf68-48f9-478b-b4a6-d356c72f148d",
        "0c8c973e-382b-4f9f-9fab-f9fdb694c435"
      ]
    },
    {
      "id": "0c7a7f12-da55-4a9d-897f-9acdb4208ebd",
      "name": "Encoder-Decoder Models Extensions",
      "definition": "Encoder-Decoder Models Extensions refer to advanced modifications and enhancements of traditional encoder-decoder architectures used in neural networks. These extensions aim to improve the models' ability to handle complex tasks such as sequence-to-sequence learning, language translation, and image captioning by incorporating additional mechanisms like attention, multi-head attention, pointer networks, and hierarchical encoding. They build upon the foundational encoder-decoder framework to address limitations such as fixed context size and to enable more flexible, accurate, and efficient data processing.",
      "categoryId": "bad8c175-0ed7-4251-8c3b-27626f157f7d",
      "subcategoryIds": [
        "819dd03c-947e-4aa8-b8c9-71b34e783f03",
        "fd5a43cc-9501-493b-bde8-9b3c5c2cba5b",
        "cd97d907-eff2-487c-8eed-94a6268bb50d",
        "e95251f3-179f-41dc-88ca-74bcc3a14616",
        "ffa9d99d-cc45-4e78-bcb4-4ea0e0ef5428",
        "aab479aa-f030-4a7c-9462-167168e2b95e",
        "82ba991b-2542-4598-bc16-e6d60eafb178",
        "6886072f-f7fb-430b-b700-d5515af9d730",
        "c446b584-ede1-4619-bc76-dff7a2c1caa5",
        "137763cc-6deb-4543-8b8e-66acaa374ca0"
      ]
    },
    {
      "id": "16fd5616-0a92-4f13-971b-0566bc0ef2ef",
      "name": "Encoder-Decoder Models Extensions Extensions",
      "definition": "Encoder-Decoder Models Extensions refer to advanced architectures and modifications built upon basic encoder-decoder frameworks used in neural network models. These extensions aim to enhance functionality, efficiency, and performance in various sequence-to-sequence tasks such as machine translation, speech recognition, and image captioning. By integrating techniques like attention mechanisms, multi-head attention, or hierarchical structures, these extensions improve the model's ability to capture complex dependencies and context within data, thereby expanding the capabilities of standard encoder-decoder systems.",
      "categoryId": "a5638ce6-55a8-4763-a612-7f8551cb8cac",
      "subcategoryIds": [
        "f593830e-ed06-4ac9-90e1-cddef817464b",
        "bd2dfdef-4542-4406-bab4-e5e64e4f4d96",
        "15bc7bae-5471-40c3-8c34-5e5e0b6562c0",
        "98f6ac63-4246-43c0-bf53-2a1b5df80b16",
        "e87cf46e-bbe9-4bb8-87d9-823b945ab660",
        "1171fd80-4eeb-41cf-acfd-cc28dfdbec74",
        "011ca329-154a-49c2-b424-920bc2b63ce4",
        "1becdea2-b85e-4858-9c30-62ecad349e78",
        "7b0320af-58a8-4973-bac1-b84a3397b5ef",
        "a55d22b4-a269-44a6-ad3f-41c4c48f823b",
        "f3ef92a3-ca60-4160-bdc2-ef358f74b237",
        "d28ba8f9-8f14-4d5c-b668-0a74e7143d12",
        "ff262723-2db8-4992-9927-cfcfc95c9104",
        "98fab91a-6730-4c23-a561-4681ffece846"
      ]
    },
    {
      "id": "80298932-9293-4c46-a6f5-b473b59ae630",
      "name": "Encoder-Decoder Models Extensions Extensions Techniques Enhancements Techniques",
      "definition": "Encoder-Decoder Models Extensions Techniques Enhancements Techniques refer to a range of advanced methods and modifications applied to the core encoder-decoder architecture commonly used in sequence-to-sequence tasks. These extensions aim to improve model performance, efficiency, and capability by incorporating additional mechanisms such as attention mechanisms, multi-head attention, transformer architectures, and other optimization strategies. They facilitate better encoding of input data and more effective decoding to generate accurate and contextually relevant outputs across various AI and machine learning applications.",
      "categoryId": "0aa60663-e0b4-4ef5-ae64-3c483f7afd5a",
      "subcategoryIds": [
        "2ca07b30-9749-4aac-8ecd-4f57fe17e8b8",
        "89fb0bdb-5de2-4c87-a398-0471cf3c6d91",
        "d56badd9-cc5b-49b5-ae7c-fbb8196ba539",
        "8c6c9bb8-dddd-42bb-bca4-b1919845288d",
        "a13a6cb3-4ebb-403c-8ffa-ca671135a29c",
        "5b6cf733-dc2d-4e3c-9a58-e8df159e40a2",
        "8c771e9b-6291-48ea-b985-297929bd06cd",
        "d8b17b6f-81d6-4f1a-9dd1-249bd3fd0f55",
        "165a845f-d4b7-496a-9a40-21c116c29baa",
        "f28e3868-c2a6-426a-a551-2ecf172792da",
        "823ea39e-bdb8-4c45-a5e3-5043f5eb430f",
        "ccb10daa-e940-42fd-987b-e8163501e55d",
        "1ee0b00b-2c49-47d0-9ace-44426f3c0555"
      ]
    },
    {
      "id": "001f0d65-df22-4844-b6a3-2d951e405b61",
      "name": "Encoder-Decoder Models Extensions Techniques",
      "definition": "Encoder-Decoder Models Extensions Techniques refer to a collection of methods and architectural modifications designed to enhance the capabilities, efficiency, and flexibility of encoder-decoder frameworks in machine learning. These techniques aim to improve the performance of sequence-to-sequence tasks such as machine translation, speech recognition, and image captioning by extending the basic encoder-decoder architecture with mechanisms like attention, residual connections, multi-head attention, and hierarchical encodings. They often address limitations related to handling long sequences, capturing complex dependencies, and improving model interpretability.",
      "categoryId": "2001811c-9dd3-4342-a62e-f433016eeae7",
      "subcategoryIds": [
        "ce86662e-0a01-46bf-a1d7-1e64a0a09900",
        "6154820b-a937-4b3d-aac6-fb21e80d979a",
        "354e8c0c-8816-48de-83ee-20d438f3c5f2",
        "ed22d86d-dd5e-4817-9c2b-04d4c7d94f57",
        "a6dda84c-0410-452e-b087-2bdce95f07bd",
        "5e4916c1-a4b6-4cbb-918f-a7b388dbd906",
        "77a5c419-b7c4-41a0-8c01-bddf1909fd48",
        "b403158a-75fd-4c30-9cf9-a893abc28b1a",
        "2fead34f-2e3e-4f4d-8d30-4b458433aed3",
        "c21032c2-3d12-4eda-a762-b31e1e98d6a2"
      ]
    },
    {
      "id": "81a8da60-542a-4bda-815f-d89e1ed72e66",
      "name": "Encoder-decoder pretraining",
      "definition": "Encoder-decoder pretraining is a training paradigm in machine learning where models are trained to understand and generate sequential data by first learning to encode input information into a meaningful internal representation and then decode that representation into a desired output. This approach is often used in natural language processing (NLP) and other sequence modeling tasks, enabling models to perform complex transformations such as translation, summarization, and question answering. During pretraining, the model learns general language understanding or feature extraction which can be later fine-tuned for specific tasks.",
      "categoryId": "24247e7a-85ff-412c-9af4-b043791f7c88",
      "subcategoryIds": [
        "2b6dfac6-ab22-46c3-b115-7de3765f88d8",
        "75e67b17-c989-43c5-b5b9-7251aaab2d28",
        "993583eb-5eaf-42f4-a6a1-af0df03b4b4a",
        "6ca16b0e-0092-4641-a965-1eb8fe569665",
        "a1b1f1b1-a66c-431b-af1a-8ebf06d031b6",
        "47a93d70-9007-4d6d-b2bf-e4665bd6073b",
        "4e65928d-6bd9-4e81-bfc5-0dbfbea7fd67",
        "b8a70357-697b-40bd-bb4c-a2e2315074d3",
        "fc103e43-ad6c-4f5e-820e-a731db766fa4",
        "f67a05a4-82e5-439b-ad9a-49f7b11ca373"
      ]
    },
    {
      "id": "13a4fc9a-c49b-4091-af6e-4efcc7191139",
      "name": "Encoding",
      "definition": "In the context of AI and machine learning, 'Encoding' refers to the process of converting data, information, or features into a particular format or representation that can be efficiently processed by algorithms. This transformation often involves translating categorical or textual data into numerical formats or compressing data to reduce its complexity while preserving essential information. Encoding is a fundamental step in data preprocessing, enabling models to interpret and learn from diverse types of data effectively.",
      "categoryId": "f14cce6a-073b-45c1-b7fe-9e7538a2a4d2",
      "subcategoryIds": [
        "6a5b2dea-a6ce-4294-bcd3-86a551f827aa",
        "67b67c62-14d2-4a9f-941d-c601e1043abd",
        "3e20c048-79bf-4880-9cbf-129f5301e007",
        "0e367078-d3e0-41d5-b281-f8801fefdebe",
        "623945e5-9edb-4f55-b6bf-3e01fbc38fc7",
        "0b24dbf9-f422-4bf6-83f2-c47d35a6b4a0",
        "a63179e7-8d3d-49f4-b62e-ce3c85172177",
        "15f50c05-15b9-489f-b484-14e8eb90e4f5"
      ]
    },
    {
      "id": "acee26d1-ed9d-4b01-8c4f-38fbfe982003",
      "name": "End-to-End Dialogue Systems",
      "definition": "End-to-End Dialogue Systems are sophisticated artificial intelligence systems designed to facilitate natural, coherent, and contextually relevant conversations with users, typically through natural language processing (NLP). These systems handle the entire dialogue process from user input to response generation within a unified framework, minimizing the need for manual feature engineering or modular pipeline components. They aim to produce human-like interactions by integrating various AI components such as language understanding, context management, and response generation into a seamless, end-to-end trainable model.",
      "categoryId": "a7f77665-b31f-4cf7-b129-008639037452",
      "subcategoryIds": [
        "f26c6243-5815-4f4e-83c2-097dc7681de9",
        "aaab80a2-cc1f-4e8c-b022-a2932b7a1f68",
        "4b9973ff-b9ba-4665-96c0-fa06b72c9141",
        "a68af72d-d19e-44ec-981e-143b8b7a3a31",
        "e799d799-21aa-4dc2-9b2b-269521016211",
        "86d834d7-8223-451b-a6c3-ec9d101f8ee2",
        "7070bc34-0c5b-40e7-8693-6777922ef12b",
        "3d5a0e4d-7c2f-4537-8e65-3a4142455a56",
        "013773e9-a181-4cc2-81cc-2bb221923492",
        "34c9f827-db91-4c5c-9d8f-b1ce3c8eac9d"
      ]
    },
    {
      "id": "85e46149-35c7-457d-a681-4baf22022b50",
      "name": "energy-based distillation",
      "definition": "Energy-based distillation is a machine learning technique that involves leveraging energy functions or energy landscapes to guide the process of model compression, transfer learning, or knowledge distillation. It derives its name from the concept of using energy metrics to evaluate and optimize the transfer of information from a teacher model to a student model, aiming to improve the efficiency and effectiveness of the distillation process by framing it within an energy minimization paradigm.",
      "categoryId": "348a13c1-41bd-4413-8ce0-a4ad78c0358e",
      "subcategoryIds": [
        "89668d7b-c6ea-45bf-84af-7172196e5126",
        "25f645bf-3041-4d4b-837c-6ab1f7aa1247",
        "6abdc6d7-b16f-47e5-9d29-5d38b80ac18e",
        "8304dea8-d06f-4a6d-81d9-30722ae5e475",
        "03f371dd-889f-422d-a7db-9bac3bf51288",
        "e27eb7ec-5079-43b5-b652-c048e10c31f5",
        "daf11e75-153a-441e-900e-f27c7e02405e"
      ]
    },
    {
      "id": "ec286bb6-55ef-4de0-b451-5fbafc92a054",
      "name": "Energy-Based GANs (EBGANs)",
      "definition": "Energy-Based Generative Adversarial Networks (EBGANs) are a class of generative models that utilize an energy function to guide the training process. Unlike traditional GANs, which rely on a discriminator to classify real versus fake data, EBGANs employ an energy function as a measure of data authenticity, where lower energy indicates closer resemblance to real data. The generator aims to produce samples that minimize the energy, effectively learning the data distribution by training with a simple autoencoder as the energy function.",
      "categoryId": "85e0dc26-c36b-4187-a352-67187084ef8c",
      "subcategoryIds": [
        "2ffc5892-ae3f-42b9-bd73-f94ae8b1cd22",
        "4a91271a-f92e-4e96-9d38-bbb2ebdde845",
        "24910d18-2f86-4e3f-b700-e2557b98c1fa",
        "76ca6724-894b-44e9-bfb0-36f39a63ae0f",
        "efb1a6fc-adf7-4f9e-97a6-eee1dea9264a",
        "3ec78f1c-e094-4cad-8de8-3082089242b6",
        "93d5253d-63ec-4f6a-a4b9-a8d734a32b83",
        "f02e9194-82a4-4e61-b3d4-c4774a74d8a7"
      ]
    },
    {
      "id": "3c7c3ef3-9ec8-416b-a1cc-b811d543b1da",
      "name": "Energy-Based Models",
      "definition": "Energy-Based Models (EBMs) are a class of probabilistic models in machine learning that define a scalar energy function over data points or configurations. The core idea is that data points with low energy values are more likely or preferable, while those with high energy are less likely. Unlike traditional probabilistic models that explicitly specify probability distributions, EBMs focus on learning an energy function such that the probability of a data point is proportional to the exponential of the negative energy. EBMs can be used for tasks such as density estimation, generative modeling, classification, and reinforcement learning by leveraging the energy landscape to represent complex data distributions.",
      "categoryId": "7ffdbcb8-700c-4730-aaba-29a5fc49d37f",
      "subcategoryIds": [
        "74a16e7c-e562-4710-b68f-92cb8086890d",
        "0ed6a6be-30f0-411b-a2bd-6f31644c1aa0",
        "c05c4aea-0360-4866-9d4b-1e0db874c142",
        "c5516522-8813-4dbf-8f1c-3c8595553ada",
        "4c3cbc87-c948-4c10-98e5-1778def5d2b3",
        "4043dec8-0796-440e-88bf-e645a281e2f9",
        "83a94af6-6319-41df-94e2-ce97781b516f",
        "366a70da-8bf7-4f3d-80c9-4c2ed31dff36",
        "278410f0-5945-4a2b-b4ad-cf33c6eb729d",
        "97512588-b103-4f2e-b6a9-4609470135e5"
      ]
    },
    {
      "id": "c76a1961-c1e5-4470-9089-0edf699a0d6a",
      "name": "Energy-Based Models (EBMs)",
      "definition": "Energy-Based Models (EBMs) are a class of probabilistic models in machine learning that define a scalar energy function over input configurations, where lower energy indicates higher likelihood. Instead of explicitly modeling probability distributions directly, EBMs assign energy values to data points and learn to assign low energies to observed data while assigning higher energies to unlikely configurations. This approach enables modeling complex data distributions and facilitates tasks such as density estimation, generative modeling, and unsupervised learning.",
      "categoryId": "c48babb1-acda-4625-9709-8bc8d7bf9bd0",
      "subcategoryIds": [
        "ee91132d-ffff-418e-a836-e6fde9a647d4",
        "c1995e9a-26a4-4b6b-9424-8d8c49060574",
        "e4d4942c-28ee-4586-8cc4-7adc9869b81f",
        "af62d2b9-d675-42a1-8ba7-20dd74705dd1",
        "a2dfa327-ec4a-4801-9194-a0985c352217",
        "41742abe-8b2d-4ad3-8c70-8a8f98483742",
        "5dbd11e1-e007-40bd-bd7d-b64e423298bb",
        "9911252b-7a83-406e-b367-83d08b734130",
        "3df0595b-8430-4484-9ac7-7aab0ab88546",
        "8ba79ca6-4657-4950-9b89-6ce0a1be5421"
      ]
    },
    {
      "id": "433f5c60-ac09-4494-82b8-f4d5c6c5cb52",
      "name": "Energy-Based Models Extensions",
      "definition": "Energy-Based Models Extensions refer to the advanced variations and adaptations of fundamental energy-based models (EBMs) in machine learning. EBMs are a class of probabilistic models that associate an energy value with each configuration of variables, where lower energies correspond to more probable configurations. Extensions of these models incorporate new architectures, training techniques, and applications that build upon the core principles of EBMs, aiming to improve their expressiveness, efficiency, and practicality in various tasks such as generation, classification, and representation learning.",
      "categoryId": "073242ce-b826-433d-a4b1-60144b3c102d",
      "subcategoryIds": [
        "e39c6b90-85c3-43ea-a912-72ae7ac72605",
        "74f04ed2-f3ce-4d5e-a9c8-81ec68c0c544",
        "16598f33-5b9a-45a0-a668-d4172c68ad2e",
        "e06ecb0a-194b-41db-82d9-086144c239cd",
        "afd99f9d-f7b2-420d-842e-25a372550a67",
        "c2bd6404-7d98-4930-a29c-5ca6602a3544",
        "58d3d088-2794-40b0-ab1c-c9a37537b794",
        "741aa725-0359-461f-be29-73d4ceccd60e"
      ]
    },
    {
      "id": "c18ad1bf-b2aa-4782-b306-612c2658d462",
      "name": "Energy-Based Reinforcement Learning",
      "definition": "Energy-Based Reinforcement Learning (EBRL) is an approach that integrates principles from energy-based models into the reinforcement learning framework. It conceptualizes the agent's goal as minimizing or managing an energy function associated with states and actions, enabling the system to learn policies that prefer low-energy configurations which correspond to desirable or optimal behaviors. This paradigm often involves defining an energy landscape where policy optimization is achieved through energy minimization, facilitating more flexible and expressive representations of complex decision-making tasks in environments with high-dimensional or structured data.",
      "categoryId": "4ada477a-e788-4c6d-80e5-d6ec17091d8f",
      "subcategoryIds": [
        "122c199a-5a13-4aae-83a2-9297791b9ed6",
        "63a150dd-e220-46b1-9df1-150ec75628eb",
        "5e7df18a-a501-417d-b4e4-21062921a814",
        "dc949e6d-4ab5-4250-b5f8-edee67b1b77a",
        "96bb374a-90f5-402b-a96c-7c46ce7a153a",
        "051cd1f7-5990-450e-9271-620f7c33388a",
        "d9d79c50-53e9-47fb-a3d2-4d6bbcf4cf91"
      ]
    },
    {
      "id": "447003d6-7ec5-4554-aacd-d4255664001f",
      "name": "Ensemble Averaging",
      "definition": "Ensemble Averaging is a statistical technique in machine learning where predictions from multiple models or multiple instances of a model are combined by averaging their outputs. This approach aims to enhance prediction accuracy and stability by reducing the variance associated with individual models, thereby producing a more robust and reliable estimate of the target variable or class.",
      "categoryId": "f0152ff9-bc55-45ab-a823-876d73f66be1",
      "subcategoryIds": [
        "8c3fb1d1-b819-494a-8b90-6e9a1c845132",
        "afd00e68-40e8-4d28-a955-3f1294a1fb25",
        "f346a992-32b6-4e46-948d-0e1ad96e45cd",
        "04a6b3d8-395b-4606-ad0d-11b234ee6219",
        "73cc6634-6fd8-4fee-bfdd-6d94897cc7d7",
        "0950964c-0dee-4558-8ec2-fa14a1f625f6",
        "ef189b0c-80a6-4884-99a1-506258fa2a01",
        "316495af-7845-489b-8408-ebd3aea984d9",
        "36f8d332-1a0d-4757-b717-7206b4f7cc4c",
        "77112380-13ae-4a14-b64b-46935ef66ed4"
      ]
    },
    {
      "id": "72f0b5d8-178b-4bd2-81a1-43215a70c0b9",
      "name": "ensemble distillation",
      "definition": "Ensemble distillation is a machine learning technique that involves transferring the collective knowledge of an ensemble of models into a single, compact model. By doing so, it aims to combine the high accuracy and robustness of ensembles with the efficiency and simplicity of a single model, typically through a process known as knowledge distillation. In essence, ensemble distillation involves training a single model (the student) to replicate the predictions of an ensemble (the teacher), thereby capturing the ensemble\u2019s performance while reducing computational complexity.",
      "categoryId": "36912372-b061-4b9d-8426-7654ac27ae37",
      "subcategoryIds": [
        "fb40d526-152d-4c70-b43b-b184291f84ab",
        "54ee4a58-fa86-4686-9ff3-ae654ad721ba",
        "47dbc55c-c28f-4f6a-bef1-694006e56fbb",
        "4c1c3923-d113-4103-8612-d6e188d55e32",
        "99577fc2-8d1e-40fb-9330-3a1e954f171c",
        "ab5bfb9a-1859-458e-a573-43686564d2af",
        "2722e7e9-f578-45d3-9fa2-42744e62638d",
        "509d4bbe-40e3-44c6-b733-0e70b775c378",
        "18452f6e-12a7-42e5-b950-a19cb4732df3",
        "c65e8e15-872b-4f84-8767-5c17ca6c5c28"
      ]
    },
    {
      "id": "f2ff07fe-1d06-4c21-a7b9-5856d1207b77",
      "name": "Ensemble Diversity",
      "definition": "Ensemble Diversity refers to the measure of variability or difference among the individual models within an ensemble method in machine learning. It quantifies how distinct the predictions of the constituent models are, which is crucial because higher diversity among models generally leads to better ensemble performance by reducing correlated errors and improving generalization. Ensemble methods, such as Random Forests or Boosting, leverage diversity to combine the strengths of multiple models, thus enhancing overall prediction accuracy and robustness.",
      "categoryId": "e1ae4119-a579-4651-a75a-35ee0178ffd5",
      "subcategoryIds": [
        "1088087c-7c6d-4dd5-b8f3-26f2290e23d8",
        "3609ab40-a53f-4507-93d7-84e0503a7340",
        "a7af6de4-4ea1-47f3-bcd3-fd85e33515b9",
        "66365281-2c25-4fac-9389-451066e31c07",
        "26747c2c-719b-4f80-b3fb-e59efab19851",
        "8f619c02-2910-483e-b530-5567b9803167",
        "98b7628e-733c-407d-9d6e-a3b79baf79a0",
        "74f26e55-c192-421b-a0be-126a18841c64",
        "bc1b5d2a-4514-4656-8be8-42412316251a",
        "aae86531-d8e1-4539-a270-944ba03e2b00",
        "affe7014-5dc1-4caf-bb92-d8b2dfff1f81",
        "edd78864-aaad-40d3-b4f5-7308c7293081"
      ]
    },
    {
      "id": "b76f9bb4-dc0d-4122-93c5-851d8b91aee7",
      "name": "Ensemble Diversity Techniques",
      "definition": "Ensemble Diversity Techniques refer to methods that aim to increase the diversity among individual models within an ensemble. These techniques are designed to ensure that models make different errors or predictions, thereby enabling the ensemble to benefit from their varied perspectives. By promoting diversity, ensemble methods can improve overall predictive performance, robustness, and generalization capabilities beyond what individual models can achieve alone.",
      "categoryId": "1cdf390f-d4d8-498d-8fb8-9d22d378fec4",
      "subcategoryIds": [
        "0ff7bcf5-7a0f-4fdc-bafc-328c6a3b3cd3",
        "a9cd3916-74da-43fc-b286-7f531a235ac7",
        "ed87ac22-cd78-40c6-aa56-559af724050b",
        "3458feb1-335c-4ea3-b183-9038ce92d7bd",
        "aefa32ec-6d81-45f8-8c2e-fc6db9fb9617",
        "0ef472e7-0e8f-40f4-a52d-404a3d7327db",
        "01394948-db81-4980-9a22-b8eb7547aa9c",
        "b7873e2d-2a24-4285-a265-3d08be88feea",
        "c443cb1b-b0e2-4a55-b231-8a3cd59517a8",
        "fed98d24-5a39-42d7-a736-accca5548a00",
        "478e7efd-328b-4ad8-bf8d-5e56add18d92",
        "f1ab8f46-c829-4020-b583-4120e7e8b063"
      ]
    },
    {
      "id": "43654e56-0d47-47c5-a314-1ff5101e8c27",
      "name": "Ensemble Diversity Techniques Extensions",
      "definition": "Ensemble Diversity Techniques Extensions refer to advanced methods and strategies used to enhance the diversity within ensemble learning models. Ensemble learning combines multiple models, such as classifiers or regressors, to improve overall performance and robustness. These extensions specifically focus on promoting diversity among the individual models to reduce correlation and errors, leading to more accurate and reliable ensemble predictions. Techniques include various methods for encouraging varied model behaviors, such as specialized training procedures, data manipulation strategies, and model architecture modifications, tailored to extend or improve upon traditional diversity techniques.",
      "categoryId": "c95a51f5-d135-4cab-b941-31ed73daf6e6",
      "subcategoryIds": [
        "50cb9faf-29ab-4859-95a3-b66693183d16",
        "fd5c37a7-b224-470e-b509-4127d1b01c39",
        "47e358fc-6e36-4c20-8227-44e8a7990458",
        "5958c35f-8ceb-4838-a69a-5861bc46bd5a",
        "5f4004a0-010b-4222-8f78-63e18a8d855d",
        "bdf48c9a-20f0-4294-a9bf-36394d3657ab",
        "1d63cb00-12c0-4d54-900b-cff93a93578a",
        "3e89f1c3-bb92-4855-901f-0b3867c6f678",
        "23668e3a-0cc7-4ae5-bcfa-8e9a1e4f6c96",
        "be1406af-9293-47e6-8482-5abf16bedc3d",
        "7c235db4-a9ec-4822-8acd-77be71d414a9",
        "550e655b-27c8-490b-b00f-07315aca437a",
        "c2bfb4cc-3a23-4c43-927c-6d07f17ad54e",
        "6245cc63-6b95-44ad-9536-0fdcaa376f79"
      ]
    },
    {
      "id": "2069fd88-858b-424e-a858-e1f4518d16ce",
      "name": "Ensemble Gradient Boosting",
      "definition": "Ensemble Gradient Boosting is a machine learning technique that combines multiple weak learners, typically decision trees, to produce a strong predictive model. It builds an ensemble sequentially, where each subsequent model attempts to correct the errors of the combined preceding models, utilizing gradient descent techniques to optimize model performance. This approach enhances prediction accuracy, robustness, and generalization capabilities compared to individual models.",
      "categoryId": "eac19e39-8d2a-42bd-b373-3e273a6ffca1",
      "subcategoryIds": [
        "8a256791-dde4-452f-bcc2-07828b865c2e",
        "5e324462-71c6-4b5e-a786-bef793924399",
        "fd31db18-0a5b-4e05-986d-f88196079f87",
        "05f808c8-e6ce-4f8f-9c36-a95e2da7de2a",
        "10ef95e7-686f-481a-97f2-9c6261db95b5"
      ]
    },
    {
      "id": "d1ae6504-1d92-4293-b958-35835fc16c0a",
      "name": "Fisher Information",
      "definition": "Fisher Information is a fundamental concept in statistical estimation theory, quantifying the amount of information that an observable random variable carries about an unknown parameter upon which the probability depends. It is mathematically defined as the expected value of the squared score, which is the gradient of the log-likelihood function with respect to the parameter. Essentially, Fisher Information measures the sensitivity of the likelihood function to changes in the parameter, providing insights into the precision with which the parameter can be estimated from data.",
      "categoryId": "f8ae95b2-95e4-4eab-ae95-6d5cfb679aaa",
      "subcategoryIds": [
        "6258d52c-ae0e-4e59-a729-49015aea6e81",
        "87d50543-ddcd-4ca5-a252-aa014635f0d3",
        "ef7c2cf0-0f0d-4c53-8d4b-722e4d73b042",
        "421b5e84-b554-46b5-b8d9-decf25f6f247",
        "a91202d1-486f-448f-8fc1-7cf3f27dc7c3",
        "c9750481-ee88-4edc-a9b0-51a829d51420",
        "132e7388-603b-4f43-9955-131312fd5219",
        "fca23da8-1b28-4960-8ac5-1ca51e48b4c0",
        "675a9e63-9e7d-427d-9c91-18639c775ff3",
        "fec24241-1cf1-436f-8ace-7f4982ce0795"
      ]
    },
    {
      "id": "34b50d76-534d-4237-afd9-b177ec1eea86",
      "name": "Fisher Information Matrix",
      "definition": "The Fisher Information Matrix (FIM) is a fundamental concept in statistics and information theory that quantifies the amount of information that an observable random variable carries about unknown parameters upon which the probability depends. Mathematically, it is a matrix of second-order partial derivatives of the log-likelihood function with respect to the parameters, representing the curvature of the likelihood surface. In the context of AI and Machine Learning, the FIM is used to analyze parameter estimability, optimize training processes, and understand model sensitivity.",
      "categoryId": "4ede7644-9540-41a6-b14d-731552eef08a",
      "subcategoryIds": [
        "6564937e-9f53-4ec5-9b0d-e82bd45a5831",
        "d4d87c07-a726-4c49-ba40-9bf07075987f",
        "7d602303-93c7-48fa-a4f2-e37886d50c51",
        "196068bd-8b8c-481a-b51e-f3f43f087fdd",
        "08493c80-7a11-4dd1-8fe8-d28497e936e7",
        "11b33a4b-c137-421c-92ef-6487beb7de47",
        "ad063f80-45a2-446c-90e2-06f40fd02638",
        "1850ea8b-bb33-4276-b4b2-d7ed194e458c",
        "506530c7-1da9-4595-b95a-d60cfc2fe42d",
        "0602b104-ba5d-4762-a504-12200bd2ac6b"
      ]
    }
  ]
}