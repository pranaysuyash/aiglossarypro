/**
 * Test script for chunked import functionality with large dataset
 */

import { chunkedImportLatestProcessedFile } from './server/chunkedImporter';

async function testChunkedImport() {
  console.log('üß™ Testing chunked import functionality with large dataset...');
  
  try {
    // Test with the chunked importer for the large 1.1GB file
    const result = await chunkedImportLatestProcessedFile({
      chunkSize: 500, // Process 500 items per chunk
      skipExisting: true,
      enableProgress: true
    });
    
    if (result.success) {
      console.log('‚úÖ Chunked import test successful!');
      console.log(`üìä Results:`);
      console.log(`   üìÇ Categories: ${result.imported.categories}`);
      console.log(`   üìã Subcategories: ${result.imported.subcategories}`);
      console.log(`   üìÑ Terms: ${result.imported.terms}`);
      console.log(`   üîÑ Chunks processed: ${result.chunksProcessed}`);
      console.log(`   ‚è±Ô∏è  Duration: ${(result.duration / 1000).toFixed(2)}s`);
      
      if (result.errors.length > 0) {
        console.log(`‚ö†Ô∏è  Errors encountered: ${result.errors.length}`);
        console.log('First 5 errors:', result.errors.slice(0, 5));
      }
    } else {
      console.error('‚ùå Chunked import failed');
      console.error('Errors:', result.errors);
    }
    
  } catch (error) {
    console.error('‚ùå Test failed:', error);
  }
}

// Run the test
testChunkedImport().catch(console.error); 